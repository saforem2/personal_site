---
title: "ðŸŽ° Deterministic `flash-attn`"
toc: true
date: 2024-06-17
date-modified: last-modified
format:
  html: default
 # ipynb: default
  gfm:
    output-file: "deterministic-flash-attn.md"
categories:
  - AuroraGPT
---


<!-- ::: {.callout-tip icon="false" title="ðŸ“’ [W\&B Report](https://api.wandb.ai/links/aurora_gpt/nqjjhzd5)" collapse="true" style="width:100%;background-color: rgba(0,0,0,0.0);border:1px solid rgba(131,131,131,0.2)!important;"} -->

> \[**NOTE**\]: For additional details, refer to the [W\&B Report](https://api.wandb.ai/links/aurora_gpt/nqjjhzd5).

<!-- ::: -->

Simple tests to confirm the loss is exactly reproducible across independent runs (when launched with the same seed).

- In particular, we set:

    ```python
    output = flash_attn_func(q, k, v, None, self.causal, deterministic=True)
    ```

  in all the `flash_attn_func(...)` calls from
  [`megatron/model/transformer.py`](https://github.com/argonne-lcf/Megatron-DeepSpeed/blob/main/megatron/model/transformer.py)

- All experiments ran on Polaris @ ALCF, using:

    ```yaml
    machine: Polaris
    args.zero_stage: 1
    args.num_layers: 32
    args.micro_batch_size: 1
    args.optimizer: "adamw"
    args.use_flash_attn: true
    env.DFL_STEM: "books"
    env.GRAD_ACC_STEPS: 8
    env.WORLD_SIZE: 8
    ```


::: {#fig-loss}

![](./assets/deterministic-flash-attn-loss.svg)

Plot of the loss curve for 3 independent runs with `deterministic=True`
:::



<!-- <iframe src="https://wandb.ai/aurora_gpt/AuroraGPT/workspace?nw=nwuserforemans" style="border:none;width:100%"> -->

<!-- <iframe src="https://wandb.ai/aurora_gpt/AuroraGPT/reports/Deterministic-Flash-Attention--Vmlldzo4MzU0OTQ0?accessToken=y1r4ftxjkxhhgpwhttag4g0rgqhxvqpi0hc1fbribk97brozbtjhrkbtc8wqkh5r" style="border:none;height:1024px;width:100%"> -->
