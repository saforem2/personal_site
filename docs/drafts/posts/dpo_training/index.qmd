---
title: "DPO Training"
date: 2024-08-20
format:
  html: default
  gfm:
    output-file: dpo_training.md
# format:
#     html:
#         highlight-style: github
# format:
#     html:
#         highlight-style:
#             light: ayu
#             dark: dracula
---

<!-- [Sam Foreman](https://samforeman.me)   -->
<!-- _2024-08-20_ -->

## FLOPs Counter

Our implementation is online at:
[`ramanathanlab/Megatron-DeepSpeed/blob/aurora/dpo_training.py`](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/aurora/dpo_training.py)

In particular, the number of floating point operations for the DPO training is
calculated using the
[`num_floating_point_operations_dpo`](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L113-L142)
method (included below for completeness):

```python
def num_floating_point_operations_dpo(args, batch_size):
    assert args is not None
    # Group Query Attention
    if not args.num_key_value_heads:
        args.num_key_value_heads = args.num_attention_heads
    # MoE
    num_experts_routed_to = 1 if args.num_experts is None else args.topk
    gated_linear_multiplier = 3 / 2 if args.swiglu else 1
    # NOTE:       f   b   f (ref)
    return (  #   ⇣---⇣---⇣----
        16    # = 4 + 8 + 4
        * batch_size
        * args.seq_length
        * args.num_layers
        * args.hidden_size
        * args.hidden_size
        * (
            1
            + (  # MLP.
                (args.ffn_hidden_size / args.hidden_size)
                 * num_experts_routed_to
                 * gated_linear_multiplier
            )
            + (args.num_key_value_heads / args.num_attention_heads)
            + (args.seq_length / args.hidden_size)
            # Logit.
            + (args.padded_vocab_size / (2 * args.num_layers * args.hidden_size))
        )
    )
```

## Batch Size

In order to use the `num_floating_point_operations_dpo` method defined above,
we need to correctly identify the `batch_size` in use.

For our DPO experiments, the `batch_size` is calculated
[\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L911-L917)
as follows:

```python
batch_size = (
    2  # tokens = torch.cat([tokens_u, tokens_p], 0)
    * gas
    * args.micro_batch_size
    * args.data_parallel_size
    * get_num_microbatches()
)
```

For the experiments on Aurora, we used the following values:

- `args.micro_batch_size = 6`
- `gas = 8`
- `get_num_microbatches() = 1`
- `args.data_parallel_size = WORLD_SIZE`[^dp_size]

This is then used to calculate the number of floating point operations
[\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L918-L921)
as

```python
num_flop_dpo = num_floating_point_operations_dpo(
    args,
    batch_size=batch_size
)
```

[^dp_size]:
    Since pure data-parallelism, our data parallel size is equal to the
    number of accelerators in use, i.e. `data_parallel_size = WORLD_SIZE`

**Note**: the full config used for the experiments on Aurora is listed in [Config](#config).

## Training Step

For our DPO training runs, we instantiate two (identical) models:

1. "main" model
2. "reference" model

A complete training step consists of the following steps:

1. Start timer `_t0` [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1137)
2. `for micro_step in range(gradient_accumulation_steps)`: [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1138-L1237)
   1. Load `u`n-preferred tokens, `tokens_u` [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1141-L1147)
   2. Load `p`referred tokens, `tokens_p`, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1156-L1162)
   3. Concatenate `tokens_c = torch.cat((tokens_p, tokens_u), 0)`, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1170-L1172)
   4. Forward pass of ("main") model, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1177-L1185)
   5. Forward pass of ("reference") model, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1187-L1197)
   6. Backward pass of ("main") model, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1220-L1229)
3. Stop timer `_t1` [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1238)
   1. Time to complete step: `_t1 - _t0`, [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1288)
   2. Calculate `FLOPs` related quantities [\[here\]](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/f2da6e31d9258461593aeaacf6a5773ae02322ef/dpo_training.py#L1293-L1296)

## Config

The full config used for the experiments on Aurora is included below:

| Key                   |  Value |
| :-------------------: | :----: |
| `MODEL_SIZE`          |   3.5B |
| `dtype`               | `bf16` |
| `ffn_hidden_size`     |  11008 |
| `hidden_size`         |   4096 |
| `seq_length`          |    512 |
| `num_key_value_heads` |     32 |
| `num_layers`          |     16 |
| `grad_acc_steps`      |      8 |
| `micro_batch_per_gpu` |      6 |
| `zero_stage`          |      1 |

: Config {#tbl-config .striped .hover}

the full DeepSpeed config `.json` for the `3.5B` model is online at:  
[`Megatron-DeepSpeed/blob/aurora/ds_configs/3p5B.json`](https://github.com/ramanathanlab/Megatron-DeepSpeed/blob/aurora/ds_configs/3p5B.json)
