<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sam Foreman">
<meta name="dcterms.date" content="2024-11-05">

<title>Parallel Training Methods – Sam Foreman</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e7535a095ba9bb2a05796f14f3cabdcd.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-e62be3cb6129fbb76f50bbe2eac19e65.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-24a25fa21c4e66e6ec26d67933426418.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-XVM2Y822Y1"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-XVM2Y822Y1', { 'anonymize_ip': true});
</script>
<meta name="mermaid-theme" content="neutral">
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
<!-- End Google Tag Manager -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Serif:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet">
<link href="https://iosevka-webfonts.github.io/iosevka-fixed/iosevka-fixed.css" rel="stylesheet" type="text/css">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../css/custom.css">
<meta property="og:title" content="Parallel Training Methods for AI">
<meta property="og:description" content="My ramblings about science and computers">
<meta property="og:image" content="https://samforeman.me/talks/ai-for-science-2024/assets/thumbnail.png">
<meta property="og:site_name" content="Sam Foreman">
<meta property="og:image:height" content="2572">
<meta property="og:image:width" content="4112">
<meta name="twitter:title" content="Parallel Training Methods for AI">
<meta name="twitter:description" content="My ramblings about science and computers">
<meta name="twitter:image" content="https://samforeman.me/talks/ai-for-science-2024/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:card" content="summary">
<meta name="twitter:image-height" content="2572">
<meta name="twitter:image-width" content="4112">
<meta name="citation_title" content="Parallel Training Methods">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2024-11-05">
<meta name="citation_cover_date" content="2024-11-05">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-11-05">
<meta name="citation_fulltext_html_url" content="https://samforeman.me/talks/ai-for-science-2024/slides">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/signature12.svg" alt="Sam Foreman" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-talks" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">talks</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-talks">    
        <li>
    <a class="dropdown-item" href="../../talks/index.html">
 <span class="dropdown-text">📢 All Talks</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/ai-for-science-2024/slides.html">
 <span class="dropdown-text">Parallel Training Methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/alcf-hpc-workshop-2024/slides.html">
 <span class="dropdown-text">AuroraGPT (ALCF Hands-On HPC)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/alcf-hpc-workshop-2024/slides.html">
 <span class="dropdown-text">ML + Foundation Models at Scale</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/hpc-user-forum/slides.html">
 <span class="dropdown-text">AuroraGPT (HPC User Forum)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/llms-at-scale/slides.html">
 <span class="dropdown-text">Training LLMs at Scale</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../talks/llms-on-polaris/slides.html">
 <span class="dropdown-text">Polaris Overview + LLMs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/parallel-training-slides/">
 <span class="dropdown-text">Parallel Training Techniques</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/llm-workshop-talk/">
 <span class="dropdown-text">LLMs from Scratch</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/LLM-tutorial">
 <span class="dropdown-text">Creating Small(-ish) LLMs</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/oneapi-talk/#0">
 <span class="dropdown-text">Exascale Science on Aurora</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/llm-lunch-talk/">
 <span class="dropdown-text">LLM Lunch Talk</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/scaling4science">
 <span class="dropdown-text">Scaling LLMs for Science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/lattice23">
 <span class="dropdown-text">MLMC (for LQCD)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/lqcd-pasc23">
 <span class="dropdown-text">Generative Modeling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/deep-fridays">
 <span class="dropdown-text">Efficient Sampling for LGT</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ai4sci-large-scale-training">
 <span class="dropdown-text">Large Scale Training</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/hparam-management-sdl2022">
 <span class="dropdown-text">Hyperparameter Management</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ATPESC-StatisticalLearning">
 <span class="dropdown-text">Statistical Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/anl-job-talk/">
 <span class="dropdown-text">Scientific Data Science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/physicsSeminar">
 <span class="dropdown-text">Machine Learning in HEP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://bit.ly/mainz21">
 <span class="dropdown-text">DLHMC for Improved Gauge Generation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://slides.com/samforeman/l2hmc-qcd-93bc0c">
 <span class="dropdown-text">ML for LQCD</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://bit.ly/mainz21_overview">
 <span class="dropdown-text">ML Techniques in LQCD</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/physicsSeminar">
 <span class="dropdown-text">ML for HEP</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">posts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="../../posts/index.html">
 <span class="dropdown-text">📬 All Posts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/spike-skipper/index.html">
 <span class="dropdown-text">🏔️ Spike Skipper</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/ezpz-at-alcf/index.html">
 <span class="dropdown-text">🍋 <code>ezpz</code> at ALCF</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/determinstic-flash-attn/index.html">
 <span class="dropdown-text">🎰 Deterministic Flash Attention</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/flash-attn-sunspot/index.html">
 <span class="dropdown-text">📸 <code>flash-attn</code> on Sunspot</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/mpi4py-reproducer/index.html">
 <span class="dropdown-text">🐛 <code>mpi4py</code> bug on Sunspot</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/ai-for-physics/diffusion/index.html">
 <span class="dropdown-text">🎲 MCMC + Diffusion Sampling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/dope-slides/index.html">
 <span class="dropdown-text">💅 How to Make Dope Slides</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/startup-times/index.html">
 <span class="dropdown-text">⏰ Starting Up Distributed Training</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/long-sequences/index.html">
 <span class="dropdown-text">🚂 Loooooooong Sequence Lengths</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/AuroraGPT/aurora-gpt/index.html">
 <span class="dropdown-text">🏎️ <code>Megatron-DeepSpeed</code> + Intel XPU</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/ai-for-physics/l2hmc-qcd/2dU1/index.html">
 <span class="dropdown-text">🎢 <code>l2hmc-qcd</code> Example: 2D U(1)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../posts/ai-for-physics/l2hmc-qcd/4dSU3/index.html">
 <span class="dropdown-text">🔳 <code>l2hmc-qcd</code> Example: 4D SU(3)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../qmd/projects/index.html">
 <span class="dropdown-text">📚 All Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ezpz">
 <span class="dropdown-text">🍋 <code>ezpz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/l2hmc-qcd">
 <span class="dropdown-text">🟥 <code>l2hmc-qcd</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/argonne-lcf/Megatron-DeepSpeed)">
 <span class="dropdown-text">🤖 <code>Megatron-DeepSpeed</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/wordplay">
 <span class="dropdown-text">💬 <code>wordplay</code> 🎮</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.alcf.anl.gov/alcf-ai-science-training-series?">
 <span class="dropdown-text">🎓 <code>ai-science-training</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/enrich">
 <span class="dropdown-text">💸 <code>enrich</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ambivalent">
 <span class="dropdown-text">🤷🏻‍♂️<code>ambivalent</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/climate-analysis">
 <span class="dropdown-text">🌍 <code>climate-analysis</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/glitz">
 <span class="dropdown-text">🎨 <code>glitz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/personal_site">
 <span class="dropdown-text">🙋🏻<code>personal_site</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/notes-demo">
 <span class="dropdown-text">🗒️ <code>Notes-Demo</code></span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/saforem2/personal_site"> 
<span class="menu-text"><span class="icon dim-text" style="font-size: 1.25rem;"><iconify-icon role="img" inline="" icon="ph:github-logo" aria-label="Icon github-logo from ph Iconify.design set." title="Icon github-logo from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.xml"> 
<span class="menu-text"><span class="icon dim-text" style="font-size: 1.25rem;"><iconify-icon role="img" inline="" icon="ph:rss" aria-label="Icon rss from ph Iconify.design set." title="Icon rss from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">👀 Overview</a></li>
  <li><a href="#outline" id="toc-outline" class="nav-link" data-scroll-target="#outline">📑 Outline</a></li>
  <li><a href="#scaling-overview" id="toc-scaling-overview" class="nav-link" data-scroll-target="#scaling-overview">🚀 Scaling: Overview</a></li>
  <li><a href="#single-gpu" id="toc-single-gpu" class="nav-link" data-scroll-target="#single-gpu">Single GPU</a></li>
  <li><a href="#data-parallel-training" id="toc-data-parallel-training" class="nav-link" data-scroll-target="#data-parallel-training">Data Parallel Training</a>
  <ul class="collapse">
  <li><a href="#data-parallel-training-forward-pass" id="toc-data-parallel-training-forward-pass" class="nav-link" data-scroll-target="#data-parallel-training-forward-pass">Data Parallel Training: Forward Pass</a></li>
  <li><a href="#data-parallel-training-backward-pass" id="toc-data-parallel-training-backward-pass" class="nav-link" data-scroll-target="#data-parallel-training-backward-pass">Data Parallel Training: Backward Pass</a></li>
  <li><a href="#data-parallel-training-1" id="toc-data-parallel-training-1" class="nav-link" data-scroll-target="#data-parallel-training-1">Data Parallel Training</a></li>
  <li><a href="#data-parallel-training-2" id="toc-data-parallel-training-2" class="nav-link" data-scroll-target="#data-parallel-training-2">Data Parallel Training</a></li>
  </ul></li>
  <li><a href="#communication" id="toc-communication" class="nav-link" data-scroll-target="#communication">🗣️ Communication</a>
  <ul class="collapse">
  <li><a href="#allreduce" id="toc-allreduce" class="nav-link" data-scroll-target="#allreduce">AllReduce</a></li>
  <li><a href="#reduce" id="toc-reduce" class="nav-link" data-scroll-target="#reduce">Reduce</a></li>
  <li><a href="#broadcast" id="toc-broadcast" class="nav-link" data-scroll-target="#broadcast">Broadcast</a></li>
  <li><a href="#allgather" id="toc-allgather" class="nav-link" data-scroll-target="#allgather">AllGather</a></li>
  <li><a href="#scatter" id="toc-scatter" class="nav-link" data-scroll-target="#scatter">Scatter</a></li>
  </ul></li>
  <li><a href="#why-distributed-training" id="toc-why-distributed-training" class="nav-link" data-scroll-target="#why-distributed-training">Why Distributed Training?</a>
  <ul class="collapse">
  <li><a href="#why-distributed-training-speedup" id="toc-why-distributed-training-speedup" class="nav-link" data-scroll-target="#why-distributed-training-speedup">Why Distributed Training? Speedup!</a></li>
  <li><a href="#dealing-with-data" id="toc-dealing-with-data" class="nav-link" data-scroll-target="#dealing-with-data">Dealing with Data</a></li>
  <li><a href="#broadcast-initial-state" id="toc-broadcast-initial-state" class="nav-link" data-scroll-target="#broadcast-initial-state">Broadcast Initial State</a></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices">Best Practices</a></li>
  </ul></li>
  <li><a href="#going-beyond-data-parallelism" id="toc-going-beyond-data-parallelism" class="nav-link" data-scroll-target="#going-beyond-data-parallelism">Going Beyond Data Parallelism</a>
  <ul class="collapse">
  <li><a href="#going-beyond-data-parallelism-deepspeed-zero" id="toc-going-beyond-data-parallelism-deepspeed-zero" class="nav-link" data-scroll-target="#going-beyond-data-parallelism-deepspeed-zero">Going beyond Data Parallelism: <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> DeepSpeed + <code>ZeRO</code></a></li>
  <li><a href="#fully-sharded-data-parallel-pytorch-fsdp" id="toc-fully-sharded-data-parallel-pytorch-fsdp" class="nav-link" data-scroll-target="#fully-sharded-data-parallel-pytorch-fsdp">Fully Sharded Data Parallel: 🔥 PyTorch + <code>FSDP</code></a></li>
  </ul></li>
  <li><a href="#additional-parallelism-strategies" id="toc-additional-parallelism-strategies" class="nav-link" data-scroll-target="#additional-parallelism-strategies">Additional Parallelism Strategies</a>
  <ul class="collapse">
  <li><a href="#pipeline-parallelism-pp" id="toc-pipeline-parallelism-pp" class="nav-link" data-scroll-target="#pipeline-parallelism-pp">Pipeline Parallelism (PP)</a></li>
  <li><a href="#tensor-parallel-tp" id="toc-tensor-parallel-tp" class="nav-link" data-scroll-target="#tensor-parallel-tp">Tensor Parallel (TP)</a></li>
  <li><a href="#tensor-parallel-tp-1" id="toc-tensor-parallel-tp-1" class="nav-link" data-scroll-target="#tensor-parallel-tp-1">Tensor Parallel (TP)</a></li>
  <li><a href="#tensor-model-parallel-training-example" id="toc-tensor-model-parallel-training-example" class="nav-link" data-scroll-target="#tensor-model-parallel-training-example">Tensor (/ Model) Parallel Training: Example</a></li>
  <li><a href="#tensor-model-parallelismefficient-large-scale" id="toc-tensor-model-parallelismefficient-large-scale" class="nav-link" data-scroll-target="#tensor-model-parallelismefficient-large-scale">Tensor (Model) Parallelism</a></li>
  <li><a href="#tensor-parallelism" id="toc-tensor-parallelism" class="nav-link" data-scroll-target="#tensor-parallelism">Tensor Parallelism</a></li>
  <li><a href="#d-parallelism" id="toc-d-parallelism" class="nav-link" data-scroll-target="#d-parallelism">3D Parallelism</a></li>
  <li><a href="#deciding-on-a-parallelism-strategy" id="toc-deciding-on-a-parallelism-strategy" class="nav-link" data-scroll-target="#deciding-on-a-parallelism-strategy">Deciding on a Parallelism Strategy</a></li>
  </ul></li>
  <li><a href="#large-language-models" id="toc-large-language-models" class="nav-link" data-scroll-target="#large-language-models">Large Language Models</a>
  <ul class="collapse">
  <li><a href="#emergent-abilities" id="toc-emergent-abilities" class="nav-link" data-scroll-target="#emergent-abilities">Emergent Abilities</a></li>
  <li><a href="#training-llms" id="toc-training-llms" class="nav-link" data-scroll-target="#training-llms">Training LLMs</a></li>
  <li><a href="#life-cycle-of-the-llm" id="toc-life-cycle-of-the-llm" class="nav-link" data-scroll-target="#life-cycle-of-the-llm">♻️ Life-Cycle of the LLM</a></li>
  <li><a href="#life-cycle-of-the-llm-1" id="toc-life-cycle-of-the-llm-1" class="nav-link" data-scroll-target="#life-cycle-of-the-llm-1">🎀 Life-Cycle of the LLM</a></li>
  <li><a href="#forward-pass" id="toc-forward-pass" class="nav-link" data-scroll-target="#forward-pass">Forward Pass</a></li>
  <li><a href="#generating-text" id="toc-generating-text" class="nav-link" data-scroll-target="#generating-text">Generating Text</a></li>
  </ul></li>
  <li><a href="#hands-on" id="toc-hands-on" class="nav-link" data-scroll-target="#hands-on">👋 Hands On</a>
  <ul class="collapse">
  <li><a href="#hands-on-getting-started" id="toc-hands-on-getting-started" class="nav-link" data-scroll-target="#hands-on-getting-started">🧑‍💻 Hands On: Getting Started</a></li>
  <li><a href="#install-ezpz-wordplay" id="toc-install-ezpz-wordplay" class="nav-link" data-scroll-target="#install-ezpz-wordplay">📦 Install {<code>ezpz</code>, <code>wordplay</code>}</a></li>
  <li><a href="#ezpz-example-video" id="toc-ezpz-example-video" class="nav-link" data-scroll-target="#ezpz-example-video"><i class="fa-brands fa-github" aria-label="github"></i> <code>ezpz</code>: Example [video]</a></li>
  <li><a href="#install-wordplay" id="toc-install-wordplay" class="nav-link" data-scroll-target="#install-wordplay">Install <code>wordplay</code> 🎮💬</a></li>
  <li><a href="#prepare-data" id="toc-prepare-data" class="nav-link" data-scroll-target="#prepare-data">Prepare Data</a></li>
  <li><a href="#launch-training-ddp" id="toc-launch-training-ddp" class="nav-link" data-scroll-target="#launch-training-ddp">Launch Training (DDP)</a></li>
  <li><a href="#training-example-output" id="toc-training-example-output" class="nav-link" data-scroll-target="#training-example-output">Training: Example Output</a></li>
  <li><a href="#wordplay-example-video" id="toc-wordplay-example-video" class="nav-link" data-scroll-target="#wordplay-example-video"><i class="fa-brands fa-github" aria-label="github"></i> <code>wordplay</code>: Example [video]</a></li>
  </ul></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">❤️ Thank you!</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">📓 References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li><li><a href="ai-for-science-2024.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Parallel Training Methods</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://samforeman.me">Sam Foreman</a> <a href="mailto:foremans@anl.gov" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 5, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="overview">👀 Overview</h2>
<ul>
<li>📊 Slides @ <a href="https://samforeman.me/talks/ai-for-science-2024/slides">samforeman.me/talks/ai-for-science-2024/slides</a>
<ul>
<li>📄 HTML version: <a href="https://samforeman.me/talks/ai-for-science-2024">samforeman.me/talks/ai-for-science-2024</a></li>
</ul></li>
<li>Course:
<ul>
<li>📂 <a href="https://www.alcf.anl.gov/alcf-ai-science-training-series">ALCF: Intro to AI-driven Science on Supercomputers</a>
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/ai-science-training-series"><code>argonne-lcf/ai-science-training-series</code></a></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="outline" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="outline">📑 Outline</h2>
<ol type="1">
<li><a href="#scaling-overview">Scaling: Overview</a></li>
<li><a href="#data-parallel-training">Data Parallel Training</a>
<ol type="1">
<li><a href="#communication">Communication</a></li>
<li><a href="#why-distributed-training">Why Distributed Training?</a></li>
</ol></li>
<li><a href="#going-beyond-data-parallelism">Beyond Data Parallelism</a>
<ol type="1">
<li><a href="#additional-parallelism-strategies">Additional Parallelism Strategies</a></li>
</ol></li>
<li><a href="#large-language-models">Large Language Models</a></li>
<li><a href="#hands-on">Hands On</a></li>
</ol>
</section>
<section id="scaling-overview" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="scaling-overview">🚀 Scaling: Overview</h2>
<ul>
<li>✅ <strong>Goal</strong>:
<ul>
<li>Minimize: <span class="highlight-red">Cost</span> (i.e.&nbsp;amount of time spent training)</li>
<li>Maximize: <span class="highlight-blue">Performance</span></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>See <a href="https://huggingface.co/docs/transformers/v4.46.0/performance">🤗 Performance and Scalability</a> for more details</p>
</div>
</div>
</div></li>
</ul>
</section>
<section id="single-gpu" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="single-gpu">Single GPU</h2>
<ul>
<li>See <a href="https://huggingface.co/docs/transformers/v4.46.0/perf_train_gpu_one">🤗 Methods and tools for efficient training on a single GPU</a></li>
</ul>
<div id="fig-single-gpu-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-single-gpu-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    subgraph G0["`GPU0`"]
        subgraph N0["`Network`"]
        end
        L0("`Loss`")
    end
    subgraph D["`Data`"]
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    x --&gt; N0
    N0 --&gt; L0
    L0 --&gt; N0
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class x,L0 red
class x1, green
class x2, blue
class x3, grey
class N0,D,G0,n0 block
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-single-gpu-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>SLOW</strong> !! model size limited by GPU memory
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-training" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="data-parallel-training">Data Parallel Training</h2>
<div id="fig-ddp-training-mermaid" class="flex-container quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ddp-training-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    subgraph D["`Data`"]
        direction TB
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    direction LR
    subgraph G0["`GPU0`"]
        direction LR
        subgraph N0["`NN`"]
        end
        %%y0("`y₀`")
        L0["`Loss`"]
    end
    subgraph G1["`GPU1`"]
        direction LR
        subgraph N1["`NN`"]
        end
        L1["`Loss`"]
    end
    subgraph G2["`GPU2`"]
        direction LR
        subgraph N2["`NN`"]
        end
        L2["`Loss`"]
    end
    x --&gt; G0
    x1 --&gt; G1
    x2 --&gt; G2
    N0 --&gt; L0
    N1 --&gt; L1
    N2 --&gt; L2
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
class x,y0,L0 red
class x1,L1 green
class x2,L2 blue
class x3,ar grey
class D,N0,N1,N2,G0,G1,G2,GU block
class AR block
class bc text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Each GPU receives <strong>unique</strong> data at each step
</figcaption>
</figure>
</div>
<section id="data-parallel-training-forward-pass" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="data-parallel-training-forward-pass">Data Parallel Training: Forward Pass</h3>
<div id="fig-ddp-training-mermaid-allreduce" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ddp-training-mermaid-allreduce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    subgraph D["`Data`"]
        direction TB
        %%xp("`xₙ₊₁`")
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    direction LR
    subgraph G0["`GPU0`"]
        direction LR
        subgraph N0["`NN`"]
        end
        %%y0("`y₀`")
        L0["`Loss`"]
    end
    subgraph G1["`GPU1`"]
        direction LR
        subgraph N1["`NN`"]
        end
        L1["`Loss`"]
    end
    subgraph G2["`GPU2`"]
        direction LR
        subgraph N2["`NN`"]
        end
        L2["`Loss`"]
    end
    subgraph AR["`Average Grads`"]
        direction TB
        ar("`(1/n) ∑ gₙ`")
    end
    x --&gt; G0
    x1 --&gt; G1
    x2 --&gt; G2
    N0 --&gt; L0
    N1 --&gt; L1
    N2 --&gt; L2
    G0 -.-&gt; AR
    G1 -.-&gt; AR
    G2 -.-&gt; AR
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class x,y0,L0 red
class x1,L1 green
class x2,L2 blue
class x3,ar grey
class D,N0,N1,N2,G0,G1,G2,GU block
class AR block
class bc text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-mermaid-allreduce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Average gradients across all GPUs
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-training-backward-pass" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="data-parallel-training-backward-pass">Data Parallel Training: Backward Pass</h3>
<div id="fig-ddp-training-broadcast" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ddp-training-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart RL
    subgraph D["`Data`"]
        direction TB
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    subgraph G0["`GPU0`"]
        direction RL
        subgraph N0["`NN`"]
        end
        L0["`Loss`"]
    end
    subgraph G1["`GPU1`"]
        direction RL
        subgraph N1["`NN`"]
        end
        L1["`Loss`"]
    end
    subgraph G2["`GPU2`"]
        direction RL
        subgraph N2["`NN`"]
        end
        L2["`Loss`"]
    end
    subgraph BC["`Send Updates`"]
        direction TB
    end
    BC -.-&gt; G0
    BC -.-&gt; G1
    BC -.-&gt; G2
    L0 ~~~ N0
    L1 ~~~ N1
    L2 ~~~ N2
    G0 ~~~ x
    G1 ~~~ x1
    G2 ~~~ x2
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class x,y0,L0 red
class x1,L1 green
class x2,L2 blue
class x3,ar grey
class D,N0,N1,N2,G0,G1,G2,GU block
class BC block
class bc text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Send global updates back to each GPU
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-training-1" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="data-parallel-training-1">Data Parallel Training</h3>
<div id="fig-ddp-training" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ddp-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    subgraph D["`Data`"]
        direction TB
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    direction LR
    subgraph G0["`GPU0`"]
        direction LR
        subgraph N0["`NN`"]
        end
        L0["`L0`"]
    end
    subgraph G1["`GPU1`"]
        direction LR
        subgraph N1["`NN`"]
        end
        L1["`L1`"]
    end
    subgraph G2["`GPU2`"]
        direction LR
        subgraph N2["`NN`"]
        end
        L2["`L2`"]
    end
    subgraph AR["`Average Grads`"]
        direction TB
        ar("`(1/n) ∑ gₙ`")
        bc("`Update Weights`")
        ar --&gt; bc
    end
    x --&gt; G0
    x1 --&gt; G1
    x2 --&gt; G2
    N0 --&gt; L0
    N1 --&gt; L1
    N2 --&gt; L2
    G0 &lt;-.-&gt; AR
    G1 &lt;-.-&gt; AR
    G2 &lt;-.-&gt; AR
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class x,y0,L0 red
class x1,L1 green
class x2,L2 blue
class x3,ar grey
class D,N0,N1,N2,G0,G1,G2,GU block
class AR block
class bc text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: See: <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">PyTorch / Distributed Data Parallel</a>
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-training-2" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="data-parallel-training-2">Data Parallel Training</h3>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Each GPU:
<ul>
<li>has <strong>identical copy</strong> of model</li>
<li>works on a <strong>unique</strong> subset of data</li>
</ul></li>
<li>Easy to get started (minor modifications to code):
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a></li>
<li>🔥 <a href="https://pytorch.org/docs/stable/notes/ddp.html">PyTorch / <code>DDP</code></a></li>
<li>🤗 <a href="https://huggingface.co/docs/transformers/accelerate">HF / <code>Accelerate</code></a></li>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://www.deepspeed.ai/">Microsoft / <code>DeepSpeed</code></a></li>
</ul></li>
<li>Requires <strong>global</strong> communication
<ul>
<li>every rank <em>must participate</em> (collective communication) !!</li>
</ul></li>
</ul>
</div>
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-avgGrads" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-avgGrads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    subgraph D["`Data`"]
        direction LR
        x("`x₀`")
        x1("`x₁`")
        x2("`x₂`")
    end
    subgraph G0["`GPU0`"]
        direction TB
        subgraph N0["`NN`"]
        end
        L0["`L₀`"]
    end
    subgraph G1["`GPU1`"]
        direction TB
        subgraph N1["`NN`"]
        end
        L1["`L₁`"]
    end
    subgraph G2["`GPU2`"]
        direction TB
        subgraph N2["`NN`"]
        end
        L2["`L₂`"]
    end
    subgraph AR["`Average Grads`"]
        direction TB
        ar("`(1/n) ∑ gₙ`")
        bc("`Update Weights`")
        ar --&gt; bc
    end
    x --&gt; G0
    x1 --&gt; G1
    x2 --&gt; G2
    N0 --&gt; L0
    N1 --&gt; L1
    N2 --&gt; L2
    G0 &lt;-.-&gt; AR
    G1 &lt;-.-&gt; AR
    G2 &lt;-.-&gt; AR
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class x,y0,L0 red
class x1,L1 green
class x2,L2 blue
class x3,ar grey
class D,N0,N1,N2,G0,G1,G2,GU block
class AR block
class bc text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-avgGrads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="communication" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="communication">🗣️ Communication</h2>
<ul>
<li>Need mechanism(s) for communicating across GPUs:
<ul>
<li><a href="https://mpi4py.readthedocs.io/en/stable/tutorial.html"><code>mpi4py</code></a></li>
<li><a href="https://pytorch.org/docs/stable/distributed.html"><code>torch.distributed</code></a></li>
</ul></li>
<li>Collective Communication:
<ul>
<li><a href="https://developer.nvidia.com/nccl">Nvidia Collective Communications Library (NCCL)</a></li>
<li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/oneccl.html#gs.gouznn">Intel oneAPI Collective Communications Library (oneCCL)</a></li>
</ul>
<div class="callout callout-style-simple callout-warning no-icon callout-titled" title="⌛ Timeouts">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
⌛ Timeouts
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li>Collective operations have to be called for each <code>rank</code> to form a complete collective operation.
<ul>
<li>Failure to do so will result in other ranks waiting <strong>indefinitely</strong></li>
</ul></li>
</ul>
</div>
</div>
</div></li>
</ul>
<section id="allreduce" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="allreduce">AllReduce</h3>
<p>Perform <em>reductions</em> on data (e.g.&nbsp;<code>sum</code>, <code>min</code>, <code>max</code>) across ranks, send result back to everyone.</p>
<div id="fig-all-reduce-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-all-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  subgraph R0["`Rank 0`"]
    x0("`x0`")
  end
  subgraph R1["`Rank 1`"]
    x1("`x1`")
  end
  subgraph R2["`Rank 2`"]
    x2("`x2`")
  end
  subgraph R3["`Rank 3`"]
    x3("`x3`")
  end
  subgraph AR["`Allreduce`"]
    xp["`x' = ∑ xₙ `"]
  end
  subgraph AR3["`Rank 3`"]
    xp3("`x'`")
  end
  subgraph AR2["`Rank 2`"]
    xp2("`x'`")
  end
  subgraph AR1["`Rank 1`"]
    xp1("`x'`")
  end
  subgraph AR0["`Rank 0`"]
    xp0("`x'`")
  end
  x0 --&gt; AR
  x1 --&gt; AR
  x2 --&gt; AR
  x3 --&gt; AR
  AR --&gt; xp0
  AR --&gt; xp1
  AR --&gt; xp2
  AR --&gt; xp3
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef pink fill:#E599F7,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
class R0,R1,R2,R3,AR,AR0,AR1,AR2,AR3 block
class xp,xp0,xp1,xp2,xp3, purple
class x0, red
class x1, green
class x2, blue
class x3, yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-all-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: All-Reduce operation: each rank receives the reduction of input values across ranks.
</figcaption>
</figure>
</div>
</section>
<section id="reduce" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="reduce">Reduce</h3>
<ul>
<li>Perform a <em>reduction</em> on data across ranks, send to individual</li>
</ul>
<div id="fig-reduce-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  subgraph R0["`Rank 0`"]
    x0("`x0`")
  end
  subgraph R1["`Rank 1`"]
    x1("`x1`")
  end
  subgraph R2["`Rank 2`"]
    x2("`x2`")
  end
  subgraph R3["`Rank 3`"]
    x3("`x3`")
  end
  subgraph AR["`Reduce`"]
    xp["`x'=reduce(x, 2, SUM)`"]
  end
  subgraph AR3["`Rank 3`"]
  end
  subgraph AR2["`Rank 2`"]
    xp2("`x'`")
  end
  subgraph AR1["`Rank 1`"]
  end
  subgraph AR0["`Rank 0`"]
  end
  x0 --&gt; AR
  x1 --&gt; AR
  x2 --&gt; AR
  x3 --&gt; AR
  AR --&gt; AR3
  AR --&gt; xp2
  AR --&gt; AR1
  AR --&gt; AR0
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef pink fill:#E599F7,stroke:#333,stroke-width:1px,color:#000
class R0,R1,R2,R3,AR,AR0,AR1,AR2,AR3, block
class xp,xp2 purple
class x0, red
class x1, green
class x2, blue
class x3, yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Reduce operation: one rank receives the reduction of input values across ranks
</figcaption>
</figure>
</div>
</section>
<section id="broadcast" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="broadcast">Broadcast</h3>
<div id="fig-broadcast-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-broadcast-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  subgraph R3["`Rank 3`"]
  end
  subgraph R2["`Rank 2`"]
    x2("`x2`")
  end
  subgraph R1["`Rank 1`"]
  end
  subgraph R0["`Rank 0`"]
  end
  subgraph AR["` `"]
    xp["`broadcast(x2, 2)`"]
  end
  subgraph AR3["`Rank 3`"]
    xp3("`x2`")
  end
  subgraph AR2["`Rank 2`"]
    xp2("`x2`")
  end
  subgraph AR1["`Rank 1`"]
    xp1("`x2`")
  end
  subgraph AR0["`Rank 0`"]
    xp0("`x2`")
  end
  x2 --&gt; AR
  AR --&gt; AR3
  AR --&gt; AR2
  AR --&gt; AR1
  AR --&gt; AR0
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383,font-weight:500
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,font-weight:500,color:#838383
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
class R0,R1,R2,R3,AR0,AR1,AR2,AR3,AR, block
class x2,xp0,xp1,xp2,xp3 blue
class xp, text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-broadcast-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: <code>broadcast</code> (send) a tensor <code><span class="math inline">x</span></code> from one rank to all ranks
</figcaption>
</figure>
</div>
</section>
<section id="allgather" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="allgather">AllGather</h3>
<div id="fig-allgather-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored" style="width:70%; text-align:center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-allgather-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  subgraph R0["`Rank 0`"]
    x0("`x0`")
  end
  subgraph R1["`Rank 1`"]
    x1("`x1`")
  end
  subgraph R2["`Rank 2`"]
    x2("`x2`")
  end
  subgraph R3["`Rank 3`"]
    x3("`x3`")
  end
  subgraph AG["`Allgather`"]
    %%xp0["`z=[empty_like(x) for _ in range(4)]`"]
    %%xp1["`dist.all_gather(z, x)`"]
  end
  subgraph AG3["`Rank 3`"]
    direction TB
    xp03("`x0`")
    xp13("`x1`")
    xp23("`x2`")
    xp33("`x3`")
  end
  subgraph AG2["`Rank 2`"]
    direction TB
    xp02("`x0`")
    xp12("`x1`")
    xp22("`x2`")
    xp32("`x3`")
  end
  subgraph AG1["`Rank 1`"]
    direction TB
    xp01("`x0`")
    xp11("`x1`")
    xp21("`x2`")
    xp31("`x3`")
  end
  subgraph AG0["`Rank 0`"]
    direction TB
    xp00("`x0`")
    xp10("`x1`")
    xp20("`x2`")
    xp30("`x3`")
  end
  x0 --&gt; AG
  x1 --&gt; AG
  x2 --&gt; AG
  x3 --&gt; AG
  AG --&gt; AG0
  AG --&gt; AG1
  AG --&gt; AG2
  AG --&gt; AG3
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,font-weight:500,color:#838383
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class xp0,xp1, text
class AG0,AG1,AG2,AG3,AG,R0,R1,R2,R3, block
class xp00,xp01,xp02,xp03, red
class xp10,xp11,xp12,xp13, green
class xp20,xp21,xp22,xp23, blue
class xp30,xp31,xp32,xp33, yellow
class x0, red
class x1, green
class x2, blue
class x3, yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-allgather-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Gathers tensors from the whole group in a list.
</figcaption>
</figure>
</div>
</section>
<section id="scatter" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="scatter">Scatter</h3>
<div id="fig-scatter-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scatter-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  subgraph R3["`Rank 3`"]
  end
  subgraph R2["`Rank 2`"]
  end
  subgraph R1["`Rank 1`"]
    direction TB
    xp03("`x0`")
    xp13("`x1`")
    xp23("`x2`")
    xp33("`x3`")
  end
  subgraph R0["`Rank 0`"]
  end
  subgraph S["`Scatter`"]
  end
  subgraph AG3["`Rank 3`"]
    x3("`x3`")
  end
  subgraph AG2["`Rank 2`"]
    x2("`x2`")
  end
  subgraph AG1["`Rank 1`"]
    x1("`x1`")
  end
  subgraph AG0["`Rank 0`"]
    x0("`x0`")
  end
  %%R0 --&gt; S
  R1 --&gt; S
  %%R2 --&gt; S
  %%R3 --&gt; S
  S --&gt; AG0
  S --&gt; AG1
  S --&gt; AG2
  S --&gt; AG3
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,font-weight:500,color:#838383
class AG0,AG1,AG2,AG3,S,R0,R1,R2,R3, block
class xp00,xp01,xp02,xp03, red
class xp10,xp11,xp12,xp13, orange
class xp20,xp21,xp22,xp23, yellow
class xp30,xp31,xp32,xp33, blue
class x0, red
class x1, green
class x2, blue
class x3, yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Scatters a list of tensors to the whole group
</figcaption>
</figure>
</div>
</section>
</section>
<section id="why-distributed-training" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="why-distributed-training">Why Distributed Training?</h2>
<ul>
<li><code>N</code> workers each processing unique batch<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> of data:
<ul>
<li>[<code>micro_batch_size = 1</code>] <span class="math inline">\times</span> [<code>N</code> GPUs] <span class="math inline">\rightarrow</span> [<b><code>global_batch_size = N</code></b>]</li>
</ul></li>
<li>Improved gradient estimators
<ul>
<li>Smooth loss landscape</li>
<li>Less iterations needed for same number of epochs
<ul>
<li>common to scale learning rate <code>lr *= sqrt(N)</code></li>
</ul></li>
</ul></li>
<li>See: <a href="https://arxiv.org/abs/1708.03888">Large Batch Training of Convolutional Networks</a></li>
</ul>
<section id="why-distributed-training-speedup" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="why-distributed-training-speedup">Why Distributed Training? Speedup!</h3>
<div id="tbl-recent-progress" class="responsive striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-recent-progress-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Recent progress
</figcaption>
<div aria-describedby="tbl-recent-progress-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="table-responsive">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Year</th>
<th style="text-align: center;">Author</th>
<th style="text-align: center;">GPU</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;"># GPU</th>
<th style="text-align: center;">TIME (s)</th>
<th style="text-align: center;">ACC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2016</td>
<td style="text-align: center;">He</td>
<td style="text-align: center;">P100</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;"><span class="red-bg">8</span></td>
<td style="text-align: center;"><span class="red-bg">104,400</span></td>
<td style="text-align: center;">75.30%</td>
</tr>
<tr class="even">
<td style="text-align: center;">2019</td>
<td style="text-align: center;">Yamazaki</td>
<td style="text-align: center;">V100</td>
<td style="text-align: center;">81,920</td>
<td style="text-align: center;"><span class="blue-bg">2048</span></td>
<td style="text-align: center;"><span class="blue-bg">72</span></td>
<td style="text-align: center;">75.08%</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</section>
<section id="dealing-with-data" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="dealing-with-data">Dealing with Data</h3>
<ul>
<li>At each training step, we want to ensure that <strong>each worker receives unique data</strong></li>
<li>This can be done in one of two ways:
<ol type="1">
<li>Manually partition data (ahead of time)
<ul>
<li>Assign <strong>unique subsets</strong> to each worker</li>
<li>Each worker can only see their local portion of the data</li>
<li>Most common approach</li>
</ul></li>
<li>From each worker, randomly select a mini-batch
<ul>
<li>Each worker can see the full dataset</li>
<li>⚠️ When randomly selecting, it is important that each worker uses different seeds to ensure they receive unique data</li>
</ul></li>
</ol></li>
</ul>
</section>
<section id="broadcast-initial-state" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="broadcast-initial-state">Broadcast Initial State</h3>
<ul>
<li>At the start of training (or when loading from a checkpoint), we want all of our workers to be initialized consistently
<ul>
<li><strong>Broadcast</strong> the model and optimizer states from <code>rank() == 0</code> worker</li>
</ul></li>
</ul>
<div id="fig-broadcast" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
0["GPU0"] --&gt; 1["GPU 1"]
CKPT --&gt; 0
0 --&gt; 2["GPU 2"]
0 --Model + Optim. State--&gt;3["GPU 3"]
0 --&gt; X["`...`"]
0 --&gt; N["GPU N"]
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class 0,1,2,3,N,X,CKPT block
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: To ensure all workers have the same copies, we load on <code>RANK==0</code> and <code>broadcast</code>
</figcaption>
</figure>
</div>
</section>
<section id="best-practices" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="best-practices">Best Practices</h3>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="⏰ Keeping things in Sync">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
⏰ Keeping things in Sync
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Computation stalls during communication !!</strong></p>
<p>Keeping the communication to computation ratio small is important for effective scaling.</p>
</div>
</div>
</div>
<div class="flex-container">
<div class="column" style="width:50%;">
<ul>
<li>Use parallel IO whenever possible
<ul>
<li>Feed each rank from different files</li>
<li>Use MPI IO to have each rank read its own batch from a file</li>
<li>Use several ranks to read data, MPI to scatter to remaining ranks
<ul>
<li>Most practical in big <em>at-scale</em> training</li>
</ul></li>
</ul></li>
</ul>
</div>
<div class="column" style="width:50%;">
<ul>
<li>Take advantage of data storage
<ul>
<li>Use <a href="https://wiki.lustre.org/Configuring_Lustre_File_Striping">striping on lustre</a></li>
</ul></li>
<li>Use the right optimizations for Aurora, Polaris, etc.</li>
<li>Preload data when possible
<ul>
<li>Offloading to a GPU frees CPU cycles for loading the next batch of data
<ul>
<li><strong>minimize IO latency this way</strong></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</section>
</section>
<section id="going-beyond-data-parallelism" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="going-beyond-data-parallelism">Going Beyond Data Parallelism</h2>
<ul>
<li>✅ Useful when model fits on single GPU:
<ul>
<li>ultimately <strong>limited by GPU memory</strong></li>
<li>model performance limited by size</li>
</ul></li>
<li>❌ When model does not fit on a single GPU:
<ul>
<li>Offloading:
<ul>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://www.deepspeed.ai/tutorials/zero/">DeepSpeed + <code>ZeRO</code></a></li>
<li>🔥 <a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">PyTorch + <code>FSDP</code></a></li>
</ul></li>
<li>Or, resort to additional parallelism strategies…</li>
</ul></li>
</ul>
<section id="going-beyond-data-parallelism-deepspeed-zero" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="going-beyond-data-parallelism-deepspeed-zero">Going beyond Data Parallelism: <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> DeepSpeed + <code>ZeRO</code></h3>
<ul>
<li>Depending on the <code>ZeRO</code> stage (1, 2, 3), we can offload:
<ol type="1">
<li><strong>Stage 1</strong>: optimizer states <span class="math inline">\left(P_{\mathrm{os}}\right)</span></li>
<li><strong>Stage 2</strong>: gradients + opt. states <span class="math inline">\left(P_{\mathrm{os}+\mathrm{g}}\right)</span></li>
<li><strong>Stage 3</strong>: model params + grads + opt. states <span class="math inline">\left(P_{\mathrm{os}+\mathrm{g}+\mathrm{p}}\right)</span></li>
</ol></li>
</ul>
<div id="fig-zero" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/zero.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;13:  DeepSpeed + ZeRO"><img src="./assets/zero.png" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="deepspeed.ai">DeepSpeed</a> + <a href="https://www.deepspeed.ai/tutorials/zero-offload/"><code>ZeRO</code></a>
</figcaption>
</figure>
</div>
</section>
<section id="fully-sharded-data-parallel-pytorch-fsdp" class="level3 smaller" data-background-color="white">
<h3 class="smaller anchored" data-background-color="white" data-anchor-id="fully-sharded-data-parallel-pytorch-fsdp">Fully Sharded Data Parallel: 🔥 PyTorch + <code>FSDP</code></h3>
<ul>
<li>Instead of maintaining per-GPU copy of <code>{params, grads, opt_states}</code>, FSDP shards (distributes) these across data-parallel workers
<ul>
<li>can optionally offload the sharded model params to CPU</li>
</ul></li>
<li><a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">Introducing PyTorch Fully Sharded Data Parallel (FSDP) API | PyTorch</a></li>
</ul>
<div id="fig-fsdp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fsdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="assets/fsdp.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;14: FSDP Workflow. Source"><img src="assets/fsdp.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fsdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: FSDP Workflow. <a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">Source</a>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="additional-parallelism-strategies" class="level2 page-columns page-full" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="additional-parallelism-strategies">Additional Parallelism Strategies</h2>
<ul>
<li><strong>Tensor (/ Model) Parallelism</strong> (<code>TP</code>):
<ul>
<li>🤗 <a href="https://huggingface.co/docs/text-generation-inference/en/conceptual/tensor_parallelism">Tensor Parallelism</a></li>
<li>🔥 <a href="https://pytorch.org/tutorials/intermediate/TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
</ul></li>
<li><strong>Pipeline Parallelism</strong> (<code>PP</code>):
<ul>
<li>🔥 <a href="https://pytorch.org/docs/main/distributed.pipelining.html">PyTorch</a></li>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://deepspeed.readthedocs.io/en/latest/pipeline.html">DeepSpeed</a></li>
</ul></li>
<li><strong>Sequence Parallelism</strong> (<code>SP</code>):
<ul>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ulysses/README.md">DeepSpeed Ulysses</a></li>
<li><a href="https://arxiv.org/abs/2405.07719v3">Unified Sequence Parallel (USP)</a>
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/feifeibear/long-context-attention">feifeibear/<code>long-context-attention</code></a></li>
</ul></li>
<li><a href="https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html">Megatron / Context Parallelism</a></li>
</ul></li>
<li>✅ All above:
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf/<code>Megatron-DeepSpeed</code></a> Supports 4D Parallelism (<code>DP</code> + <code>TP</code> + <code>PP</code> + <code>SP</code>)</li>
</ul></li>
</ul>
<section id="pipeline-parallelism-pp" class="level3 page-columns page-full" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="pipeline-parallelism-pp">Pipeline Parallelism (PP)</h3>
<div class="flex-container" style="place-content: end space-evenly;">
<div class="column" style="width:60%;">
<ul>
<li>Model is split up <strong>vertically</strong> (layer-level) across multiple GPUs</li>
<li>Each GPU:
<ul>
<li>has a portion of the full model</li>
<li>processes <em>in parallel</em> different stages of the pipeline (on a small chunk of the batch)</li>
</ul></li>
<li>See:
<ul>
<li>🔥 <a href="https://pytorch.org/docs/main/distributed.pipelining.html">PyTorch / Pipeline Parallelism</a></li>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://deepspeed.readthedocs.io/en/latest/pipeline.html">DeepSpeed / Pipeline Parallelism</a></li>
</ul></li>
</ul>
</div>
<div class="column" style="width:40%;">
<div id="fig-pipeline-parallelism" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pipeline-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TB
    subgraph G0["`GPU 0`"]
        direction LR
        a0("`Layer 0`")
        b0("`Layer 1`")
    end
    subgraph G1["`GPU 1`"]
        direction LR
        a1("`Layer 2`")
        b1("`Layer 3`")
    end
    a0 -.-&gt; b0
    b0 --&gt; a1
    a1 -.-&gt; b1
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
class G0,G1, block
class a0, red
class b0, green
class a1, blue
class b1, yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pipeline-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: Pipeline Parallelism
</figcaption>
</figure>
</div>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="margin-aside">

</div></div></section>
<section id="tensor-parallel-tp" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="tensor-parallel-tp">Tensor Parallel (TP)</h3>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Each tensor is split up into multiple chunks</li>
<li>Each shard of the tensor resides on its designated GPU</li>
<li>During processing each shard gets processed separately (and in parallel) on different GPUs
<ul>
<li>synced at the end of the step</li>
</ul></li>
<li>See: <a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">🤗 Model Parallelism</a> for additional details</li>
</ul>
</div>
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-model-parallel-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
   subgraph G0["`GPU0`"]
    direction TB
    a0("`Layer 0`")
    b0("`Layer 1`")
    c0("`Layer 2`")
    d0("`Layer 3`")
   end
   subgraph G1["`GPU1`"]
    direction TB
    a1("`Layer 0`")
    b1("`Layer 1`")
    c1("`Layer 2`")
    d1("`Layer 3`")
   end
   a0 &lt;-.-&gt; a1
   b0 &lt;-.-&gt; b1
   c0 &lt;-.-&gt; c1
   d0 &lt;-.-&gt; d1
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
class G0,G1, block
class a0,a1 red
class b0,b1 green
class c0,c1 blue
class d0,d1 yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16: Tensor Parallel Training
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="tensor-parallel-tp-1" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="tensor-parallel-tp-1">Tensor Parallel (TP)</h3>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Suitable when the model is too large to fit onto a single device (CPU / GPU)</li>
<li>Typically <strong>more complicated</strong> to implement than data parallel training
<ul>
<li>This is what one may call <em>horizontal parallelism</em></li>
<li>Communication whenever dataflow between two subsets</li>
</ul></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed"><code>argonne-lcf/Megatron-DeepSpeed</code></a></li>
<li>🤗 <a href="https://github.com/huggingface/nanotron"><code>huggingface/nanotron</code></a></li>
</ul>
</div>
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-model-parallel-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
   subgraph G0["`GPU0`"]
    direction TB
    a0("`Layer 0`")
    b0("`Layer 1`")
    c0("`Layer 2`")
    d0("`Layer 3`")
   end
   subgraph G1["`GPU1`"]
    direction TB
    a1("`Layer 0`")
    b1("`Layer 1`")
    c1("`Layer 2`")
    d1("`Layer 3`")
   end
   a0 &lt;-.-&gt; a1
   b0 &lt;-.-&gt; b1
   c0 &lt;-.-&gt; c1
   d0 &lt;-.-&gt; d1
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
class G0,G1, block
class a0,a1 red
class b0,b1 green
class c0,c1 blue
class d0,d1 yellow
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17: Tensor Parallel Training
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="notes">
<ul>
<li>Split up network over multiple workers
<ul>
<li>Each receives disjoint subset</li>
<li>All communication associated with subsets are distributed</li>
</ul></li>
<li>Communication whenever dataflow between two subsets</li>
<li>Typically <strong>more complicated</strong> to implement than data parallel training</li>
<li>Suitable when the model is too large to fit onto a single device (CPU / GPU)</li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed"><code>argonne-lcf/Megatron-DeepSpeed</code></a></li>
<li>🤗 <a href="https://github.com/huggingface/nanotron"><code>huggingface/nanotron</code></a></li>
</ul>
<p>See: <a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">🤗 Model Parallelism</a> for additional details</p>
</div>
</section>
<section id="tensor-model-parallel-training-example" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="tensor-model-parallel-training-example">Tensor (/ Model) Parallel Training: Example</h3>
<div class="flex-container">
<div class="column" style="width: 60%;">
<p>Want to compute: <span class="math display">y = \sum_{i} x_{i} W_{i} = x_0 W_0 + x_1 W_1 + x_2 W_2</span> where each GPU only has only its portion of the full weights as shown below</p>
<ol type="1">
<li>Compute: <span class="math inline">x_{0} W_{0}\rightarrow</span> <code>GPU1</code></li>
<li>Compute: <span class="math inline">x_{0} W_{0} + x_{1} W_{1}\rightarrow</span> <code>GPU2</code></li>
<li>Compute: <span class="math inline">y = \sum_{i} x_{i} W_{i}</span> ✅</li>
</ol>
</div>
<div class="column">
<div id="fig-tensor-parallel-example-mermaid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tensor-parallel-example-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
  subgraph X2["`GPU2`"]
    direction LR
    c("`W₂`")
  end
  subgraph X1["`GPU1`"]
    direction TB
    b("`W₁`")
  end
  subgraph X0["`GPU0`"]
    a("`W₀`")
  end
  X0 &lt;-.-&gt; X1
  X1 &lt;-.-&gt; X2
  t0("`x₀`") --&gt; X0
  t1("`x₁`") --&gt; X1
  t2("`x₂`") --&gt; X2
classDef redText fill:#CCCCCC02,stroke:#FF8181,stroke-width:2px,color:#838383,font-weight:500
classDef orangeText fill:#CCCCCC02,stroke:#FFC47F,stroke-width:2px,color:#838383
classDef yellowText fill:#CCCCCC02,stroke:#FFFF7F,stroke-width:2px,color:#838383
classDef blueText fill:#CCCCCC02,stroke:#7DCAff,stroke-width:2px,color:#838383
classDef greenText fill:#CCCCCC02,stroke:#98E6A5,stroke-width:2px,color:#838383
classDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000
classDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000
classDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000
classDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000
classDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000
classDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000
classDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383
classDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383
class a, red
class b, green
class c, blue
class X0,X1,X2, block
%%class t0, redText
%%class t1, greenText
%%class t2, blueText
class a0,b0,c0, text
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tensor-parallel-example-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18: Simple example of tensor parallelism
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="tensor-model-parallelismefficient-large-scale" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="tensor-model-parallelismefficient-large-scale">Tensor (Model) Parallelism<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></h3>
<ul>
<li>In <strong>Tensor Paralleism</strong> each GPU processes only a slice of a tensor and only aggregates the full tensor for operations that require the whole thing.
<ul>
<li>The main building block of any transformer is a fully connected <code>nn.Linear</code> followed by a nonlinear activation GeLU.
<ul>
<li><code>Y = GeLU(XA)</code>, where X and Y are the input and output vectors, and A is the weight matrix.</li>
</ul></li>
<li>If we look at the computation in matrix form, it’s easy to see how the matrix multiplication can be split between multiple GPUs:</li>
</ul></li>
</ul>
</section>
<section id="tensor-parallelism" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="tensor-parallelism">Tensor Parallelism</h3>
<div id="fig-parallel-gemm" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-parallel-gemm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="assets/parallelism-tp-parallel_gemm.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;19: Tensor Parallel GEMM. This information is based on (the much more in-depth) TP Overview by @anton-l"><img src="assets/parallelism-tp-parallel_gemm.png" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-parallel-gemm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;19: Tensor Parallel GEMM. This information is based on (the much more in-depth) <a href="https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530">TP Overview</a> by <a href="https://github.com/anton-l">@anton-l</a>
</figcaption>
</figure>
</div>
</section>
<section id="d-parallelism" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="d-parallelism">3D Parallelism</h3>
<ul>
<li><code>DP</code> + <code>TP</code> + <code>PP</code> (3D) Parallelism</li>
</ul>
<div id="fig-3dparallel" class="quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center!important;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="assets/parallelism-deepspeed-3d.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;20: Figure taken from 3D parallelism: Scaling to trillion-parameter models"><img src="assets/parallelism-deepspeed-3d.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20: Figure taken from <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/">3D parallelism: Scaling to trillion-parameter models</a>
</figcaption>
</figure>
</div>
</section>
<section id="deciding-on-a-parallelism-strategy" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="deciding-on-a-parallelism-strategy">Deciding on a Parallelism Strategy</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Single GPU</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Single Node / Multi-GPU</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Multi-Node / Multi-GPU</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<ul>
<li>Model fits onto a single GPU:
<ul>
<li>Normal use</li>
</ul></li>
<li>Model <strong>DOES NOT</strong> fit on a single GPU:
<ul>
<li><code>ZeRO</code> + Offload CPU (or, optionally, <code>NVMe</code>)</li>
</ul></li>
<li>Largest layer <strong>DOES NOT</strong> fit on a single GPU:
<ul>
<li><code>ZeRO</code> + Enable <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#memory-centric-tiling">Memory Centric Tiling (MCT)</a>
<ul>
<li>MCT Allows running of arbitrarily large layers by automatically splitting them and executing them sequentially.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="flex-container">
<div class="column">
<ul>
<li>Model fits onto a single GPU
<ul>
<li><a href="https://pytorch.org/docs/stable/notes/ddp.html"><code>DDP</code></a></li>
<li><a href="https://deepspeed.readthedocs.io/en/latest/zero3.html"><code>ZeRO</code></a></li>
</ul></li>
</ul>
</div>
<div class="column">
<ul>
<li>Model <strong>DOES NOT</strong> fit onto a single GPU
<ol type="1">
<li><a href="https://www.deepspeed.ai/tutorials/pipeline/">Pipeline Parallelism (<code>PP</code>)</a></li>
<li><a href="https://deepspeed.readthedocs.io/en/latest/zero3.html"><code>ZeRO</code></a></li>
<li><a href="https://pytorch.org/docs/stable/distributed.tensor.parallel.html">Tensor Parallelism (<code>TP</code>)</a></li>
</ol></li>
</ul>
</div>
</div>
<ul>
<li><p>With sufficiently fast connectivity between nodes, these three strategies should be comparable.</p>
<ul>
<li>Otherwise, <code>PP</code> <span class="math inline">&gt;</span> <code>ZeRO</code> <span class="math inline">\simeq</span> <code>TP</code>.</li>
</ul></li>
</ul>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<ul>
<li><p>When you have fast inter-node connectivity:</p>
<ul>
<li><code>ZeRO</code> (virtually <strong>NO</strong> modifications)</li>
<li><code>PP</code> + <code>ZeRO</code> + <code>TP</code> + <code>DP</code> (less communication, at the cost of <strong>MAJOR</strong> modifications)
<ul>
<li><p>when you have slow inter-node connectivity and still low on GPU memory:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="ex">DP</span> + PP + TP + ZeRO-1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><strong>NOTE</strong>: <code>TP</code> is almost <em>always</em> used within a single node, e.g.<br>
<code>TP &lt;= GPUS_PER_NODE</code></li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="large-language-models" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="large-language-models">Large Language Models</h2>
<div id="fig-llms" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/llms.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;21: Large Language Models have (LLM)s have taken the NLP community world by storm."><img src="./assets/llms.gif" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21: Large Language Models have (LLM)s have taken the <del>NLP community</del> <strong>world</strong> by storm<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.
</figcaption>
</figure>
</div>
<section id="emergent-abilities" class="level3" data-background-color="#FBFBFD">
<h3 data-background-color="#FBFBFD" class="anchored" data-anchor-id="emergent-abilities">Emergent Abilities</h3>
<div id="fig-emergent-abilities" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-emergent-abilities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/emergent-abilities.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;22: Emergent abilities of Large Language Models @yao2023tree"><img src="./assets/emergent-abilities.gif" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-emergent-abilities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22: <a href="https://arxiv.org/abs/2206.07682">Emergent abilities of Large Language Models</a> <span class="citation" data-cites="yao2023tree">Yao et al. (<a href="#ref-yao2023tree" role="doc-biblioref">2023</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="training-llms" class="level3 r-stretch" data-background-color="white">
<h3 class="r-stretch anchored" data-background-color="white" data-anchor-id="training-llms">Training LLMs</h3>
<div class="flex-container" style="align-items: flex-end; width:90%; text-align:center;">
<div class="column" style="width: 60%;">
<div id="fig-evolution" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/evolution.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;23: Visualization from @yang2023harnessing"><img src="./assets/evolution.gif" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23: Visualization from <span class="citation" data-cites="yang2023harnessing">Yang et al. (<a href="#ref-yang2023harnessing" role="doc-biblioref">2023</a>)</span>
</figcaption>
</figure>
</div>
</div>
<div class="column" style="width:40%;">
<div id="fig-it-hungers" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/it_hungers.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;24: It’s hungry! @wei2022emergentabilitieslargelanguage"><img src="./assets/it_hungers.jpeg" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24: It’s hungry! <span class="citation" data-cites="wei2022emergentabilitieslargelanguage">Wei et al. (<a href="#ref-wei2022emergentabilitieslargelanguage" role="doc-biblioref">2022</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="life-cycle-of-the-llm" class="level3" data-auto-animate="true" data-background-color="white">
<h3 data-auto-animate="true" data-background-color="white" class="anchored" data-anchor-id="life-cycle-of-the-llm">♻️ Life-Cycle of the LLM</h3>
<div class="flex-container">
<div class="column" style="width: 40%;">
<ol type="1">
<li>Data collection + preprocessing</li>
<li><strong>Pre-training</strong>
<ul>
<li>Architecture decisions, model size, etc.</li>
</ul></li>
<li>Supervised Fine-Tuning
<ul>
<li>Instruction Tuning</li>
<li>Alignment</li>
</ul></li>
<li>Deploy (+ monitor, re-evaluate, etc.)</li>
</ol>
</div>
<div class="column" style="width:50%;">
<div id="fig-pretrain-two" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;25: Pre-training: Virtually all of the compute used during pre-training."><img src="./assets/gpt3-training-step-back-prop.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25: <strong>Pre-training</strong>: Virtually <em>all of the compute</em> used during pre-training<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="life-cycle-of-the-llm-1" class="level3" data-auto-animate="true" data-background-color="white">
<h3 data-auto-animate="true" data-background-color="white" class="anchored" data-anchor-id="life-cycle-of-the-llm-1">🎀 Life-Cycle of the LLM</h3>
<div class="flex-container">
<div class="column" style="width: 50%;">
<ol type="1">
<li>Data collection + preprocessing</li>
<li>Pre-training
<ul>
<li>Architecture decisions, model size, etc.</li>
</ul></li>
<li><strong>Supervised Fine-Tuning</strong>
<ul>
<li>Instruction Tuning</li>
<li>Alignment</li>
</ul></li>
<li>Deploy (+ monitor, re-evaluate, etc.)</li>
</ol>
</div>
<div class="column" style="width:50%;">
<div id="fig-finetune-lifecycle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-finetune-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/gpt3-fine-tuning.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;26: Fine-tuning: Fine-tuning actually updates the model’s weights to make the model better at a certain task."><img src="./assets/gpt3-fine-tuning.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-finetune-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;26: <strong>Fine-tuning</strong>: Fine-tuning actually updates the model’s weights to make the model better at a certain task<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="forward-pass" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="forward-pass">Forward Pass</h3>
<div id="fig-hf-assisted-generation" class="quarto-float quarto-figure quarto-figure-center anchored" style="width:100%;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hf-assisted-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/hf_assisted_generation.mov" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;27: Language Model trained for causal language modeling."><video src="./assets/hf_assisted_generation.mov" class="img-fluid" controls=""></video></a><a href="./assets/hf_assisted_generation.mov">Video</a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hf-assisted-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;27: Language Model trained for causal language modeling<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.
</figcaption>
</figure>
</div>
</section>
<section id="generating-text" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="generating-text">Generating Text</h3>
<div id="fig-generating-text" class="quarto-float quarto-figure quarto-figure-center anchored" style="width: 100%;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/hf_assisted_generation2.mov" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;28: Language Model trained for causal language modeling."><video src="./assets/hf_assisted_generation2.mov" class="img-fluid" controls=""></video></a><a href="./assets/hf_assisted_generation2.mov">Video</a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;28: Language Model trained for causal language modeling<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="hands-on" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="hands-on">👋 Hands On</h2>
<p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/ai-science-training-series/tree/main/06_parallel_training#hands-on">ai-science-training-series / 06_parallel_training</a></p>
<section id="hands-on-getting-started" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="hands-on-getting-started">🧑‍💻 Hands On: Getting Started</h3>
<ol type="1">
<li><p>🌱 Clone Repo(s):</p>
<ul>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/wordplay">saforem2/<code>wordplay</code></a></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">git</span> clone https://github.com/saforem2/wordplay</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="bu">cd</span> wordplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">git</span> clone https://github.com/saforem2/ezpz deps/ezpz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><p>🐍 Setup Python:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="bu">export</span> <span class="va">PBS_O_WORKDIR</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span> <span class="kw">&amp;&amp;</span> <span class="bu">source</span> deps/ezpz/src/ezpz/bin/utils.sh</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="ex">ezpz_setup_python</span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="ex">ezpz_setup_job</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="install-ezpz-wordplay" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="install-ezpz-wordplay">📦 Install {<code>ezpz</code>, <code>wordplay</code>}</h3>
<ol type="1">
<li><p>Install Python packages:</p>
<ol type="1">
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> <span class="st">"./deps/ezpz"</span> <span class="at">--require-virtualenv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>wordplay</code></a>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># from inside `wordplay/`</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> . <span class="at">--require-virtualenv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol></li>
<li><p>Test distributed setup:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="ex">mpirun</span> <span class="at">-n</span> <span class="st">"</span><span class="va">${NGPUS}</span><span class="st">"</span> python3 <span class="at">-m</span> ezpz.test_dist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>See: 🍋 <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py"><code>ezpz/test_dist.py</code></a></p></li>
</ol>
</section>
<section id="ezpz-example-video" class="level3" data-background-color="#121314">
<h3 data-background-color="#121314" class="anchored" data-anchor-id="ezpz-example-video"><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz"><code>ezpz</code></a>: Example [<a href="https://asciinema.org/a/668460">video</a>]</h3>
<div id="fig-ezpz-asciinema" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<script src="https://asciinema.org/a/668460.js" id="asciicast-668460" async="true"></script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;29: Example: using <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py">🍋 <code>ezpz.test_dist</code></a> to train a small model using DDP
</figcaption>
</figure>
</div>
</section>
<section id="install-wordplay" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="install-wordplay">Install <a href="https://github.com/saforem2/wordplay"><code>wordplay</code> 🎮💬</a></h3>
<div id="fig-nanoGPT" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nanoGPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/nanogpt.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;30: The simplest, fastest repository for training / finetuning GPT based models. Figure from karpathy/nanoGPT"><img src="./assets/nanogpt.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nanoGPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;30: The simplest, fastest repository for training / finetuning GPT based models. Figure from <a href="https://github.com/karpathy/nanoGPT">karpathy/<code>nanoGPT</code></a>
</figcaption>
</figure>
</div>
</section>
<section id="prepare-data" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="prepare-data">Prepare Data</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1"></a><span class="ex">python3</span> wordplay/data/shakespeare_char/prepare.py</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="co"># Using HF_DATASETS_CACHE=/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/.cache/huggingface</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># length of dataset in characters: 1,115,394</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co"># all the unique characters:</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co">#  !$&amp;\',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz</span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co"># vocab size: 65</span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="co"># train has 1,003,854 tokens</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="co"># val has 111,540 tokens</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="launch-training-ddp" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="launch-training-ddp">Launch Training (DDP)</h3>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="ex">launch</span> python3 <span class="at">-m</span> wordplay <span class="dt">\</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>    train.backend=DDP <span class="dt">\</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>    train.eval_interval=100 <span class="dt">\</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>    data=shakespeare <span class="dt">\</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>    train.dtype=bf16 <span class="dt">\</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>    model.batch_size=64 <span class="dt">\</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>    model.block_size=1024 <span class="dt">\</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>    train.max_iters=1000 <span class="dt">\</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>    train.log_interval=10 <span class="dt">\</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>    train.compile=false <span class="dt">\</span></span>
<span id="cb9-11"><a href="#cb9-11"></a>    <span class="kw">|</span> <span class="fu">tee</span> wordplay-gpt2-DDP.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training-example-output" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="training-example-output">Training: Example Output</h3>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource java number-lines code-with-copy"><code class="sourceCode java"><span id="cb10-1"><a href="#cb10-1"></a></span>
<span id="cb10-2"><a href="#cb10-2"></a>```bash</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.746540</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">156</span><span class="op">]</span> <span class="op">-</span> Setting logging level to <span class="er">'</span>INFO<span class="er">'</span> on <span class="er">'</span>RANK <span class="op">==</span> <span class="dv">0</span><span class="er">'</span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.748763</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">157</span><span class="op">]</span> <span class="op">-</span> Setting logging level to <span class="er">'</span>CRITICAL<span class="er">'</span> on all others <span class="er">'</span>RANK <span class="op">!=</span> <span class="dv">0</span><span class="er">'</span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.749453</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">160</span><span class="op">]</span> <span class="op">-</span> To disable <span class="kw">this</span> behavior<span class="op">,</span> and log from ALL <span class="fu">ranks</span> <span class="op">(</span>not recommended<span class="op">),</span> set<span class="op">:</span> <span class="er">'</span>export LOG_FROM_ALL_RANKS<span class="op">=</span><span class="dv">1</span><span class="er">'</span>  in your environment<span class="op">,</span> and re<span class="op">-</span>run<span class="op">.</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.772718</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">81</span><span class="op">]</span> <span class="op">-</span> Setting HF_DATASETS_CACHE to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/.</span><span class="fu">cache</span><span class="op">/</span>huggingface<span class="op">/</span>datasets</span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.341532</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.342381</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.342430</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">3</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">3</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.348657</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">95</span><span class="op">]</span> <span class="op">-</span></span>
<span id="cb10-11"><a href="#cb10-11"></a></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="op">[</span>dist_info<span class="op">]:</span></span>
<span id="cb10-13"><a href="#cb10-13"></a>  • DEVICE<span class="op">=</span>cuda</span>
<span id="cb10-14"><a href="#cb10-14"></a>  • DEVICE_ID<span class="op">=</span>cuda<span class="op">:</span><span class="dv">0</span></span>
<span id="cb10-15"><a href="#cb10-15"></a>  • DISTRIBUTED_BACKEND<span class="op">=</span>nccl</span>
<span id="cb10-16"><a href="#cb10-16"></a>  • GPUS_PER_NODE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>  • HOSTS<span class="op">=[</span><span class="er">'</span>x3101c0s13b0n0<span class="op">.</span><span class="fu">hsn</span><span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span><span class="er">'</span><span class="op">]</span></span>
<span id="cb10-18"><a href="#cb10-18"></a>  • HOSTFILE<span class="op">=/</span><span class="dt">var</span><span class="op">/</span>spool<span class="op">/</span>pbs<span class="op">/</span>aux<span class="op">/</span><span class="fl">2024084.</span>polaris<span class="op">-</span>pbs<span class="op">-</span><span class="fl">01.</span>hsn<span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span></span>
<span id="cb10-19"><a href="#cb10-19"></a>  • HOSTNAME<span class="op">=</span>x3101c0s13b0n0<span class="op">.</span><span class="fu">hsn</span><span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span></span>
<span id="cb10-20"><a href="#cb10-20"></a>  • LOCAL_RANK<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-21"><a href="#cb10-21"></a>  • MACHINE<span class="op">=</span>Polaris</span>
<span id="cb10-22"><a href="#cb10-22"></a>  • NUM_NODES<span class="op">=</span><span class="dv">1</span></span>
<span id="cb10-23"><a href="#cb10-23"></a>  • NGPUS<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-24"><a href="#cb10-24"></a>  • NGPUS_AVAILABLE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-25"><a href="#cb10-25"></a>  • NODE_ID<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-26"><a href="#cb10-26"></a>  • RANK<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-27"><a href="#cb10-27"></a>  • SCHEDULER<span class="op">=</span>PBS</span>
<span id="cb10-28"><a href="#cb10-28"></a>  • WORLD_SIZE_TOTAL<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-29"><a href="#cb10-29"></a>  • WORLD_SIZE_IN_USE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-30"><a href="#cb10-30"></a>  • LAUNCH_CMD<span class="op">=</span>mpiexec <span class="op">--</span>verbose <span class="op">--</span>envall <span class="op">-</span>n <span class="dv">4</span> <span class="op">-</span>ppn <span class="dv">4</span> <span class="op">--</span>hostfile <span class="op">/</span><span class="dt">var</span><span class="op">/</span>spool<span class="op">/</span>pbs<span class="op">/</span>aux<span class="op">/</span><span class="fl">2024084.</span>polaris<span class="op">-</span>pbs<span class="op">-</span><span class="fl">01.</span>hsn<span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span> <span class="op">--</span>cpu<span class="op">-</span>bind depth <span class="op">-</span>d <span class="dv">16</span></span>
<span id="cb10-31"><a href="#cb10-31"></a></span>
<span id="cb10-32"><a href="#cb10-32"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.351446</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">725</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="dv">0</span><span class="op">/</span><span class="dv">4</span><span class="op">]</span> Using device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span> with backend<span class="op">=</span><span class="er">'</span>DDP<span class="er">'</span> <span class="op">+</span> <span class="er">'</span>nccl<span class="er">'</span> <span class="cf">for</span> distributed training<span class="op">.</span></span>
<span id="cb10-33"><a href="#cb10-33"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.356169</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-34"><a href="#cb10-34"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.356692</span><span class="op">][</span>WARNING<span class="op">][</span>dist<span class="op">:</span><span class="dv">364</span><span class="op">]</span> <span class="op">-</span> Using <span class="op">[</span><span class="dv">4</span> <span class="op">/</span> <span class="dv">4</span><span class="op">]</span> available <span class="st">"cuda"</span> devices <span class="op">!!</span></span>
<span id="cb10-35"><a href="#cb10-35"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.359571</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">317</span><span class="op">]</span> <span class="op">-</span> Loading val from <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>data<span class="op">/</span>shakespeare_char<span class="op">/</span>val<span class="op">.</span><span class="fu">bin</span></span>
<span id="cb10-36"><a href="#cb10-36"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.360138</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">317</span><span class="op">]</span> <span class="op">-</span> Loading train from <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>data<span class="op">/</span>shakespeare_char<span class="op">/</span>train<span class="op">.</span><span class="fu">bin</span></span>
<span id="cb10-37"><a href="#cb10-37"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.361154</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">442</span><span class="op">]</span> <span class="op">-</span> Tokens per iteration<span class="op">:</span> <span class="dv">262</span><span class="op">,</span><span class="dv">144</span></span>
<span id="cb10-38"><a href="#cb10-38"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.361574</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">465</span><span class="op">]</span> <span class="op">-</span> Using self<span class="op">.</span><span class="fu">ptdtype</span><span class="op">=</span>torch<span class="op">.</span><span class="fu">float16</span> on self<span class="op">.</span><span class="fu">device_type</span><span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span></span>
<span id="cb10-39"><a href="#cb10-39"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362002</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">471</span><span class="op">]</span> <span class="op">-</span> Initializing a <span class="kw">new</span> model from scratch</span>
<span id="cb10-40"><a href="#cb10-40"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362529</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">874</span><span class="op">]</span> <span class="op">-</span> Setting up wandb from rank<span class="op">:</span> <span class="dv">0</span></span>
<span id="cb10-41"><a href="#cb10-41"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362896</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">875</span><span class="op">]</span> <span class="op">-</span> Using<span class="op">:</span> WB PROJECT<span class="op">:</span> WordPlay</span>
<span id="cb10-42"><a href="#cb10-42"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.451786</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">905</span><span class="op">]</span> <span class="op">-</span> W<span class="op">&amp;</span>B RUN<span class="op">:</span> <span class="op">[</span>still<span class="op">-</span>frog<span class="op">-</span><span class="dv">17</span><span class="op">](</span>https<span class="op">:</span><span class="co">//wandb.ai/aurora_gpt/WordPlay/runs/6by9vpcj)</span></span>
<span id="cb10-43"><a href="#cb10-43"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.464106</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">312</span><span class="op">]</span> <span class="op">-</span> Updating wandb<span class="op">.</span><span class="fu">run</span><span class="op">:</span> still<span class="op">-</span>frog<span class="op">-</span><span class="dv">17</span> config with <span class="st">"DIST_INFO"</span></span>
<span id="cb10-44"><a href="#cb10-44"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.469424</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">938</span><span class="op">]</span> <span class="op">-</span> Running on machine<span class="op">=</span><span class="er">'</span>Polaris<span class="er">'</span></span>
<span id="cb10-45"><a href="#cb10-45"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.471151</span><span class="op">][</span>WARNING<span class="op">][</span>__main__<span class="op">:</span><span class="dv">89</span><span class="op">]</span> <span class="op">-</span> <span class="op">{</span></span>
<span id="cb10-46"><a href="#cb10-46"></a>    <span class="st">"train"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-47"><a href="#cb10-47"></a>        <span class="st">"framework"</span><span class="op">:</span> <span class="st">"pytorch"</span><span class="op">,</span></span>
<span id="cb10-48"><a href="#cb10-48"></a>        <span class="st">"backend"</span><span class="op">:</span> <span class="st">"DDP"</span><span class="op">,</span></span>
<span id="cb10-49"><a href="#cb10-49"></a>        <span class="st">"device"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-50"><a href="#cb10-50"></a>        <span class="st">"seed"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-51"><a href="#cb10-51"></a>        <span class="st">"port"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-52"><a href="#cb10-52"></a>        <span class="st">"ds_config_path"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-53"><a href="#cb10-53"></a>        <span class="st">"precision"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-54"><a href="#cb10-54"></a>        <span class="st">"ngpus"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-55"><a href="#cb10-55"></a>        <span class="st">"use_wandb"</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb10-56"><a href="#cb10-56"></a>        <span class="st">"eval_interval"</span><span class="op">:</span> <span class="dv">100</span><span class="op">,</span></span>
<span id="cb10-57"><a href="#cb10-57"></a>        <span class="st">"log_interval"</span><span class="op">:</span> <span class="dv">10</span><span class="op">,</span></span>
<span id="cb10-58"><a href="#cb10-58"></a>        <span class="st">"eval_iters"</span><span class="op">:</span> <span class="dv">200</span><span class="op">,</span></span>
<span id="cb10-59"><a href="#cb10-59"></a>        <span class="st">"eval_only"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-60"><a href="#cb10-60"></a>        <span class="st">"always_save_checkpoint"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-61"><a href="#cb10-61"></a>        <span class="st">"init_from"</span><span class="op">:</span> <span class="st">"scratch"</span><span class="op">,</span></span>
<span id="cb10-62"><a href="#cb10-62"></a>        <span class="st">"wandb_project"</span><span class="op">:</span> <span class="st">"WordPlay"</span><span class="op">,</span></span>
<span id="cb10-63"><a href="#cb10-63"></a>        <span class="st">"max_iters"</span><span class="op">:</span> <span class="dv">1000</span><span class="op">,</span></span>
<span id="cb10-64"><a href="#cb10-64"></a>        <span class="st">"warmup_iters"</span><span class="op">:</span> <span class="dv">100</span><span class="op">,</span></span>
<span id="cb10-65"><a href="#cb10-65"></a>        <span class="st">"dtype"</span><span class="op">:</span> <span class="st">"bf16"</span><span class="op">,</span></span>
<span id="cb10-66"><a href="#cb10-66"></a>        <span class="st">"compile"</span><span class="op">:</span> <span class="kw">false</span></span>
<span id="cb10-67"><a href="#cb10-67"></a>    <span class="op">},</span></span>
<span id="cb10-68"><a href="#cb10-68"></a>    <span class="st">"model"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-69"><a href="#cb10-69"></a>        <span class="st">"n_layer"</span><span class="op">:</span> <span class="dv">12</span><span class="op">,</span></span>
<span id="cb10-70"><a href="#cb10-70"></a>        <span class="st">"n_head"</span><span class="op">:</span> <span class="dv">12</span><span class="op">,</span></span>
<span id="cb10-71"><a href="#cb10-71"></a>        <span class="st">"n_embd"</span><span class="op">:</span> <span class="dv">768</span><span class="op">,</span></span>
<span id="cb10-72"><a href="#cb10-72"></a>        <span class="st">"batch_size"</span><span class="op">:</span> <span class="dv">64</span><span class="op">,</span></span>
<span id="cb10-73"><a href="#cb10-73"></a>        <span class="st">"block_size"</span><span class="op">:</span> <span class="dv">1024</span><span class="op">,</span></span>
<span id="cb10-74"><a href="#cb10-74"></a>        <span class="st">"activation"</span><span class="op">:</span> <span class="st">"gelu"</span><span class="op">,</span></span>
<span id="cb10-75"><a href="#cb10-75"></a>        <span class="st">"dropout"</span><span class="op">:</span> <span class="fl">0.0</span><span class="op">,</span></span>
<span id="cb10-76"><a href="#cb10-76"></a>        <span class="st">"bias"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-77"><a href="#cb10-77"></a>        <span class="st">"vocab_size"</span><span class="op">:</span> <span class="dv">65</span></span>
<span id="cb10-78"><a href="#cb10-78"></a>    <span class="op">},</span></span>
<span id="cb10-79"><a href="#cb10-79"></a>    <span class="st">"data"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-80"><a href="#cb10-80"></a>        <span class="st">"dataset"</span><span class="op">:</span> <span class="st">"shakespeare_char"</span><span class="op">,</span></span>
<span id="cb10-81"><a href="#cb10-81"></a>        <span class="st">"out_dir"</span><span class="op">:</span> <span class="st">"out-shakespeare-char"</span><span class="op">,</span></span>
<span id="cb10-82"><a href="#cb10-82"></a>        <span class="st">"root_path"</span><span class="op">:</span> <span class="kw">null</span></span>
<span id="cb10-83"><a href="#cb10-83"></a>    <span class="op">},</span></span>
<span id="cb10-84"><a href="#cb10-84"></a>    <span class="st">"optimizer"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-85"><a href="#cb10-85"></a>        <span class="st">"gas"</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span></span>
<span id="cb10-86"><a href="#cb10-86"></a>        <span class="st">"name"</span><span class="op">:</span> <span class="st">"AdamW"</span><span class="op">,</span></span>
<span id="cb10-87"><a href="#cb10-87"></a>        <span class="st">"learning_rate"</span><span class="op">:</span> <span class="fl">0.0006</span><span class="op">,</span></span>
<span id="cb10-88"><a href="#cb10-88"></a>        <span class="st">"weight_decay"</span><span class="op">:</span> <span class="fl">0.1</span><span class="op">,</span></span>
<span id="cb10-89"><a href="#cb10-89"></a>        <span class="st">"beta1"</span><span class="op">:</span> <span class="fl">0.9</span><span class="op">,</span></span>
<span id="cb10-90"><a href="#cb10-90"></a>        <span class="st">"beta2"</span><span class="op">:</span> <span class="fl">0.95</span><span class="op">,</span></span>
<span id="cb10-91"><a href="#cb10-91"></a>        <span class="st">"grad_clip"</span><span class="op">:</span> <span class="fl">1.0</span><span class="op">,</span></span>
<span id="cb10-92"><a href="#cb10-92"></a>        <span class="st">"decay_lr"</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb10-93"><a href="#cb10-93"></a>        <span class="st">"lr_decay_iters"</span><span class="op">:</span> <span class="dv">600000</span><span class="op">,</span></span>
<span id="cb10-94"><a href="#cb10-94"></a>        <span class="st">"min_lr"</span><span class="op">:</span> <span class="fl">6e-05</span></span>
<span id="cb10-95"><a href="#cb10-95"></a>    <span class="op">}</span></span>
<span id="cb10-96"><a href="#cb10-96"></a><span class="op">}</span></span>
<span id="cb10-97"><a href="#cb10-97"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.474305</span><span class="op">][</span>WARNING<span class="op">][</span>__main__<span class="op">:</span><span class="dv">90</span><span class="op">]</span> <span class="op">-</span> Output dir<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-98"><a href="#cb10-98"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.474922</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">246</span><span class="op">]</span> <span class="op">-</span> Initializing a <span class="kw">new</span> model from scratch</span>
<span id="cb10-99"><a href="#cb10-99"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.258904</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">255</span><span class="op">]</span> <span class="op">-</span> number of parameters<span class="op">:</span> <span class="fl">85.</span><span class="er">00</span>M</span>
<span id="cb10-100"><a href="#cb10-100"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.290004</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">264</span><span class="op">]</span> <span class="op">-</span> Model size<span class="op">:</span> num_params<span class="op">=</span><span class="dv">85003776</span></span>
<span id="cb10-101"><a href="#cb10-101"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.292626</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">445</span><span class="op">]</span> <span class="op">-</span> num decayed parameter tensors<span class="op">:</span> <span class="dv">50</span><span class="op">,</span> with <span class="dv">85</span><span class="op">,</span><span class="dv">771</span><span class="op">,</span><span class="er">008</span> parameters</span>
<span id="cb10-102"><a href="#cb10-102"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.293296</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">449</span><span class="op">]</span> <span class="op">-</span> num non<span class="op">-</span>decayed parameter tensors<span class="op">:</span> <span class="dv">25</span><span class="op">,</span> with <span class="dv">19</span><span class="op">,</span><span class="dv">200</span> parameters</span>
<span id="cb10-103"><a href="#cb10-103"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515324</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:1'"</span></span>
<span id="cb10-104"><a href="#cb10-104"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515340</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:2'"</span></span>
<span id="cb10-105"><a href="#cb10-105"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515465</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:3'"</span></span>
<span id="cb10-106"><a href="#cb10-106"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">18.431814</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">465</span><span class="op">]</span> <span class="op">-</span> using fused AdamW<span class="op">:</span> True</span>
<span id="cb10-107"><a href="#cb10-107"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">18.432620</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:0'"</span></span>
<span id="cb10-108"><a href="#cb10-108"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.951020</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">356</span><span class="op">]</span> <span class="op">-</span> • self<span class="op">.</span><span class="fu">model</span><span class="op">=</span><span class="fu">GPT</span><span class="op">(</span></span>
<span id="cb10-109"><a href="#cb10-109"></a>  <span class="op">(</span>transformer<span class="op">):</span> <span class="fu">ModuleDict</span><span class="op">(</span></span>
<span id="cb10-110"><a href="#cb10-110"></a>    <span class="op">(</span>wte<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">65</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-111"><a href="#cb10-111"></a>    <span class="op">(</span>wpe<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">1024</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-112"><a href="#cb10-112"></a>    <span class="op">(</span>drop<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-113"><a href="#cb10-113"></a>    <span class="op">(</span>h<span class="op">):</span> <span class="fu">ModuleList</span><span class="op">(</span></span>
<span id="cb10-114"><a href="#cb10-114"></a>      <span class="op">(</span><span class="dv">0</span><span class="op">-</span><span class="dv">11</span><span class="op">):</span> <span class="dv">12</span> x <span class="fu">Block</span><span class="op">(</span></span>
<span id="cb10-115"><a href="#cb10-115"></a>        <span class="op">(</span>ln_1<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-116"><a href="#cb10-116"></a>        <span class="op">(</span>attn<span class="op">):</span> <span class="fu">CausalSelfAttention</span><span class="op">(</span></span>
<span id="cb10-117"><a href="#cb10-117"></a>          <span class="op">(</span>c_attn<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">2304</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-118"><a href="#cb10-118"></a>          <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-119"><a href="#cb10-119"></a>          <span class="op">(</span>attn_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-120"><a href="#cb10-120"></a>          <span class="op">(</span>resid_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-121"><a href="#cb10-121"></a>        <span class="op">)</span></span>
<span id="cb10-122"><a href="#cb10-122"></a>        <span class="op">(</span>ln_2<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-123"><a href="#cb10-123"></a>        <span class="op">(</span>mlp<span class="op">):</span> <span class="fu">MLP</span><span class="op">(</span></span>
<span id="cb10-124"><a href="#cb10-124"></a>          <span class="op">(</span>c_fc<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-125"><a href="#cb10-125"></a>          <span class="op">(</span>act_fn<span class="op">):</span> <span class="fu">GELU</span><span class="op">(</span>approximate<span class="op">=</span><span class="er">'</span>none<span class="er">'</span><span class="op">)</span></span>
<span id="cb10-126"><a href="#cb10-126"></a>          <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-127"><a href="#cb10-127"></a>          <span class="op">(</span>dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-128"><a href="#cb10-128"></a>        <span class="op">)</span></span>
<span id="cb10-129"><a href="#cb10-129"></a>      <span class="op">)</span></span>
<span id="cb10-130"><a href="#cb10-130"></a>    <span class="op">)</span></span>
<span id="cb10-131"><a href="#cb10-131"></a>    <span class="op">(</span>ln_f<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-132"><a href="#cb10-132"></a>  <span class="op">)</span></span>
<span id="cb10-133"><a href="#cb10-133"></a>  <span class="op">(</span>lm_head<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">65</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-134"><a href="#cb10-134"></a><span class="op">)</span></span>
<span id="cb10-135"><a href="#cb10-135"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.955340</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">357</span><span class="op">]</span> <span class="op">-</span> • self<span class="op">.</span><span class="fu">grad_scaler</span><span class="op">=&lt;</span>torch<span class="op">.</span><span class="fu">cuda</span><span class="op">.</span><span class="fu">amp</span><span class="op">.</span><span class="fu">grad_scaler</span><span class="op">.</span><span class="fu">GradScaler</span> object at <span class="bn">0x145a38f0f090</span><span class="op">&gt;</span></span>
<span id="cb10-136"><a href="#cb10-136"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.956897</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> • self<span class="op">.</span><span class="fu">model_engine</span><span class="op">=</span><span class="fu">DistributedDataParallel</span><span class="op">(</span></span>
<span id="cb10-137"><a href="#cb10-137"></a>  <span class="op">(</span>module<span class="op">):</span> <span class="fu">GPT</span><span class="op">(</span></span>
<span id="cb10-138"><a href="#cb10-138"></a>    <span class="op">(</span>transformer<span class="op">):</span> <span class="fu">ModuleDict</span><span class="op">(</span></span>
<span id="cb10-139"><a href="#cb10-139"></a>      <span class="op">(</span>wte<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">65</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-140"><a href="#cb10-140"></a>      <span class="op">(</span>wpe<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">1024</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-141"><a href="#cb10-141"></a>      <span class="op">(</span>drop<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-142"><a href="#cb10-142"></a>      <span class="op">(</span>h<span class="op">):</span> <span class="fu">ModuleList</span><span class="op">(</span></span>
<span id="cb10-143"><a href="#cb10-143"></a>        <span class="op">(</span><span class="dv">0</span><span class="op">-</span><span class="dv">11</span><span class="op">):</span> <span class="dv">12</span> x <span class="fu">Block</span><span class="op">(</span></span>
<span id="cb10-144"><a href="#cb10-144"></a>          <span class="op">(</span>ln_1<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-145"><a href="#cb10-145"></a>          <span class="op">(</span>attn<span class="op">):</span> <span class="fu">CausalSelfAttention</span><span class="op">(</span></span>
<span id="cb10-146"><a href="#cb10-146"></a>            <span class="op">(</span>c_attn<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">2304</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-147"><a href="#cb10-147"></a>            <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-148"><a href="#cb10-148"></a>            <span class="op">(</span>attn_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-149"><a href="#cb10-149"></a>            <span class="op">(</span>resid_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-150"><a href="#cb10-150"></a>          <span class="op">)</span></span>
<span id="cb10-151"><a href="#cb10-151"></a>          <span class="op">(</span>ln_2<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-152"><a href="#cb10-152"></a>          <span class="op">(</span>mlp<span class="op">):</span> <span class="fu">MLP</span><span class="op">(</span></span>
<span id="cb10-153"><a href="#cb10-153"></a>            <span class="op">(</span>c_fc<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-154"><a href="#cb10-154"></a>            <span class="op">(</span>act_fn<span class="op">):</span> <span class="fu">GELU</span><span class="op">(</span>approximate<span class="op">=</span><span class="er">'</span>none<span class="er">'</span><span class="op">)</span></span>
<span id="cb10-155"><a href="#cb10-155"></a>            <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-156"><a href="#cb10-156"></a>            <span class="op">(</span>dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-157"><a href="#cb10-157"></a>          <span class="op">)</span></span>
<span id="cb10-158"><a href="#cb10-158"></a>        <span class="op">)</span></span>
<span id="cb10-159"><a href="#cb10-159"></a>      <span class="op">)</span></span>
<span id="cb10-160"><a href="#cb10-160"></a>      <span class="op">(</span>ln_f<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-161"><a href="#cb10-161"></a>    <span class="op">)</span></span>
<span id="cb10-162"><a href="#cb10-162"></a>    <span class="op">(</span>lm_head<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">65</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-163"><a href="#cb10-163"></a>  <span class="op">)</span></span>
<span id="cb10-164"><a href="#cb10-164"></a><span class="op">)</span></span>
<span id="cb10-165"><a href="#cb10-165"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.961066</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">359</span><span class="op">]</span> <span class="op">-</span> • self<span class="op">.</span><span class="fu">optimizer</span><span class="op">=</span><span class="fu">AdamW</span> <span class="op">(</span></span>
<span id="cb10-166"><a href="#cb10-166"></a><span class="bu">Parameter</span> <span class="bu">Group</span> <span class="dv">0</span></span>
<span id="cb10-167"><a href="#cb10-167"></a>    amsgrad<span class="op">:</span> False</span>
<span id="cb10-168"><a href="#cb10-168"></a>    betas<span class="op">:</span> <span class="op">(</span><span class="fl">0.9</span><span class="op">,</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span id="cb10-169"><a href="#cb10-169"></a>    capturable<span class="op">:</span> False</span>
<span id="cb10-170"><a href="#cb10-170"></a>    differentiable<span class="op">:</span> False</span>
<span id="cb10-171"><a href="#cb10-171"></a>    eps<span class="op">:</span> <span class="fl">1e-08</span></span>
<span id="cb10-172"><a href="#cb10-172"></a>    foreach<span class="op">:</span> None</span>
<span id="cb10-173"><a href="#cb10-173"></a>    fused<span class="op">:</span> True</span>
<span id="cb10-174"><a href="#cb10-174"></a>    lr<span class="op">:</span> <span class="fl">0.0006</span></span>
<span id="cb10-175"><a href="#cb10-175"></a>    maximize<span class="op">:</span> False</span>
<span id="cb10-176"><a href="#cb10-176"></a>    weight_decay<span class="op">:</span> <span class="fl">0.1</span></span>
<span id="cb10-177"><a href="#cb10-177"></a></span>
<span id="cb10-178"><a href="#cb10-178"></a><span class="bu">Parameter</span> <span class="bu">Group</span> <span class="dv">1</span></span>
<span id="cb10-179"><a href="#cb10-179"></a>    amsgrad<span class="op">:</span> False</span>
<span id="cb10-180"><a href="#cb10-180"></a>    betas<span class="op">:</span> <span class="op">(</span><span class="fl">0.9</span><span class="op">,</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span id="cb10-181"><a href="#cb10-181"></a>    capturable<span class="op">:</span> False</span>
<span id="cb10-182"><a href="#cb10-182"></a>    differentiable<span class="op">:</span> False</span>
<span id="cb10-183"><a href="#cb10-183"></a>    eps<span class="op">:</span> <span class="fl">1e-08</span></span>
<span id="cb10-184"><a href="#cb10-184"></a>    foreach<span class="op">:</span> None</span>
<span id="cb10-185"><a href="#cb10-185"></a>    fused<span class="op">:</span> True</span>
<span id="cb10-186"><a href="#cb10-186"></a>    lr<span class="op">:</span> <span class="fl">0.0006</span></span>
<span id="cb10-187"><a href="#cb10-187"></a>    maximize<span class="op">:</span> False</span>
<span id="cb10-188"><a href="#cb10-188"></a>    weight_decay<span class="op">:</span> <span class="fl">0.0</span></span>
<span id="cb10-189"><a href="#cb10-189"></a><span class="op">)</span></span>
<span id="cb10-190"><a href="#cb10-190"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.988827</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">802</span><span class="op">]</span> <span class="op">-</span> Startup time<span class="op">:</span> <span class="fl">6.7125</span></span>
<span id="cb10-191"><a href="#cb10-191"></a>                Training Legend</span>
<span id="cb10-192"><a href="#cb10-192"></a>┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span id="cb10-193"><a href="#cb10-193"></a>┃    abbr     ┃ desc                           ┃</span>
<span id="cb10-194"><a href="#cb10-194"></a>┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩</span>
<span id="cb10-195"><a href="#cb10-195"></a>│    step     │ <span class="bu">Current</span> training iteration     │</span>
<span id="cb10-196"><a href="#cb10-196"></a>│    loss     │ Loss value                     │</span>
<span id="cb10-197"><a href="#cb10-197"></a>│     dt      │ Elapsed time per training step │</span>
<span id="cb10-198"><a href="#cb10-198"></a>│     dtf     │ Elapsed time per forward step  │</span>
<span id="cb10-199"><a href="#cb10-199"></a>│     dtb     │ Elapsed time per backward step │</span>
<span id="cb10-200"><a href="#cb10-200"></a>│     sps     │ Samples per second             │</span>
<span id="cb10-201"><a href="#cb10-201"></a>│ sps_per_gpu │ Samples per <span class="fu">second</span> <span class="op">(</span>per GPU<span class="op">)</span>   │</span>
<span id="cb10-202"><a href="#cb10-202"></a>│     tps     │ Tokens per second              │</span>
<span id="cb10-203"><a href="#cb10-203"></a>│ tps_per_gpu │ Tokens per <span class="fu">second</span> <span class="op">(</span>per GPU<span class="op">)</span>    │</span>
<span id="cb10-204"><a href="#cb10-204"></a>│     mfu     │ Model flops utilization        │</span>
<span id="cb10-205"><a href="#cb10-205"></a>│ train_loss  │ Training loss value            │</span>
<span id="cb10-206"><a href="#cb10-206"></a>│  val_loss   │ Validation loss value          │</span>
<span id="cb10-207"><a href="#cb10-207"></a>└─────────────┴────────────────────────────────┘</span>
<span id="cb10-208"><a href="#cb10-208"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">21.451865</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-209"><a href="#cb10-209"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">21.452667</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-210"><a href="#cb10-210"></a>What is an LLM<span class="op">?</span>eelEl\<span class="er">'</span>$nltPwBSWal<span class="op">,;</span>PWw bbu\<span class="er">'</span>HiyP\<span class="er">'</span>FWwF <span class="op">&amp;</span>AhW<span class="op">:</span>ygrn kk<span class="op">-</span>\<span class="er">'\'</span>KFlMwnlEfflkc<span class="op">,</span>elpWaWtgml$Pgglhllw lglhFllzczPAFHpeAAPPSltgkrWPPhlEMgcrN ggPWt<span class="op">-</span>WPSSzHSkkrzzk<span class="op">.</span><span class="fu">FFrtSSkgMll</span><span class="op">&amp;</span>gFXr<span class="op">,</span>hghaueaVPW<span class="op">-</span>pHFF<span class="op">-</span>gg<span class="op">,,,</span>FF<span class="op">,,</span>kbApgg gg\<span class="er">'</span>aWWzzkk\<span class="er">'</span>a\<span class="er">'</span>CggHl$bGeA<span class="op">,</span>FFk<span class="op">,,</span>SF<span class="op">;</span>UF<span class="op">,,</span>aZ <span class="op">;</span>gglee$<span class="op">,</span>k<span class="op">.</span><span class="fu">US</span><span class="op">&amp;</span>kg<span class="op">:</span>S<span class="op">,,</span>zVzzc</span>
<span id="cb10-211"><a href="#cb10-211"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">01.573073</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">10</span> loss<span class="op">=</span><span class="fl">3.154310</span> dt<span class="op">=</span><span class="fl">0.282833</span> dtf<span class="op">=</span><span class="fl">0.005247</span> dtb<span class="op">=</span><span class="fl">0.011417</span> sps<span class="op">=</span><span class="fl">14.142633</span> sps_per_gpu<span class="op">=</span><span class="fl">3.535658</span> tps<span class="op">=</span><span class="fl">926851.609409</span> tps_per_gpu<span class="op">=</span><span class="fl">231712.902352</span> mfu<span class="op">=</span><span class="fl">46.288281</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-212"><a href="#cb10-212"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">04.402750</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">20</span> loss<span class="op">=</span><span class="fl">2.660851</span> dt<span class="op">=</span><span class="fl">0.306263</span> dtf<span class="op">=</span><span class="fl">0.005233</span> dtb<span class="op">=</span><span class="fl">0.011419</span> sps<span class="op">=</span><span class="fl">13.060678</span> sps_per_gpu<span class="op">=</span><span class="fl">3.265170</span> tps<span class="op">=</span><span class="fl">855944.613638</span> tps_per_gpu<span class="op">=</span><span class="fl">213986.153409</span> mfu<span class="op">=</span><span class="fl">45.934162</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-213"><a href="#cb10-213"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">07.237507</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">30</span> loss<span class="op">=</span><span class="fl">2.543283</span> dt<span class="op">=</span><span class="fl">0.283021</span> dtf<span class="op">=</span><span class="fl">0.005238</span> dtb<span class="op">=</span><span class="fl">0.011245</span> sps<span class="op">=</span><span class="fl">14.133211</span> sps_per_gpu<span class="op">=</span><span class="fl">3.533303</span> tps<span class="op">=</span><span class="fl">926234.088226</span> tps_per_gpu<span class="op">=</span><span class="fl">231558.522057</span> mfu<span class="op">=</span><span class="fl">45.966490</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-214"><a href="#cb10-214"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">10.077248</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">40</span> loss<span class="op">=</span><span class="fl">2.503963</span> dt<span class="op">=</span><span class="fl">0.285001</span> dtf<span class="op">=</span><span class="fl">0.005213</span> dtb<span class="op">=</span><span class="fl">0.011471</span> sps<span class="op">=</span><span class="fl">14.035061</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508765</span> tps<span class="op">=</span><span class="fl">919801.749941</span> tps_per_gpu<span class="op">=</span><span class="fl">229950.437485</span> mfu<span class="op">=</span><span class="fl">45.963461</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-215"><a href="#cb10-215"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">12.917039</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">50</span> loss<span class="op">=</span><span class="fl">2.477469</span> dt<span class="op">=</span><span class="fl">0.283532</span> dtf<span class="op">=</span><span class="fl">0.005166</span> dtb<span class="op">=</span><span class="fl">0.011294</span> sps<span class="op">=</span><span class="fl">14.107763</span> sps_per_gpu<span class="op">=</span><span class="fl">3.526941</span> tps<span class="op">=</span><span class="fl">924566.380009</span> tps_per_gpu<span class="op">=</span><span class="fl">231141.595002</span> mfu<span class="op">=</span><span class="fl">45.984530</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-216"><a href="#cb10-216"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">15.760749</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">60</span> loss<span class="op">=</span><span class="fl">2.471083</span> dt<span class="op">=</span><span class="fl">0.284630</span> dtf<span class="op">=</span><span class="fl">0.005140</span> dtb<span class="op">=</span><span class="fl">0.011224</span> sps<span class="op">=</span><span class="fl">14.053326</span> sps_per_gpu<span class="op">=</span><span class="fl">3.513332</span> tps<span class="op">=</span><span class="fl">920998.786204</span> tps_per_gpu<span class="op">=</span><span class="fl">230249.696551</span> mfu<span class="op">=</span><span class="fl">45.985675</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-217"><a href="#cb10-217"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">18.602785</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">70</span> loss<span class="op">=</span><span class="fl">2.458894</span> dt<span class="op">=</span><span class="fl">0.283926</span> dtf<span class="op">=</span><span class="fl">0.005219</span> dtb<span class="op">=</span><span class="fl">0.010383</span> sps<span class="op">=</span><span class="fl">14.088155</span> sps_per_gpu<span class="op">=</span><span class="fl">3.522039</span> tps<span class="op">=</span><span class="fl">923281.352698</span> tps_per_gpu<span class="op">=</span><span class="fl">230820.338174</span> mfu<span class="op">=</span><span class="fl">45.998106</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-218"><a href="#cb10-218"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">21.451433</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">80</span> loss<span class="op">=</span><span class="fl">2.489088</span> dt<span class="op">=</span><span class="fl">0.285537</span> dtf<span class="op">=</span><span class="fl">0.005183</span> dtb<span class="op">=</span><span class="fl">0.011373</span> sps<span class="op">=</span><span class="fl">14.008683</span> sps_per_gpu<span class="op">=</span><span class="fl">3.502171</span> tps<span class="op">=</span><span class="fl">918073.060430</span> tps_per_gpu<span class="op">=</span><span class="fl">229518.265108</span> mfu<span class="op">=</span><span class="fl">45.983282</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-219"><a href="#cb10-219"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">24.302241</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">90</span> loss<span class="op">=</span><span class="fl">2.471990</span> dt<span class="op">=</span><span class="fl">0.300767</span> dtf<span class="op">=</span><span class="fl">0.005445</span> dtb<span class="op">=</span><span class="fl">0.010290</span> sps<span class="op">=</span><span class="fl">13.299337</span> sps_per_gpu<span class="op">=</span><span class="fl">3.324834</span> tps<span class="op">=</span><span class="fl">871585.359388</span> tps_per_gpu<span class="op">=</span><span class="fl">217896.339847</span> mfu<span class="op">=</span><span class="fl">45.737774</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-220"><a href="#cb10-220"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">27.153275</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">100</span> loss<span class="op">=</span><span class="fl">2.445556</span> dt<span class="op">=</span><span class="fl">0.285869</span> dtf<span class="op">=</span><span class="fl">0.005182</span> dtb<span class="op">=</span><span class="fl">0.011251</span> sps<span class="op">=</span><span class="fl">13.992403</span> sps_per_gpu<span class="op">=</span><span class="fl">3.498101</span> tps<span class="op">=</span><span class="fl">917006.151328</span> tps_per_gpu<span class="op">=</span><span class="fl">229251.537832</span> mfu<span class="op">=</span><span class="fl">45.743655</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-221"><a href="#cb10-221"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">28.182553</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-222"><a href="#cb10-222"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">28.183179</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-223"><a href="#cb10-223"></a></span>
<span id="cb10-224"><a href="#cb10-224"></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-225"><a href="#cb10-225"></a></span>
<span id="cb10-226"><a href="#cb10-226"></a>Goupay my winghimithell bls ger t bon sinthard ht omind be<span class="op">,</span></span>
<span id="cb10-227"><a href="#cb10-227"></a>And lereind h py balithand frd oforondof wimon me hageas thinero mand<span class="op">,</span></span>
<span id="cb10-228"><a href="#cb10-228"></a>Thacanes<span class="op">,</span></span>
<span id="cb10-229"><a href="#cb10-229"></a>An frift ghik med d herthecke ntore thack couthen ale<span class="op">,</span> t thit ang d m t h chy me fache ag<span class="op">,</span> wit my hathan glat ng</span>
<span id="cb10-230"><a href="#cb10-230"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">06.025837</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-231"><a href="#cb10-231"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">06.026607</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-232"><a href="#cb10-232"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">07.682968</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-233"><a href="#cb10-233"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">10.519506</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">110</span> loss<span class="op">=</span><span class="fl">2.433923</span> dt<span class="op">=</span><span class="fl">0.285038</span> dtf<span class="op">=</span><span class="fl">0.005757</span> dtb<span class="op">=</span><span class="fl">0.011762</span> sps<span class="op">=</span><span class="fl">14.033209</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508302</span> tps<span class="op">=</span><span class="fl">919680.367894</span> tps_per_gpu<span class="op">=</span><span class="fl">229920.091974</span> mfu<span class="op">=</span><span class="fl">45.762304</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-234"><a href="#cb10-234"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">13.362148</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">120</span> loss<span class="op">=</span><span class="fl">2.429014</span> dt<span class="op">=</span><span class="fl">0.284445</span> dtf<span class="op">=</span><span class="fl">0.005222</span> dtb<span class="op">=</span><span class="fl">0.011486</span> sps<span class="op">=</span><span class="fl">14.062460</span> sps_per_gpu<span class="op">=</span><span class="fl">3.515615</span> tps<span class="op">=</span><span class="fl">921597.361532</span> tps_per_gpu<span class="op">=</span><span class="fl">230399.340383</span> mfu<span class="op">=</span><span class="fl">45.788661</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-235"><a href="#cb10-235"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">16.210694</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">130</span> loss<span class="op">=</span><span class="fl">2.402059</span> dt<span class="op">=</span><span class="fl">0.285559</span> dtf<span class="op">=</span><span class="fl">0.005199</span> dtb<span class="op">=</span><span class="fl">0.011765</span> sps<span class="op">=</span><span class="fl">14.007633</span> sps_per_gpu<span class="op">=</span><span class="fl">3.501908</span> tps<span class="op">=</span><span class="fl">918004.211586</span> tps_per_gpu<span class="op">=</span><span class="fl">229501.052897</span> mfu<span class="op">=</span><span class="fl">45.794438</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-236"><a href="#cb10-236"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">19.061546</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">140</span> loss<span class="op">=</span><span class="fl">2.374062</span> dt<span class="op">=</span><span class="fl">0.285476</span> dtf<span class="op">=</span><span class="fl">0.005239</span> dtb<span class="op">=</span><span class="fl">0.011453</span> sps<span class="op">=</span><span class="fl">14.011662</span> sps_per_gpu<span class="op">=</span><span class="fl">3.502916</span> tps<span class="op">=</span><span class="fl">918268.297093</span> tps_per_gpu<span class="op">=</span><span class="fl">229567.074273</span> mfu<span class="op">=</span><span class="fl">45.800956</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-237"><a href="#cb10-237"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">21.917283</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">150</span> loss<span class="op">=</span><span class="fl">2.365385</span> dt<span class="op">=</span><span class="fl">0.285846</span> dtf<span class="op">=</span><span class="fl">0.005125</span> dtb<span class="op">=</span><span class="fl">0.011320</span> sps<span class="op">=</span><span class="fl">13.993568</span> sps_per_gpu<span class="op">=</span><span class="fl">3.498392</span> tps<span class="op">=</span><span class="fl">917082.475791</span> tps_per_gpu<span class="op">=</span><span class="fl">229270.618948</span> mfu<span class="op">=</span><span class="fl">45.800900</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-238"><a href="#cb10-238"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">24.771924</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">160</span> loss<span class="op">=</span><span class="fl">2.317337</span> dt<span class="op">=</span><span class="fl">0.280788</span> dtf<span class="op">=</span><span class="fl">0.005173</span> dtb<span class="op">=</span><span class="fl">0.011249</span> sps<span class="op">=</span><span class="fl">14.245602</span> sps_per_gpu<span class="op">=</span><span class="fl">3.561401</span> tps<span class="op">=</span><span class="fl">933599.792506</span> tps_per_gpu<span class="op">=</span><span class="fl">233399.948127</span> mfu<span class="op">=</span><span class="fl">45.883340</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-239"><a href="#cb10-239"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">27.626812</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">170</span> loss<span class="op">=</span><span class="fl">2.256231</span> dt<span class="op">=</span><span class="fl">0.284973</span> dtf<span class="op">=</span><span class="fl">0.005141</span> dtb<span class="op">=</span><span class="fl">0.011299</span> sps<span class="op">=</span><span class="fl">14.036416</span> sps_per_gpu<span class="op">=</span><span class="fl">3.509104</span> tps<span class="op">=</span><span class="fl">919890.544506</span> tps_per_gpu<span class="op">=</span><span class="fl">229972.636126</span> mfu<span class="op">=</span><span class="fl">45.889069</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-240"><a href="#cb10-240"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">30.480952</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">180</span> loss<span class="op">=</span><span class="fl">2.216419</span> dt<span class="op">=</span><span class="fl">0.286555</span> dtf<span class="op">=</span><span class="fl">0.005180</span> dtb<span class="op">=</span><span class="fl">0.011402</span> sps<span class="op">=</span><span class="fl">13.958906</span> sps_per_gpu<span class="op">=</span><span class="fl">3.489726</span> tps<span class="op">=</span><span class="fl">914810.852170</span> tps_per_gpu<span class="op">=</span><span class="fl">228702.713043</span> mfu<span class="op">=</span><span class="fl">45.868857</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-241"><a href="#cb10-241"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">33.337342</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">190</span> loss<span class="op">=</span><span class="fl">2.145123</span> dt<span class="op">=</span><span class="fl">0.291456</span> dtf<span class="op">=</span><span class="fl">0.005409</span> dtb<span class="op">=</span><span class="fl">0.019347</span> sps<span class="op">=</span><span class="fl">13.724205</span> sps_per_gpu<span class="op">=</span><span class="fl">3.431051</span> tps<span class="op">=</span><span class="fl">899429.467247</span> tps_per_gpu<span class="op">=</span><span class="fl">224857.366812</span> mfu<span class="op">=</span><span class="fl">45.773849</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-242"><a href="#cb10-242"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">36.194584</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">200</span> loss<span class="op">=</span><span class="fl">2.068149</span> dt<span class="op">=</span><span class="fl">0.285703</span> dtf<span class="op">=</span><span class="fl">0.005153</span> dtb<span class="op">=</span><span class="fl">0.011286</span> sps<span class="op">=</span><span class="fl">14.000555</span> sps_per_gpu<span class="op">=</span><span class="fl">3.500139</span> tps<span class="op">=</span><span class="fl">917540.393411</span> tps_per_gpu<span class="op">=</span><span class="fl">229385.098353</span> mfu<span class="op">=</span><span class="fl">45.778791</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-243"><a href="#cb10-243"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">37.224149</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-244"><a href="#cb10-244"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">37.224745</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-245"><a href="#cb10-245"></a></span>
<span id="cb10-246"><a href="#cb10-246"></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-247"><a href="#cb10-247"></a></span>
<span id="cb10-248"><a href="#cb10-248"></a>LORTESS LA<span class="op">:</span></span>
<span id="cb10-249"><a href="#cb10-249"></a>No<span class="op">,</span> sighappat selace<span class="op">?</span> don downd sourciceans note cancen up sof liond</span>
<span id="cb10-250"><a href="#cb10-250"></a>This and my man<span class="op">,</span> werame<span class="op">,</span> of re thee</span>
<span id="cb10-251"><a href="#cb10-251"></a>Thise not will I on land brond sul me a fingore<span class="op">?</span></span>
<span id="cb10-252"><a href="#cb10-252"></a></span>
<span id="cb10-253"><a href="#cb10-253"></a>FLER<span class="op">:</span></span>
<span id="cb10-254"><a href="#cb10-254"></a>Tisint your not nare lame o igen<span class="op">,-</span>to brorst<span class="op">.</span></span>
<span id="cb10-255"><a href="#cb10-255"></a></span>
<span id="cb10-256"><a href="#cb10-256"></a><span class="fu">SamERS</span><span class="op">:</span></span>
<span id="cb10-257"><a href="#cb10-257"></a>Sin<span class="op">:</span></span>
<span id="cb10-258"><a href="#cb10-258"></a>I\<span class="er">'</span>l hell she lor hen w</span>
<span id="cb10-259"><a href="#cb10-259"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">14.409129</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-260"><a href="#cb10-260"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">14.409820</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-261"><a href="#cb10-261"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">16.366935</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-262"><a href="#cb10-262"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">19.245061</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">210</span> loss<span class="op">=</span><span class="fl">1.982169</span> dt<span class="op">=</span><span class="fl">0.283305</span> dtf<span class="op">=</span><span class="fl">0.005223</span> dtb<span class="op">=</span><span class="fl">0.011284</span> sps<span class="op">=</span><span class="fl">14.119042</span> sps_per_gpu<span class="op">=</span><span class="fl">3.529760</span> tps<span class="op">=</span><span class="fl">925305.515083</span> tps_per_gpu<span class="op">=</span><span class="fl">231326.378771</span> mfu<span class="op">=</span><span class="fl">45.822019</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-263"><a href="#cb10-263"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">22.092430</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">220</span> loss<span class="op">=</span><span class="fl">1.897731</span> dt<span class="op">=</span><span class="fl">0.284759</span> dtf<span class="op">=</span><span class="fl">0.005217</span> dtb<span class="op">=</span><span class="fl">0.011187</span> sps<span class="op">=</span><span class="fl">14.046945</span> sps_per_gpu<span class="op">=</span><span class="fl">3.511736</span> tps<span class="op">=</span><span class="fl">920580.608106</span> tps_per_gpu<span class="op">=</span><span class="fl">230145.152026</span> mfu<span class="op">=</span><span class="fl">45.837327</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-264"><a href="#cb10-264"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">24.942639</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">230</span> loss<span class="op">=</span><span class="fl">1.817213</span> dt<span class="op">=</span><span class="fl">0.285266</span> dtf<span class="op">=</span><span class="fl">0.005208</span> dtb<span class="op">=</span><span class="fl">0.011446</span> sps<span class="op">=</span><span class="fl">14.022003</span> sps_per_gpu<span class="op">=</span><span class="fl">3.505501</span> tps<span class="op">=</span><span class="fl">918945.985503</span> tps_per_gpu<span class="op">=</span><span class="fl">229736.496376</span> mfu<span class="op">=</span><span class="fl">45.842940</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-265"><a href="#cb10-265"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">27.797910</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">240</span> loss<span class="op">=</span><span class="fl">1.779287</span> dt<span class="op">=</span><span class="fl">0.285465</span> dtf<span class="op">=</span><span class="fl">0.005189</span> dtb<span class="op">=</span><span class="fl">0.011220</span> sps<span class="op">=</span><span class="fl">14.012250</span> sps_per_gpu<span class="op">=</span><span class="fl">3.503062</span> tps<span class="op">=</span><span class="fl">918306.793546</span> tps_per_gpu<span class="op">=</span><span class="fl">229576.698387</span> mfu<span class="op">=</span><span class="fl">45.844800</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-266"><a href="#cb10-266"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">30.653597</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">250</span> loss<span class="op">=</span><span class="fl">1.704220</span> dt<span class="op">=</span><span class="fl">0.289284</span> dtf<span class="op">=</span><span class="fl">0.005471</span> dtb<span class="op">=</span><span class="fl">0.010346</span> sps<span class="op">=</span><span class="fl">13.827253</span> sps_per_gpu<span class="op">=</span><span class="fl">3.456813</span> tps<span class="op">=</span><span class="fl">906182.836379</span> tps_per_gpu<span class="op">=</span><span class="fl">226545.709095</span> mfu<span class="op">=</span><span class="fl">45.785926</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-267"><a href="#cb10-267"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">33.512769</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">260</span> loss<span class="op">=</span><span class="fl">1.671318</span> dt<span class="op">=</span><span class="fl">0.287679</span> dtf<span class="op">=</span><span class="fl">0.005125</span> dtb<span class="op">=</span><span class="fl">0.011250</span> sps<span class="op">=</span><span class="fl">13.904380</span> sps_per_gpu<span class="op">=</span><span class="fl">3.476095</span> tps<span class="op">=</span><span class="fl">911237.442617</span> tps_per_gpu<span class="op">=</span><span class="fl">227809.360654</span> mfu<span class="op">=</span><span class="fl">45.758182</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-268"><a href="#cb10-268"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">36.373461</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">270</span> loss<span class="op">=</span><span class="fl">1.650952</span> dt<span class="op">=</span><span class="fl">0.298661</span> dtf<span class="op">=</span><span class="fl">0.005118</span> dtb<span class="op">=</span><span class="fl">0.011520</span> sps<span class="op">=</span><span class="fl">13.393107</span> sps_per_gpu<span class="op">=</span><span class="fl">3.348277</span> tps<span class="op">=</span><span class="fl">877730.651421</span> tps_per_gpu<span class="op">=</span><span class="fl">219432.662855</span> mfu<span class="op">=</span><span class="fl">45.565875</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-269"><a href="#cb10-269"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">39.236930</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">280</span> loss<span class="op">=</span><span class="fl">1.573242</span> dt<span class="op">=</span><span class="fl">0.285970</span> dtf<span class="op">=</span><span class="fl">0.005171</span> dtb<span class="op">=</span><span class="fl">0.011290</span> sps<span class="op">=</span><span class="fl">13.987477</span> sps_per_gpu<span class="op">=</span><span class="fl">3.496869</span> tps<span class="op">=</span><span class="fl">916683.279847</span> tps_per_gpu<span class="op">=</span><span class="fl">229170.819962</span> mfu<span class="op">=</span><span class="fl">45.587333</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-270"><a href="#cb10-270"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">42.100605</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">290</span> loss<span class="op">=</span><span class="fl">1.533265</span> dt<span class="op">=</span><span class="fl">0.286487</span> dtf<span class="op">=</span><span class="fl">0.005432</span> dtb<span class="op">=</span><span class="fl">0.011288</span> sps<span class="op">=</span><span class="fl">13.962259</span> sps_per_gpu<span class="op">=</span><span class="fl">3.490565</span> tps<span class="op">=</span><span class="fl">915030.617828</span> tps_per_gpu<span class="op">=</span><span class="fl">228757.654457</span> mfu<span class="op">=</span><span class="fl">45.598392</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-271"><a href="#cb10-271"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">44.964424</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">300</span> loss<span class="op">=</span><span class="fl">1.492064</span> dt<span class="op">=</span><span class="fl">0.288480</span> dtf<span class="op">=</span><span class="fl">0.005355</span> dtb<span class="op">=</span><span class="fl">0.011480</span> sps<span class="op">=</span><span class="fl">13.865774</span> sps_per_gpu<span class="op">=</span><span class="fl">3.466443</span> tps<span class="op">=</span><span class="fl">908707.340870</span> tps_per_gpu<span class="op">=</span><span class="fl">227176.835218</span> mfu<span class="op">=</span><span class="fl">45.576766</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-272"><a href="#cb10-272"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">45.995833</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-273"><a href="#cb10-273"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">45.996497</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-274"><a href="#cb10-274"></a></span>
<span id="cb10-275"><a href="#cb10-275"></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-276"><a href="#cb10-276"></a></span>
<span id="cb10-277"><a href="#cb10-277"></a>RICHMORD<span class="op">:</span></span>
<span id="cb10-278"><a href="#cb10-278"></a>Char stire<span class="op">?</span> how in those are name the range hone<span class="op">.</span></span>
<span id="cb10-279"><a href="#cb10-279"></a></span>
<span id="cb10-280"><a href="#cb10-280"></a><span class="fu">GLOUCESTER</span><span class="op">:</span></span>
<span id="cb10-281"><a href="#cb10-281"></a>Nay<span class="op">,</span> in lond<span class="er">'</span>s time the palt are worder more</span>
<span id="cb10-282"><a href="#cb10-282"></a>That wilt in the purpose be a pey</span>
<span id="cb10-283"><a href="#cb10-283"></a>And thou thine onter hands<span class="op">,</span> and the which broth<span class="op">.</span></span>
<span id="cb10-284"><a href="#cb10-284"></a></span>
<span id="cb10-285"><a href="#cb10-285"></a><span class="fu">ELBOWINCA</span><span class="op">:</span></span>
<span id="cb10-286"><a href="#cb10-286"></a>At lie my lord with the me an arms be a s</span>
<span id="cb10-287"><a href="#cb10-287"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">23.549987</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-288"><a href="#cb10-288"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">23.550696</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-289"><a href="#cb10-289"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">25.496559</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-290"><a href="#cb10-290"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">28.374854</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">310</span> loss<span class="op">=</span><span class="fl">1.444200</span> dt<span class="op">=</span><span class="fl">0.299907</span> dtf<span class="op">=</span><span class="fl">0.005333</span> dtb<span class="op">=</span><span class="fl">0.010637</span> sps<span class="op">=</span><span class="fl">13.337481</span> sps_per_gpu<span class="op">=</span><span class="fl">3.334370</span> tps<span class="op">=</span><span class="fl">874085.133345</span> tps_per_gpu<span class="op">=</span><span class="fl">218521.283336</span> mfu<span class="op">=</span><span class="fl">45.384395</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-291"><a href="#cb10-291"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">31.223079</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">320</span> loss<span class="op">=</span><span class="fl">1.429350</span> dt<span class="op">=</span><span class="fl">0.285238</span> dtf<span class="op">=</span><span class="fl">0.005245</span> dtb<span class="op">=</span><span class="fl">0.011485</span> sps<span class="op">=</span><span class="fl">14.023353</span> sps_per_gpu<span class="op">=</span><span class="fl">3.505838</span> tps<span class="op">=</span><span class="fl">919034.479880</span> tps_per_gpu<span class="op">=</span><span class="fl">229758.619970</span> mfu<span class="op">=</span><span class="fl">45.435743</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-292"><a href="#cb10-292"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">34.074957</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">330</span> loss<span class="op">=</span><span class="fl">1.362220</span> dt<span class="op">=</span><span class="fl">0.285027</span> dtf<span class="op">=</span><span class="fl">0.005165</span> dtb<span class="op">=</span><span class="fl">0.011407</span> sps<span class="op">=</span><span class="fl">14.033736</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508434</span> tps<span class="op">=</span><span class="fl">919714.904826</span> tps_per_gpu<span class="op">=</span><span class="fl">229928.726207</span> mfu<span class="op">=</span><span class="fl">45.485355</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-293"><a href="#cb10-293"></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">36.929464</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">340</span> loss<span class="op">=</span><span class="fl">1.350888</span> dt<span class="op">=</span><span class="fl">0.284436</span> dtf<span class="op">=</span><span class="fl">0.005199</span> dtb<span class="op">=</span><span class="fl">0.011287</span> sps<span class="op">=</span><span class="fl">14.062893</span> sps_per_gpu<span class="op">=</span><span class="fl">3.515723</span> tps<span class="op">=</span><span class="fl">921625.744709</span> tps_per_gpu<span class="op">=</span><span class="fl">230406.436177</span> mfu<span class="op">=</span><span class="fl">45.539549</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-294"><a href="#cb10-294"></a>```</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="wordplay-example-video" class="level3" data-background-color="#121314">
<h3 data-background-color="#121314" class="anchored" data-anchor-id="wordplay-example-video"><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/wordplay"><code>wordplay</code></a>: Example [<a href="https://asciinema.org/a/668462">video</a>]</h3>
<div id="fig-wordplay-asciinema" class="asciinema quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wordplay-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<script src="https://asciinema.org/a/668462.js" id="asciicast-668462" async="true"></script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wordplay-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;31: Training a LLM to talk like Shakespeare using <a href="https://github.com/saforem2/wordplay">saforem2/<code>wordplay</code> 🎮💬</a>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="thank-you" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="thank-you">❤️ Thank you!</h2>
<ul>
<li><p>Organizers</p></li>
<li><p>Feel free to reach out!</p>
<p><split even=""></split></p>
<p><a href="https://samforeman.me"><i class="fas fa-home"></i></a> <a href="mailto:foremans@anl.gov"><i class="far fa-paper-plane"></i></a> <a href="https://www.twitter.com/saforem2"><i class="fab fa-twitter"></i></a></p>
<p></p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Acknowledgements">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Acknowledgements
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357</p>
</div>
</div>
</div>
</section>
<section id="references" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="references">📓 References</h2>
<ul>
<li>Title slide (Tetris animation) from: <a href="https://emilhvitfeldt.github.io/quarto-iframe-examples/tetris/index.html" class="uri">https://emilhvitfeldt.github.io/quarto-iframe-examples/tetris/index.html</a></li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-wei2022emergentabilitieslargelanguage" class="csl-entry" role="listitem">
Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. <span>“Emergent Abilities of Large Language Models.”</span> <a href="https://arxiv.org/abs/2206.07682">https://arxiv.org/abs/2206.07682</a>.
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. <span>“Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.”</span> <a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a>.
</div>
<div id="ref-yao2023tree" class="csl-entry" role="listitem">
Yao, Shunyu, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. <span>“Tree of Thoughts: Deliberate Problem Solving with Large Language Models.”</span> <a href="https://arxiv.org/abs/2305.10601">https://arxiv.org/abs/2305.10601</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p><code>micro_batch_size</code> = batch_size <strong>per</strong> GPU<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://arxiv.org/abs/2104.04473">Efficient Large-Scale Language Model Training on GPU Clusters</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Source: <a href="https://github.com/Hannibal046/Awesome-LLM"><i class="fa-brands fa-github" aria-label="github"></i> <code>Hannibal046/Awesome-LLM</code></a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">🤗 Generation with LLMs</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">🤗 Generation with LLMs</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@unpublished{foreman2024,
  author = {Foreman, Sam},
  title = {Parallel {Training} {Methods}},
  date = {2024-11-05},
  url = {https://samforeman.me/talks/ai-for-science-2024/slides},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-foreman2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Foreman, Sam. 2024. <span>“Parallel Training Methods.”</span> November
5. <a href="https://samforeman.me/talks/ai-for-science-2024/slides">https://samforeman.me/talks/ai-for-science-2024/slides</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/samforeman\.me");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="saforem2/personal_site" data-repo-id="R_kgDOGbjyRw" data-category="General" data-category-id="DIC_kwDOGbjyR84CjWfk" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="dark" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>