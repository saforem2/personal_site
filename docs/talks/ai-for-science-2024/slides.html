<!DOCTYPE html>
<html lang="en"><head>
<link href="../../assets/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-8a26b56b5b7f347156652bf4abc788ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.36">

  <meta name="author" content="Sam Foreman">
  <meta name="dcterms.date" content="2024-11-05">
  <title>Sam Foreman ‚Äì Parallel Training Methods</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #383a42;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #383a42; } /* Normal */
    code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
    code span.an { color: #50a14f; } /* Annotation */
    code span.at { color: #a626a4; } /* Attribute */
    code span.bn { color: #986801; } /* BaseN */
    code span.bu { color: #a626a4; } /* BuiltIn */
    code span.cf { color: #a626a4; } /* ControlFlow */
    code span.ch { color: #50a14f; } /* Char */
    code span.cn { color: #986801; } /* Constant */
    code span.co { color: #a0a1a7; font-style: italic; } /* Comment */
    code span.cv { color: #e45649; font-style: italic; } /* CommentVar */
    code span.do { color: #e45649; } /* Documentation */
    code span.dt { color: #a626a4; } /* DataType */
    code span.dv { color: #986801; } /* DecVal */
    code span.er { color: #f44747; text-decoration: underline; } /* Error */
    code span.ex { color: #4078f2; font-weight: bold; } /* Extension */
    code span.fl { color: #986801; } /* Float */
    code span.fu { color: #4078f2; } /* Function */
    code span.im { color: #50a14f; } /* Import */
    code span.in { color: #c45b00; } /* Information */
    code span.kw { color: #a626a4; } /* Keyword */
    code span.op { color: #a626a4; } /* Operator */
    code span.ot { color: #27ae60; } /* Other */
    code span.pp { color: #a626a4; } /* Preprocessor */
    code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
    code span.sc { color: #0184bc; } /* SpecialChar */
    code span.ss { color: #da4453; } /* SpecialString */
    code span.st { color: #50a14f; } /* String */
    code span.va { color: #e45649; } /* Variable */
    code span.vs { color: #da4453; } /* VerbatimString */
    code span.wa { color: #da4453; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-8ee8b167a994038033535ed56bd99dd6.css">
  <link rel="stylesheet" href="../../css/custom.css">
  <link rel="stylesheet" href="../../css/svgbob.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-XVM2Y822Y1"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-XVM2Y822Y1', { 'anonymize_ip': true});
  </script>
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
  <!-- End Google Tag Manager -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Serif:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;display=swap" rel="stylesheet">
<meta property="og:title" content="Parallel Training Methods for AI">
<meta property="og:description" content="My ramblings about science and computers">
<meta property="og:image" content="https://samforeman.me/talks/ai-for-science-2024/assets/thumbnail.png">
<meta property="og:site_name" content="Sam Foreman">
<meta property="og:image:height" content="2572">
<meta property="og:image:width" content="4112">
<meta name="twitter:title" content="Parallel Training Methods for AI">
<meta name="twitter:description" content="My ramblings about science and computers">
<meta name="twitter:image" content="https://samforeman.me/talks/ai-for-science-2024/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:card" content="summary">
<meta name="twitter:image-height" content="2572">
<meta name="twitter:image-width" content="4112">
<meta name="citation_title" content="Parallel Training Methods">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2024-11-05">
<meta name="citation_cover_date" content="2024-11-05">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-11-05">
<meta name="citation_fulltext_html_url" content="https://samforeman.me/talks/ai-for-science-2024/slides">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calƒ±ÃÄ;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC‚Äô23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=V√§in√§ Hatanp√§√§;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ond≈ôej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>
<body class="quarto-light">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-iframe="./tetris/index.html" data-background-size="contain" class="quarto-title-block center">
    <div class="quarto-title-container" style="background-color: oklch(from #C16FAD calc(l * 1.15) c h / 0.1);
        border-radius: 10px;
        text-align:center;
        padding: 0px;
        padding-left: 1.5em;
        padding-right: 1.5em; max-width: min-content; min-width: max-content;
        border: 1px solid #C16FAD;
        margin-left: auto;
        margin-right: auto;
        padding-top: 0.2em;
        padding-bottom: 0.2em;
        line-height: 1.5em!important;
    ">
        <h1 class="title" style="color:#FFFFFF; text-shadow: 0 2px 3px rgba(0, 0, 0, 0.7); font-size: 250%">Parallel Training Methods</h1>
                        <p class="location" style="color:#cccccc; text-shadow: 0 2px 3px rgba(0, 0, 0, 0.4); font-size: 150%;">@
            <a href="https://www.alcf.anl.gov/alcf-ai-science-training-series">Intro to AI-driven Science on Supercomputers</a>
        </p>
                        <p class="author" style="text-shadow: 0 2px 3px rgba(0, 0, 0, 0.3); font-size: 110%; margin-top: 0.5em;color:#B0B0B0;">Sam Foreman
        </p>
                                <p class="affiliation" style="color: hsl(0, 0%, 80%); text-shadow: 0 2px 3px rgba(0, 0, 0, 0.3); font-size: 125%;">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a></p>
                                        <p class="date" style="color: hsl(0, 0%, 60%); text-shadow: 0 2px 3px rgba(0, 0, 0, 0.3); font-size: 100%">2024-11-05
        </p>
                <!--  -->
        <!-- <p class="slide-url">https://samforeman.me/talks/ai-for-science-2024/slides.html</p> -->
        <!--  -->
    </div>
</section>
<section id="overview" class="title-slide slide level1 center" data-background-color="white">
<h1>üëÄ Overview</h1>
<ul>
<li>üìä Slides @ <a href="https://samforeman.me/talks/ai-for-science-2024/slides">samforeman.me/talks/ai-for-science-2024/slides</a>
<ul>
<li>üìÑ HTML version: <a href="https://samforeman.me/talks/ai-for-science-2024">samforeman.me/talks/ai-for-science-2024</a></li>
</ul></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/ai-science-training-series">argonne-lcf/<code>ai-science-training-series</code></a>
<ul>
<li><a href="https://www.alcf.anl.gov/alcf-ai-science-training-series">Series Page</a></li>
</ul></li>
</ul>
</section>

<section id="outline" class="title-slide slide level1 center" data-background-color="white">
<h1>üìë Outline</h1>
<ol type="1">
<li><a href="#/scaling-overview">Scaling: Overview</a></li>
<li><a href="#/data-parallel-training">Data Parallel Training</a>
<ol type="1">
<li><a href="#/communication">Communication</a></li>
<li><a href="#/why-distributed-training">Why Distributed Training?</a></li>
</ol></li>
<li><a href="#/going-beyond-data-parallelism">Beyond Data Parallelism</a>
<ol type="1">
<li><a href="#/additional-parallelism-strategies">Additional Parallelism Strategies</a></li>
</ol></li>
<li><a href="#/large-language-models">Large Language Models</a></li>
<li><a href="#/hands-on">Hands On</a></li>
</ol>
</section>

<section id="scaling-overview" class="title-slide slide level1 center" data-background-color="white">
<h1>üöÄ Scaling: Overview</h1>
<ul>
<li>‚úÖ <strong>Goal</strong>:
<ul>
<li>Minimize: <span class="highlight-red">Cost</span> (i.e.&nbsp;amount of time spent training)</li>
<li>Maximize: <span class="highlight-blue">Performance</span></li>
</ul>
<div title="üìë Note">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>üìë Note</strong></p>
</div>
<div class="callout-content">
<p>See <a href="https://huggingface.co/docs/transformers/v4.46.0/performance">ü§ó Performance and Scalability</a> for more details</p>
</div>
</div>
</div>
</div></li>
</ul>
</section>

<section id="training-on-a-single-device" class="title-slide slide level1 center" data-background-color="white">
<h1>üê¢ Training on a Single Device</h1>
<ul>
<li>See <a href="https://huggingface.co/docs/transformers/v4.46.0/perf_train_gpu_one">ü§ó Methods and tools for efficient training on a single GPU</a></li>
</ul>
<div id="fig-single-gpu-1" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-single-gpu-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: SLOW !! model size limited by GPU memory"><img data-src="index_files/figure-revealjs/mermaid-figure-1.png" style="width:4.27in;height:3.63in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-single-gpu-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <strong>SLOW</strong> !! model size limited by GPU memory
</figcaption>
</figure>
</div>
</section>

<section>
<section id="training-on-multiple-gpus-data-parallelism" class="title-slide slide level1 center" data-background-color="white">
<h1>üèéÔ∏è Training on Multiple GPUs: Data Parallelism</h1>
<div id="fig-ddp-training-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ddp-training-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-16.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Each GPU receives unique data at each step"><img data-src="index_files/figure-revealjs/mermaid-figure-16.png" style="width:4.69in;height:5.08in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Each GPU receives <strong>unique</strong> data at each step
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-forward-pass" class="slide level2 center" data-background-color="white">
<h2>Data Parallel: Forward Pass</h2>
<div id="fig-ddp-training-mermaid-allreduce" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ddp-training-mermaid-allreduce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Average gradients across all GPUs"><img data-src="index_files/figure-revealjs/mermaid-figure-15.png" style="width:6.98in;height:5.08in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-mermaid-allreduce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Average gradients across all GPUs
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-backward-pass" class="slide level2 center" data-background-color="white">
<h2>Data Parallel: Backward Pass</h2>
<div id="fig-ddp-backward-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ddp-backward-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Send global updates back to each GPU"><img data-src="index_files/figure-revealjs/mermaid-figure-14.png" style="width:6.56in;height:5.08in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-backward-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Send global updates back to each GPU
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-full-setup" class="slide level2 center" data-background-color="white">
<h2>Data Parallel: Full Setup</h2>
<div id="fig-ddp-training" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ddp-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: See: PyTorch / Distributed Data Parallel"><img data-src="index_files/figure-revealjs/mermaid-figure-13.png" style="width:7.29in;height:5.08in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ddp-training-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: See: <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">PyTorch / Distributed Data Parallel</a>
</figcaption>
</figure>
</div>
</section>
<section id="data-parallel-training" class="slide level2 center" data-background-color="white">
<h2>Data Parallel: Training</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[55,45]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 55.0%;justify-content: flex-start;">
<ul>
<li>Each GPU:
<ul>
<li>has <strong>identical copy</strong> of model</li>
<li>works on a <strong>unique</strong> subset of data</li>
</ul></li>
<li>Easy to get started (minor modifications to code):
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a></li>
<li>üî• <a href="https://pytorch.org/docs/stable/notes/ddp.html">PyTorch / <code>DDP</code></a></li>
<li>ü§ó <a href="https://huggingface.co/docs/transformers/accelerate">HF / <code>Accelerate</code></a></li>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://www.deepspeed.ai/">Microsoft / <code>DeepSpeed</code></a></li>
</ul></li>
<li>Requires <strong>global</strong> communication
<ul>
<li>every rank <em>must participate</em> (collective communication) !!</li>
</ul></li>
</ul>
</div><div class="column quarto-layout-cell" style="flex-basis: 45.0%;justify-content: flex-start;">
<div id="fig-avgGrads" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-avgGrads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: "><img data-src="index_files/figure-revealjs/mermaid-figure-12.png" style="width:5.66in;height:7.52in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-avgGrads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6
</figcaption>
</figure>
</div>
</div></div>
</div>
</section></section>
<section>
<section id="communication" class="title-slide slide level1 center" data-background-color="white">
<h1>üó£Ô∏è Communication</h1>
<ul>
<li>Need mechanism(s) for communicating across GPUs:
<ul>
<li><a href="https://mpi4py.readthedocs.io/en/stable/tutorial.html"><code>mpi4py</code></a></li>
<li><a href="https://pytorch.org/docs/stable/distributed.html"><code>torch.distributed</code></a></li>
</ul></li>
<li>Collective Communication:
<ul>
<li><a href="https://developer.nvidia.com/nccl">Nvidia Collective Communications Library (NCCL)</a></li>
<li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/oneccl.html#gs.gouznn">Intel oneAPI Collective Communications Library (oneCCL)</a></li>
</ul>
<div title="‚åõ Timeouts">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚åõ Timeouts</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Collective operations have to be called for each <code>rank</code> to form a complete collective operation.
<ul>
<li>Failure to do so will result in other ranks waiting <strong>indefinitely</strong></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div></li>
</ul>
</section>
<section id="allreduce" class="slide level2 center" data-background-color="white">
<h2>AllReduce</h2>
<p>Perform <em>reductions</em> on data (e.g.&nbsp;<code>sum</code>, <code>min</code>, <code>max</code>) across ranks, send result back to everyone.</p>
<div id="fig-all-reduce-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-all-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: All-Reduce operation: each rank receives the reduction of input values across ranks."><img data-src="index_files/figure-revealjs/mermaid-figure-11.png" style="width:5.94in;height:4.72in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-all-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: All-Reduce operation: each rank receives the reduction of input values across ranks.
</figcaption>
</figure>
</div>
</section>
<section id="reduce" class="slide level2 center" data-background-color="white">
<h2>Reduce</h2>
<ul>
<li>Perform a <em>reduction</em> on data across ranks, send to individual</li>
</ul>
<div id="fig-reduce-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;8: Reduce operation: one rank receives the reduction of input values across ranks"><img data-src="index_files/figure-revealjs/mermaid-figure-10.png" style="width:5.64in;height:4.72in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-reduce-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Reduce operation: one rank receives the reduction of input values across ranks
</figcaption>
</figure>
</div>
</section>
<section id="broadcast" class="slide level2 center" data-background-color="white">
<h2>Broadcast</h2>
<div id="fig-broadcast-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-broadcast-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-9.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;9: broadcast (send) a tensor x from one rank to all ranks"><img data-src="index_files/figure-revealjs/mermaid-figure-9.png" style="width:6.58in;height:4.98in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-broadcast-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: <code>broadcast</code> (send) a tensor <code><span class="math inline">x</span></code> from one rank to all ranks
</figcaption>
</figure>
</div>
</section>
<section id="allgather" class="slide level2 center" data-background-color="white">
<h2>AllGather</h2>
<div id="fig-allgather-mermaid" class="quarto-float quarto-figure quarto-figure-center" style="width:66%; text-align:center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-allgather-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-8.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;10: Gathers tensors from the whole group in a list."><img data-src="index_files/figure-revealjs/mermaid-figure-8.png" style="width:7.45in;height:7.1in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-allgather-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Gathers tensors from the whole group in a list.
</figcaption>
</figure>
</div>
</section>
<section id="scatter" class="slide level2 center" data-background-color="white">
<h2>Scatter</h2>
<div id="fig-scatter-mermaid" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-scatter-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-7.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;11: Scatters a list of tensors to the whole group"><img data-src="index_files/figure-revealjs/mermaid-figure-7.png" style="width:8.45in;height:4.31in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-mermaid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Scatters a list of tensors to the whole group
</figcaption>
</figure>
</div>
</section></section>
<section>
<section id="why-distributed-training" class="title-slide slide level1 center" data-background-color="white">
<h1>‚ö° Why Distributed Training?</h1>
<ul>
<li><code>N</code> workers each processing unique batch<sup>1</sup> of data:
<ul>
<li>[<code>micro_batch_size = 1</code>] <span class="math inline">\times</span> [<code>N</code> GPUs] <span class="math inline">\rightarrow</span> [<b><code>global_batch_size = N</code></b>]</li>
</ul></li>
<li>Improved gradient estimators
<ul>
<li>Smooth loss landscape</li>
<li>Less iterations needed for same number of epochs
<ul>
<li>common to scale learning rate <code>lr *= sqrt(N)</code></li>
</ul></li>
</ul></li>
<li>See: <a href="https://arxiv.org/abs/1708.03888">Large Batch Training of Convolutional Networks</a></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn1"><p><code>micro_batch_size</code> = batch_size <strong>per</strong> GPU</p></li></ol></aside></section>
<section id="why-distributed-training-speedup" class="slide level2 center" data-background-color="white">
<h2>Why Distributed Training? Speedup!</h2>
<div id="tbl-recent-progress" class="responsive striped hover quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-recent-progress-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Recent progress
</figcaption>
<div aria-describedby="tbl-recent-progress-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="table-responsive">
<table class="table-striped table-hover caption-top">
<colgroup>
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Year</th>
<th style="text-align: center;">Author</th>
<th style="text-align: center;">GPU</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;"># GPU</th>
<th style="text-align: center;">TIME (s)</th>
<th style="text-align: center;">ACC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2016</td>
<td style="text-align: center;">He</td>
<td style="text-align: center;">P100</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;"><span class="red-bg">8</span></td>
<td style="text-align: center;"><span class="red-bg">104,400</span></td>
<td style="text-align: center;">75.30%</td>
</tr>
<tr class="even">
<td style="text-align: center;">2019</td>
<td style="text-align: center;">Yamazaki</td>
<td style="text-align: center;">V100</td>
<td style="text-align: center;">81,920</td>
<td style="text-align: center;"><span class="blue-bg">2048</span></td>
<td style="text-align: center;"><span class="blue-bg">72</span></td>
<td style="text-align: center;">75.08%</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</section>
<section id="dealing-with-data" class="slide level2 center" data-background-color="white">
<h2>Dealing with Data</h2>
<ul>
<li>At each training step, we want to ensure that <strong>each worker receives unique data</strong></li>
<li>This can be done in one of two ways:
<ol type="1">
<li>Manually partition data (ahead of time)
<ul>
<li>Assign <strong>unique subsets</strong> to each worker</li>
<li>Each worker can only see their local portion of the data</li>
<li>Most common approach</li>
</ul></li>
<li>From each worker, randomly select a mini-batch
<ul>
<li>Each worker can see the full dataset</li>
<li>‚ö†Ô∏è When randomly selecting, it is important that each worker uses different seeds to ensure they receive unique data</li>
</ul></li>
</ol></li>
</ul>
</section>
<section id="broadcast-initial-state" class="slide level2 center" data-background-color="white">
<h2>Broadcast Initial State</h2>
<ul>
<li>At the start of training (or when loading from a checkpoint), we want all of our workers to be initialized consistently
<ul>
<li><strong>Broadcast</strong> the model and optimizer states from <code>rank() == 0</code> worker</li>
</ul></li>
</ul>
<div id="fig-broadcast" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-6.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;12: To ensure all workers have the same copies, we load on RANK==0 and broadcast"><img data-src="index_files/figure-revealjs/mermaid-figure-6.png" style="width:7.38in;height:3.15in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-broadcast-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: To ensure all workers have the same copies, we load on <code>RANK==0</code> and <code>broadcast</code>
</figcaption>
</figure>
</div>
</section>
<section id="best-practices" class="slide level2 center" data-background-color="white">
<h2>Best Practices</h2>
<div title="‚è∞ Keeping things in Sync">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚è∞ Keeping things in Sync</strong></p>
</div>
<div class="callout-content">
<p><strong>Computation stalls during communication !!</strong></p>
<p>Keeping the communication to computation ratio small is important for effective scaling.</p>
</div>
</div>
</div>
</div>
<div class="flex-container">
<div class="column" style="width:50%;">
<ul>
<li>Use parallel IO whenever possible
<ul>
<li>Feed each rank from different files</li>
<li>Use MPI IO to have each rank read its own batch from a file</li>
<li>Use several ranks to read data, MPI to scatter to remaining ranks
<ul>
<li>Most practical in big <em>at-scale</em> training</li>
</ul></li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<ul>
<li>Take advantage of data storage
<ul>
<li>Use <a href="https://wiki.lustre.org/Configuring_Lustre_File_Striping">striping on lustre</a></li>
</ul></li>
<li>Use the right optimizations for Aurora, Polaris, etc.</li>
<li>Preload data when possible
<ul>
<li>Offloading to a GPU frees CPU cycles for loading the next batch of data
<ul>
<li><strong>minimize IO latency this way</strong></li>
</ul></li>
</ul></li>
</ul>
</div></div>
</section>
<section id="going-beyond-data-parallelism" class="slide level2 center" data-background-color="white">
<h2>Going Beyond Data Parallelism</h2>
<ul>
<li>‚úÖ Useful when model fits on single GPU:
<ul>
<li>ultimately <strong>limited by GPU memory</strong></li>
<li>model performance limited by size</li>
</ul></li>
<li>‚ö†Ô∏è When model does not fit on a single GPU:
<ul>
<li>Offloading (can only get you so far‚Ä¶):
<ul>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://www.deepspeed.ai/tutorials/zero/">DeepSpeed + <code>ZeRO</code></a></li>
<li>üî• <a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">PyTorch + <code>FSDP</code></a></li>
</ul></li>
<li>Otherwise, resort to <a href="#/additional-parallelism-strategies">model parallelism strategies</a></li>
</ul></li>
</ul>
</section>
<section id="going-beyond-data-parallelism-deepspeed-zero" class="slide level2 center" data-background-color="white">
<h2>Going beyond Data Parallelism: <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> DeepSpeed + <code>ZeRO</code></h2>
<ul>
<li>Depending on the <code>ZeRO</code> stage (1, 2, 3), we can offload:
<ol type="1">
<li><strong>Stage 1</strong>: optimizer states <span class="math inline">\left(P_{\mathrm{os}}\right)</span></li>
<li><strong>Stage 2</strong>: gradients + opt. states <span class="math inline">\left(P_{\mathrm{os}+\mathrm{g}}\right)</span></li>
<li><strong>Stage 3</strong>: model params + grads + opt. states <span class="math inline">\left(P_{\mathrm{os}+\mathrm{g}+\mathrm{p}}\right)</span></li>
</ol></li>
</ul>

<img data-src="./assets/zero.png" class="r-stretch quarto-figure-center" id="fig-zero"><p class="caption">
Figure&nbsp;13: <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="deepspeed.ai">DeepSpeed</a> + <a href="https://www.deepspeed.ai/tutorials/zero-offload/"><code>ZeRO</code></a>
</p></section>
<section id="fully-sharded-data-parallel-pytorch-fsdp" class="slide level2 smaller center" data-background-color="white">
<h2>Fully Sharded Data Parallel: üî• PyTorch + <code>FSDP</code></h2>
<ul>
<li>Instead of maintaining per-GPU copy of <code>{params, grads, opt_states}</code>, FSDP shards (distributes) these across data-parallel workers
<ul>
<li>can optionally offload the sharded model params to CPU</li>
</ul></li>
<li><a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">Introducing PyTorch Fully Sharded Data Parallel (FSDP) API | PyTorch</a></li>
</ul>
<div id="fig-fsdp" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-fsdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="assets/fsdp.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;14: FSDP Workflow. Source"><img data-src="assets/fsdp.png"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fsdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: FSDP Workflow. <a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">Source</a>
</figcaption>
</figure>
</div>
</section></section>
<section>
<section id="additional-parallelism-strategies" class="title-slide slide level1 center" data-background-color="white">
<h1>üï∏Ô∏è Additional Parallelism Strategies</h1>
<ul>
<li><strong>Tensor (/ Model) Parallelism</strong> (<code>TP</code>):
<ul>
<li>ü§ó <a href="https://huggingface.co/docs/text-generation-inference/en/conceptual/tensor_parallelism">Tensor Parallelism</a></li>
<li>üî• <a href="https://pytorch.org/tutorials/intermediate/TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
</ul></li>
<li><strong>Pipeline Parallelism</strong> (<code>PP</code>):
<ul>
<li>üî• <a href="https://pytorch.org/docs/main/distributed.pipelining.html">PyTorch</a>, <iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://deepspeed.readthedocs.io/en/latest/pipeline.html">DeepSpeed</a></li>
</ul></li>
<li><strong>Sequence Parallelism</strong> (<code>SP</code>):
<ul>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ulysses/README.md">DeepSpeed Ulysses</a></li>
<li><a href="https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html">Megatron / Context Parallelism</a></li>
<li><a href="https://arxiv.org/abs/2405.07719v3">Unified Sequence Parallel (USP)</a>
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/feifeibear/long-context-attention">feifeibear/<code>long-context-attention</code></a></li>
</ul></li>
</ul></li>
<li><label><input type="checkbox" checked=""><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf/<code>Megatron-DeepSpeed</code></a></label>
<ul>
<li>Supports 4D Parallelism (<code>DP</code> + <code>TP</code> + <code>PP</code> + <code>SP</code>)</li>
</ul></li>
</ul>
</section>
<section id="pipeline-parallelism-pp" class="slide level2 center" data-background-color="white">
<h2>Pipeline Parallelism (PP)</h2>
<div class="flex-container" style="place-content: end space-evenly;">
<div class="column" style="width:60%;">
<ul>
<li>Model is split up <strong>vertically</strong> (layer-level) across multiple GPUs</li>
<li>Each GPU:
<ul>
<li>has a portion of the full model</li>
<li>processes <em>in parallel</em> different stages of the pipeline (on a small chunk of the batch)</li>
</ul></li>
<li>See:
<ul>
<li>üî• <a href="https://pytorch.org/docs/main/distributed.pipelining.html">PyTorch / Pipeline Parallelism</a></li>
<li><iconify-icon role="img" inline="" icon="logos:microsoft-icon" aria-label="Icon microsoft-icon from logos Iconify.design set." title="Icon microsoft-icon from logos Iconify.design set."></iconify-icon> <a href="https://deepspeed.readthedocs.io/en/latest/pipeline.html">DeepSpeed / Pipeline Parallelism</a></li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div id="fig-pipeline-parallelism" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-pipeline-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure&nbsp;15: Pipeline Parallelism"><img data-src="index_files/figure-revealjs/mermaid-figure-5.png" style="width:1.76in;height:5.02in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pipeline-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: Pipeline Parallelism
</figcaption>
</figure>
</div>
</div></div>

<aside><div>

</div></aside></section>
<section id="tensor-parallel-tp" class="slide level2 center" data-background-color="white">
<h2>Tensor Parallel (TP)</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Each tensor is split up into multiple chunks</li>
<li>Each shard of the tensor resides on its designated GPU</li>
<li>During processing each shard gets processed separately (and in parallel) on different GPUs
<ul>
<li>synced at the end of the step</li>
</ul></li>
<li>See: <a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">ü§ó Model Parallelism</a> for additional details</li>
</ul>
</div><div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-model-parallel-1" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Figure&nbsp;16: Tensor Parallel Training"><img data-src="index_files/figure-revealjs/mermaid-figure-4.png" style="width:3.45in;height:4.71in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16: Tensor Parallel Training
</figcaption>
</figure>
</div>
</div></div>
</div>
</section>
<section id="tensor-parallel-tp-1" class="slide level2 center" data-background-color="white">
<h2>Tensor Parallel (TP)</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[50,50]">
<div class="quarto-layout-row">
<div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Suitable when the model is too large to fit onto a single device (CPU / GPU)</li>
<li>Typically <strong>more complicated</strong> to implement than data parallel training
<ul>
<li>This is what one may call <em>horizontal parallelism</em></li>
<li>Communication whenever dataflow between two subsets</li>
</ul></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed"><code>argonne-lcf/Megatron-DeepSpeed</code></a></li>
<li>ü§ó <a href="https://github.com/huggingface/nanotron"><code>huggingface/nanotron</code></a></li>
</ul>
</div><div class="column quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-model-parallel-1" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;17: Tensor Parallel Training"><img data-src="index_files/figure-revealjs/mermaid-figure-3.png" style="width:3.45in;height:4.71in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-parallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17: Tensor Parallel Training
</figcaption>
</figure>
</div>
</div></div>
</div>
<aside class="notes">
<ul>
<li>Split up network over multiple workers
<ul>
<li>Each receives disjoint subset</li>
<li>All communication associated with subsets are distributed</li>
</ul></li>
<li>Communication whenever dataflow between two subsets</li>
<li>Typically <strong>more complicated</strong> to implement than data parallel training</li>
<li>Suitable when the model is too large to fit onto a single device (CPU / GPU)</li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed"><code>argonne-lcf/Megatron-DeepSpeed</code></a></li>
<li>ü§ó <a href="https://github.com/huggingface/nanotron"><code>huggingface/nanotron</code></a></li>
</ul>
<p>See: <a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">ü§ó Model Parallelism</a> for additional details</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="tensor-model-parallel-training-example" class="slide level2 center" data-background-color="white">
<h2>Tensor (/ Model) Parallel Training: Example</h2>
<div class="flex-container">
<div class="column" style="width: 60%;">
<p>Want to compute: <span class="math display">y = \sum_{i} x_{i} W_{i} = x_0 W_0 + x_1 W_1 + x_2 W_2</span> where each GPU only has only its portion of the full weights as shown below</p>
<ol type="1">
<li>Compute: <span class="math inline">x_{0} W_{0}\rightarrow</span> <code>GPU1</code></li>
<li>Compute: <span class="math inline">x_{0} W_{0} + x_{1} W_{1}\rightarrow</span> <code>GPU2</code></li>
<li>Compute: <span class="math inline">y = \sum_{i} x_{i} W_{i}</span> ‚úÖ</li>
</ol>
</div><div class="column" style="width: 25%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><a href="index_files/figure-revealjs/mermaid-figure-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img data-src="index_files/figure-revealjs/mermaid-figure-2.png" style="width:3.04in;height:6.27in"></a></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
</section>
<section id="tensor-model-parallelismefficient-large-scale" class="slide level2 center" data-background-color="white">
<h2>Tensor (Model) Parallelism<sup>1</sup></h2>
<ul>
<li>In <strong>Tensor Paralleism</strong> each GPU processes only a slice of a tensor and only aggregates the full tensor for operations that require the whole thing.
<ul>
<li>The main building block of any transformer is a fully connected <code>nn.Linear</code> followed by a nonlinear activation GeLU.
<ul>
<li><code>Y = GeLU(XA)</code>, where X and Y are the input and output vectors, and A is the weight matrix.</li>
</ul></li>
<li>If we look at the computation in matrix form, it‚Äôs easy to see how the matrix multiplication can be split between multiple GPUs:</li>
</ul></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn2"><p><a href="https://arxiv.org/abs/2104.04473">Efficient Large-Scale Language Model Training on GPU Clusters</a></p></li></ol></aside></section>
<section id="tensor-parallelism" class="slide level2 center" data-background-color="white">
<h2>Tensor Parallelism</h2>

<img data-src="assets/parallelism-tp-parallel_gemm.png" class="r-stretch quarto-figure-center" id="fig-parallel-gemm"><p class="caption">
Figure&nbsp;18: Tensor Parallel GEMM. This information is based on (the much more in-depth) <a href="https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530">TP Overview</a> by <a href="https://github.com/anton-l">@anton-l</a>
</p></section>
<section id="d-parallelism" class="slide level2 center" data-background-color="white">
<h2>3D Parallelism</h2>
<ul>
<li><code>DP</code> + <code>TP</code> + <code>PP</code> (3D) Parallelism</li>
</ul>
<div id="fig-3dparallel" class="quarto-float quarto-figure quarto-figure-center" style="text-align:center!important;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="assets/parallelism-deepspeed-3d.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Figure&nbsp;19: Figure taken from 3D parallelism: Scaling to trillion-parameter models"><img data-src="assets/parallelism-deepspeed-3d.png"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;19: Figure taken from <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/">3D parallelism: Scaling to trillion-parameter models</a>
</figcaption>
</figure>
</div>
</section>
<section id="deciding-on-a-parallelism-strategy" class="slide level2 center" data-background-color="white">
<h2>Deciding on a Parallelism Strategy</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Single GPU</a></li><li><a href="#tabset-1-2">Single Node / Multi-GPU</a></li><li><a href="#tabset-1-3">Multi-Node / Multi-GPU</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<ul>
<li>Model fits onto a single GPU:
<ul>
<li>Normal use</li>
</ul></li>
<li>Model <strong>DOES NOT</strong> fit on a single GPU:
<ul>
<li><code>ZeRO</code> + Offload CPU (or, optionally, <code>NVMe</code>)</li>
</ul></li>
<li>Largest layer <strong>DOES NOT</strong> fit on a single GPU:
<ul>
<li><code>ZeRO</code> + Enable <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#memory-centric-tiling">Memory Centric Tiling (MCT)</a>
<ul>
<li>MCT Allows running of arbitrarily large layers by automatically splitting them and executing them sequentially.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="tabset-1-2">
<div class="flex-container">
<div class="column">
<ul>
<li>Model fits onto a single GPU
<ul>
<li><a href="https://pytorch.org/docs/stable/notes/ddp.html"><code>DDP</code></a></li>
<li><a href="https://deepspeed.readthedocs.io/en/latest/zero3.html"><code>ZeRO</code></a></li>
</ul></li>
</ul>
</div><div class="column">
<ul>
<li>Model <strong>DOES NOT</strong> fit onto a single GPU
<ol type="1">
<li><a href="https://www.deepspeed.ai/tutorials/pipeline/">Pipeline Parallelism (<code>PP</code>)</a></li>
<li><a href="https://deepspeed.readthedocs.io/en/latest/zero3.html"><code>ZeRO</code></a></li>
<li><a href="https://pytorch.org/docs/stable/distributed.tensor.parallel.html">Tensor Parallelism (<code>TP</code>)</a></li>
</ol></li>
</ul>
</div></div>
<ul>
<li><p>With sufficiently fast connectivity between nodes, these three strategies should be comparable.</p>
<ul>
<li>Otherwise, <code>PP</code> <span class="math inline">&gt;</span> <code>ZeRO</code> <span class="math inline">\simeq</span> <code>TP</code>.</li>
</ul></li>
</ul>
</div>
<div id="tabset-1-3">
<ul>
<li><p>When you have fast inter-node connectivity:</p>
<ul>
<li><code>ZeRO</code> (virtually <strong>NO</strong> modifications)</li>
<li><code>PP</code> + <code>ZeRO</code> + <code>TP</code> + <code>DP</code> (less communication, at the cost of <strong>MAJOR</strong> modifications)
<ul>
<li><p>when you have slow inter-node connectivity and still low on GPU memory:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a></a><span class="ex">DP</span> + PP + TP + ZeRO-1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><strong>NOTE</strong>: <code>TP</code> is almost <em>always</em> used within a single node, e.g.<br>
<code>TP &lt;= GPUS_PER_NODE</code></li>
</ul></li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section id="large-language-models" class="title-slide slide level1 center" data-background-color="white">
<h1>ü¶ô Large Language Models</h1>
<div id="fig-llms" class="r-stretch quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/llms.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Figure&nbsp;20: Large Language Models have (LLM)s have taken the NLP community world by storm."><img data-src="./assets/llms.gif" class="r-stretch"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20: Large Language Models have (LLM)s have taken the <del>NLP community</del> <strong>world</strong> by storm<sup>1</sup>.
</figcaption>
</figure>
</div>
<aside><ol class="aside-footnotes"><li id="fn3"><p>Source: <a href="https://github.com/Hannibal046/Awesome-LLM"><i class="fa-brands fa-github" aria-label="github"></i> <code>Hannibal046/Awesome-LLM</code></a></p></li></ol></aside></section>
<section id="emergent-abilities" class="slide level2 center" data-background-color="#FBFBFD">
<h2>üîÆ Emergent Abilities</h2>
<div id="fig-emergent-abilities" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-emergent-abilities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/emergent-abilities.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Figure&nbsp;21: See @wei2022emergentabilitieslargelanguage, @yao2023tree"><img data-src="./assets/emergent-abilities.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-emergent-abilities-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21: See <span class="citation" data-cites="wei2022emergentabilitieslargelanguage">Wei et al. (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>, <span class="citation" data-cites="yao2023tree">Yao et al. (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span>
</figcaption>
</figure>
</div>
</section>
<section id="training-llms" class="slide level2 center" data-background-color="white">
<h2>ü¶ú Training LLMs</h2>
<div class="flex-container" style="align-items: flex-end;width: 100%;">
<div class="column">
<div id="fig-evolution" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/evolution.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="Figure&nbsp;22: Visualization from @yang2023harnessing"><img data-src="./assets/evolution.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22: Visualization from <span class="citation" data-cites="yang2023harnessing">Yang et al. (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span>
</figcaption>
</figure>
</div>
</div><div class="column">
<div id="fig-it-hungers" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/it_hungers.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="Figure&nbsp;23: It‚Äôs hungry! @wei2022emergentabilitieslargelanguage"><img data-src="./assets/it_hungers.jpeg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;23: It‚Äôs hungry! <span class="citation" data-cites="wei2022emergentabilitieslargelanguage">Wei et al. (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>
</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="life-cycle-of-the-llm" class="slide level2 center" data-auto-animate="true" data-background-color="white">
<h2 data-id="quarto-animate-title">‚ôªÔ∏è Life-Cycle of the LLM</h2>
<div class="flex-container">
<div class="column" style="width: 40%;">
<ol type="1">
<li>Data collection + preprocessing</li>
<li><strong>Pre-training</strong>
<ul>
<li>Architecture decisions, model size, etc.</li>
</ul></li>
<li>Supervised Fine-Tuning
<ul>
<li>Instruction Tuning</li>
<li>Alignment</li>
</ul></li>
<li>Deploy (+ monitor, re-evaluate, etc.)</li>
</ol>
</div><div class="column" style="width:50%;">
<div id="fig-pretrain-two" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Figure&nbsp;24: Pre-training: Virtually all of the compute used during pre-training."><img data-src="./assets/gpt3-training-step-back-prop.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;24: <strong>Pre-training</strong>: Virtually <em>all of the compute</em> used during pre-training<sup>1</sup>.
</figcaption>
</figure>
</div>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn4"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p></li></ol></aside></section>
<section id="life-cycle-of-the-llm-1" class="slide level2 center" data-auto-animate="true" data-background-color="white">
<h2 data-id="quarto-animate-title">üéÄ Life-Cycle of the LLM</h2>
<div class="flex-container">
<div class="column" style="width: 50%;">
<ol type="1">
<li>Data collection + preprocessing</li>
<li>Pre-training
<ul>
<li>Architecture decisions, model size, etc.</li>
</ul></li>
<li><strong>Supervised Fine-Tuning</strong>
<ul>
<li>Instruction Tuning</li>
<li>Alignment</li>
</ul></li>
<li>Deploy (+ monitor, re-evaluate, etc.)</li>
</ol>
</div><div class="column" style="width:50%;">
<div id="fig-finetune-lifecycle" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-finetune-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/gpt3-fine-tuning.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="Figure&nbsp;25: Fine-tuning: Fine-tuning actually updates the model‚Äôs weights to make the model better at a certain task."><img data-src="./assets/gpt3-fine-tuning.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-finetune-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25: <strong>Fine-tuning</strong>: Fine-tuning actually updates the model‚Äôs weights to make the model better at a certain task<sup>1</sup>.
</figcaption>
</figure>
</div>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn5"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p></li></ol></aside></section>
<section id="forward-pass" class="slide level2 center" data-background-color="white">
<h2>‚è© Forward Pass</h2>
<div id="fig-hf-assisted-generation" class="quarto-float quarto-figure quarto-figure-center" style="width:100%;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-hf-assisted-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/hf_assisted_generation.mov" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Figure&nbsp;26: Language Model trained for causal language modeling."><video data-src="./assets/hf_assisted_generation.mov" controls=""></video></a><a href="./assets/hf_assisted_generation.mov">Video</a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hf-assisted-generation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;26: Language Model trained for causal language modeling<sup>1</sup>.
</figcaption>
</figure>
</div>
<aside><ol class="aside-footnotes"><li id="fn6"><p>Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">ü§ó Generation with LLMs</a></p></li></ol></aside></section>
<section id="generating-text" class="slide level2 center" data-background-color="white">
<h2>üí¨ Generating Text</h2>
<div id="fig-generating-text" class="quarto-float quarto-figure quarto-figure-center" style="width: 100%;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/hf_assisted_generation2.mov" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Figure&nbsp;27: Language Model trained for causal language modeling."><video data-src="./assets/hf_assisted_generation2.mov" controls=""></video></a><a href="./assets/hf_assisted_generation2.mov">Video</a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;27: Language Model trained for causal language modeling<sup>1</sup>.
</figcaption>
</figure>
</div>
<aside><ol class="aside-footnotes"><li id="fn7"><p>Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">ü§ó Generation with LLMs</a></p></li></ol></aside></section></section>
<section>
<section id="hands-on" class="title-slide slide level1 center" data-background-color="white">
<h1>üëã Hands On</h1>
<p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/ai-science-training-series/tree/main/06_parallel_training#hands-on">ai-science-training-series / 06_parallel_training</a></p>
</section>
<section id="hands-on-getting-started" class="slide level2 center" data-background-color="white">
<h2>üßë‚Äçüíª Hands On: Getting Started</h2>
<ol type="1">
<li><p>üå± Clone Repo(s):</p>
<ul>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/wordplay">saforem2/<code>wordplay</code></a></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a></a><span class="fu">git</span> clone https://github.com/saforem2/wordplay</span>
<span id="cb2-2"><a></a><span class="bu">cd</span> wordplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a></a><span class="fu">git</span> clone https://github.com/saforem2/ezpz deps/ezpz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul></li>
<li><p>üêç Setup Python:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a></a><span class="bu">export</span> <span class="va">PBS_O_WORKDIR</span><span class="op">=</span><span class="va">$(</span><span class="bu">pwd</span><span class="va">)</span> <span class="kw">&amp;&amp;</span> <span class="bu">source</span> deps/ezpz/src/ezpz/bin/utils.sh</span>
<span id="cb4-2"><a></a><span class="ex">ezpz_setup_python</span></span>
<span id="cb4-3"><a></a><span class="ex">ezpz_setup_job</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="install-ezpz-wordplay" class="slide level2 center" data-background-color="white">
<h2>üì¶ Install {<code>ezpz</code>, <code>wordplay</code>}</h2>
<ol type="1">
<li><p>Install Python packages:</p>
<ol type="1">
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>ezpz</code></a>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> <span class="st">"./deps/ezpz"</span> <span class="at">--require-virtualenv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2/<code>wordplay</code></a>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a></a><span class="co"># from inside `wordplay/`</span></span>
<span id="cb6-2"><a></a><span class="ex">python3</span> <span class="at">-m</span> pip install <span class="at">-e</span> . <span class="at">--require-virtualenv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol></li>
<li><p>Test distributed setup:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a></a><span class="ex">mpirun</span> <span class="at">-n</span> <span class="st">"</span><span class="va">${NGPUS}</span><span class="st">"</span> python3 <span class="at">-m</span> ezpz.test_dist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>See: üçã <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py"><code>ezpz/test_dist.py</code></a></p></li>
</ol>
</section>
<section id="ezpz-example-video" class="slide level2 center" data-background-color="#121314">
<h2><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz"><code>ezpz</code></a>: Example [<a href="https://asciinema.org/a/668460">video</a>]</h2>
<div id="fig-ezpz-asciinema" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<script src="https://asciinema.org/a/668460.js" id="asciicast-668460" async="true"></script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;28: Example: using <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py">üçã <code>ezpz.test_dist</code></a> to train a small model using DDP
</figcaption>
</figure>
</div>
</section>
<section id="install-wordplay" class="slide level2 center" data-background-color="white">
<h2>Install <a href="https://github.com/saforem2/wordplay"><code>wordplay</code> üéÆüí¨</a></h2>
<div id="fig-nanoGPT" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-nanoGPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/nanogpt.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="Figure&nbsp;29: The simplest, fastest repository for training / finetuning GPT based models. Figure from karpathy/nanoGPT"><img data-src="./assets/nanogpt.jpg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nanoGPT-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;29: The simplest, fastest repository for training / finetuning GPT based models. Figure from <a href="https://github.com/karpathy/nanoGPT">karpathy/<code>nanoGPT</code></a>
</figcaption>
</figure>
</div>
</section>
<section id="prepare-data" class="slide level2 center" data-background-color="white">
<h2>Prepare Data</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a></a><span class="ex">python3</span> wordplay/data/shakespeare_char/prepare.py</span>
<span id="cb8-2"><a></a><span class="co"># Using HF_DATASETS_CACHE=/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/.cache/huggingface</span></span>
<span id="cb8-3"><a></a><span class="co"># length of dataset in characters: 1,115,394</span></span>
<span id="cb8-4"><a></a><span class="co"># all the unique characters:</span></span>
<span id="cb8-5"><a></a><span class="co">#  !$&amp;\',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz</span></span>
<span id="cb8-6"><a></a><span class="co"># vocab size: 65</span></span>
<span id="cb8-7"><a></a><span class="co"># train has 1,003,854 tokens</span></span>
<span id="cb8-8"><a></a><span class="co"># val has 111,540 tokens</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="launch-training-ddp" class="slide level2 center" data-background-color="white">
<h2>Launch Training (DDP)</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a></a><span class="ex">launch</span> python3 <span class="at">-m</span> wordplay <span class="dt">\</span></span>
<span id="cb9-2"><a></a>    train.backend=DDP <span class="dt">\</span></span>
<span id="cb9-3"><a></a>    train.eval_interval=100 <span class="dt">\</span></span>
<span id="cb9-4"><a></a>    data=shakespeare <span class="dt">\</span></span>
<span id="cb9-5"><a></a>    train.dtype=bf16 <span class="dt">\</span></span>
<span id="cb9-6"><a></a>    model.batch_size=64 <span class="dt">\</span></span>
<span id="cb9-7"><a></a>    model.block_size=1024 <span class="dt">\</span></span>
<span id="cb9-8"><a></a>    train.max_iters=1000 <span class="dt">\</span></span>
<span id="cb9-9"><a></a>    train.log_interval=10 <span class="dt">\</span></span>
<span id="cb9-10"><a></a>    train.compile=false <span class="dt">\</span></span>
<span id="cb9-11"><a></a>    <span class="kw">|</span> <span class="fu">tee</span> wordplay-gpt2-DDP.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training-example-output" class="slide level2 center" data-background-color="white">
<h2>Training: Example Output</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource java number-lines code-with-copy"><code class="sourceCode java"><span id="cb10-1"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.746540</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">156</span><span class="op">]</span> <span class="op">-</span> Setting logging level to <span class="er">'</span>INFO<span class="er">'</span> on <span class="er">'</span>RANK <span class="op">==</span> <span class="dv">0</span><span class="er">'</span></span>
<span id="cb10-2"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.748763</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">157</span><span class="op">]</span> <span class="op">-</span> Setting logging level to <span class="er">'</span>CRITICAL<span class="er">'</span> on all others <span class="er">'</span>RANK <span class="op">!=</span> <span class="dv">0</span><span class="er">'</span></span>
<span id="cb10-3"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.749453</span><span class="op">][</span>INFO<span class="op">][</span>__init__<span class="op">:</span><span class="dv">160</span><span class="op">]</span> <span class="op">-</span> To disable <span class="kw">this</span> behavior<span class="op">,</span> and log from ALL <span class="fu">ranks</span> <span class="op">(</span>not recommended<span class="op">),</span> set<span class="op">:</span> <span class="er">'</span>export LOG_FROM_ALL_RANKS<span class="op">=</span><span class="dv">1</span><span class="er">'</span>  in your environment<span class="op">,</span> and re<span class="op">-</span>run<span class="op">.</span></span>
<span id="cb10-4"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">11.772718</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">81</span><span class="op">]</span> <span class="op">-</span> Setting HF_DATASETS_CACHE to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/.</span><span class="fu">cache</span><span class="op">/</span>huggingface<span class="op">/</span>datasets</span>
<span id="cb10-5"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.341532</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-6"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.342381</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-7"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.342430</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">3</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">3</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-8"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.348657</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">95</span><span class="op">]</span> <span class="op">-</span></span>
<span id="cb10-9"><a></a></span>
<span id="cb10-10"><a></a><span class="op">[</span>dist_info<span class="op">]:</span></span>
<span id="cb10-11"><a></a>  ‚Ä¢ DEVICE<span class="op">=</span>cuda</span>
<span id="cb10-12"><a></a>  ‚Ä¢ DEVICE_ID<span class="op">=</span>cuda<span class="op">:</span><span class="dv">0</span></span>
<span id="cb10-13"><a></a>  ‚Ä¢ DISTRIBUTED_BACKEND<span class="op">=</span>nccl</span>
<span id="cb10-14"><a></a>  ‚Ä¢ GPUS_PER_NODE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-15"><a></a>  ‚Ä¢ HOSTS<span class="op">=[</span><span class="er">'</span>x3101c0s13b0n0<span class="op">.</span><span class="fu">hsn</span><span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span><span class="er">'</span><span class="op">]</span></span>
<span id="cb10-16"><a></a>  ‚Ä¢ HOSTFILE<span class="op">=/</span><span class="dt">var</span><span class="op">/</span>spool<span class="op">/</span>pbs<span class="op">/</span>aux<span class="op">/</span><span class="fl">2024084.</span>polaris<span class="op">-</span>pbs<span class="op">-</span><span class="fl">01.</span>hsn<span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span></span>
<span id="cb10-17"><a></a>  ‚Ä¢ HOSTNAME<span class="op">=</span>x3101c0s13b0n0<span class="op">.</span><span class="fu">hsn</span><span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span></span>
<span id="cb10-18"><a></a>  ‚Ä¢ LOCAL_RANK<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-19"><a></a>  ‚Ä¢ MACHINE<span class="op">=</span>Polaris</span>
<span id="cb10-20"><a></a>  ‚Ä¢ NUM_NODES<span class="op">=</span><span class="dv">1</span></span>
<span id="cb10-21"><a></a>  ‚Ä¢ NGPUS<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-22"><a></a>  ‚Ä¢ NGPUS_AVAILABLE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-23"><a></a>  ‚Ä¢ NODE_ID<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-24"><a></a>  ‚Ä¢ RANK<span class="op">=</span><span class="dv">0</span></span>
<span id="cb10-25"><a></a>  ‚Ä¢ SCHEDULER<span class="op">=</span>PBS</span>
<span id="cb10-26"><a></a>  ‚Ä¢ WORLD_SIZE_TOTAL<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-27"><a></a>  ‚Ä¢ WORLD_SIZE_IN_USE<span class="op">=</span><span class="dv">4</span></span>
<span id="cb10-28"><a></a>  ‚Ä¢ LAUNCH_CMD<span class="op">=</span>mpiexec <span class="op">--</span>verbose <span class="op">--</span>envall <span class="op">-</span>n <span class="dv">4</span> <span class="op">-</span>ppn <span class="dv">4</span> <span class="op">--</span>hostfile <span class="op">/</span><span class="dt">var</span><span class="op">/</span>spool<span class="op">/</span>pbs<span class="op">/</span>aux<span class="op">/</span><span class="fl">2024084.</span>polaris<span class="op">-</span>pbs<span class="op">-</span><span class="fl">01.</span>hsn<span class="op">.</span><span class="fu">cm</span><span class="op">.</span><span class="fu">polaris</span><span class="op">.</span><span class="fu">alcf</span><span class="op">.</span><span class="fu">anl</span><span class="op">.</span><span class="fu">gov</span> <span class="op">--</span>cpu<span class="op">-</span>bind depth <span class="op">-</span>d <span class="dv">16</span></span>
<span id="cb10-29"><a></a></span>
<span id="cb10-30"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.351446</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">725</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="dv">0</span><span class="op">/</span><span class="dv">4</span><span class="op">]</span> Using device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span> with backend<span class="op">=</span><span class="er">'</span>DDP<span class="er">'</span> <span class="op">+</span> <span class="er">'</span>nccl<span class="er">'</span> <span class="cf">for</span> distributed training<span class="op">.</span></span>
<span id="cb10-31"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.356169</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span>device<span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span><span class="op">][</span>rank<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>local_rank<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">3</span><span class="op">][</span>node<span class="op">=</span><span class="dv">0</span><span class="op">/</span><span class="dv">0</span><span class="op">]</span></span>
<span id="cb10-32"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.356692</span><span class="op">][</span>WARNING<span class="op">][</span>dist<span class="op">:</span><span class="dv">364</span><span class="op">]</span> <span class="op">-</span> Using <span class="op">[</span><span class="dv">4</span> <span class="op">/</span> <span class="dv">4</span><span class="op">]</span> available <span class="st">"cuda"</span> devices <span class="op">!!</span></span>
<span id="cb10-33"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.359571</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">317</span><span class="op">]</span> <span class="op">-</span> Loading val from <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>data<span class="op">/</span>shakespeare_char<span class="op">/</span>val<span class="op">.</span><span class="fu">bin</span></span>
<span id="cb10-34"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.360138</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">317</span><span class="op">]</span> <span class="op">-</span> Loading train from <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>data<span class="op">/</span>shakespeare_char<span class="op">/</span>train<span class="op">.</span><span class="fu">bin</span></span>
<span id="cb10-35"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.361154</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">442</span><span class="op">]</span> <span class="op">-</span> Tokens per iteration<span class="op">:</span> <span class="dv">262</span><span class="op">,</span><span class="dv">144</span></span>
<span id="cb10-36"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.361574</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">465</span><span class="op">]</span> <span class="op">-</span> Using self<span class="op">.</span><span class="fu">ptdtype</span><span class="op">=</span>torch<span class="op">.</span><span class="fu">float16</span> on self<span class="op">.</span><span class="fu">device_type</span><span class="op">=</span><span class="er">'</span>cuda<span class="er">'</span></span>
<span id="cb10-37"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362002</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">471</span><span class="op">]</span> <span class="op">-</span> Initializing a <span class="kw">new</span> model from scratch</span>
<span id="cb10-38"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362529</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">874</span><span class="op">]</span> <span class="op">-</span> Setting up wandb from rank<span class="op">:</span> <span class="dv">0</span></span>
<span id="cb10-39"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">15.362896</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">875</span><span class="op">]</span> <span class="op">-</span> Using<span class="op">:</span> WB PROJECT<span class="op">:</span> WordPlay</span>
<span id="cb10-40"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.451786</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">905</span><span class="op">]</span> <span class="op">-</span> W<span class="op">&amp;</span>B RUN<span class="op">:</span> <span class="op">[</span>still<span class="op">-</span>frog<span class="op">-</span><span class="dv">17</span><span class="op">](</span>https<span class="op">:</span><span class="co">//wandb.ai/aurora_gpt/WordPlay/runs/6by9vpcj)</span></span>
<span id="cb10-41"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.464106</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">312</span><span class="op">]</span> <span class="op">-</span> Updating wandb<span class="op">.</span><span class="fu">run</span><span class="op">:</span> still<span class="op">-</span>frog<span class="op">-</span><span class="dv">17</span> config with <span class="st">"DIST_INFO"</span></span>
<span id="cb10-42"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.469424</span><span class="op">][</span>INFO<span class="op">][</span>dist<span class="op">:</span><span class="dv">938</span><span class="op">]</span> <span class="op">-</span> Running on machine<span class="op">=</span><span class="er">'</span>Polaris<span class="er">'</span></span>
<span id="cb10-43"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.471151</span><span class="op">][</span>WARNING<span class="op">][</span>__main__<span class="op">:</span><span class="dv">89</span><span class="op">]</span> <span class="op">-</span> <span class="op">{</span></span>
<span id="cb10-44"><a></a>    <span class="st">"train"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-45"><a></a>        <span class="st">"framework"</span><span class="op">:</span> <span class="st">"pytorch"</span><span class="op">,</span></span>
<span id="cb10-46"><a></a>        <span class="st">"backend"</span><span class="op">:</span> <span class="st">"DDP"</span><span class="op">,</span></span>
<span id="cb10-47"><a></a>        <span class="st">"device"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-48"><a></a>        <span class="st">"seed"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-49"><a></a>        <span class="st">"port"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-50"><a></a>        <span class="st">"ds_config_path"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-51"><a></a>        <span class="st">"precision"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-52"><a></a>        <span class="st">"ngpus"</span><span class="op">:</span> <span class="kw">null</span><span class="op">,</span></span>
<span id="cb10-53"><a></a>        <span class="st">"use_wandb"</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb10-54"><a></a>        <span class="st">"eval_interval"</span><span class="op">:</span> <span class="dv">100</span><span class="op">,</span></span>
<span id="cb10-55"><a></a>        <span class="st">"log_interval"</span><span class="op">:</span> <span class="dv">10</span><span class="op">,</span></span>
<span id="cb10-56"><a></a>        <span class="st">"eval_iters"</span><span class="op">:</span> <span class="dv">200</span><span class="op">,</span></span>
<span id="cb10-57"><a></a>        <span class="st">"eval_only"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-58"><a></a>        <span class="st">"always_save_checkpoint"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-59"><a></a>        <span class="st">"init_from"</span><span class="op">:</span> <span class="st">"scratch"</span><span class="op">,</span></span>
<span id="cb10-60"><a></a>        <span class="st">"wandb_project"</span><span class="op">:</span> <span class="st">"WordPlay"</span><span class="op">,</span></span>
<span id="cb10-61"><a></a>        <span class="st">"max_iters"</span><span class="op">:</span> <span class="dv">1000</span><span class="op">,</span></span>
<span id="cb10-62"><a></a>        <span class="st">"warmup_iters"</span><span class="op">:</span> <span class="dv">100</span><span class="op">,</span></span>
<span id="cb10-63"><a></a>        <span class="st">"dtype"</span><span class="op">:</span> <span class="st">"bf16"</span><span class="op">,</span></span>
<span id="cb10-64"><a></a>        <span class="st">"compile"</span><span class="op">:</span> <span class="kw">false</span></span>
<span id="cb10-65"><a></a>    <span class="op">},</span></span>
<span id="cb10-66"><a></a>    <span class="st">"model"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-67"><a></a>        <span class="st">"n_layer"</span><span class="op">:</span> <span class="dv">12</span><span class="op">,</span></span>
<span id="cb10-68"><a></a>        <span class="st">"n_head"</span><span class="op">:</span> <span class="dv">12</span><span class="op">,</span></span>
<span id="cb10-69"><a></a>        <span class="st">"n_embd"</span><span class="op">:</span> <span class="dv">768</span><span class="op">,</span></span>
<span id="cb10-70"><a></a>        <span class="st">"batch_size"</span><span class="op">:</span> <span class="dv">64</span><span class="op">,</span></span>
<span id="cb10-71"><a></a>        <span class="st">"block_size"</span><span class="op">:</span> <span class="dv">1024</span><span class="op">,</span></span>
<span id="cb10-72"><a></a>        <span class="st">"activation"</span><span class="op">:</span> <span class="st">"gelu"</span><span class="op">,</span></span>
<span id="cb10-73"><a></a>        <span class="st">"dropout"</span><span class="op">:</span> <span class="fl">0.0</span><span class="op">,</span></span>
<span id="cb10-74"><a></a>        <span class="st">"bias"</span><span class="op">:</span> <span class="kw">false</span><span class="op">,</span></span>
<span id="cb10-75"><a></a>        <span class="st">"vocab_size"</span><span class="op">:</span> <span class="dv">65</span></span>
<span id="cb10-76"><a></a>    <span class="op">},</span></span>
<span id="cb10-77"><a></a>    <span class="st">"data"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-78"><a></a>        <span class="st">"dataset"</span><span class="op">:</span> <span class="st">"shakespeare_char"</span><span class="op">,</span></span>
<span id="cb10-79"><a></a>        <span class="st">"out_dir"</span><span class="op">:</span> <span class="st">"out-shakespeare-char"</span><span class="op">,</span></span>
<span id="cb10-80"><a></a>        <span class="st">"root_path"</span><span class="op">:</span> <span class="kw">null</span></span>
<span id="cb10-81"><a></a>    <span class="op">},</span></span>
<span id="cb10-82"><a></a>    <span class="st">"optimizer"</span><span class="op">:</span> <span class="op">{</span></span>
<span id="cb10-83"><a></a>        <span class="st">"gas"</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span></span>
<span id="cb10-84"><a></a>        <span class="st">"name"</span><span class="op">:</span> <span class="st">"AdamW"</span><span class="op">,</span></span>
<span id="cb10-85"><a></a>        <span class="st">"learning_rate"</span><span class="op">:</span> <span class="fl">0.0006</span><span class="op">,</span></span>
<span id="cb10-86"><a></a>        <span class="st">"weight_decay"</span><span class="op">:</span> <span class="fl">0.1</span><span class="op">,</span></span>
<span id="cb10-87"><a></a>        <span class="st">"beta1"</span><span class="op">:</span> <span class="fl">0.9</span><span class="op">,</span></span>
<span id="cb10-88"><a></a>        <span class="st">"beta2"</span><span class="op">:</span> <span class="fl">0.95</span><span class="op">,</span></span>
<span id="cb10-89"><a></a>        <span class="st">"grad_clip"</span><span class="op">:</span> <span class="fl">1.0</span><span class="op">,</span></span>
<span id="cb10-90"><a></a>        <span class="st">"decay_lr"</span><span class="op">:</span> <span class="kw">true</span><span class="op">,</span></span>
<span id="cb10-91"><a></a>        <span class="st">"lr_decay_iters"</span><span class="op">:</span> <span class="dv">600000</span><span class="op">,</span></span>
<span id="cb10-92"><a></a>        <span class="st">"min_lr"</span><span class="op">:</span> <span class="fl">6e-05</span></span>
<span id="cb10-93"><a></a>    <span class="op">}</span></span>
<span id="cb10-94"><a></a><span class="op">}</span></span>
<span id="cb10-95"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.474305</span><span class="op">][</span>WARNING<span class="op">][</span>__main__<span class="op">:</span><span class="dv">90</span><span class="op">]</span> <span class="op">-</span> Output dir<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-96"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">16.474922</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">246</span><span class="op">]</span> <span class="op">-</span> Initializing a <span class="kw">new</span> model from scratch</span>
<span id="cb10-97"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.258904</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">255</span><span class="op">]</span> <span class="op">-</span> number of parameters<span class="op">:</span> <span class="fl">85.</span><span class="er">00</span>M</span>
<span id="cb10-98"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.290004</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">264</span><span class="op">]</span> <span class="op">-</span> Model size<span class="op">:</span> num_params<span class="op">=</span><span class="dv">85003776</span></span>
<span id="cb10-99"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.292626</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">445</span><span class="op">]</span> <span class="op">-</span> num decayed parameter tensors<span class="op">:</span> <span class="dv">50</span><span class="op">,</span> with <span class="dv">85</span><span class="op">,</span><span class="dv">771</span><span class="op">,</span><span class="er">008</span> parameters</span>
<span id="cb10-100"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.293296</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">449</span><span class="op">]</span> <span class="op">-</span> num non<span class="op">-</span>decayed parameter tensors<span class="op">:</span> <span class="dv">25</span><span class="op">,</span> with <span class="dv">19</span><span class="op">,</span><span class="dv">200</span> parameters</span>
<span id="cb10-101"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515324</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:1'"</span></span>
<span id="cb10-102"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515340</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:2'"</span></span>
<span id="cb10-103"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">17.515465</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:3'"</span></span>
<span id="cb10-104"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">18.431814</span><span class="op">][</span>INFO<span class="op">][</span>model<span class="op">:</span><span class="dv">465</span><span class="op">]</span> <span class="op">-</span> using fused AdamW<span class="op">:</span> True</span>
<span id="cb10-105"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">18.432620</span><span class="op">][</span>CRITICAL<span class="op">][</span>trainer<span class="op">:</span><span class="dv">316</span><span class="op">]</span> <span class="op">-</span> <span class="st">"devid='cuda:0'"</span></span>
<span id="cb10-106"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.951020</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">356</span><span class="op">]</span> <span class="op">-</span> ‚Ä¢ self<span class="op">.</span><span class="fu">model</span><span class="op">=</span><span class="fu">GPT</span><span class="op">(</span></span>
<span id="cb10-107"><a></a>  <span class="op">(</span>transformer<span class="op">):</span> <span class="fu">ModuleDict</span><span class="op">(</span></span>
<span id="cb10-108"><a></a>    <span class="op">(</span>wte<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">65</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-109"><a></a>    <span class="op">(</span>wpe<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">1024</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-110"><a></a>    <span class="op">(</span>drop<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-111"><a></a>    <span class="op">(</span>h<span class="op">):</span> <span class="fu">ModuleList</span><span class="op">(</span></span>
<span id="cb10-112"><a></a>      <span class="op">(</span><span class="dv">0</span><span class="op">-</span><span class="dv">11</span><span class="op">):</span> <span class="dv">12</span> x <span class="fu">Block</span><span class="op">(</span></span>
<span id="cb10-113"><a></a>        <span class="op">(</span>ln_1<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-114"><a></a>        <span class="op">(</span>attn<span class="op">):</span> <span class="fu">CausalSelfAttention</span><span class="op">(</span></span>
<span id="cb10-115"><a></a>          <span class="op">(</span>c_attn<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">2304</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-116"><a></a>          <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-117"><a></a>          <span class="op">(</span>attn_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-118"><a></a>          <span class="op">(</span>resid_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-119"><a></a>        <span class="op">)</span></span>
<span id="cb10-120"><a></a>        <span class="op">(</span>ln_2<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-121"><a></a>        <span class="op">(</span>mlp<span class="op">):</span> <span class="fu">MLP</span><span class="op">(</span></span>
<span id="cb10-122"><a></a>          <span class="op">(</span>c_fc<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-123"><a></a>          <span class="op">(</span>act_fn<span class="op">):</span> <span class="fu">GELU</span><span class="op">(</span>approximate<span class="op">=</span><span class="er">'</span>none<span class="er">'</span><span class="op">)</span></span>
<span id="cb10-124"><a></a>          <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-125"><a></a>          <span class="op">(</span>dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-126"><a></a>        <span class="op">)</span></span>
<span id="cb10-127"><a></a>      <span class="op">)</span></span>
<span id="cb10-128"><a></a>    <span class="op">)</span></span>
<span id="cb10-129"><a></a>    <span class="op">(</span>ln_f<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-130"><a></a>  <span class="op">)</span></span>
<span id="cb10-131"><a></a>  <span class="op">(</span>lm_head<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">65</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-132"><a></a><span class="op">)</span></span>
<span id="cb10-133"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.955340</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">357</span><span class="op">]</span> <span class="op">-</span> ‚Ä¢ self<span class="op">.</span><span class="fu">grad_scaler</span><span class="op">=&lt;</span>torch<span class="op">.</span><span class="fu">cuda</span><span class="op">.</span><span class="fu">amp</span><span class="op">.</span><span class="fu">grad_scaler</span><span class="op">.</span><span class="fu">GradScaler</span> object at <span class="bn">0x145a38f0f090</span><span class="op">&gt;</span></span>
<span id="cb10-134"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.956897</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">358</span><span class="op">]</span> <span class="op">-</span> ‚Ä¢ self<span class="op">.</span><span class="fu">model_engine</span><span class="op">=</span><span class="fu">DistributedDataParallel</span><span class="op">(</span></span>
<span id="cb10-135"><a></a>  <span class="op">(</span>module<span class="op">):</span> <span class="fu">GPT</span><span class="op">(</span></span>
<span id="cb10-136"><a></a>    <span class="op">(</span>transformer<span class="op">):</span> <span class="fu">ModuleDict</span><span class="op">(</span></span>
<span id="cb10-137"><a></a>      <span class="op">(</span>wte<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">65</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-138"><a></a>      <span class="op">(</span>wpe<span class="op">):</span> <span class="fu">Embedding</span><span class="op">(</span><span class="dv">1024</span><span class="op">,</span> <span class="dv">768</span><span class="op">)</span></span>
<span id="cb10-139"><a></a>      <span class="op">(</span>drop<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-140"><a></a>      <span class="op">(</span>h<span class="op">):</span> <span class="fu">ModuleList</span><span class="op">(</span></span>
<span id="cb10-141"><a></a>        <span class="op">(</span><span class="dv">0</span><span class="op">-</span><span class="dv">11</span><span class="op">):</span> <span class="dv">12</span> x <span class="fu">Block</span><span class="op">(</span></span>
<span id="cb10-142"><a></a>          <span class="op">(</span>ln_1<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-143"><a></a>          <span class="op">(</span>attn<span class="op">):</span> <span class="fu">CausalSelfAttention</span><span class="op">(</span></span>
<span id="cb10-144"><a></a>            <span class="op">(</span>c_attn<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">2304</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-145"><a></a>            <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-146"><a></a>            <span class="op">(</span>attn_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-147"><a></a>            <span class="op">(</span>resid_dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-148"><a></a>          <span class="op">)</span></span>
<span id="cb10-149"><a></a>          <span class="op">(</span>ln_2<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-150"><a></a>          <span class="op">(</span>mlp<span class="op">):</span> <span class="fu">MLP</span><span class="op">(</span></span>
<span id="cb10-151"><a></a>            <span class="op">(</span>c_fc<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-152"><a></a>            <span class="op">(</span>act_fn<span class="op">):</span> <span class="fu">GELU</span><span class="op">(</span>approximate<span class="op">=</span><span class="er">'</span>none<span class="er">'</span><span class="op">)</span></span>
<span id="cb10-153"><a></a>            <span class="op">(</span>c_proj<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">3072</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-154"><a></a>            <span class="op">(</span>dropout<span class="op">):</span> <span class="fu">Dropout</span><span class="op">(</span>p<span class="op">=</span><span class="fl">0.0</span><span class="op">,</span> inplace<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-155"><a></a>          <span class="op">)</span></span>
<span id="cb10-156"><a></a>        <span class="op">)</span></span>
<span id="cb10-157"><a></a>      <span class="op">)</span></span>
<span id="cb10-158"><a></a>      <span class="op">(</span>ln_f<span class="op">):</span> <span class="fu">LayerNorm</span><span class="op">()</span></span>
<span id="cb10-159"><a></a>    <span class="op">)</span></span>
<span id="cb10-160"><a></a>    <span class="op">(</span>lm_head<span class="op">):</span> <span class="fu">Linear</span><span class="op">(</span>in_features<span class="op">=</span><span class="dv">768</span><span class="op">,</span> out_features<span class="op">=</span><span class="dv">65</span><span class="op">,</span> bias<span class="op">=</span>False<span class="op">)</span></span>
<span id="cb10-161"><a></a>  <span class="op">)</span></span>
<span id="cb10-162"><a></a><span class="op">)</span></span>
<span id="cb10-163"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.961066</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">359</span><span class="op">]</span> <span class="op">-</span> ‚Ä¢ self<span class="op">.</span><span class="fu">optimizer</span><span class="op">=</span><span class="fu">AdamW</span> <span class="op">(</span></span>
<span id="cb10-164"><a></a><span class="bu">Parameter</span> <span class="bu">Group</span> <span class="dv">0</span></span>
<span id="cb10-165"><a></a>    amsgrad<span class="op">:</span> False</span>
<span id="cb10-166"><a></a>    betas<span class="op">:</span> <span class="op">(</span><span class="fl">0.9</span><span class="op">,</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span id="cb10-167"><a></a>    capturable<span class="op">:</span> False</span>
<span id="cb10-168"><a></a>    differentiable<span class="op">:</span> False</span>
<span id="cb10-169"><a></a>    eps<span class="op">:</span> <span class="fl">1e-08</span></span>
<span id="cb10-170"><a></a>    foreach<span class="op">:</span> None</span>
<span id="cb10-171"><a></a>    fused<span class="op">:</span> True</span>
<span id="cb10-172"><a></a>    lr<span class="op">:</span> <span class="fl">0.0006</span></span>
<span id="cb10-173"><a></a>    maximize<span class="op">:</span> False</span>
<span id="cb10-174"><a></a>    weight_decay<span class="op">:</span> <span class="fl">0.1</span></span>
<span id="cb10-175"><a></a></span>
<span id="cb10-176"><a></a><span class="bu">Parameter</span> <span class="bu">Group</span> <span class="dv">1</span></span>
<span id="cb10-177"><a></a>    amsgrad<span class="op">:</span> False</span>
<span id="cb10-178"><a></a>    betas<span class="op">:</span> <span class="op">(</span><span class="fl">0.9</span><span class="op">,</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span id="cb10-179"><a></a>    capturable<span class="op">:</span> False</span>
<span id="cb10-180"><a></a>    differentiable<span class="op">:</span> False</span>
<span id="cb10-181"><a></a>    eps<span class="op">:</span> <span class="fl">1e-08</span></span>
<span id="cb10-182"><a></a>    foreach<span class="op">:</span> None</span>
<span id="cb10-183"><a></a>    fused<span class="op">:</span> True</span>
<span id="cb10-184"><a></a>    lr<span class="op">:</span> <span class="fl">0.0006</span></span>
<span id="cb10-185"><a></a>    maximize<span class="op">:</span> False</span>
<span id="cb10-186"><a></a>    weight_decay<span class="op">:</span> <span class="fl">0.0</span></span>
<span id="cb10-187"><a></a><span class="op">)</span></span>
<span id="cb10-188"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">19.988827</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">802</span><span class="op">]</span> <span class="op">-</span> Startup time<span class="op">:</span> <span class="fl">6.7125</span></span>
<span id="cb10-189"><a></a>                Training Legend</span>
<span id="cb10-190"><a></a>‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì</span>
<span id="cb10-191"><a></a>‚îÉ    abbr     ‚îÉ desc                           ‚îÉ</span>
<span id="cb10-192"><a></a>‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©</span>
<span id="cb10-193"><a></a>‚îÇ    step     ‚îÇ <span class="bu">Current</span> training iteration     ‚îÇ</span>
<span id="cb10-194"><a></a>‚îÇ    loss     ‚îÇ Loss value                     ‚îÇ</span>
<span id="cb10-195"><a></a>‚îÇ     dt      ‚îÇ Elapsed time per training step ‚îÇ</span>
<span id="cb10-196"><a></a>‚îÇ     dtf     ‚îÇ Elapsed time per forward step  ‚îÇ</span>
<span id="cb10-197"><a></a>‚îÇ     dtb     ‚îÇ Elapsed time per backward step ‚îÇ</span>
<span id="cb10-198"><a></a>‚îÇ     sps     ‚îÇ Samples per second             ‚îÇ</span>
<span id="cb10-199"><a></a>‚îÇ sps_per_gpu ‚îÇ Samples per <span class="fu">second</span> <span class="op">(</span>per GPU<span class="op">)</span>   ‚îÇ</span>
<span id="cb10-200"><a></a>‚îÇ     tps     ‚îÇ Tokens per second              ‚îÇ</span>
<span id="cb10-201"><a></a>‚îÇ tps_per_gpu ‚îÇ Tokens per <span class="fu">second</span> <span class="op">(</span>per GPU<span class="op">)</span>    ‚îÇ</span>
<span id="cb10-202"><a></a>‚îÇ     mfu     ‚îÇ Model flops utilization        ‚îÇ</span>
<span id="cb10-203"><a></a>‚îÇ train_loss  ‚îÇ Training loss value            ‚îÇ</span>
<span id="cb10-204"><a></a>‚îÇ  val_loss   ‚îÇ Validation loss value          ‚îÇ</span>
<span id="cb10-205"><a></a>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
<span id="cb10-206"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">21.451865</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-207"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">42</span><span class="op">:</span><span class="fl">21.452667</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-208"><a></a>What is an LLM<span class="op">?</span>eelEl\<span class="er">'</span>$nltPwBSWal<span class="op">,;</span>PWw bbu\<span class="er">'</span>HiyP\<span class="er">'</span>FWwF <span class="op">&amp;</span>AhW<span class="op">:</span>ygrn kk<span class="op">-</span>\<span class="er">'\'</span>KFlMwnlEfflkc<span class="op">,</span>elpWaWtgml$Pgglhllw lglhFllzczPAFHpeAAPPSltgkrWPPhlEMgcrN ggPWt<span class="op">-</span>WPSSzHSkkrzzk<span class="op">.</span><span class="fu">FFrtSSkgMll</span><span class="op">&amp;</span>gFXr<span class="op">,</span>hghaueaVPW<span class="op">-</span>pHFF<span class="op">-</span>gg<span class="op">,,,</span>FF<span class="op">,,</span>kbApgg gg\<span class="er">'</span>aWWzzkk\<span class="er">'</span>a\<span class="er">'</span>CggHl$bGeA<span class="op">,</span>FFk<span class="op">,,</span>SF<span class="op">;</span>UF<span class="op">,,</span>aZ <span class="op">;</span>gglee$<span class="op">,</span>k<span class="op">.</span><span class="fu">US</span><span class="op">&amp;</span>kg<span class="op">:</span>S<span class="op">,,</span>zVzzc</span>
<span id="cb10-209"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">01.573073</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">10</span> loss<span class="op">=</span><span class="fl">3.154310</span> dt<span class="op">=</span><span class="fl">0.282833</span> dtf<span class="op">=</span><span class="fl">0.005247</span> dtb<span class="op">=</span><span class="fl">0.011417</span> sps<span class="op">=</span><span class="fl">14.142633</span> sps_per_gpu<span class="op">=</span><span class="fl">3.535658</span> tps<span class="op">=</span><span class="fl">926851.609409</span> tps_per_gpu<span class="op">=</span><span class="fl">231712.902352</span> mfu<span class="op">=</span><span class="fl">46.288281</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-210"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">04.402750</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">20</span> loss<span class="op">=</span><span class="fl">2.660851</span> dt<span class="op">=</span><span class="fl">0.306263</span> dtf<span class="op">=</span><span class="fl">0.005233</span> dtb<span class="op">=</span><span class="fl">0.011419</span> sps<span class="op">=</span><span class="fl">13.060678</span> sps_per_gpu<span class="op">=</span><span class="fl">3.265170</span> tps<span class="op">=</span><span class="fl">855944.613638</span> tps_per_gpu<span class="op">=</span><span class="fl">213986.153409</span> mfu<span class="op">=</span><span class="fl">45.934162</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-211"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">07.237507</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">30</span> loss<span class="op">=</span><span class="fl">2.543283</span> dt<span class="op">=</span><span class="fl">0.283021</span> dtf<span class="op">=</span><span class="fl">0.005238</span> dtb<span class="op">=</span><span class="fl">0.011245</span> sps<span class="op">=</span><span class="fl">14.133211</span> sps_per_gpu<span class="op">=</span><span class="fl">3.533303</span> tps<span class="op">=</span><span class="fl">926234.088226</span> tps_per_gpu<span class="op">=</span><span class="fl">231558.522057</span> mfu<span class="op">=</span><span class="fl">45.966490</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-212"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">10.077248</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">40</span> loss<span class="op">=</span><span class="fl">2.503963</span> dt<span class="op">=</span><span class="fl">0.285001</span> dtf<span class="op">=</span><span class="fl">0.005213</span> dtb<span class="op">=</span><span class="fl">0.011471</span> sps<span class="op">=</span><span class="fl">14.035061</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508765</span> tps<span class="op">=</span><span class="fl">919801.749941</span> tps_per_gpu<span class="op">=</span><span class="fl">229950.437485</span> mfu<span class="op">=</span><span class="fl">45.963461</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-213"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">12.917039</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">50</span> loss<span class="op">=</span><span class="fl">2.477469</span> dt<span class="op">=</span><span class="fl">0.283532</span> dtf<span class="op">=</span><span class="fl">0.005166</span> dtb<span class="op">=</span><span class="fl">0.011294</span> sps<span class="op">=</span><span class="fl">14.107763</span> sps_per_gpu<span class="op">=</span><span class="fl">3.526941</span> tps<span class="op">=</span><span class="fl">924566.380009</span> tps_per_gpu<span class="op">=</span><span class="fl">231141.595002</span> mfu<span class="op">=</span><span class="fl">45.984530</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-214"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">15.760749</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">60</span> loss<span class="op">=</span><span class="fl">2.471083</span> dt<span class="op">=</span><span class="fl">0.284630</span> dtf<span class="op">=</span><span class="fl">0.005140</span> dtb<span class="op">=</span><span class="fl">0.011224</span> sps<span class="op">=</span><span class="fl">14.053326</span> sps_per_gpu<span class="op">=</span><span class="fl">3.513332</span> tps<span class="op">=</span><span class="fl">920998.786204</span> tps_per_gpu<span class="op">=</span><span class="fl">230249.696551</span> mfu<span class="op">=</span><span class="fl">45.985675</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-215"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">18.602785</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">70</span> loss<span class="op">=</span><span class="fl">2.458894</span> dt<span class="op">=</span><span class="fl">0.283926</span> dtf<span class="op">=</span><span class="fl">0.005219</span> dtb<span class="op">=</span><span class="fl">0.010383</span> sps<span class="op">=</span><span class="fl">14.088155</span> sps_per_gpu<span class="op">=</span><span class="fl">3.522039</span> tps<span class="op">=</span><span class="fl">923281.352698</span> tps_per_gpu<span class="op">=</span><span class="fl">230820.338174</span> mfu<span class="op">=</span><span class="fl">45.998106</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-216"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">21.451433</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">80</span> loss<span class="op">=</span><span class="fl">2.489088</span> dt<span class="op">=</span><span class="fl">0.285537</span> dtf<span class="op">=</span><span class="fl">0.005183</span> dtb<span class="op">=</span><span class="fl">0.011373</span> sps<span class="op">=</span><span class="fl">14.008683</span> sps_per_gpu<span class="op">=</span><span class="fl">3.502171</span> tps<span class="op">=</span><span class="fl">918073.060430</span> tps_per_gpu<span class="op">=</span><span class="fl">229518.265108</span> mfu<span class="op">=</span><span class="fl">45.983282</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-217"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">24.302241</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">90</span> loss<span class="op">=</span><span class="fl">2.471990</span> dt<span class="op">=</span><span class="fl">0.300767</span> dtf<span class="op">=</span><span class="fl">0.005445</span> dtb<span class="op">=</span><span class="fl">0.010290</span> sps<span class="op">=</span><span class="fl">13.299337</span> sps_per_gpu<span class="op">=</span><span class="fl">3.324834</span> tps<span class="op">=</span><span class="fl">871585.359388</span> tps_per_gpu<span class="op">=</span><span class="fl">217896.339847</span> mfu<span class="op">=</span><span class="fl">45.737774</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-218"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">27.153275</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">100</span> loss<span class="op">=</span><span class="fl">2.445556</span> dt<span class="op">=</span><span class="fl">0.285869</span> dtf<span class="op">=</span><span class="fl">0.005182</span> dtb<span class="op">=</span><span class="fl">0.011251</span> sps<span class="op">=</span><span class="fl">13.992403</span> sps_per_gpu<span class="op">=</span><span class="fl">3.498101</span> tps<span class="op">=</span><span class="fl">917006.151328</span> tps_per_gpu<span class="op">=</span><span class="fl">229251.537832</span> mfu<span class="op">=</span><span class="fl">45.743655</span> train_loss<span class="op">=</span><span class="fl">4.125778</span> val_loss<span class="op">=</span><span class="fl">4.128809</span></span>
<span id="cb10-219"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">28.182553</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-220"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">43</span><span class="op">:</span><span class="fl">28.183179</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-221"><a></a></span>
<span id="cb10-222"><a></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-223"><a></a></span>
<span id="cb10-224"><a></a>Goupay my winghimithell bls ger t bon sinthard ht omind be<span class="op">,</span></span>
<span id="cb10-225"><a></a>And lereind h py balithand frd oforondof wimon me hageas thinero mand<span class="op">,</span></span>
<span id="cb10-226"><a></a>Thacanes<span class="op">,</span></span>
<span id="cb10-227"><a></a>An frift ghik med d herthecke ntore thack couthen ale<span class="op">,</span> t thit ang d m t h chy me fache ag<span class="op">,</span> wit my hathan glat ng</span>
<span id="cb10-228"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">06.025837</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-229"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">06.026607</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-230"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">07.682968</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-231"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">10.519506</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">110</span> loss<span class="op">=</span><span class="fl">2.433923</span> dt<span class="op">=</span><span class="fl">0.285038</span> dtf<span class="op">=</span><span class="fl">0.005757</span> dtb<span class="op">=</span><span class="fl">0.011762</span> sps<span class="op">=</span><span class="fl">14.033209</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508302</span> tps<span class="op">=</span><span class="fl">919680.367894</span> tps_per_gpu<span class="op">=</span><span class="fl">229920.091974</span> mfu<span class="op">=</span><span class="fl">45.762304</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-232"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">13.362148</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">120</span> loss<span class="op">=</span><span class="fl">2.429014</span> dt<span class="op">=</span><span class="fl">0.284445</span> dtf<span class="op">=</span><span class="fl">0.005222</span> dtb<span class="op">=</span><span class="fl">0.011486</span> sps<span class="op">=</span><span class="fl">14.062460</span> sps_per_gpu<span class="op">=</span><span class="fl">3.515615</span> tps<span class="op">=</span><span class="fl">921597.361532</span> tps_per_gpu<span class="op">=</span><span class="fl">230399.340383</span> mfu<span class="op">=</span><span class="fl">45.788661</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-233"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">16.210694</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">130</span> loss<span class="op">=</span><span class="fl">2.402059</span> dt<span class="op">=</span><span class="fl">0.285559</span> dtf<span class="op">=</span><span class="fl">0.005199</span> dtb<span class="op">=</span><span class="fl">0.011765</span> sps<span class="op">=</span><span class="fl">14.007633</span> sps_per_gpu<span class="op">=</span><span class="fl">3.501908</span> tps<span class="op">=</span><span class="fl">918004.211586</span> tps_per_gpu<span class="op">=</span><span class="fl">229501.052897</span> mfu<span class="op">=</span><span class="fl">45.794438</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-234"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">19.061546</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">140</span> loss<span class="op">=</span><span class="fl">2.374062</span> dt<span class="op">=</span><span class="fl">0.285476</span> dtf<span class="op">=</span><span class="fl">0.005239</span> dtb<span class="op">=</span><span class="fl">0.011453</span> sps<span class="op">=</span><span class="fl">14.011662</span> sps_per_gpu<span class="op">=</span><span class="fl">3.502916</span> tps<span class="op">=</span><span class="fl">918268.297093</span> tps_per_gpu<span class="op">=</span><span class="fl">229567.074273</span> mfu<span class="op">=</span><span class="fl">45.800956</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-235"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">21.917283</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">150</span> loss<span class="op">=</span><span class="fl">2.365385</span> dt<span class="op">=</span><span class="fl">0.285846</span> dtf<span class="op">=</span><span class="fl">0.005125</span> dtb<span class="op">=</span><span class="fl">0.011320</span> sps<span class="op">=</span><span class="fl">13.993568</span> sps_per_gpu<span class="op">=</span><span class="fl">3.498392</span> tps<span class="op">=</span><span class="fl">917082.475791</span> tps_per_gpu<span class="op">=</span><span class="fl">229270.618948</span> mfu<span class="op">=</span><span class="fl">45.800900</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-236"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">24.771924</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">160</span> loss<span class="op">=</span><span class="fl">2.317337</span> dt<span class="op">=</span><span class="fl">0.280788</span> dtf<span class="op">=</span><span class="fl">0.005173</span> dtb<span class="op">=</span><span class="fl">0.011249</span> sps<span class="op">=</span><span class="fl">14.245602</span> sps_per_gpu<span class="op">=</span><span class="fl">3.561401</span> tps<span class="op">=</span><span class="fl">933599.792506</span> tps_per_gpu<span class="op">=</span><span class="fl">233399.948127</span> mfu<span class="op">=</span><span class="fl">45.883340</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-237"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">27.626812</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">170</span> loss<span class="op">=</span><span class="fl">2.256231</span> dt<span class="op">=</span><span class="fl">0.284973</span> dtf<span class="op">=</span><span class="fl">0.005141</span> dtb<span class="op">=</span><span class="fl">0.011299</span> sps<span class="op">=</span><span class="fl">14.036416</span> sps_per_gpu<span class="op">=</span><span class="fl">3.509104</span> tps<span class="op">=</span><span class="fl">919890.544506</span> tps_per_gpu<span class="op">=</span><span class="fl">229972.636126</span> mfu<span class="op">=</span><span class="fl">45.889069</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-238"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">30.480952</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">180</span> loss<span class="op">=</span><span class="fl">2.216419</span> dt<span class="op">=</span><span class="fl">0.286555</span> dtf<span class="op">=</span><span class="fl">0.005180</span> dtb<span class="op">=</span><span class="fl">0.011402</span> sps<span class="op">=</span><span class="fl">13.958906</span> sps_per_gpu<span class="op">=</span><span class="fl">3.489726</span> tps<span class="op">=</span><span class="fl">914810.852170</span> tps_per_gpu<span class="op">=</span><span class="fl">228702.713043</span> mfu<span class="op">=</span><span class="fl">45.868857</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-239"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">33.337342</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">190</span> loss<span class="op">=</span><span class="fl">2.145123</span> dt<span class="op">=</span><span class="fl">0.291456</span> dtf<span class="op">=</span><span class="fl">0.005409</span> dtb<span class="op">=</span><span class="fl">0.019347</span> sps<span class="op">=</span><span class="fl">13.724205</span> sps_per_gpu<span class="op">=</span><span class="fl">3.431051</span> tps<span class="op">=</span><span class="fl">899429.467247</span> tps_per_gpu<span class="op">=</span><span class="fl">224857.366812</span> mfu<span class="op">=</span><span class="fl">45.773849</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-240"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">36.194584</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">200</span> loss<span class="op">=</span><span class="fl">2.068149</span> dt<span class="op">=</span><span class="fl">0.285703</span> dtf<span class="op">=</span><span class="fl">0.005153</span> dtb<span class="op">=</span><span class="fl">0.011286</span> sps<span class="op">=</span><span class="fl">14.000555</span> sps_per_gpu<span class="op">=</span><span class="fl">3.500139</span> tps<span class="op">=</span><span class="fl">917540.393411</span> tps_per_gpu<span class="op">=</span><span class="fl">229385.098353</span> mfu<span class="op">=</span><span class="fl">45.778791</span> train_loss<span class="op">=</span><span class="fl">2.439494</span> val_loss<span class="op">=</span><span class="fl">2.478951</span></span>
<span id="cb10-241"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">37.224149</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-242"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">44</span><span class="op">:</span><span class="fl">37.224745</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-243"><a></a></span>
<span id="cb10-244"><a></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-245"><a></a></span>
<span id="cb10-246"><a></a>LORTESS LA<span class="op">:</span></span>
<span id="cb10-247"><a></a>No<span class="op">,</span> sighappat selace<span class="op">?</span> don downd sourciceans note cancen up sof liond</span>
<span id="cb10-248"><a></a>This and my man<span class="op">,</span> werame<span class="op">,</span> of re thee</span>
<span id="cb10-249"><a></a>Thise not will I on land brond sul me a fingore<span class="op">?</span></span>
<span id="cb10-250"><a></a></span>
<span id="cb10-251"><a></a>FLER<span class="op">:</span></span>
<span id="cb10-252"><a></a>Tisint your not nare lame o igen<span class="op">,-</span>to brorst<span class="op">.</span></span>
<span id="cb10-253"><a></a></span>
<span id="cb10-254"><a></a><span class="fu">SamERS</span><span class="op">:</span></span>
<span id="cb10-255"><a></a>Sin<span class="op">:</span></span>
<span id="cb10-256"><a></a>I\<span class="er">'</span>l hell she lor hen w</span>
<span id="cb10-257"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">14.409129</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-258"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">14.409820</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-259"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">16.366935</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-260"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">19.245061</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">210</span> loss<span class="op">=</span><span class="fl">1.982169</span> dt<span class="op">=</span><span class="fl">0.283305</span> dtf<span class="op">=</span><span class="fl">0.005223</span> dtb<span class="op">=</span><span class="fl">0.011284</span> sps<span class="op">=</span><span class="fl">14.119042</span> sps_per_gpu<span class="op">=</span><span class="fl">3.529760</span> tps<span class="op">=</span><span class="fl">925305.515083</span> tps_per_gpu<span class="op">=</span><span class="fl">231326.378771</span> mfu<span class="op">=</span><span class="fl">45.822019</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-261"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">22.092430</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">220</span> loss<span class="op">=</span><span class="fl">1.897731</span> dt<span class="op">=</span><span class="fl">0.284759</span> dtf<span class="op">=</span><span class="fl">0.005217</span> dtb<span class="op">=</span><span class="fl">0.011187</span> sps<span class="op">=</span><span class="fl">14.046945</span> sps_per_gpu<span class="op">=</span><span class="fl">3.511736</span> tps<span class="op">=</span><span class="fl">920580.608106</span> tps_per_gpu<span class="op">=</span><span class="fl">230145.152026</span> mfu<span class="op">=</span><span class="fl">45.837327</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-262"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">24.942639</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">230</span> loss<span class="op">=</span><span class="fl">1.817213</span> dt<span class="op">=</span><span class="fl">0.285266</span> dtf<span class="op">=</span><span class="fl">0.005208</span> dtb<span class="op">=</span><span class="fl">0.011446</span> sps<span class="op">=</span><span class="fl">14.022003</span> sps_per_gpu<span class="op">=</span><span class="fl">3.505501</span> tps<span class="op">=</span><span class="fl">918945.985503</span> tps_per_gpu<span class="op">=</span><span class="fl">229736.496376</span> mfu<span class="op">=</span><span class="fl">45.842940</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-263"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">27.797910</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">240</span> loss<span class="op">=</span><span class="fl">1.779287</span> dt<span class="op">=</span><span class="fl">0.285465</span> dtf<span class="op">=</span><span class="fl">0.005189</span> dtb<span class="op">=</span><span class="fl">0.011220</span> sps<span class="op">=</span><span class="fl">14.012250</span> sps_per_gpu<span class="op">=</span><span class="fl">3.503062</span> tps<span class="op">=</span><span class="fl">918306.793546</span> tps_per_gpu<span class="op">=</span><span class="fl">229576.698387</span> mfu<span class="op">=</span><span class="fl">45.844800</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-264"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">30.653597</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">250</span> loss<span class="op">=</span><span class="fl">1.704220</span> dt<span class="op">=</span><span class="fl">0.289284</span> dtf<span class="op">=</span><span class="fl">0.005471</span> dtb<span class="op">=</span><span class="fl">0.010346</span> sps<span class="op">=</span><span class="fl">13.827253</span> sps_per_gpu<span class="op">=</span><span class="fl">3.456813</span> tps<span class="op">=</span><span class="fl">906182.836379</span> tps_per_gpu<span class="op">=</span><span class="fl">226545.709095</span> mfu<span class="op">=</span><span class="fl">45.785926</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-265"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">33.512769</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">260</span> loss<span class="op">=</span><span class="fl">1.671318</span> dt<span class="op">=</span><span class="fl">0.287679</span> dtf<span class="op">=</span><span class="fl">0.005125</span> dtb<span class="op">=</span><span class="fl">0.011250</span> sps<span class="op">=</span><span class="fl">13.904380</span> sps_per_gpu<span class="op">=</span><span class="fl">3.476095</span> tps<span class="op">=</span><span class="fl">911237.442617</span> tps_per_gpu<span class="op">=</span><span class="fl">227809.360654</span> mfu<span class="op">=</span><span class="fl">45.758182</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-266"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">36.373461</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">270</span> loss<span class="op">=</span><span class="fl">1.650952</span> dt<span class="op">=</span><span class="fl">0.298661</span> dtf<span class="op">=</span><span class="fl">0.005118</span> dtb<span class="op">=</span><span class="fl">0.011520</span> sps<span class="op">=</span><span class="fl">13.393107</span> sps_per_gpu<span class="op">=</span><span class="fl">3.348277</span> tps<span class="op">=</span><span class="fl">877730.651421</span> tps_per_gpu<span class="op">=</span><span class="fl">219432.662855</span> mfu<span class="op">=</span><span class="fl">45.565875</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-267"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">39.236930</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">280</span> loss<span class="op">=</span><span class="fl">1.573242</span> dt<span class="op">=</span><span class="fl">0.285970</span> dtf<span class="op">=</span><span class="fl">0.005171</span> dtb<span class="op">=</span><span class="fl">0.011290</span> sps<span class="op">=</span><span class="fl">13.987477</span> sps_per_gpu<span class="op">=</span><span class="fl">3.496869</span> tps<span class="op">=</span><span class="fl">916683.279847</span> tps_per_gpu<span class="op">=</span><span class="fl">229170.819962</span> mfu<span class="op">=</span><span class="fl">45.587333</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-268"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">42.100605</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">290</span> loss<span class="op">=</span><span class="fl">1.533265</span> dt<span class="op">=</span><span class="fl">0.286487</span> dtf<span class="op">=</span><span class="fl">0.005432</span> dtb<span class="op">=</span><span class="fl">0.011288</span> sps<span class="op">=</span><span class="fl">13.962259</span> sps_per_gpu<span class="op">=</span><span class="fl">3.490565</span> tps<span class="op">=</span><span class="fl">915030.617828</span> tps_per_gpu<span class="op">=</span><span class="fl">228757.654457</span> mfu<span class="op">=</span><span class="fl">45.598392</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-269"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">44.964424</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">300</span> loss<span class="op">=</span><span class="fl">1.492064</span> dt<span class="op">=</span><span class="fl">0.288480</span> dtf<span class="op">=</span><span class="fl">0.005355</span> dtb<span class="op">=</span><span class="fl">0.011480</span> sps<span class="op">=</span><span class="fl">13.865774</span> sps_per_gpu<span class="op">=</span><span class="fl">3.466443</span> tps<span class="op">=</span><span class="fl">908707.340870</span> tps_per_gpu<span class="op">=</span><span class="fl">227176.835218</span> mfu<span class="op">=</span><span class="fl">45.576766</span> train_loss<span class="op">=</span><span class="fl">2.045786</span> val_loss<span class="op">=</span><span class="fl">2.148510</span></span>
<span id="cb10-270"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">45.995833</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">820</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>prompt<span class="er">'</span><span class="op">]:</span> <span class="er">'</span>What is an LLM<span class="op">?</span><span class="er">'</span></span>
<span id="cb10-271"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">45</span><span class="op">:</span><span class="fl">45.996497</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">824</span><span class="op">]</span> <span class="op">-</span> <span class="op">[</span><span class="er">'</span>response<span class="er">'</span><span class="op">]:</span></span>
<span id="cb10-272"><a></a></span>
<span id="cb10-273"><a></a>What is an LLM<span class="op">?</span></span>
<span id="cb10-274"><a></a></span>
<span id="cb10-275"><a></a>RICHMORD<span class="op">:</span></span>
<span id="cb10-276"><a></a>Char stire<span class="op">?</span> how in those are name the range hone<span class="op">.</span></span>
<span id="cb10-277"><a></a></span>
<span id="cb10-278"><a></a><span class="fu">GLOUCESTER</span><span class="op">:</span></span>
<span id="cb10-279"><a></a>Nay<span class="op">,</span> in lond<span class="er">'</span>s time the palt are worder more</span>
<span id="cb10-280"><a></a>That wilt in the purpose be a pey</span>
<span id="cb10-281"><a></a>And thou thine onter hands<span class="op">,</span> and the which broth<span class="op">.</span></span>
<span id="cb10-282"><a></a></span>
<span id="cb10-283"><a></a><span class="fu">ELBOWINCA</span><span class="op">:</span></span>
<span id="cb10-284"><a></a>At lie my lord with the me an arms be a s</span>
<span id="cb10-285"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">23.549987</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">760</span><span class="op">]</span> <span class="op">-</span> Saving checkpoint to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span></span>
<span id="cb10-286"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">23.550696</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">761</span><span class="op">]</span> <span class="op">-</span> Saving model to<span class="op">:</span> <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span><span class="op">/</span>model<span class="op">.</span><span class="fu">pth</span></span>
<span id="cb10-287"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">25.496559</span><span class="op">][</span>INFO<span class="op">][</span>configs<span class="op">:</span><span class="dv">141</span><span class="op">]</span> <span class="op">-</span> Appending <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span>outputs<span class="op">/</span>runs<span class="op">/</span>pytorch<span class="op">/</span>DDP<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">/</span><span class="bn">07</span><span class="op">-</span><span class="dv">42</span><span class="op">-</span><span class="dv">13</span> to <span class="op">/</span>home<span class="op">/</span>foremans<span class="op">/</span>tmp<span class="op">/</span>polaris<span class="op">-</span>talk<span class="op">/</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span><span class="op">-</span><span class="bn">073327</span><span class="op">/</span>wordplay<span class="op">/</span>src<span class="op">/</span>ckpts<span class="op">/</span>checkpoints<span class="op">.</span><span class="fu">log</span></span>
<span id="cb10-288"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">28.374854</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">310</span> loss<span class="op">=</span><span class="fl">1.444200</span> dt<span class="op">=</span><span class="fl">0.299907</span> dtf<span class="op">=</span><span class="fl">0.005333</span> dtb<span class="op">=</span><span class="fl">0.010637</span> sps<span class="op">=</span><span class="fl">13.337481</span> sps_per_gpu<span class="op">=</span><span class="fl">3.334370</span> tps<span class="op">=</span><span class="fl">874085.133345</span> tps_per_gpu<span class="op">=</span><span class="fl">218521.283336</span> mfu<span class="op">=</span><span class="fl">45.384395</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-289"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">31.223079</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">320</span> loss<span class="op">=</span><span class="fl">1.429350</span> dt<span class="op">=</span><span class="fl">0.285238</span> dtf<span class="op">=</span><span class="fl">0.005245</span> dtb<span class="op">=</span><span class="fl">0.011485</span> sps<span class="op">=</span><span class="fl">14.023353</span> sps_per_gpu<span class="op">=</span><span class="fl">3.505838</span> tps<span class="op">=</span><span class="fl">919034.479880</span> tps_per_gpu<span class="op">=</span><span class="fl">229758.619970</span> mfu<span class="op">=</span><span class="fl">45.435743</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-290"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">34.074957</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">330</span> loss<span class="op">=</span><span class="fl">1.362220</span> dt<span class="op">=</span><span class="fl">0.285027</span> dtf<span class="op">=</span><span class="fl">0.005165</span> dtb<span class="op">=</span><span class="fl">0.011407</span> sps<span class="op">=</span><span class="fl">14.033736</span> sps_per_gpu<span class="op">=</span><span class="fl">3.508434</span> tps<span class="op">=</span><span class="fl">919714.904826</span> tps_per_gpu<span class="op">=</span><span class="fl">229928.726207</span> mfu<span class="op">=</span><span class="fl">45.485355</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span>
<span id="cb10-291"><a></a><span class="op">[</span><span class="dv">2024</span><span class="op">-</span><span class="bn">07</span><span class="op">-</span><span class="dv">17</span> <span class="bn">07</span><span class="op">:</span><span class="dv">46</span><span class="op">:</span><span class="fl">36.929464</span><span class="op">][</span>INFO<span class="op">][</span>trainer<span class="op">:</span><span class="dv">885</span><span class="op">]</span> <span class="op">-</span> step<span class="op">=</span><span class="dv">340</span> loss<span class="op">=</span><span class="fl">1.350888</span> dt<span class="op">=</span><span class="fl">0.284436</span> dtf<span class="op">=</span><span class="fl">0.005199</span> dtb<span class="op">=</span><span class="fl">0.011287</span> sps<span class="op">=</span><span class="fl">14.062893</span> sps_per_gpu<span class="op">=</span><span class="fl">3.515723</span> tps<span class="op">=</span><span class="fl">921625.744709</span> tps_per_gpu<span class="op">=</span><span class="fl">230406.436177</span> mfu<span class="op">=</span><span class="fl">45.539549</span> train_loss<span class="op">=</span><span class="fl">1.495372</span> val_loss<span class="op">=</span><span class="fl">1.713714</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="wordplay-example-video" class="slide level2 center" data-background-color="#121314">
<h2><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/wordplay"><code>wordplay</code></a>: Example [<a href="https://asciinema.org/a/668462">video</a>]</h2>
<div id="fig-wordplay-asciinema" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-wordplay-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<script src="https://asciinema.org/a/668462.js" id="asciicast-668462" async="true"></script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wordplay-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;30: Training a LLM to talk like Shakespeare using <a href="https://github.com/saforem2/wordplay">saforem2/<code>wordplay</code> üéÆüí¨</a>
</figcaption>
</figure>
</div>
</section></section>
<section id="thank-you" class="title-slide slide level1 center" data-background-color="white">
<h1>‚ù§Ô∏è Thank you!</h1>
<ul>
<li><p>Organizers</p></li>
<li><p>Feel free to reach out!</p>
<p><split even=""></split></p>
<p><a href="https://samforeman.me"><i class="fas fa-home"></i></a> <a href="mailto:foremans@anl.gov"><i class="far fa-paper-plane"></i></a> <a href="https://www.twitter.com/saforem2"><i class="fab fa-twitter"></i></a></p>
<p></p></li>
</ul>
<div title="Acknowledgements">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Acknowledgements</strong></p>
</div>
<div class="callout-content">
<p>This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357</p>
</div>
</div>
</div>
</div>
</section>

<section id="references" class="title-slide slide level1 smaller scrollable" data-background-color="white">
<h1>üìì References</h1>
<ul>
<li>Title slide (Tetris animation) from: <a href="https://emilhvitfeldt.github.io/quarto-iframe-examples/tetris/index.html" class="uri">https://emilhvitfeldt.github.io/quarto-iframe-examples/tetris/index.html</a></li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-wei2022emergentabilitieslargelanguage" class="csl-entry" role="listitem">
Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. <span>‚ÄúEmergent Abilities of Large Language Models.‚Äù</span> <a href="https://arxiv.org/abs/2206.07682">https://arxiv.org/abs/2206.07682</a>.
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. <span>‚ÄúHarnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.‚Äù</span> <a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a>.
</div>
<div id="ref-yao2023tree" class="csl-entry" role="listitem">
Yao, Shunyu, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. <span>‚ÄúTree of Thoughts: Deliberate Problem Solving with Large Language Models.‚Äù</span> <a href="https://arxiv.org/abs/2305.10601">https://arxiv.org/abs/2305.10601</a>.
</div>
</div>
</section>


    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../assets/anl.svg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://samforeman.me/talks/ai-for-science-2024/slides">samforeman.me/talks/ai-for-science-2024/slides</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: false,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.1,

        maxScale: 4,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/samforeman\.me");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>