<!DOCTYPE html>
<html lang="en"><head>
<link href="../../../assets/favicon-sf.svg" rel="icon" type="image/svg+xml">
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<link href="../../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.14">

  <meta name="author" content="Sam Foreman">
  <meta name="dcterms.date" content="2025-05-21">
  <title>Sam Foreman – LLMs on Aurora: Overview</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto-adfaf1e0563def780b78d2a6c3afa1b1.css">
  <link rel="stylesheet" href="../../../css/navbar-active.css">
  <link rel="stylesheet" href="../../../css/custom.css">
  <link rel="stylesheet" href="../../../css/svgbob.css">
  <link rel="stylesheet" href="../../../static/fonts/MIosevkaQp/MIosevkaQp.css">
  <link rel="stylesheet" href="../../../static/fonts/MIosevkaTerm/MIosevkaTerm.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
  <!-- End Google Tag Manager -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
<meta property="og:title" content="LLMs on Aurora: AuroraGPT">
<meta property="og:description" content="Presented at the 2025 ALCF INCITE GPU Hackathon">
<meta property="og:image" content="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT/assets/thumbnail.png">
<meta property="og:site_name" content="Sam Foreman">
<meta property="og:image:height" content="2160">
<meta property="og:image:width" content="3840">
<meta name="twitter:title" content="LLMs on Aurora: AuroraGPT">
<meta name="twitter:description" content="Presented at the 2025 ALCF INCITE GPU Hackathon">
<meta name="twitter:image" content="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:image-height" content="2160">
<meta name="twitter:image-width" content="3840">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="LLMs on Aurora: Overview">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2025-05-21">
<meta name="citation_cover_date" content="2025-05-21">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-05-21">
<meta name="citation_fulltext_html_url" content="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT/slides.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=HiPerRAG: High-performance retrieval augmented generation for scientific insights;,citation_author=Ozan Gokdemir;,citation_author=Carlo Siebenschuh;,citation_author=Alexander Brace;,citation_author=Azton Wells;,citation_author=Brian Hsu;,citation_author=Kyle Hippe;,citation_author=Priyanka V. Setty;,citation_author=Aswathy Ajith;,citation_author=J. Gregory Pauloski;,citation_author=Varuni Sastry;,citation_author=Sam Foreman;,citation_author=Huihuo Zheng;,citation_author=Heng Ma;,citation_author=Bharat Kale;,citation_author=Nicholas Chia;,citation_author=Thomas Gibbs;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Francis J. Alexander;,citation_author=Anima Anandkumar;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2505.04846;">
<meta name="citation_reference" content="citation_title=MOFA: Discovering materials for carbon capture with a GenAI- and simulation-based workflow;,citation_author=Xiaoli Yan;,citation_author=Nathaniel Hudson;,citation_author=Hyun Park;,citation_author=Daniel Grzenda;,citation_author=J. Gregory Pauloski;,citation_author=Marcus Schwarting;,citation_author=Haochen Pan;,citation_author=Hassan Harb;,citation_author=Samuel Foreman;,citation_author=Chris Knight;,citation_author=Tom Gibbs;,citation_author=Kyle Chard;,citation_author=Santanu Chaudhuri;,citation_author=Emad Tajkhorshid;,citation_author=Ian Foster;,citation_author=Mohamad Moosavi;,citation_author=Logan Ward;,citation_author=E. A. Huerta;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2501.10651;">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_abstract=We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &amp;amp;amp;gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinö Hatanpää;,citation_author=Varuni K. Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=Bharat Kale;,citation_author=Carla M. Mann;,citation_author=Heng Ma;,citation_author=Yun-Hsuan Cheng;,citation_author=Yuliana Zamora;,citation_author=Shengchao Liu;,citation_author=Chaowei Xiao;,citation_author=Murali Emani;,citation_author=Tom Gibbs;,citation_author=Mahidhar Tatineni;,citation_author=Deepak Canchi;,citation_author=Jerome Mitchell;,citation_author=Koichi Yamada;,citation_author=Maria Garzaran;,citation_author=Michael E. Papka;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1109/SC41406.2024.00013;,citation_doi=10.1109/SC41406.2024.00013;,citation_isbn=9798350352917;,citation_conference_title=Proceedings of the international conference for high performance computing, networking, storage, and analysis;,citation_conference=IEEE Press;,citation_series_title=SC ’24;">
<meta name="citation_reference" content="citation_title=Quality measures for dynamic graph generative models;,citation_author=Ryien Hosseini;,citation_author=Filippo Simini;,citation_author=Venkatram Vishwanath;,citation_author=Rebecca Willett;,citation_author=Henry Hoffmann;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://openreview.net/forum?id=8bjspmAMBk;,citation_conference_title=The thirteenth international conference on learning representations;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the Ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.22323/1.334.0245;,citation_volume=LATTICE2018;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calı̀;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2207.07641;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04607;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC’23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2312.08936;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinä Hatanpää;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=S. Foreman;,citation_author=X. Jin;,citation_author=J. Osborn;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_conference_title=The 38th international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>
<body class="quarto-light">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">LLMs on Aurora: Overview</h1>
  <p class="subtitle">🌌 AuroraGPT</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<a href="https://samforeman.me">Sam Foreman</a> 
</div>
<div class="quarto-title-author-email">
<a href="mailto:foremans@anl.gov">foremans@anl.gov</a>
</div>
        <p class="quarto-title-affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
    </div>
</div>

  <p class="date">2025-05-21</p>
</section>
<section id="section" class="slide level2 center" data-background-image="assets/colorized-50.jpg" loading="lazy" style="data-background-size: cover;">
<h2></h2>
<div style="border-radius: 6px; text-align:left; padding: 10pt; margin-left: auto; margin-right: auto; line-height: 1.25lh!important; background-color: hsla(222, 88%, 13%, 0.5);">
<div class="flex-container" style="text-shadow: 0 2px 3px rgba(0, 0, 0, 0.7); justify-content: space-between; align-content: flex-start; border-bottom: 1px solid hsla(360, 0%, 90%, 0.5);">
<div style="font-size: 1.25em; font-weight: 600;">
<p><span style="color: hsla(0, 0%, 80%, 1.0)!important;">ALCF INCITE GPU HACKATHON</span><br>
<span style="color: hsla(0, 0%, 75%, 1.0)!important;">May 20–22, 2025</span></p>
</div>
<p><span style="font-size: 1.5em; font-weight: 600; color:#FFFFFF"><i class="fa-solid fa-shapes" aria-label="shapes"></i></span></p>
</div>
<p><span style="font-size: 1.9em; font-weight: 700; text-shadow: 0 2px 3px rgba(0, 0, 0, 0.7); color:hsla(0, 0%, 100%, 1.0); margin-block: 1rem;">LLMs on Aurora: 🌌 AuroraGPT</span></p>
<p><span style="color:hsla(0, 0%, 80%, 1.0);font-size: 1.5em; font-weight: 600; text-shadow: 0 2px 3px rgba(0, 0, 0, 0.7); ">Sam Foreman</span></p>
<p><span style="color:hsla(0, 0%, 75%, 1.0);font-size: 1.2em; font-weight: 500; text-shadow: 0 2px 3px rgba(0, 0, 0, 0.7);"><em>2025-05-21</em></span></p>
</div>
</section>
<section id="alcf-incite-hackathon-2025" class="slide level2 center" data-background-color="white">
<h2>ALCF Incite Hackathon 2025</h2>
<ul>
<li><a href="https://www.alcf.anl.gov/events/alcf-incite-gpu-hackathon">2025 ALCF INCITE GPU Hackathon (20-May 22, 2025)</a></li>
<li>LLMs on Aurora<sup>1</sup>:
<ul>
<li><a href="https://samforeman.me/talks/incite-hackathon-2025/ezpz/slides">🍋 Hands-On: ezpz</a></li>
<li><a href="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT">🌌 Overview: AuroraGPT</a></li>
</ul></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn1"><p><em>my</em> talks can be found at: <a href="https://samforeman.me/talks/incite-hackathon-2025">https://samforeman.me/talks/incite-hackathon-2025</a></p></li></ol></aside></section>
<section id="auroragpt-goals" class="slide level2 smaller center" data-background-color="white">
<h2>🎯 AuroraGPT: Goals</h2>
<div class="flex-container" style="justify-content: space-around;">
<div class="column" style="width: 55%">
<div class="blue-card">
<p><a href="https://auroragpt.anl.gov"><strong>AuroraGPT</strong></a>: <em>General purpose scientific LLM</em><br>
Broadly trained on a general corpora plus scientific<br>
{papers, texts, data}</p>
</div>
<ul>
<li><strong>Explore pathways</strong> towards a “Scientific Assistant” model</li>
<li><strong>Build with international partners</strong> (RIKEN, BSC, others)</li>
<li><strong>Multilingual</strong> English, 日本語, French, German, Spanish</li>
<li><strong>Multimodal</strong>: images, tables, equations, proofs, time series, graphs, fields, sequences, etc</li>
</ul>
</div><div class="column" style="text-align: center;">
<div id="fig-awesome-llm" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-awesome-llm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/llms.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Image from  Hannibal046 / Awesome-LLM"><img data-src="./assets/llms.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-awesome-llm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Image from <iconify-icon role="img" inline="" icon="fa:github" aria-label="Icon github from fa Iconify.design set." title="Icon github from fa Iconify.design set."></iconify-icon> <a href="https://github.com/Hannibal046/Awesome-LLM">Hannibal046 / <code>Awesome-LLM</code></a>
</figcaption>
</figure>
</div>
</div></div>
<div id="fig-timeline" class="quarto-float quarto-figure quarto-figure-center" style="margin-left:auto;margin-right:auto;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/timelines.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Credit to the entire AuroraGPT team for slides."><img data-src="./assets/timelines.png" style="margin-left:auto;margin-right:auto;;width:75.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Credit to the entire AuroraGPT team for slides.
</figcaption>
</figure>
</div>
<aside class="notes">
<ul>
<li>Here to talk about AuroraGPT, Argonne’s internal effort to build a general purpose scientific LLM, broadly trained on a general corpora of text + scientific {papers, text, data}</li>
<li>As part of this effort, we plan to…
<ul>
<li>Explore pathways, build with international partners, multi-{lingual, modal}</li>
</ul></li>
<li>Rough timeline of the project and deliverables:
<ul>
<li>202{3,4}: text-only models, plan to release a series of {7B, 70B, 1T} models</li>
<li>202{4,5}: Basic multi-modal models</li>
<li>202{5,6}: Advanced scientific multimodal models</li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="issues-with-publicly-available-llms" class="slide level2 center" data-background-color="white">
<h2>🦙 Issues with “Publicly Available” LLMs</h2>
<ul>
<li><strong>Trust</strong> and <strong>Safety</strong>:
<ul>
<li>Skepticism about deployment in critical infrastructure</li>
<li>Correctness and reliability of model outputs</li>
</ul></li>
<li><strong>Transparency</strong>:
<ul>
<li>Data governance, <em>what was used for pre-training</em>? fine-tuning?
<ul>
<li><strong>generally unknown</strong></li>
</ul></li>
<li>What is <em>open source</em>?
<ul>
<li>Model weights?</li>
<li>Pre-training {code, logs, metrics} ?</li>
</ul></li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li>Why are we doing this?</li>
<li>What is the issue with current LLMs?
<ul>
<li><strong>Trust and safety</strong>
<ul>
<li>Hallucinations, false confidence</li>
<li>Can this be reliably mitigated?</li>
<li>Scaling up inference compute seems to help
<ul>
<li>reasoning models, TTT, etc.</li>
</ul></li>
</ul></li>
<li><strong>Transparency</strong>
<ul>
<li>Different frontier labs have different definitions of “open source”</li>
<li>e.g.&nbsp;Llama no longer releases base models
<ul>
<li>Libgen ??</li>
</ul></li>
<li>AllenAI institute, olmo models good example</li>
</ul></li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="auroragpt-open-science-foundation-model" class="slide level2 center" data-background-color="white">
<h2>🧪 AuroraGPT: Open Science Foundation Model</h2>
<div id="fig-aurora-gpt" class="quarto-float quarto-figure quarto-figure-center" style="vertical-align:center;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-aurora-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/AuroraGPT.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: High-level overview of AuroraGPT project"><img data-src="./assets/AuroraGPT.svg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aurora-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: High-level overview of AuroraGPT project
</figcaption>
</figure>
</div>
<aside class="notes">
<ul>
<li>AuroraGPT will be a publicly distributed, open source foundation model for open science</li>
<li>Is being trained on:
<ul>
<li>Scientific / engineering structured data</li>
<li>General text, media, news, etc.</li>
<li>Large amounts of low to medium quality data</li>
<li>Much less high quality data (that is publicly available for use)</li>
</ul></li>
<li>This data is then cleaned, processed, de-duplicated and used for the initial pre-training phase of the model</li>
<li>The vast majority of the overall compute is spent during this initial pre-training phase
<ul>
<li>This is the group I help to lead and will be talking a bit about today</li>
</ul></li>
<li>The initial pre-training phase is currently underway
<ul>
<li>Eventually, given a bit of time, effort and magic, the model will be ready for fine-tuning and additional training for a variety of downstream tasks</li>
</ul></li>
<li>The pretrained model will then be handed off for additional fine-tuning on a variety of downstream tasks
<ul>
<li>Scientific discovery</li>
<li>Accelerate scientific tasks</li>
<li>Digital twins</li>
<li>Inverse design</li>
<li>Code optimization</li>
<li>Accelerated simulations</li>
<li>Autonomous experiments</li>
<li>Co-design</li>
</ul></li>
<li>Becoming increasingly clear that LLMs have the potential to drastically accelerate computational science
<ul>
<li>We’ve seen this already for {GenSLMs, Weather / Climate / Earth Systems Modeling, Particle Physics, etc.}</li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="auroragpt-outcomes" class="slide level2 center" data-background-color="white">
<h2>📊 AuroraGPT: Outcomes</h2>
<ul>
<li><p><strong>Datasets and data pipelines</strong> for preparing science training data</p></li>
<li><p><strong>Software infrastructure and workflows</strong> to train, evaluate and deploy LLMs at scale for scientific resarch purposes</p>
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf/Megatron-DeepSpeed</a><br>
<span class="dim-text">End-to-end training and inference, on <em>any</em> GPU cluster</span></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/inference-endpoints">argonne-lcf/inference-endpoints</a><br>
<span class="dim-text">Inference endpoints for LLMs, hosted @ ALCF</span></li>
</ul></li>
<li><p><strong>Evaluation of state-of-the-art LLM Models</strong>:</p>
<ul>
<li>Determine where they fall short in deep scientific tasks</li>
<li>Where deep data may have an impact</li>
</ul></li>
</ul>
</section>
<section id="what-do-we-hope-to-get" class="slide level2 center" data-background-color="white">
<h2>📚 What do we hope to get?</h2>
<ul>
<li><strong>Assessment of the approach</strong> of augmenting web training data with two forms of data specific to science:
<ul>
<li>Full text scientific papers</li>
<li>Structured scientific datasets (suitably mapped to narrative form)</li>
</ul></li>
<li><strong>Research grade artifacts</strong> (<strong>models</strong>) for scientific community for adaptation for downstream uses<sup>1</sup></li>
<li><strong>Promotion of responsible AI</strong> best practices where we can figure them out</li>
<li><strong>International Collaborations</strong> around the long term goal of <em>AGI for science</em></li>
</ul>
<aside class="notes">
<ul>
<li>Deliverables:
<ul>
<li>datasets, pipelines</li>
<li>software infrastructure, workflows to interface with science applications</li>
<li>checkpoints, models, logs, workbook, insights, etc.</li>
</ul></li>
<li>Hope to understand:
<ul>
<li>How different state-of-the-art models perform at different scientific tasks</li>
<li>where deep data may have an impact</li>
<li>feasibility of generically augmenting text with scientific structured data</li>
</ul></li>
<li>Huge undertaking that will require large international collaborations around long term goal of AGI for science</li>
<li>Extra points:
<ul>
<li>Well known that LLMs are good for non-consequential tasks</li>
<li>Known to “hallucinate” and create false information</li>
<li>Can this be mitigated reliably ??</li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn2"><p><span class="citation" data-cites="mprot-dpo2024">(<a href="#/bibliography" role="doc-biblioref" onclick="">Dharuman et al. 2024</a>)</span></p></li></ol></aside></section>
<section id="aurora" class="slide level2 center" data-background-color="white">
<h2>🌌 Aurora</h2>
<div class="flex-container" style="align-items: center;">
<div class="column" style="width:5%;">
<div id="tbl-aurora" class="responsive striped hover quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-tbl">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Aurora Specs
</figcaption>
<div aria-describedby="tbl-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="table-responsive">
<table class="table-striped table-hover caption-top">
<thead>
<tr class="header">
<th style="text-align: right;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">Racks</td>
<td style="text-align: left;">166</td>
</tr>
<tr class="even">
<td style="text-align: right;">Nodes</td>
<td style="text-align: left;">10,624</td>
</tr>
<tr class="odd">
<td style="text-align: right;">CPUs</td>
<td style="text-align: left;">21,248</td>
</tr>
<tr class="even">
<td style="text-align: right;">GPUs</td>
<td style="text-align: left;">63,744</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NICs</td>
<td style="text-align: left;">84,992</td>
</tr>
<tr class="even">
<td style="text-align: right;">HBM</td>
<td style="text-align: left;">8 PB</td>
</tr>
<tr class="odd">
<td style="text-align: right;">DDR5c</td>
<td style="text-align: left;">10 PB</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div><div class="column" style="text-align:center">
<div id="fig-aurora" class="r-stretch quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/aurora.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Aurora: Fact Sheet."><img data-src="./assets/aurora.png"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Aurora: <a href="https://www.alcf.anl.gov/sites/default/files/2024-07/Aurora_FactSheet_2024.pdf">Fact Sheet</a>.
</figcaption>
</figure>
</div>
<p>🏆 <a href="https://www.intel.com/content/www/us/en/newsroom/news/intel-powered-aurora-supercomputer-breaks-exascale-barrier.html">Fastest AI system in the world</a></p>
</div></div>
</section>
<section id="alcf-ai-testbed" class="slide level2 center" data-background-color="white">
<h2>🤖 ALCF AI Testbed</h2>
<ul>
<li>ALCF AI Testbed Systems are in production and <a href="https://accounts.alcf.anl.gov/#/allocationRequests">available for allocations</a> to the research community</li>
<li>Significant improvement in time-to-solution and energy-efficiency for diverse AI for science applications.</li>
<li><a href="https://nairrpilot.org/">NAIRR Pilot</a></li>
</ul>
<div class="red-card" style="color: #FF5252; font-size:90%;">
<p>Up to <span class="math inline">≈</span> <strong>25</strong><span class="math inline">\times</span> throughput improvement for genomic FMs with <strong>6.5</strong><span class="math inline">\times</span> energy efficiency</p>
</div>
<div class="flex-container" style="align-items: flex-start; gap: 2pt; text-align:left;">
<div id="fig-sambanova" class="column quarto-float quarto-figure quarto-figure-center" style="width:22%; text-align: left;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-sambanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/sambanova.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: SambaNova SN-30 2nd Gen, 8 nodes with 64 AI Accelerators"><img data-src="./assets/sambanova.jpeg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sambanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>SambaNova SN-30</strong> 2nd Gen, 8 nodes with 64 AI Accelerators
</figcaption>
</figure>
</div><div id="fig-graphcore" class="column quarto-float quarto-figure quarto-figure-center" style="width:22%; text-align:left;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-graphcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/graphcore.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Graphcore Bow: Pod-64 configuration with 64 accelerators"><img data-src="./assets/graphcore.png"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-graphcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>Graphcore Bow</strong>: Pod-64 configuration with 64 accelerators
</figcaption>
</figure>
</div><div id="fig-cerebras" class="column quarto-float quarto-figure quarto-figure-center" style="width:22%; text-align:left;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-cerebras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/cerebras.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Cerebras: 2x CS-2 WSE with Memory-X and Swarm-X technologies"><img data-src="./assets/cerebras.jpeg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cerebras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>Cerebras</strong>: 2x CS-2 WSE with Memory-X and Swarm-X technologies
</figcaption>
</figure>
</div><div id="fig-groq" class="column quarto-float quarto-figure quarto-figure-center" style="width:22%; text-align:left;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-groq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/groq.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;8: GroqRack: 9 nodes, 8 GroqChip v1.5 Tensor streaming processors accelerators per node"><img data-src="./assets/groq.jpeg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-groq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: <strong>GroqRack</strong>: 9 nodes, 8 GroqChip v1.5 Tensor streaming processors accelerators per node
</figcaption>
</figure>
</div></div>
</section>
<section id="team-leads" class="slide level2 smaller center" data-background-color="white">
<h2>👥 Team Leads</h2>
<div style="font-size: 90%;">
<div class="flex-container" style="text-align: center; align-items: center;">
<p><strong>Planning</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/rick-stevens.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Rick Stevens"><img data-src="./assets/team/rick-stevens.png" style="height:1.04167in" alt="Rick Stevens"></a></p>
<figcaption>Rick Stevens<sup>1</sup></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/ian-foster.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Ian Foster"><img data-src="./assets/team/ian-foster.png" style="height:1.04167in" alt="Ian Foster"></a></p>
<figcaption>Ian Foster</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/rinku-gupta.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Rinku Gupta"><img data-src="./assets/team/rinku-gupta.png" style="height:1.04167in" alt="Rinku Gupta"></a></p>
<figcaption>Rinku Gupta</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/mike-papka.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Mike Papka"><img data-src="./assets/team/mike-papka.png" style="height:1.04167in" alt="Mike Papka"></a></p>
<figcaption>Mike Papka</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/arvind-ramanathan.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Arvind Ramanathan"><img data-src="./assets/team/arvind-ramanathan.png" style="height:1.04167in" alt="Arvind Ramanathan"></a></p>
<figcaption>Arvind Ramanathan</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/fangfang-xia.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Fangfang Xia"><img data-src="./assets/team/fangfang-xia.png" style="height:1.04167in" alt="Fangfang Xia"></a></p>
<figcaption>Fangfang Xia</figcaption>
</figure>
</div>
</div>
<div class="flex-container" style="text-align: center;">
<div class="col">
<p><strong>Data</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/ian-foster.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Ian Foster"><img data-src="./assets/team/ian-foster.png" style="height:1.04167in" alt="Ian Foster"></a></p>
<figcaption>Ian Foster</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/robert-underwood.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Robert Underwood"><img data-src="./assets/team/robert-underwood.png" style="height:1.04167in" alt="Robert Underwood"></a></p>
<figcaption>Robert Underwood</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Training</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/venkat-vishwanath.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Venkat Vishwanath"><img data-src="./assets/team/venkat-vishwanath.png" style="height:1.04167in" alt="Venkat Vishwanath"></a></p>
<figcaption>Venkat Vishwanath</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/sam-foreman.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" title="Sam Foreman"><img data-src="./assets/team/sam-foreman.png" style="height:1.04167in" alt="Sam Foreman"></a></p>
<figcaption><span style="color: #ff1a8f; background-color: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); font-weight: 500;">Sam Foreman</span></figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Evaluation</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/franck-cappello.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19" title="Franck Cappello"><img data-src="./assets/team/franck-cappello.png" style="height:1.04167in" alt="Franck Cappello"></a></p>
<figcaption>Franck Cappello</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/sandeep-madireddy.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Sandeep Madireddy"><img data-src="./assets/team/sandeep-madireddy.png" style="height:1.04167in" alt="Sandeep Madireddy"></a></p>
<figcaption>Sandeep Madireddy</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/bo-li.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Bo Li"><img data-src="./assets/team/bo-li.png" style="height:1.04167in" alt="Bo Li"></a></p>
<figcaption>Bo Li</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Post</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/eliu-huerta.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Eliu Huerta"><img data-src="./assets/team/eliu-huerta.png" style="height:1.04167in" alt="Eliu Huerta"></a></p>
<figcaption>Eliu Huerta</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/azton-wells.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="Azton Wells"><img data-src="./assets/team/azton-wells.png" style="height:1.04167in" alt="Azton Wells"></a></p>
<figcaption>Azton Wells</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Inference</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/rajeev-thakur.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="Rajeev Thakur"><img data-src="./assets/team/rajeev-thakur.png" style="height:1.04167in" alt="Rajeev Thakur"></a></p>
<figcaption>Rajeev Thakur</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Comms</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/charlie-catlett.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Charlie Catlett"><img data-src="./assets/team/charlie-catlett.png" style="height:1.04167in" alt="Charlie Catlett"></a></p>
<figcaption>Charlie Catlett</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/david-martin.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="David Martin"><img data-src="./assets/team/david-martin.png" style="height:1.04167in" alt="David Martin"></a></p>
<figcaption>David Martin</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Distribution</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="./assets/team/brad-ullrich.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Brad Ullrich"><img data-src="./assets/team/brad-ullrich.png" style="height:1.04167in" alt="Brad Ullrich"></a></p>
<figcaption>Brad Ullrich</figcaption>
</figure>
</div>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn3"><p>Lead</p></li></ol></aside></section>
<section id="teams" class="slide level2 center" data-auto-animate="true" data-background-color="white">
<h2 data-id="quarto-animate-title">🤝 Teams</h2>
<div class="flex-container">
<div class="column">
<ul>
<li><strong>Planning</strong></li>
<li><strong>Data Prep</strong>
<ul>
<li>Accumulate 20+ T tokens of high-quality scientific text and structured data</li>
</ul></li>
<li><span style="background: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); border: 1px solid #ff1a8f; border-radius: 0.25px;"><strong>Models / Training</strong></span><sup>1</sup>
<ul>
<li>Train (entirely from scratch) a series of models on publicly available data</li>
</ul></li>
<li><strong>Evaluation</strong>
<ul>
<li>Skills, trustworthiness, safety, robustness, privacy, machine ethics</li>
</ul></li>
</ul>
</div><div class="column">
<ul>
<li><strong>Post-Training</strong>
<ul>
<li>Fine-tuning, alignment</li>
</ul></li>
<li><strong>Inference</strong>
<ul>
<li>Model serving, API development / public-facing web services</li>
</ul></li>
<li><strong>Distribution</strong>
<ul>
<li>Licensing, generating and distributing artifacts for public consumption</li>
</ul></li>
<li><strong>Communication</strong></li>
</ul>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn4"><p>Co-led by: Venkat Vishwanath, <strong>Sam Foreman</strong></p></li></ol></aside></section>
<section id="data" class="slide level2 center" data-background-color="white">
<h2>📚 Data</h2>
<div class="green-card">
<p>✅ <strong>Goal</strong>: Assemble a large corpus of documents (general and scientific) to train and fine-tune AuroraGPT models</p>
</div>
<ul>
<li><strong>Challenges</strong>: Avoid / detect contamination with benchmarks
<ul>
<li>Respect copyright (ACM Digital Library), privacy, and ethical considerations</li>
</ul></li>
<li><strong>Performance Challenges</strong>: <em>High throughput</em> data processing
<ul>
<li>Converting PDF <span class="math inline">\rightarrow</span> text (math formula, figures)</li>
<li>Convert science information (data) into text (narratives)</li>
<li>De-duplication (syntactic and semantic) of scientific documents (to avoid memorization, bias)</li>
</ul></li>
<li><strong>Quantity</strong>: Considering 20+ Trillion tokens <span class="math inline">\rightarrow\approx</span> 100M papers</li>
<li><strong>Domains</strong>: All (long-term) scientific domains, starting with:
<ul>
<li>Material science, Physics, Biology, Computer Science, Climate Science</li>
</ul></li>
</ul>
</section>
<section id="dataset-processing" class="slide level2 center" data-background-color="white">
<h2>⏱️ Dataset Processing</h2>
<ul>
<li>To train a fixed model on trillions of tokens requires:
<ol type="1">
<li><strong>Aggregating</strong> data from multiple different <em>corpora</em><br>
(e.g.&nbsp;ArXiv, Reddit, StackExchange, GitHub, Wikipedia, etc.)</li>
<li><strong>Sampling</strong> <em>each training batch</em> according to a fixed distribution across corpora</li>
<li><strong>Building</strong> indices that map batches of tokens into these files (indexing)</li>
</ol>
<div class="red-card">
<p>The original implementation was <em>slow</em>:</p>
<ul>
<li>Designed to run <em>serially</em> on a <strong>single device</strong></li>
<li><strong>Major bottleneck</strong> when debugging data pipeline at scale</li>
</ul>
</div></li>
</ul>
</section>
<section id="accelerating-dataset-processing-results" class="slide level2 center" data-background-color="white">
<h2>🚀 Accelerating Dataset Processing: Results</h2>
<div class="flex-container" style="padding: 10pt; justify-content: space-around; align-items: flex-start;">
<div class="column" style="width:25%;">
<ul>
<li>Original implementation:
<ul>
<li><strong>Slow</strong>!</li>
<li><span class="dim-text">🐌 ~ 1 hr</span>/2T tokens</li>
</ul></li>
<li><label><input type="checkbox" checked="">Fix:</label>
<ul>
<li>Wrote <em>asynchronous</em>, <strong>distributed</strong> implementation</li>
<li><em>significantly</em> improves performance (<strong>30x</strong> !!)</li>
<li>🏎️💨 <span style="color:#2296F3;">~ <strong>2 min</strong></span>/2T tokens</li>
</ul></li>
</ul>
</div><div class="column">
<div id="fig-data-processing" class="r-stretch quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-data-processing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/data-processing.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Figure&nbsp;9: Time spent preparing 2T tokens"><img data-src="./assets/data-processing.svg" class="r-stretch"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-processing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Time spent preparing 2T tokens
</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="model-training" class="slide level2 smaller center" data-background-color="white">
<h2>🦜 Model Training</h2>
<div class="flex-container" style="text-align: left; width: 100%; justify-content: space-around; line-height: 1em; gap: 5pt;">
<div class="column green-card" style="margin:unset;">
<p>✅ <span style="color: var(--green-fg);"><strong>Goals</strong></span></p>
<ul>
<li>Want training runs at scale to be:
<ul>
<li>efficient</li>
<li>stable</li>
<li>reproducible</li>
</ul></li>
<li>This requires:
<ul>
<li>robust data pipelines / file IO</li>
<li>effectively overlapping compute with communication</li>
<li>stability across {network, filesystem, machine}</li>
</ul></li>
<li>3D / Multi-dimensional Parallelism strategies</li>
<li>Large batch training</li>
<li>Second order optimizers</li>
<li>Sub-quadratic attention</li>
<li>State space models</li>
<li><em>Highly optimized GPU kernels</em></li>
</ul>
</div><div class="column red-card">
<p>❌ <span style="color: var(--quarto-scss-export-re);"><strong>Challenges</strong></span></p>
<ul>
<li><em>Looong time</em> to train, can be:
<ul>
<li>weeks (even months) of continuous training</li>
<li>order of magnitude longer than typical NN training jobs</li>
</ul></li>
<li>Stability issues:
<ul>
<li>failures are expensive (but inevitable)</li>
<li>stragglers common at scale</li>
</ul></li>
<li>Individual jobs are:
<ul>
<li><strong>fragile</strong></li>
<li>only as good as the worst rank</li>
<li>one hang or bad worker can crash job</li>
<li>network / filesystem / other-user(s) dependent</li>
</ul></li>
<li>Cost / benefits of different collective communication algorithms
<ul>
<li>depend on optimized / efficient implementations</li>
</ul></li>
<li>Network performance</li>
<li><em>Highly optimized GPU kernels</em></li>
</ul>
</div></div>

<aside><div>
<p><iconify-icon role="img" inline="" icon="fa:github" aria-label="Icon github from fa Iconify.design set." title="Icon github from fa Iconify.design set."></iconify-icon> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf / Megatron-DeepSpeed</a></p>
</div></aside></section>
<section id="loss-curve-training-auroragpt-7b-on-2t-tokens" class="slide level2 center" data-background-color="white">
<h2>📉 Loss Curve: Training AuroraGPT-7B on 2T Tokens</h2>
<div id="fig-loss-curve" class="quarto-float quarto-figure quarto-figure-center" style="margin-left:auto;margin-right:auto;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-loss-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/train-val-loss-vs-tokens-medium.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="Figure&nbsp;10: Loss curve during training on 2T tokens."><img data-src="./assets/train-val-loss-vs-tokens-medium.svg" style="margin-left:auto;margin-right:auto;;width:90.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loss-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Loss curve during training on 2T tokens.
</figcaption>
</figure>
</div>
</section>
<section id="evaluating-fm-skills-for-science" class="slide level2 center" data-background-color="white">
<h2>🤔 Evaluating FM Skills for Science</h2>
<ul>
<li>What to measure?
<ul>
<li><strong>Knowledge Extraction, Retrieval, Distillation, Synthesis</strong>: LLM is provided a question or instruction and a truthful answer is expected</li>
<li><strong>Text Grounded</strong>: Answers are expected to be fully grounded on peer-reviewed references to support responses</li>
<li><strong>Reasoning</strong>: LLMs are expected to solve deductive (prove a theory or hypothesis from formal logic and observations), inductive (validate / explain observations from theories) problems</li>
<li><strong>Creativity</strong>: A creative answer is expected from a question or instruction
<ul>
<li>thoughtful dialogue, coding, etc.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="evaluating-fm-skills-for-science-criteria" class="slide level2 center" data-background-color="white">
<h2>⚖️ Evaluating FM Skills for Science: Criteria</h2>
<ul>
<li>Criteria for all of the above:
<ul>
<li><strong>Correctness</strong> of facts</li>
<li><strong>Accuracy</strong> of solutions and inferences</li>
<li><strong>Reliability</strong> consistently good in quality or performance</li>
<li><strong>Speed</strong> how fast to produce a response</li>
<li><strong># shots</strong> how many examples are needed for good quality
<ul>
<li>Extent of <em>prompt engineering</em></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="mprot-dpo-scaling-results" class="slide level2 smaller center" data-background-color="white">
<h2>🧬 MProt-DPO: Scaling Results</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div class="flex-container" style="align-items: center; text-align: center; margin-left: auto; margin-right: auto;">
<div id="fig-mprot-3p5B-scaling0" class="quarto-float quarto-figure quarto-figure-center" style="margin:0; padding-unset;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-mprot-3p5B-scaling0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/mprot-3p5B-scaling-2.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-30" title="Figure&nbsp;11: Scaling results for 3.5B model across ~38,400 GPUs"><img data-src="./assets/mprot-3p5B-scaling-2.svg" style="margin:0; padding-unset;;width:100.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mprot-3p5B-scaling0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Scaling results for <code>3.5B</code> model across ~38,400 GPUs
</figcaption>
</figure>
</div>
</div>
</div><div class="column" style="width:30%;">
<ul>
<li><p>~ <span class="highlight-blue">4 EFLOPS</span> @ Aurora</p></li>
<li><p>38,400 XPUs<br>
= 3200 [node] x 12 [XPU / node]</p></li>
<li><p>🔔 Gordon Bell Finalist<sup>1</sup>:</p>
<ul>
<li><a href="https://dl.acm.org/doi/10.1109/SC41406.2024.00013">MProt-DPO: Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows</a></li>
</ul></li>
</ul>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn5"><p><span class="citation" data-cites="mprot-dpo2024">(<a href="#/bibliography" role="doc-biblioref" onclick="">Dharuman et al. 2024</a>)</span></p></li></ol></aside></section>
<section id="references" class="slide level2 center" data-background-color="white">
<h2>📓 References</h2>
<div class="flex-container" style="gap: 2pt;">
<div class="column">
<ul>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf / <code>Megatron-DeepSpeed</code></a><br>
<span class="dim-text">For the largest of large language models.</span></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2 / <code>ezpz</code></a><br>
<span class="dim-text">Distributed training, ezpz. 🍋</span></li>
<li>📊 See my other slides at <a href="https://samforeman.me/talks">samforeman.me/talks</a>:
<ul>
<li><a href="https://saforem2.github.io/llm-workshop-talk">LLMs from Scratch</a></li>
<li><a href="https://saforem2.github.io/LLM-tutorial">Creating Small(~ish) LLMs</a></li>
<li><a href="https://saforem2.github.io/parallel-training-slides">Parallel Training Techniques</a></li>
<li><a href="https://samforeman.me/talks/llms-on-polaris/#/title-slide">LLMs on Polaris</a></li>
<li><a href="https://samforeman.me/talks/llms-at-scale/">Training LLMs at Scale</a></li>
</ul></li>
</ul>
</div><div class="column">
<ul>
<li>👀 See also:
<ul>
<li><a href="https://www.anl.gov/article/new-international-consortium-formed-to-create-trustworthy-and-reliable-generative-ai-models-for">New international consortium for generative AI models for science</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li><a href="https://huggingface.co/docs/transformers/en/perf_train_gpu_many">🤗 Efficient Training on Multiple GPUs</a></li>
<li><a href="https://www.deepspeed.ai/getting-started/">Getting Started - DeepSpeed</a></li>
<li>🕸️ <a href="https://openreview.net/forum?id=8bjspmAMBk">Quality Measures for Dynamic Graph Generative Models</a><br>
<span class="citation" data-cites="hosseini2025quality">(<a href="#/bibliography" role="doc-biblioref" onclick="">Hosseini et al. 2025</a>)</span></li>
</ul></li>
</ul>
</div></div>
</section>
<section id="thank-you" class="slide level2 center" data-background-color="white">
<h2>❤️ Thank you!</h2>
<ul>
<li><p>Organizers</p></li>
<li><p>Feel free to reach out!</p>
<p><split even=""></split></p>
<p><a href="https://samforeman.me"><i class="fas fa-home"></i></a> <a href="mailto:///foremans@anl.gov"><i class="far fa-paper-plane"></i></a> <a href="https://www.twitter.com/saforem2"><i class="fab fa-twitter"></i></a></p>
<p></p></li>
</ul>
<div title="🙏 Acknowledgements">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>🙏 Acknowledgements</strong></p>
</div>
<div class="callout-content">
<p>This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357.</p>
</div>
</div>
</div>
</div>
</section>
<section id="bibliography" class="slide level2 smaller scrollable" data-background-color="white">
<h2>📑 Bibliography</h2>
<ul>
<li>Refs:
<ul>
<li><span class="citation" data-cites="wei2022emergentabilitieslargelanguage">Wei et al. (<a href="#/bibliography" role="doc-biblioref" onclick="">2022</a>)</span></li>
<li>Animations from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li>
</ul></li>
</ul>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-mprot-dpo2024" class="csl-entry" role="listitem">
Dharuman, Gautham, Kyle Hippe, Alexander Brace, Sam Foreman, Väinö Hatanpää, Varuni K. Sastry, Huihuo Zheng, et al. 2024. <span>“MProt-DPO: Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows with Direct Preference Optimization.”</span> In <em>Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis</em>. SC ’24. Atlanta, GA, USA: IEEE Press. <a href="https://doi.org/10.1109/SC41406.2024.00013">https://doi.org/10.1109/SC41406.2024.00013</a>.
</div>
<div id="ref-hosseini2025quality" class="csl-entry" role="listitem">
Hosseini, Ryien, Filippo Simini, Venkatram Vishwanath, Rebecca Willett, and Henry Hoffmann. 2025. <span>“Quality Measures for Dynamic Graph Generative Models.”</span> In <em>The Thirteenth International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=8bjspmAMBk">https://openreview.net/forum?id=8bjspmAMBk</a>.
</div>
<div id="ref-song2023ds4sci" class="csl-entry" role="listitem">
Song, Shuaiwen Leon, Bonnie Kruft, Minjia Zhang, Conglong Li, Shiyang Chen, Chengming Zhang, Masahiro Tanaka, et al. 2023. <span>“DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery Through Sophisticated AI System Technologies.”</span> <a href="https://arxiv.org/abs/2310.04610">https://arxiv.org/abs/2310.04610</a>.
</div>
<div id="ref-wei2022emergentabilitieslargelanguage" class="csl-entry" role="listitem">
Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. <span>“Emergent Abilities of Large Language Models.”</span> <a href="https://arxiv.org/abs/2206.07682">https://arxiv.org/abs/2206.07682</a>.
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. <span>“Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.”</span> <a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a>.
</div>
</div>
</section>
<section id="mprot-dpo-scaling-results-1" class="slide level2 smaller center" data-background-color="#1c1c1c">
<h2>🧬 MProt-DPO: Scaling Results</h2>
<div class="columns">
<div id="fig-mprot-3p5B-scaling" class="column quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-mprot-3p5B-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/mprot-3p5B-scaling-2.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-31" title="Figure&nbsp;12: 3.5B model"><img data-src="./assets/mprot-3p5B-scaling-2.svg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mprot-3p5B-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: <code>3.5B</code> model
</figcaption>
</figure>
</div><div id="fig-mprot-7B-scaling" class="column quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-mprot-7B-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/mprot-7B-scaling-2.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-32" title="Figure&nbsp;13: 7B model"><img data-src="./assets/mprot-7B-scaling-2.svg"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mprot-7B-scaling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: <code>7B</code> model
</figcaption>
</figure>
</div></div>
</section>
<section id="loooooooooong-sequence-lengths" class="slide level2 smaller center" data-background-color="#1c1c1c">
<h2>🚂 Loooooooooong Sequence Lengths</h2>
<div class="flex-container" style="align-items: center; justify-content: center;">
<p><a href="../../../assets/anl.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-33"><img data-src="../../../assets/anl.svg" style="height:50pt; margin: unset; padding: 0"></a></p>
<p><span class="dim-text" style="font-size: 2.0em;"><iconify-icon role="img" inline="" icon="ic:baseline-plus" aria-label="Icon baseline-plus from ic Iconify.design set." title="Icon baseline-plus from ic Iconify.design set."></iconify-icon></span></p>
<p><a href="../../../assets/deepspeed-logo-transparent.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img data-src="../../../assets/deepspeed-logo-transparent.svg" style="height:50pt; margin: unset; padding: 0;"></a></p>
</div>
<ul>
<li>Working with <a href="https://github.com/microsoft/DeepSpeed"><i class="fa-brands fa-microsoft" aria-label="microsoft"></i> Microsoft/DeepSpeed</a> team to enable longer sequence lengths (context windows) for LLMs
<ul>
<li>See my <a href="https://samforeman.me/posts/auroragpt/long-sequences/">blog post</a> for additional details</li>
</ul></li>
</ul>
<div id="fig-long-seq" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-long-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="flex-container">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/25B.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-35" title="25B"><img data-src="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/25B.svg"></a></p>
<figcaption>25B</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/33B.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-36" title="33B"><img data-src="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/33B.svg"></a></p>
<figcaption>33B</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-long-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: Maximum (achievable) <code>SEQ_LEN</code> for both <code>25B</code> and <code>33B</code> models (See: <span class="citation" data-cites="song2023ds4sci">Song et al. (<a href="#/bibliography" role="doc-biblioref" onclick="">2023</a>)</span>)
</figcaption>
</figure>
</div>

<aside><div>
<p><a href="https://github.com/saforem2/scaling4science"><i class="fa-brands fa-github" aria-label="github"></i> <code>scaling4science</code></a><br>
<a href="https://github.com/saforem2/Megatron-DS-Benchmarking"><i class="fa-brands fa-github" aria-label="github"></i> <code>Megatron-DS-Benchmarking</code></a></p>
</div></aside></section>
<section id="life-cycle-of-the-llm" class="slide level2 center" data-background-color="white">
<h2>♻️ Life Cycle of the LLM</h2>
<div class="panel-tabset" style="text-align:center">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">📝 Pre-training</a></li><li><a href="#tabset-1-2">🎀 Fine-Tuning</a></li></ul>
<div class="tab-content" style="text-align:center">
<div id="tabset-1-1">
<div id="fig-pretraining" class="quarto-float quarto-figure quarto-figure-center" style="width:90%; text-align: center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-pretraining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-37" title="Figure&nbsp;15: Pre-training: Virtually all of the compute used during pretraining phase"><img data-src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretraining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: <strong>Pre-training</strong>: Virtually all of the compute used during pretraining phase
</figcaption>
</figure>
</div>
</div>
<div id="tabset-1-2">
<div id="fig-fine-tuning" class="quarto-float quarto-figure quarto-figure-center" style="width:90%; text-align: center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-fine-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-38" title="Figure&nbsp;16: Fine-tuning: Fine-tuning actually updates the model’s weights to make the model better at a certain task."><img data-src="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fine-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16: <strong>Fine-tuning</strong>: Fine-tuning actually updates the model’s weights to make the model better at a certain task.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="training-llms" class="slide level2 smaller center" data-background-color="white">
<h2>🍎 Training LLMs</h2>
<div class="flex-container" style="align-items: flex-end;">
<div class="column" style="width:221pt;">
<div id="fig-it-hungers" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true" class="lightbox" data-gallery="quarto-lightbox-gallery-39" title="Figure&nbsp;17: It’s hungry!"><img data-src="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17: It’s hungry!
</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<div id="fig-evolution" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-40" title="Figure&nbsp;18: Visualization from @yang2023harnessing"><img data-src="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;18: Visualization from <span class="citation" data-cites="yang2023harnessing">Yang et al. (<a href="#/bibliography" role="doc-biblioref" onclick="">2023</a>)</span>
</figcaption>
</figure>
</div>
</div></div>


</section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../../assets/anl.svg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT/slides">samforeman.me/talks/incite-hackathon-2025/AuroraGPT/slides</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-text-resizer/revealjs-text-resizer.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: false,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, RevealTextResizer, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/samforeman\.me");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>