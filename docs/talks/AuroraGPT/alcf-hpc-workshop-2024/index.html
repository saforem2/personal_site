<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sam Foreman">
<meta name="dcterms.date" content="2024-10-30">

<title>AuroraGPT: ANL’s General Purpose Scientific LLM – Sam Foreman</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../talks/test/slides.html" rel="prev">
<link href="../../../assets/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-49827a6032b70b85983380df837a8e6d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-e7cce4e5decb9dc760b438a0c873e39d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<link href="../../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">

<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>

<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans&amp;family=IBM+Plex+Sans+Condensed&amp;family=IBM+Plex+Mono&amp;display=swap" rel="stylesheet">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
<!-- End Google Tag Manager -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<script src="https://app.rybbit.io/api/script.js" data-site-id="152" defer=""></script>

  <script defer="" src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../css/colors-oklch.min.css">
<link rel="stylesheet" href="../../../css/custom.css">
<link rel="stylesheet" href="../../../css/svgbob.css">
<link rel="stylesheet" href="../../../static/fonts/MIosevkaQp/MIosevkaQp.css">
<link rel="stylesheet" href="../../../static/fonts/MIosevkaterm/MIosevkaTerm.css">
<meta property="og:title" content="AuroraGPT @ ALCF Hands-On HPC Workshop 2024">
<meta property="og:description" content="Overview of AuroraGPT at ALCF">
<meta property="og:image" content="https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/assets/thumbnail.png">
<meta property="og:site_name" content="Sam Foreman">
<meta property="og:image:height" content="2572">
<meta property="og:image:width" content="4112">
<meta name="twitter:title" content="AuroraGPT @ ALCF Hands-On HPC Workshop 2024">
<meta name="twitter:description" content="Overview of AuroraGPT at ALCF">
<meta name="twitter:image" content="https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:card" content="summary">
<meta name="twitter:image-height" content="2572">
<meta name="twitter:image-width" content="4112">
<meta name="citation_title" content="AuroraGPT: ANL&amp;amp;#039;s General Purpose Scientific LLM">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2024-10-30">
<meta name="citation_cover_date" content="2024-10-30">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-10-30">
<meta name="citation_fulltext_html_url" content="https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_abstract=We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &amp;amp;amp;gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinö Hatanpää;,citation_author=Varuni K. Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=Bharat Kale;,citation_author=Carla M. Mann;,citation_author=Heng Ma;,citation_author=Yun-Hsuan Cheng;,citation_author=Yuliana Zamora;,citation_author=Shengchao Liu;,citation_author=Chaowei Xiao;,citation_author=Murali Emani;,citation_author=Tom Gibbs;,citation_author=Mahidhar Tatineni;,citation_author=Deepak Canchi;,citation_author=Jerome Mitchell;,citation_author=Koichi Yamada;,citation_author=Maria Garzaran;,citation_author=Michael E. Papka;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1109/SC41406.2024.00013;,citation_doi=10.1109/SC41406.2024.00013;,citation_isbn=9798350352917;,citation_conference_title=Proceedings of the international conference for high performance computing, networking, storage, and analysis;,citation_conference=IEEE Press;,citation_series_title=SC ’24;">
<meta name="citation_reference" content="citation_title=Quality measures for dynamic graph generative models;,citation_author=Ryien Hosseini;,citation_author=Filippo Simini;,citation_author=Venkatram Vishwanath;,citation_author=Rebecca Willett;,citation_author=Henry Hoffmann;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://openreview.net/forum?id=8bjspmAMBk;,citation_conference_title=The thirteenth international conference on learning representations;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the Ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.22323/1.334.0245;,citation_volume=LATTICE2018;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calı̀;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC’23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinä Hatanpää;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=S. Foreman;,citation_author=X. Jin;,citation_author=J. Osborn;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_conference_title=The 38th international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../assets/signature-navbar-orig.svg" alt="Sam Foreman" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../talks/index.html" aria-current="page"> 
<span class="menu-text">talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../posts/index.html"> 
<span class="menu-text">posts</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../../projects/index.html">
 <span class="dropdown-text">📚 All Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ezpz">
 <span class="dropdown-text">🍋 <code>ezpz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/l2hmc-qcd">
 <span class="dropdown-text">🟥 <code>l2hmc-qcd</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/argonne-lcf/Megatron-DeepSpeed)">
 <span class="dropdown-text">🤖 <code>Megatron-DeepSpeed</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/wordplay">
 <span class="dropdown-text">💬 <code>wordplay</code> 🎮</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.alcf.anl.gov/alcf-ai-science-training-series?">
 <span class="dropdown-text">🎓 <code>ai-science-training</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/enrich">
 <span class="dropdown-text">💸 <code>enrich</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ambivalent">
 <span class="dropdown-text">🤷🏻‍♂️<code>ambivalent</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/climate-analysis">
 <span class="dropdown-text">🌍 <code>climate-analysis</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/glitz">
 <span class="dropdown-text">🎨 <code>glitz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/personal_site">
 <span class="dropdown-text">🙋🏻<code>personal_site</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/notes-demo">
 <span class="dropdown-text">🗒️ <code>Notes-Demo</code></span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/saforem2/personal_site"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:github-logo" aria-label="Icon github-logo from ph Iconify.design set." title="Icon github-logo from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../index.xml"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:rss" aria-label="Icon rss from ph Iconify.design set." title="Icon rss from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../talks/index.html">🎙️ Talks</a></li><li class="breadcrumb-item"><a href="../../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html">AuroraGPT</a></li><li class="breadcrumb-item"><a href="../../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html">AuroraGPT: ANL’s General Purpose Scientific LLM</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../projects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📚 Projects</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../posts/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📬 Posts</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/aurora-frameworks-2025-numpy-2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚧 Frameworks Issue with <code>numpy &gt; 2</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/dope-slides/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">💅 How to Make Dope Slides</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/ezpz-at-alcf/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🍋 <code>ezpz</code> @ ALCF</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/ezpz-v1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📝 ezpz-v1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/installing-pytorch-on-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🔥 Building PyTorch from Source on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/resume/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">👤 Résumé</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/svgbob/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🫥 svgbob</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/torchtune-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🪛 Torchtune on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/torchtune-patch-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚑 Torchtune Patch on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../posts/AuroraGPT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🤖 AuroraGPT</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/aurora-gpt/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏎️ Megatron-DeepSpeed on Intel XPU</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/checkpoints/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">💾 Converting Checkpoints</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/determinstic-flash-attn/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎰 Deterministic <code>flash-attn</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/flash-attn-sunspot/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📸 <code>flash-attn</code> on Sunspot</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/long-sequences/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚂 Loooooooong Sequence Lengths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/mpi4py-reproducer/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🐛 <code>mpi4py</code> bug on Sunspot</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/spike-skipper/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏔️ Spike Skipper</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/AuroraGPT/startup-times/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🐢 Starting Up Distributed Training on Aurora</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">⚛️ AI for Physics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/ai-for-physics/diffusion/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎲 MCMC + Diffusion Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">🎢 L2HMC for LQCD</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/ai-for-physics/l2hmc-qcd/2dU1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎢 <code>l2hmc-qcd</code> Example: 2D U(1)</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">4dSU3nb</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🕸️ l2hmc-qcd Example: 4D SU(3)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">📗 Jupyter</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/jupyter/test/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏁 <code>l2hmc</code> Example: 2D <span class="math inline">U(1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">L2hmc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/jupyter/l2hmc/4dSU3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🔳 <code>l2hmc-qcd</code> Example: 4D SU(3)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../talks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎙️ Talks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/ai-for-science-2024/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallel Training Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/alcf-hpc-workshop-2024/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning and Foundation Models at Scale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/aurora-gpt-fm-for-electric-grid/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AuroraGPT: Foundation Models for Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/hpc-user-forum/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AuroraGPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/incite-hackathon-2025/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Large Language Models on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/lattice23/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MLMC: Machine Learning Monte Carlo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/llms-at-scale/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training LLMs at Scale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/llms-on-polaris/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LLMs on Polaris</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/test/slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test Rendering on Mobile</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">AuroraGPT</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">AuroraGPT: ANL’s General Purpose Scientific LLM</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#auroragpt-goals" id="toc-auroragpt-goals" class="nav-link active" data-scroll-target="#auroragpt-goals">🎯 AuroraGPT Goals</a></li>
  <li><a href="#auroragpt-open-science-foundation-models" id="toc-auroragpt-open-science-foundation-models" class="nav-link" data-scroll-target="#auroragpt-open-science-foundation-models">🧪 AuroraGPT: Open Science Foundation Models</a></li>
  <li><a href="#auroragpt-outcomes" id="toc-auroragpt-outcomes" class="nav-link" data-scroll-target="#auroragpt-outcomes">📊 AuroraGPT Outcomes</a></li>
  <li><a href="#aurora" id="toc-aurora" class="nav-link" data-scroll-target="#aurora">🌌 Aurora</a></li>
  <li><a href="#alcf-ai-testbed" id="toc-alcf-ai-testbed" class="nav-link" data-scroll-target="#alcf-ai-testbed">🤖 ALCF AI Testbed</a></li>
  <li><a href="#team-leads" id="toc-team-leads" class="nav-link" data-scroll-target="#team-leads">👥 Team Leads</a></li>
  <li><a href="#teams" id="toc-teams" class="nav-link" data-scroll-target="#teams">🤝 Teams</a></li>
  <li><a href="#model-training" id="toc-model-training" class="nav-link" data-scroll-target="#model-training">🦜 Model Training</a></li>
  <li><a href="#accelerating-dataset-processing-at-scale-for-training" id="toc-accelerating-dataset-processing-at-scale-for-training" class="nav-link" data-scroll-target="#accelerating-dataset-processing-at-scale-for-training">🚀 Accelerating Dataset Processing at Scale for Training</a></li>
  <li><a href="#accelerating-dataset-processing-results" id="toc-accelerating-dataset-processing-results" class="nav-link" data-scroll-target="#accelerating-dataset-processing-results">🚀 Accelerating Dataset Processing: Results</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">📓 References</a></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">❤️ Thank you!</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">📑 Bibliography</a></li>
  <li><a href="#extras" id="toc-extras" class="nav-link" data-scroll-target="#extras">🎁 Extras</a>
  <ul class="collapse">
  <li><a href="#loooooooooong-sequence-lengths" id="toc-loooooooooong-sequence-lengths" class="nav-link" data-scroll-target="#loooooooooong-sequence-lengths">🚂 Loooooooooong Sequence Lengths</a></li>
  <li><a href="#life-cycle-of-the-llm" id="toc-life-cycle-of-the-llm" class="nav-link" data-scroll-target="#life-cycle-of-the-llm">♻️ Life Cycle of the LLM</a></li>
  <li><a href="#training-llms" id="toc-training-llms" class="nav-link" data-scroll-target="#training-llms">🍎 Training LLMs</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/saforem2/personal_site/blob/main/talks/AuroraGPT/alcf-hpc-workshop-2024/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/saforem2/personal_site/edit/main/talks/AuroraGPT/alcf-hpc-workshop-2024/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/personal_site/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li><li><a href="AuroraGPT-ALCF-Hands-On-HPC-Workshop-2024.md"><i class="bi bi-file-code"></i>Github (GFM)</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../talks/index.html">🎙️ Talks</a></li><li class="breadcrumb-item"><a href="../../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html">AuroraGPT</a></li><li class="breadcrumb-item"><a href="../../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html">AuroraGPT: ANL’s General Purpose Scientific LLM</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">AuroraGPT: ANL’s General Purpose Scientific LLM</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://samforeman.me">Sam Foreman</a> <a href="mailto:foremans@anl.gov" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 30, 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">May 18, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="auroragpt-goals" class="level2 smaller" data-background-color="white">
<h2 class="smaller anchored" data-background-color="white" data-anchor-id="auroragpt-goals">🎯 AuroraGPT Goals</h2>
<div class="flex-container" style="flex-direction: column; justify-content: space-around;">
<div class="flex-container" style="flex-direction: row; justify-content: space-around; align-items:center;">
<div class="column" style="width: 55%">
<div class="blue-card">
<p><strong>AuroraGPT</strong>: <em>General purpose scientific LLM</em><br>
Broadly trained on a general corpora plus scientific {papers, texts, data}</p>
</div>
<ul>
<li><strong>Explore pathways</strong> towards a “Scientific Assistant” model</li>
<li><strong>Build with international partners</strong> (RIKEN, BSC, others)</li>
<li><strong>Multilingual</strong> English, 日本語, French, German, Spanish</li>
<li><strong>Multimodal</strong>: images, tables, equations, proofs, time series, graphs, fields, sequences, etc</li>
</ul>
</div>
<div class="column" style="text-align: center;">
<div id="fig-awesome-llm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-awesome-llm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/llms.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Image from  Hannibal046/Awesome-LLM"><img src="./assets/llms.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-awesome-llm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Image from <iconify-icon role="img" inline="" icon="fa:github" aria-label="Icon github from fa Iconify.design set." title="Icon github from fa Iconify.design set."></iconify-icon> <a href="https://github.com/Hannibal046/Awesome-LLM"><code>Hannibal046/Awesome-LLM</code></a>
</figcaption>
</figure>
</div>
</div>
</div>
<div id="fig-timeline" class="quarto-float quarto-figure quarto-figure-center anchored" style="margin-left:auto;margin-right:auto;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/timelines.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Credit to the entire AuroraGPT team for slides."><img src="./assets/timelines.png" class="img-fluid figure-img" style="margin-left:auto;margin-right:auto;;width:75.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Credit to the entire AuroraGPT team for slides.
</figcaption>
</figure>
</div>
</div>
<div class="notes">
<ul>
<li><p>Here to talk about AuroraGPT, Argonne’s internal effort to build a general purpose scientific LLM, broadly trained on a general corpora of text + scientific {papers, text, data}</p></li>
<li><p>As part of this effort, we plan to…</p>
<ul>
<li>Explore pathways, build with international partners, multi-{lingual, modal}</li>
</ul></li>
<li><p>Rough timeline of the project and deliverables:</p>
<ul>
<li>202{3,4}: text-only models, plan to release a series of {7B, 70B, 1T} models</li>
<li>202{4,5}: Basic multi-modal models</li>
<li>202{5,6}: Advanced scientific multimodal models</li>
</ul></li>
</ul>
</div>
</section>
<section id="auroragpt-open-science-foundation-models" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="auroragpt-open-science-foundation-models">🧪 AuroraGPT: Open Science Foundation Models</h2>
<div id="fig-aurora-gpt" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored" style="vertical-align:center;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-aurora-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/AuroraGPT.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3:  argonne-lcf/Megatron-DeepSpeed"><img src="./assets/AuroraGPT.svg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aurora-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed"><code>argonne-lcf/Megatron-DeepSpeed</code></a>
</figcaption>
</figure>
</div>
<div class="notes">
<ul>
<li>AuroraGPT will be a publicly distributed, open source foundation model for open science</li>
<li>Is being trained on:
<ul>
<li>Scientific / engineering structured data</li>
<li>General text, media, news, etc.</li>
<li>Large amounts of low to medium quality data</li>
<li>Much less high quality data (that is publicly available for use)</li>
</ul></li>
<li>This data is then cleaned, processed, de-duplicated and used for the initial pre-training phase of the model</li>
<li>The vast majority of the overall compute is spent during this initial pre-training phase
<ul>
<li>This is the group I help to lead and will be talking a bit about today</li>
</ul></li>
<li>The initial pre-training phase is currently underway
<ul>
<li>Eventually, given a bit of time, effort and magic, the model will be ready for fine-tuning and additional training for a variety of downstream tasks</li>
</ul></li>
<li>The pretrained model will then be handed off for additional fine-tuning on a variety of downstream tasks
<ul>
<li>Scientific discovery</li>
<li>Accelerate scientific tasks</li>
<li>Digital twins</li>
<li>Inverse design</li>
<li>Code optimization</li>
<li>Accelerated simulations</li>
<li>Autonomous experiments</li>
<li>Co-design</li>
</ul></li>
<li>Becoming increasingly clear that LLMs have the potential to drastically accelerate computational science
<ul>
<li>We’ve seen this already for {GenSLMs, Weather / Climate / Earth Systems Modeling, Particle Physics, etc.}</li>
</ul></li>
</ul>
</div>
</section>
<section id="auroragpt-outcomes" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="auroragpt-outcomes">📊 AuroraGPT Outcomes</h2>
<ul>
<li><strong>Datasets and data pipelines</strong> for preparing science training data</li>
<li><strong>Software infrastructure and workflows</strong> to train, evaluate and deploy LLMs at scale for scientific resarch purposes</li>
<li><strong>Evaluation of state-of-the-art LLM Models</strong> to determine where they fall short in deep scientific tasks and where deep data may have an impact</li>
<li><strong>Assessment of the approach</strong> of augmenting web training data with two forms of data specific to science
<ul>
<li>Full text scientific papers</li>
<li>Structured scientific datasets (suitably mapped to narrative form)</li>
</ul></li>
<li><strong>Research grade artifacts</strong> (<strong>models</strong>) for scientific community for adaptation for downstream uses</li>
<li><strong>Promotion of responsible AI</strong> best practices where we can figure them out</li>
<li><strong>International Collaborations</strong> around the long term goal of <em>AGI for science</em></li>
</ul>
<div class="notes">
<ul>
<li><p>Deliverables:</p>
<ul>
<li>datasets, pipelines</li>
<li>software infrastructure, workflows to interface with science applications</li>
<li>checkpoints, models, logs, workbook, insights, etc.</li>
</ul></li>
<li><p>Hope to understand:</p>
<ul>
<li>How different state-of-the-art models perform at different scientific tasks</li>
<li>where deep data may have an impact</li>
<li>feasibility of generically augmenting text with scientific structured data</li>
</ul></li>
<li><p>Huge undertaking that will require large international collaborations around long term goal of AGI for science</p></li>
<li><p>Extra points:</p>
<ul>
<li>Well known that LLMs are good for non-consequential tasks</li>
<li>Known to “hallucinate” and create false information</li>
<li>Can this be mitigated reliably ??</li>
</ul></li>
</ul>
</div>
</section>
<section id="aurora" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="aurora">🌌 Aurora</h2>
<div class="flex-container" style="align-items: center;">
<div class="column" style="width:5%;">
<div id="tbl-aurora" class="responsive striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Aurora Specs
</figcaption>
<div aria-describedby="tbl-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="table-responsive">
<table class="table-striped table-hover caption-top table">
<caption>Aurora Specs</caption>
<thead>
<tr class="header">
<th style="text-align: right;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">Racks</td>
<td style="text-align: left;">166</td>
</tr>
<tr class="even">
<td style="text-align: right;">Nodes</td>
<td style="text-align: left;">10,624</td>
</tr>
<tr class="odd">
<td style="text-align: right;">CPUs</td>
<td style="text-align: left;">21,248</td>
</tr>
<tr class="even">
<td style="text-align: right;">GPUs</td>
<td style="text-align: left;">63,744</td>
</tr>
<tr class="odd">
<td style="text-align: right;">NICs</td>
<td style="text-align: left;">84,992</td>
</tr>
<tr class="even">
<td style="text-align: right;">HBM</td>
<td style="text-align: left;">8 PB</td>
</tr>
<tr class="odd">
<td style="text-align: right;">DDR5c</td>
<td style="text-align: left;">10 PB</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="column">
<div id="fig-aurora" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/aurora.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Aurora Fact Sheet"><img src="./assets/aurora.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aurora-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <a href="https://www.alcf.anl.gov/sites/default/files/2024-07/Aurora_FactSheet_2024.pdf">Aurora Fact Sheet</a>
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="alcf-ai-testbed" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="alcf-ai-testbed">🤖 ALCF AI Testbed</h2>
<ul>
<li>ALCF AI Testbed Systems are in production and <a href="https://accounts.alcf.anl.gov/#/allocationRequests">available for allocations</a> to the research community</li>
<li>Significant improvement in time-to-solution and energy-efficiency for diverse AI for science applications.</li>
<li><a href="https://nairrpilot.org/">NAIRR Pilot</a></li>
</ul>
<div class="red-card" style="color: #FF5252; font-size:90%;">
<p>Up to <strong>25</strong><span class="math inline">\times</span> improvement for genomic foundation models with <strong>6.5</strong><span class="math inline">\times</span> energy efficiency</p>
</div>
<div class="flex-container" style="align-items: flex-end;">
<div id="fig-sambanova" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sambanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/sambanova.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: SambaNova SN-30: 2nd Gen, 8 nodes with 64 AI Accelerators"><img src="./assets/sambanova.jpeg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sambanova-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>SambaNova SN-30</strong>: 2nd Gen, 8 nodes with 64 AI Accelerators
</figcaption>
</figure>
</div>
<div id="fig-graphcore" class="column quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-graphcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/graphcore.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;6: Graphcore Bow: generation accelerators: Pod-64 configuration with 64 accelerators"><img src="./assets/graphcore.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-graphcore-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: <strong>Graphcore Bow</strong>: generation accelerators: Pod-64 configuration with 64 accelerators
</figcaption>
</figure>
</div>
<div id="fig-cerebras" class="column quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cerebras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/cerebras.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;7: Cerebras: 2x CS-2 WSE with Memory-X and Swarm-X technologies"><img src="./assets/cerebras.jpeg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cerebras-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: <strong>Cerebras</strong>: 2x CS-2 WSE with Memory-X and Swarm-X technologies
</figcaption>
</figure>
</div>
<div id="fig-groq" class="column quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-groq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/groq.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;8: GroqRack: 9 nodes, 8 GroqChip v1.5 Tensor streaming processors accelerators per node"><img src="./assets/groq.jpeg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-groq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: <strong>GroqRack</strong>: 9 nodes, 8 GroqChip v1.5 Tensor streaming processors accelerators per node
</figcaption>
</figure>
</div>
</div>
</section>
<section id="team-leads" class="level2 smaller" data-background-color="white">
<h2 class="smaller anchored" data-background-color="white" data-anchor-id="team-leads">👥 Team Leads</h2>
<div style="font-size: 100%;">
<div class="flex-container" style="text-align: center; align-items: center;">
<p><strong>Planning</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/rick-stevens.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Rick Stevens"><img src="./assets/team/rick-stevens.png" style="height:1.04167in" alt="Rick Stevens" class="figure-img"></a></p>
<figcaption>Rick Stevens<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/ian-foster.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Ian Foster"><img src="./assets/team/ian-foster.png" style="height:1.04167in" alt="Ian Foster" class="figure-img"></a></p>
<figcaption>Ian Foster</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/rinku-gupta.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Rinku Gupta"><img src="./assets/team/rinku-gupta.png" style="height:1.04167in" alt="Rinku Gupta" class="figure-img"></a></p>
<figcaption>Rinku Gupta</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/mike-papka.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Mike Papka"><img src="./assets/team/mike-papka.png" style="height:1.04167in" alt="Mike Papka" class="figure-img"></a></p>
<figcaption>Mike Papka</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/arvind-ramanathan.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Arvind Ramanathan"><img src="./assets/team/arvind-ramanathan.png" style="height:1.04167in" alt="Arvind Ramanathan" class="figure-img"></a></p>
<figcaption>Arvind Ramanathan</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/fangfang-xia.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Fangfang Xia"><img src="./assets/team/fangfang-xia.png" style="height:1.04167in" alt="Fangfang Xia" class="figure-img"></a></p>
<figcaption>Fangfang Xia</figcaption>
</figure>
</div>
</div>
<div class="flex-container" style="text-align: center;">
<div class="col">
<p><strong>Data</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/ian-foster.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Ian Foster"><img src="./assets/team/ian-foster.png" style="height:1.04167in" alt="Ian Foster" class="figure-img"></a></p>
<figcaption>Ian Foster</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/robert-underwood.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Robert Underwood"><img src="./assets/team/robert-underwood.png" style="height:1.04167in" alt="Robert Underwood" class="figure-img"></a></p>
<figcaption>Robert Underwood</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Training</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/venkat-vishwanath.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Venkat Vishwanath"><img src="./assets/team/venkat-vishwanath.png" style="height:1.04167in" alt="Venkat Vishwanath" class="figure-img"></a></p>
<figcaption>Venkat Vishwanath</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/sam-foreman.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" title="Sam Foreman"><img src="./assets/team/sam-foreman.png" style="height:1.04167in" alt="Sam Foreman" class="figure-img"></a></p>
<figcaption><span style="color: #ff1a8f; background-color: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); font-weight: 500;">Sam Foreman</span></figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Evaluation</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/franck-cappello.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19" title="Franck Cappello"><img src="./assets/team/franck-cappello.png" style="height:1.04167in" alt="Franck Cappello" class="figure-img"></a></p>
<figcaption>Franck Cappello</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/sandeep-madireddy.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20" title="Sandeep Madireddy"><img src="./assets/team/sandeep-madireddy.png" style="height:1.04167in" alt="Sandeep Madireddy" class="figure-img"></a></p>
<figcaption>Sandeep Madireddy</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/bo-li.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21" title="Bo Li"><img src="./assets/team/bo-li.png" style="height:1.04167in" alt="Bo Li" class="figure-img"></a></p>
<figcaption>Bo Li</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Post</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/eliu-huerta.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22" title="Eliu Huerta"><img src="./assets/team/eliu-huerta.png" style="height:1.04167in" alt="Eliu Huerta" class="figure-img"></a></p>
<figcaption>Eliu Huerta</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/azton-wells.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23" title="Azton Wells"><img src="./assets/team/azton-wells.png" style="height:1.04167in" alt="Azton Wells" class="figure-img"></a></p>
<figcaption>Azton Wells</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Inference</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/rajeev-thakur.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24" title="Rajeev Thakur"><img src="./assets/team/rajeev-thakur.png" style="height:1.04167in" alt="Rajeev Thakur" class="figure-img"></a></p>
<figcaption>Rajeev Thakur</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Comms</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/charlie-catlett.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Charlie Catlett"><img src="./assets/team/charlie-catlett.png" style="height:1.04167in" alt="Charlie Catlett" class="figure-img"></a></p>
<figcaption>Charlie Catlett</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/david-martin.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="David Martin"><img src="./assets/team/david-martin.png" style="height:1.04167in" alt="David Martin" class="figure-img"></a></p>
<figcaption>David Martin</figcaption>
</figure>
</div>
</div>
<div class="col">
<p><strong>Distribution</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="./assets/team/brad-ullrich.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Brad Ullrich"><img src="./assets/team/brad-ullrich.png" style="height:1.04167in" alt="Brad Ullrich" class="figure-img"></a></p>
<figcaption>Brad Ullrich</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="teams" class="level2" data-auto-animate="true" data-background-color="white">
<h2 data-auto-animate="true" data-background-color="white" class="anchored" data-anchor-id="teams">🤝 Teams</h2>
<div class="flex-container">
<div class="column">
<ul>
<li><strong>Planning</strong></li>
<li><strong>Data Prep</strong>
<ul>
<li>Accumulate 20+ T tokens of high-quality scientific text and structured data</li>
</ul></li>
<li><span style="background: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); border: 1px solid #ff1a8f; border-radius: 0.25px;"><strong>Models / Training</strong></span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
<ul>
<li>Train (entirely from scratch) a series of models on publicly available data</li>
</ul></li>
<li><strong>Evaluation</strong>
<ul>
<li>Skills, trustworthiness, safety, robustness, privacy, machine ethics</li>
</ul></li>
</ul>
</div>
<div class="column">
<ul>
<li><strong>Post-Training</strong>
<ul>
<li>Fine-tuning, alignment</li>
</ul></li>
<li><strong>Inference</strong>
<ul>
<li>Model serving, API development / public-facing web services</li>
</ul></li>
<li><strong>Distribution</strong>
<ul>
<li>Licensing, generating and distributing artifacts for public consumption</li>
</ul></li>
<li><strong>Communication</strong></li>
</ul>
</div>
</div>
</section>
<section id="model-training" class="level2 smaller page-columns page-full" data-background-color="white">
<h2 class="smaller anchored" data-background-color="white" data-anchor-id="model-training">🦜 Model Training</h2>
<div class="flex-container" style="text-align: left; width: 100%; justify-content: space-around; line-height: 1em; gap: 5pt;">
<div class="column" style="background: oklch(from #03BD00 calc(l * 1.15) c h / 0.1); border: 1px solid #03BD00; border-radius: 0.25em; padding: 3pt 8pt;">
<p>✅ <span style="color: #03BD00;"><strong>Goals</strong></span></p>
<ul>
<li>Want training runs at scale to be:
<ul>
<li>efficient</li>
<li>stable</li>
<li>reproducible</li>
</ul></li>
<li>This requires:
<ul>
<li>robust data pipelines / file IO</li>
<li>effectively overlapping compute with communication</li>
<li>stability across {network, filesystem, machine}</li>
</ul></li>
<li>3D / Multi-dimensional Parallelism strategies</li>
<li>Large batch training</li>
<li>Second order optimizers</li>
<li>Sub-quadratic attention</li>
<li>State space models</li>
<li><em>Highly optimized GPU kernels</em></li>
</ul>
</div>
<div class="column" style="background: oklch(from #E90102 calc(l * 1.15) c h / 0.1); border: 1px solid #E90102; border-radius: 0.25em; padding: 3pt 8pt;">
<p>❌ <span style="color: #E90102;"><strong>Challenges</strong></span></p>
<ul>
<li><em>Looong time</em> to train, can be:
<ul>
<li>weeks (even months) of continuous training</li>
<li>order of magnitude longer than typical NN training jobs</li>
</ul></li>
<li>Stability issues:
<ul>
<li>failures are expensive (but inevitable)</li>
<li>stragglers common at scale</li>
</ul></li>
<li>Individual jobs are:
<ul>
<li><strong>fragile</strong></li>
<li>only as good as the worst rank</li>
<li>one hang or bad worker can crash job</li>
<li>network / filesystem / other-user(s) dependent</li>
</ul></li>
<li>Cost / benefits of different collective communication algorithms
<ul>
<li>depend on optimized / efficient implementations</li>
</ul></li>
<li>Network performance</li>
<li><em>Highly optimized GPU kernels</em></li>
</ul>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p><iconify-icon role="img" inline="" icon="fa:github" aria-label="Icon github from fa Iconify.design set." title="Icon github from fa Iconify.design set."></iconify-icon> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf / <code>Megatron-DeepSpeed</code></a></p>
</div></div></section>
<section id="accelerating-dataset-processing-at-scale-for-training" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="accelerating-dataset-processing-at-scale-for-training">🚀 Accelerating Dataset Processing at Scale for Training</h2>
<ul>
<li>To train a fixed model on trillions of tokens requires:
<ul>
<li>Aggregating data from multiple different <em>corpora</em> (e.g.&nbsp;Reddit, StackExchange, GitHub, etc.)</li>
<li>Sampling <em>each training batch</em> according to a fixed distribution across corpora</li>
<li>Building indices that map batches of tokens into these files (indexing)</li>
</ul></li>
<li>The original implementation was slow, and designed to run on a single device
<ul>
<li>Major bottleneck when debugging data pipeline at scale</li>
</ul></li>
<li><label><input type="checkbox" checked="">Completely re-wrote an asynchronous, distributed implementation that <em>significantly</em> improves performance</label></li>
</ul>
</section>
<section id="accelerating-dataset-processing-results" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="accelerating-dataset-processing-results">🚀 Accelerating Dataset Processing: Results</h2>
<ul class="task-list">
<li><label><input type="checkbox" checked="">Completely re-wrote an asynchronous, distributed implementation that <em>significantly</em> improves performance (<del>60 min</del> <span class="math inline">\rightarrow</span> 4 min)</label></li>
</ul>
<div class="flex-container">
<div id="fig-data-blendable" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-blendable-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/blendable.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Figure&nbsp;9: Time spent building BlendableDataset"><img src="./assets/blendable.svg" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-blendable-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Time spent building <code>BlendableDataset</code>
</figcaption>
</figure>
</div>
<div id="fig-data-gpt" class="r-stretch quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./assets/gpt.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="Figure&nbsp;10: Time spent building GPTDataset"><img src="./assets/gpt.svg" class="r-stretch img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-gpt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Time spent building <code>GPTDataset</code>
</figcaption>
</figure>
</div>
</div>
</section>
<section id="references" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="references">📓 References</h2>
<div class="flex-container" style="gap: 2pt;">
<div class="column">
<ul>
<li>See my other slides at <a href="https://samforeman.me/talks">samforeman.me/talks</a>
<ul>
<li><a href="https://saforem2.github.io/llm-workshop-talk">LLMs from Scratch</a></li>
<li><a href="https://saforem2.github.io/LLM-tutorial">Creating Small(~ish) LLMs</a></li>
<li><a href="https://saforem2.github.io/parallel-training-slides">Parallel Training Techniques</a></li>
<li><a href="https://samforeman.me/talks/llms-on-polaris/#/title-slide">LLMs on Polaris</a></li>
<li><a href="https://samforeman.me/talks/llms-at-scale/">Training LLMs at Scale</a></li>
</ul></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/argonne-lcf/Megatron-DeepSpeed">argonne-lcf / <code>Megatron-DeepSpeed</code></a><br>
<span class="dim-text">For the largest of large language models.</span></li>
<li><i class="fa-brands fa-github" aria-label="github"></i> <a href="https://github.com/saforem2/ezpz">saforem2 / <code>ezpz</code></a><br>
<span class="dim-text">Distributed training, ezpz. 🍋</span></li>
</ul>
</div>
<div class="column">
<ul>
<li>👀 See also:
<ul>
<li><a href="https://www.anl.gov/article/new-international-consortium-formed-to-create-trustworthy-and-reliable-generative-ai-models-for">New international consortium for generative AI models for science</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li><a href="https://pytorch.org/docs/master/notes/ddp.html">Distributed Data Parallel — PyTorch master documentation</a></li>
<li><a href="https://huggingface.co/docs/transformers/en/perf_train_gpu_many">🤗 Efficient Training on Multiple GPUs</a></li>
<li><a href="https://www.deepspeed.ai/getting-started/">Getting Started - DeepSpeed</a></li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="thank-you" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="thank-you">❤️ Thank you!</h2>
<ul>
<li><p>Organizers</p></li>
<li><p>Feel free to reach out!</p>
<p><split even=""></split></p>
<p><a href="https://samforeman.me"><i class="fas fa-home"></i></a> <a href="mailto:///foremans@anl.gov"><i class="far fa-paper-plane"></i></a> <a href="https://www.twitter.com/saforem2"><i class="fab fa-twitter"></i></a></p>
<p></p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="🙏 Acknowledgements">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
🙏 Acknowledgements
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357.</p>
</div>
</div>
</div>
</section>
<section id="bibliography" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="bibliography">📑 Bibliography</h2>
<ul>
<li>Refs:
<ul>
<li><span class="citation" data-cites="wei2022emergentabilitieslargelanguage">Wei et al. (<a href="#ref-wei2022emergentabilitieslargelanguage" role="doc-biblioref">2022</a>)</span></li>
<li>Animations from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li>
</ul></li>
</ul>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-song2023ds4sci" class="csl-entry" role="listitem">
Song, Shuaiwen Leon, Bonnie Kruft, Minjia Zhang, Conglong Li, Shiyang Chen, Chengming Zhang, Masahiro Tanaka, et al. 2023. <span>“DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery Through Sophisticated AI System Technologies.”</span> <a href="https://arxiv.org/abs/2310.04610">https://arxiv.org/abs/2310.04610</a>.
</div>
<div id="ref-wei2022emergentabilitieslargelanguage" class="csl-entry" role="listitem">
Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, et al. 2022. <span>“Emergent Abilities of Large Language Models.”</span> <a href="https://arxiv.org/abs/2206.07682">https://arxiv.org/abs/2206.07682</a>.
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. <span>“Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.”</span> <a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a>.
</div>
</div>
</section>
<section id="extras" class="level2 page-columns page-full" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="extras">🎁 Extras</h2>
<section id="loooooooooong-sequence-lengths" class="level3 smaller page-columns page-full" data-background-color="#1c1c1c">
<h3 class="smaller anchored" data-background-color="#1c1c1c" data-anchor-id="loooooooooong-sequence-lengths">🚂 Loooooooooong Sequence Lengths</h3>
<div class="flex-container" style="align-items: center; justify-content: center;">
<p><a href="../../../assets/anl.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img src="../../../assets/anl.svg" class="img-fluid" style="height:50pt;"></a></p>
<p><span class="dim-text" style="font-size: 2.0em;"><iconify-icon role="img" inline="" icon="ic:baseline-plus" aria-label="Icon baseline-plus from ic Iconify.design set." title="Icon baseline-plus from ic Iconify.design set."></iconify-icon></span></p>
<p><a href="../../../assets/deepspeed-logo-transparent.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="../../../assets/deepspeed-logo-transparent.svg" class="img-fluid" style="height:50pt;"></a></p>
</div>
<ul>
<li>Working with <a href="https://github.com/microsoft/DeepSpeed"><i class="fa-brands fa-microsoft" aria-label="microsoft"></i> Microsoft/DeepSpeed</a> team to enable longer sequence lengths (context windows) for LLMs
<ul>
<li>See my <a href="https://samforeman.me/posts/auroragpt/long-sequences/">blog post</a> for additional details</li>
</ul></li>
</ul>
<div id="fig-long-seq" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-long-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="flex-container">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/25B.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-32" title="25B"><img src="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/25B.svg" class="img-fluid figure-img"></a></p>
<figcaption>25B</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/33B.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-33" title="33B"><img src="https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/33B.svg" class="img-fluid figure-img"></a></p>
<figcaption>33B</figcaption>
</figure>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-long-seq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Maximum (achievable) <code>SEQ_LEN</code> for both <code>25B</code> and <code>33B</code> models (See: <span class="citation" data-cites="song2023ds4sci">Song et al. (<a href="#ref-song2023ds4sci" role="doc-biblioref">2023</a>)</span>)
</figcaption>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p><a href="https://github.com/saforem2/scaling4science"><i class="fa-brands fa-github" aria-label="github"></i> <code>scaling4science</code></a><br>
<a href="https://github.com/saforem2/Megatron-DS-Benchmarking"><i class="fa-brands fa-github" aria-label="github"></i> <code>Megatron-DS-Benchmarking</code></a></p>
</div></div></section>
<section id="life-cycle-of-the-llm" class="level3" data-background-color="white">
<h3 data-background-color="white" class="anchored" data-anchor-id="life-cycle-of-the-llm">♻️ Life Cycle of the LLM</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset" style="text-align:center">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">📝 Pre-training</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">🎀 Fine-Tuning</a></li></ul>
<div class="tab-content" style="text-align:center">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div id="fig-pretraining" class="quarto-float quarto-figure quarto-figure-center anchored" style="width:90%; text-align: center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pretraining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-34" title="Figure&nbsp;12: Pre-training: Virtually all of the compute used during pretraining phase"><img src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretraining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: <strong>Pre-training</strong>: Virtually all of the compute used during pretraining phase
</figcaption>
</figure>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div id="fig-fine-tuning" class="quarto-float quarto-figure quarto-figure-center anchored" style="width:90%; text-align: center; margin-left: auto; margin-right: auto;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fine-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-35" title="Figure&nbsp;13: Fine-tuning: Fine-tuning actually updates the model’s weights to make the model better at a certain task."><img src="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fine-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: <strong>Fine-tuning</strong>: Fine-tuning actually updates the model’s weights to make the model better at a certain task.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="training-llms" class="level3 smaller" data-background-color="white">
<h3 class="smaller anchored" data-background-color="white" data-anchor-id="training-llms">🍎 Training LLMs</h3>
<div class="flex-container" style="align-items: flex-end;">
<div class="column" style="width:33%;">
<div id="fig-it-hungers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true" class="lightbox" data-gallery="quarto-lightbox-gallery-36" title="Figure&nbsp;14: It’s hungry!"><img src="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-it-hungers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: It’s hungry!
</figcaption>
</figure>
</div>
</div>
<div class="column" style="width:60%;">
<div id="fig-evolution" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-37" title="Figure&nbsp;15: Visualization from @yang2023harnessing"><img src="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: Visualization from <span class="citation" data-cites="yang2023harnessing">Yang et al. (<a href="#ref-yang2023harnessing" role="doc-biblioref">2023</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>



</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Lead<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Co-led by: Venkat Vishwanath, Sam Foreman<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@unpublished{foreman2024,
  author = {Foreman, Sam},
  title = {AuroraGPT: {ANL’s} {General} {Purpose} {Scientific} {LLM}},
  date = {2024-10-30},
  url = {https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-foreman2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Foreman, Sam. 2024. <span>“AuroraGPT: ANL’s General Purpose Scientific
LLM.”</span> October 30. <a href="https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides">https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/samforeman\.me");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "saforem2/personal_site";
    script.dataset.repoId = "R_kgDOGbjyRw";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOGbjyR84CjWfk";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../talks/test/slides.html" class="pagination-link" aria-label="Test Rendering on Mobile">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Test Rendering on Mobile</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">title:</span><span class="co"> "AuroraGPT: ANL's General Purpose Scientific LLM"</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># institute: "Argonne Leadership Computing Facility"</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co"># institute: "[ALCF](https://www.alcf.anl.gov/)"</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="an">date:</span><span class="co"> 2024-10-30</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co"># cookie-consent: true</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="an">location:</span><span class="co"> "[ALCF Hands-on HPC Workshop](https://www.alcf.anl.gov/events/2024-alcf-hands-hpc-workshop)"</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="an">location-url:</span><span class="co"> "https://www.alcf.anl.gov/events/2024-alcf-hands-hpc-workshop"</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co"># location: "[ALCF Hands-on HPC Workshop](https://www.alcf.anl.gov/events/2024-alcf-hands-hpc-workshop)"</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co"># fig-cap-location: top</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="an">number-sections:</span><span class="co"> false</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="an">image:</span><span class="co"> ./assets/thumbnail.png</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="an">bibliography:</span><span class="co"> ../../../references.bib</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="an">editor:</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">  render-on-save: true</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">  freeze: auto</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="an">twitter-card:</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co">  image: ./assets/thumbnail.png</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co">  creator: "saforem2"</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="co">  site: "saforem2"</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co">  title: "AuroraGPT @ ALCF Hands-On HPC Workshop 2024"</span></span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="co">  description: "Overview of AuroraGPT at ALCF"</span></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="co">  card-style: summary</span></span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="an">open-graph:</span></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="co">  title: "AuroraGPT @ ALCF Hands-On HPC Workshop 2024"</span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="co">  description: "Overview of AuroraGPT at ALCF"</span></span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="co">  image: ./assets/thumbnail.png</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span class="an">citation:</span></span>
<span id="cb1-29"><a href="#cb1-29"></a><span class="co">   author: Sam Foreman</span></span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="co">   type: speech</span></span>
<span id="cb1-31"><a href="#cb1-31"></a><span class="co">   url: https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides</span></span>
<span id="cb1-32"><a href="#cb1-32"></a><span class="co"># toc-expand: true</span></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="an">format:</span></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="co">  # html:</span></span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="co">  #   shift-heading-level-by: 1</span></span>
<span id="cb1-36"><a href="#cb1-36"></a><span class="co">  html: default</span></span>
<span id="cb1-37"><a href="#cb1-37"></a><span class="co">  revealjs:</span></span>
<span id="cb1-38"><a href="#cb1-38"></a><span class="co">    # width: 1024</span></span>
<span id="cb1-39"><a href="#cb1-39"></a><span class="co">    # height: 768</span></span>
<span id="cb1-40"><a href="#cb1-40"></a><span class="co">    max-scale: 4.0</span></span>
<span id="cb1-41"><a href="#cb1-41"></a><span class="co">    min-scale: 0.1</span></span>
<span id="cb1-42"><a href="#cb1-42"></a><span class="co">    # title: "AuroraGPT"</span></span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="co">    pdf-separate-fragments: true</span></span>
<span id="cb1-44"><a href="#cb1-44"></a><span class="co">    shift-heading-level-by: -1</span></span>
<span id="cb1-45"><a href="#cb1-45"></a><span class="co">    center: false</span></span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="co">    footer: "[samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides](https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides)"</span></span>
<span id="cb1-47"><a href="#cb1-47"></a><span class="co">    slide-url: https://samforeman.me/talks/AuroraGPT/alcf-hpc-workshop-2024/slides.html</span></span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="co">    template-partials:</span></span>
<span id="cb1-49"><a href="#cb1-49"></a><span class="co">      - title-slide.html</span></span>
<span id="cb1-50"><a href="#cb1-50"></a><span class="co">    title-slide-attributes:</span></span>
<span id="cb1-51"><a href="#cb1-51"></a><span class="co">      # data-background-iframe: "file:///iframes/center-of-universe/index.html"</span></span>
<span id="cb1-52"><a href="#cb1-52"></a><span class="co">      # data-background-image: "https://raw.githubusercontent.com/saforem3/llm-lunch-talk/refs/heads/main/docs/assets/image2.png"</span></span>
<span id="cb1-53"><a href="#cb1-53"></a><span class="co">      data-background-size: cover</span></span>
<span id="cb1-54"><a href="#cb1-54"></a><span class="co">      data-background-iframe: https://emilhvitfeldt.github.io/quarto-iframe-examples/stars/index.html</span></span>
<span id="cb1-55"><a href="#cb1-55"></a><span class="co">      # background-color: dark</span></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="co">      # data-background-color: dark</span></span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="co">    # shift-heading-level-by: -1</span></span>
<span id="cb1-58"><a href="#cb1-58"></a><span class="co">  gfm:</span></span>
<span id="cb1-59"><a href="#cb1-59"></a><span class="co">    output-file: "AuroraGPT-ALCF-Hands-On-HPC-Workshop-2024.md"</span></span>
<span id="cb1-60"><a href="#cb1-60"></a><span class="co">---</span></span>
<span id="cb1-61"><a href="#cb1-61"></a></span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="fu">## 🎯 AuroraGPT Goals {.smaller background-color="white"}</span></span>
<span id="cb1-63"><a href="#cb1-63"></a></span>
<span id="cb1-64"><a href="#cb1-64"></a>::: {.flex-container style="flex-direction: column; justify-content: space-around;"}</span>
<span id="cb1-65"><a href="#cb1-65"></a></span>
<span id="cb1-66"><a href="#cb1-66"></a>::: {.flex-container style="flex-direction: row; justify-content: space-around; align-items:center;"}</span>
<span id="cb1-67"><a href="#cb1-67"></a></span>
<span id="cb1-68"><a href="#cb1-68"></a>::: {.column style="width: 55%"}</span>
<span id="cb1-69"><a href="#cb1-69"></a></span>
<span id="cb1-70"><a href="#cb1-70"></a>::: {.blue-card}</span>
<span id="cb1-71"><a href="#cb1-71"></a>**AuroraGPT**: _General purpose scientific LLM_  </span>
<span id="cb1-72"><a href="#cb1-72"></a>Broadly trained on a general corpora plus scientific {papers, texts, data}</span>
<span id="cb1-73"><a href="#cb1-73"></a>:::</span>
<span id="cb1-74"><a href="#cb1-74"></a></span>
<span id="cb1-75"><a href="#cb1-75"></a><span class="ss">- </span>**Explore pathways** towards a "Scientific Assistant" model</span>
<span id="cb1-76"><a href="#cb1-76"></a><span class="ss">- </span>**Build with international partners** (RIKEN, BSC, others)</span>
<span id="cb1-77"><a href="#cb1-77"></a><span class="ss">- </span>**Multilingual** English, 日本語, French, German, Spanish</span>
<span id="cb1-78"><a href="#cb1-78"></a><span class="ss">- </span>**Multimodal**: images, tables, equations, proofs, time series,  graphs, fields, sequences, etc</span>
<span id="cb1-79"><a href="#cb1-79"></a></span>
<span id="cb1-80"><a href="#cb1-80"></a>:::</span>
<span id="cb1-81"><a href="#cb1-81"></a></span>
<span id="cb1-82"><a href="#cb1-82"></a>::: {.column style="text-align: center;"}</span>
<span id="cb1-83"><a href="#cb1-83"></a></span>
<span id="cb1-84"><a href="#cb1-84"></a>::: {#fig-awesome-llm}</span>
<span id="cb1-85"><a href="#cb1-85"></a></span>
<span id="cb1-86"><a href="#cb1-86"></a><span class="al">![](./assets/llms.gif)</span></span>
<span id="cb1-87"><a href="#cb1-87"></a></span>
<span id="cb1-88"><a href="#cb1-88"></a>Image from {{&lt; iconify fa github &gt;}} <span class="co">[</span><span class="ot">`Hannibal046/Awesome-LLM`</span><span class="co">](https://github.com/Hannibal046/Awesome-LLM)</span></span>
<span id="cb1-89"><a href="#cb1-89"></a>:::</span>
<span id="cb1-90"><a href="#cb1-90"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a>:::</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a>:::</span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a>::: {#fig-timeline}</span>
<span id="cb1-96"><a href="#cb1-96"></a></span>
<span id="cb1-97"><a href="#cb1-97"></a><span class="al">![](./assets/timelines.png)</span>{width="75%" style="margin-left:auto;margin-right:auto;"}</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a>Credit to the entire AuroraGPT team for slides.</span>
<span id="cb1-100"><a href="#cb1-100"></a>:::</span>
<span id="cb1-101"><a href="#cb1-101"></a></span>
<span id="cb1-102"><a href="#cb1-102"></a></span>
<span id="cb1-103"><a href="#cb1-103"></a>:::</span>
<span id="cb1-104"><a href="#cb1-104"></a></span>
<span id="cb1-105"><a href="#cb1-105"></a>::: {.notes}</span>
<span id="cb1-106"><a href="#cb1-106"></a></span>
<span id="cb1-107"><a href="#cb1-107"></a><span class="ss">- </span>Here to talk about AuroraGPT, Argonne's internal effort to build a general</span>
<span id="cb1-108"><a href="#cb1-108"></a>  purpose scientific LLM, broadly trained on a general corpora of text +</span>
<span id="cb1-109"><a href="#cb1-109"></a>  scientific {papers, text, data}</span>
<span id="cb1-110"><a href="#cb1-110"></a></span>
<span id="cb1-111"><a href="#cb1-111"></a><span class="ss">- </span>As part of this effort, we plan to...</span>
<span id="cb1-112"><a href="#cb1-112"></a><span class="ss">    - </span>Explore pathways, build with international partners, multi-{lingual, modal}</span>
<span id="cb1-113"><a href="#cb1-113"></a></span>
<span id="cb1-114"><a href="#cb1-114"></a><span class="ss">- </span>Rough timeline of the project and deliverables:</span>
<span id="cb1-115"><a href="#cb1-115"></a><span class="ss">    - </span>202{3,4}: text-only models, plan to release a series of {7B, 70B, 1T} models</span>
<span id="cb1-116"><a href="#cb1-116"></a><span class="ss">    - </span>202{4,5}: Basic multi-modal models</span>
<span id="cb1-117"><a href="#cb1-117"></a><span class="ss">    - </span>202{5,6}: Advanced scientific multimodal models</span>
<span id="cb1-118"><a href="#cb1-118"></a></span>
<span id="cb1-119"><a href="#cb1-119"></a>:::</span>
<span id="cb1-120"><a href="#cb1-120"></a></span>
<span id="cb1-121"><a href="#cb1-121"></a><span class="fu">## 🧪 AuroraGPT: Open Science Foundation Models {background-color="white"}</span></span>
<span id="cb1-122"><a href="#cb1-122"></a></span>
<span id="cb1-123"><a href="#cb1-123"></a>::: {#fig-aurora-gpt .r-stretch style="vertical-align:center;"}</span>
<span id="cb1-124"><a href="#cb1-124"></a></span>
<span id="cb1-125"><a href="#cb1-125"></a><span class="al">![](./assets/AuroraGPT.svg)</span></span>
<span id="cb1-126"><a href="#cb1-126"></a></span>
<span id="cb1-127"><a href="#cb1-127"></a>{{&lt; fa brands github &gt;}} <span class="co">[</span><span class="ot">`argonne-lcf/Megatron-DeepSpeed`</span><span class="co">](https://github.com/argonne-lcf/Megatron-DeepSpeed)</span></span>
<span id="cb1-128"><a href="#cb1-128"></a>:::</span>
<span id="cb1-129"><a href="#cb1-129"></a></span>
<span id="cb1-130"><a href="#cb1-130"></a>::: {.notes}</span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a><span class="ss">- </span>AuroraGPT will be a publicly distributed, open source foundation model for</span>
<span id="cb1-133"><a href="#cb1-133"></a>open science</span>
<span id="cb1-134"><a href="#cb1-134"></a><span class="ss">- </span>Is being trained on:</span>
<span id="cb1-135"><a href="#cb1-135"></a><span class="ss">  - </span>Scientific / engineering structured data</span>
<span id="cb1-136"><a href="#cb1-136"></a><span class="ss">  - </span>General text, media, news, etc.</span>
<span id="cb1-137"><a href="#cb1-137"></a><span class="ss">  - </span>Large amounts of low to medium quality data</span>
<span id="cb1-138"><a href="#cb1-138"></a><span class="ss">  - </span>Much less high quality data (that is publicly available for use)</span>
<span id="cb1-139"><a href="#cb1-139"></a><span class="ss">- </span>This data is then cleaned, processed, de-duplicated and used for the initial</span>
<span id="cb1-140"><a href="#cb1-140"></a>pre-training phase of the model</span>
<span id="cb1-141"><a href="#cb1-141"></a><span class="ss">- </span>The vast majority of the overall compute is spent during this initial</span>
<span id="cb1-142"><a href="#cb1-142"></a>pre-training phase</span>
<span id="cb1-143"><a href="#cb1-143"></a><span class="ss">    - </span>This is the group I help to lead and will be talking a bit about today</span>
<span id="cb1-144"><a href="#cb1-144"></a><span class="ss">- </span>The initial pre-training phase is currently underway</span>
<span id="cb1-145"><a href="#cb1-145"></a><span class="ss">    - </span>Eventually, given a bit of time, effort and magic, the model will be</span>
<span id="cb1-146"><a href="#cb1-146"></a>    ready for fine-tuning and additional training for a variety of downstream</span>
<span id="cb1-147"><a href="#cb1-147"></a>    tasks</span>
<span id="cb1-148"><a href="#cb1-148"></a><span class="ss">- </span>The pretrained model will then be handed off for additional fine-tuning on a</span>
<span id="cb1-149"><a href="#cb1-149"></a>variety of downstream tasks</span>
<span id="cb1-150"><a href="#cb1-150"></a><span class="ss">    - </span>Scientific discovery</span>
<span id="cb1-151"><a href="#cb1-151"></a><span class="ss">    - </span>Accelerate scientific tasks</span>
<span id="cb1-152"><a href="#cb1-152"></a><span class="ss">    - </span>Digital twins</span>
<span id="cb1-153"><a href="#cb1-153"></a><span class="ss">    - </span>Inverse design</span>
<span id="cb1-154"><a href="#cb1-154"></a><span class="ss">    - </span>Code optimization</span>
<span id="cb1-155"><a href="#cb1-155"></a><span class="ss">    - </span>Accelerated simulations</span>
<span id="cb1-156"><a href="#cb1-156"></a><span class="ss">    - </span>Autonomous experiments</span>
<span id="cb1-157"><a href="#cb1-157"></a><span class="ss">    - </span>Co-design</span>
<span id="cb1-158"><a href="#cb1-158"></a></span>
<span id="cb1-159"><a href="#cb1-159"></a><span class="ss">- </span>Becoming increasingly clear that LLMs have the potential to drastically</span>
<span id="cb1-160"><a href="#cb1-160"></a>accelerate computational science</span>
<span id="cb1-161"><a href="#cb1-161"></a><span class="ss">    - </span>We've seen this already for {GenSLMs, Weather / Climate / Earth Systems</span>
<span id="cb1-162"><a href="#cb1-162"></a>    Modeling, Particle Physics, etc.}</span>
<span id="cb1-163"><a href="#cb1-163"></a></span>
<span id="cb1-164"><a href="#cb1-164"></a>:::</span>
<span id="cb1-165"><a href="#cb1-165"></a></span>
<span id="cb1-166"><a href="#cb1-166"></a><span class="fu">## 📊 AuroraGPT Outcomes {background-color="white"}</span></span>
<span id="cb1-167"><a href="#cb1-167"></a></span>
<span id="cb1-168"><a href="#cb1-168"></a><span class="ss">- </span>**Datasets and data pipelines** for preparing science training data</span>
<span id="cb1-169"><a href="#cb1-169"></a><span class="ss">- </span>**Software infrastructure and workflows** to train, evaluate and deploy LLMs</span>
<span id="cb1-170"><a href="#cb1-170"></a>  at scale for scientific resarch purposes</span>
<span id="cb1-171"><a href="#cb1-171"></a><span class="ss">- </span>**Evaluation of state-of-the-art LLM Models** to determine where they fall</span>
<span id="cb1-172"><a href="#cb1-172"></a>  short in deep scientific tasks and where deep data may have an impact</span>
<span id="cb1-173"><a href="#cb1-173"></a><span class="ss">- </span>**Assessment of the approach** of augmenting web training data with two forms</span>
<span id="cb1-174"><a href="#cb1-174"></a>  of data specific to science</span>
<span id="cb1-175"><a href="#cb1-175"></a><span class="ss">    - </span>Full text scientific papers</span>
<span id="cb1-176"><a href="#cb1-176"></a><span class="ss">    - </span>Structured scientific datasets (suitably mapped to narrative form)</span>
<span id="cb1-177"><a href="#cb1-177"></a><span class="ss">- </span>**Research grade artifacts** (**models**) for scientific community for</span>
<span id="cb1-178"><a href="#cb1-178"></a>  adaptation for downstream uses</span>
<span id="cb1-179"><a href="#cb1-179"></a><span class="ss">- </span>**Promotion of responsible AI** best practices where we can figure them out</span>
<span id="cb1-180"><a href="#cb1-180"></a><span class="ss">- </span>**International Collaborations** around the long term goal of _AGI for science_</span>
<span id="cb1-181"><a href="#cb1-181"></a></span>
<span id="cb1-182"><a href="#cb1-182"></a>::: {.notes}</span>
<span id="cb1-183"><a href="#cb1-183"></a></span>
<span id="cb1-184"><a href="#cb1-184"></a><span class="ss">- </span>Deliverables:</span>
<span id="cb1-185"><a href="#cb1-185"></a><span class="ss">    - </span>datasets, pipelines</span>
<span id="cb1-186"><a href="#cb1-186"></a><span class="ss">    - </span>software infrastructure, workflows to interface with science applications</span>
<span id="cb1-187"><a href="#cb1-187"></a><span class="ss">    - </span>checkpoints, models, logs, workbook, insights, etc.</span>
<span id="cb1-188"><a href="#cb1-188"></a><span class="ss">- </span>Hope to understand:</span>
<span id="cb1-189"><a href="#cb1-189"></a><span class="ss">    - </span>How different state-of-the-art models perform at different scientific tasks</span>
<span id="cb1-190"><a href="#cb1-190"></a><span class="ss">    - </span>where deep data may have an impact</span>
<span id="cb1-191"><a href="#cb1-191"></a><span class="ss">    - </span>feasibility of generically augmenting text with scientific structured data</span>
<span id="cb1-192"><a href="#cb1-192"></a><span class="ss">- </span>Huge undertaking that will require large international collaborations around</span>
<span id="cb1-193"><a href="#cb1-193"></a>  long term goal of AGI for science</span>
<span id="cb1-194"><a href="#cb1-194"></a></span>
<span id="cb1-195"><a href="#cb1-195"></a><span class="ss">- </span>Extra points:</span>
<span id="cb1-196"><a href="#cb1-196"></a><span class="ss">    - </span>Well known that LLMs are good for non-consequential tasks</span>
<span id="cb1-197"><a href="#cb1-197"></a><span class="ss">    - </span>Known to "hallucinate" and create false information</span>
<span id="cb1-198"><a href="#cb1-198"></a><span class="ss">    - </span>Can this be mitigated reliably ??</span>
<span id="cb1-199"><a href="#cb1-199"></a></span>
<span id="cb1-200"><a href="#cb1-200"></a>:::</span>
<span id="cb1-201"><a href="#cb1-201"></a></span>
<span id="cb1-202"><a href="#cb1-202"></a><span class="fu">## 🌌 Aurora {background-color="white"}</span></span>
<span id="cb1-203"><a href="#cb1-203"></a></span>
<span id="cb1-204"><a href="#cb1-204"></a>::: {.flex-container style="align-items: center;"}</span>
<span id="cb1-205"><a href="#cb1-205"></a></span>
<span id="cb1-206"><a href="#cb1-206"></a>::: {.column style="width:5%;"}</span>
<span id="cb1-207"><a href="#cb1-207"></a></span>
<span id="cb1-208"><a href="#cb1-208"></a>::: {#tbl-aurora}</span>
<span id="cb1-209"><a href="#cb1-209"></a></span>
<span id="cb1-210"><a href="#cb1-210"></a><span class="pp">|</span> <span class="co">&lt;!-- --&gt;</span> <span class="pp">|</span> <span class="co">&lt;!-- --&gt;</span> <span class="pp">|</span></span>
<span id="cb1-211"><a href="#cb1-211"></a><span class="pp">|---------:|:--------|</span></span>
<span id="cb1-212"><a href="#cb1-212"></a><span class="pp">|</span> Racks    <span class="pp">|</span>    166   <span class="pp">|</span></span>
<span id="cb1-213"><a href="#cb1-213"></a><span class="pp">|</span> Nodes    <span class="pp">|</span>  10,624  <span class="pp">|</span></span>
<span id="cb1-214"><a href="#cb1-214"></a><span class="pp">|</span> CPUs     <span class="pp">|</span>  21,248  <span class="pp">|</span></span>
<span id="cb1-215"><a href="#cb1-215"></a><span class="pp">|</span> GPUs     <span class="pp">|</span>  63,744  <span class="pp">|</span></span>
<span id="cb1-216"><a href="#cb1-216"></a><span class="pp">|</span> NICs     <span class="pp">|</span>  84,992  <span class="pp">|</span></span>
<span id="cb1-217"><a href="#cb1-217"></a><span class="pp">|</span> HBM      <span class="pp">|</span>   8 PB   <span class="pp">|</span></span>
<span id="cb1-218"><a href="#cb1-218"></a><span class="pp">|</span> DDR5c    <span class="pp">|</span>   10 PB  <span class="pp">|</span></span>
<span id="cb1-219"><a href="#cb1-219"></a></span>
<span id="cb1-220"><a href="#cb1-220"></a>: Aurora Specs {.responsive .striped .hover}</span>
<span id="cb1-221"><a href="#cb1-221"></a></span>
<span id="cb1-222"><a href="#cb1-222"></a>:::</span>
<span id="cb1-223"><a href="#cb1-223"></a></span>
<span id="cb1-224"><a href="#cb1-224"></a>:::</span>
<span id="cb1-225"><a href="#cb1-225"></a></span>
<span id="cb1-226"><a href="#cb1-226"></a>::: {.column}</span>
<span id="cb1-227"><a href="#cb1-227"></a></span>
<span id="cb1-228"><a href="#cb1-228"></a>::: {#fig-aurora .r-stretch}</span>
<span id="cb1-229"><a href="#cb1-229"></a></span>
<span id="cb1-230"><a href="#cb1-230"></a><span class="al">![](./assets/aurora.png)</span></span>
<span id="cb1-231"><a href="#cb1-231"></a></span>
<span id="cb1-232"><a href="#cb1-232"></a><span class="co">[</span><span class="ot">Aurora Fact Sheet</span><span class="co">](https://www.alcf.anl.gov/sites/default/files/2024-07/Aurora_FactSheet_2024.pdf)</span></span>
<span id="cb1-233"><a href="#cb1-233"></a>:::</span>
<span id="cb1-234"><a href="#cb1-234"></a></span>
<span id="cb1-235"><a href="#cb1-235"></a>:::</span>
<span id="cb1-236"><a href="#cb1-236"></a></span>
<span id="cb1-237"><a href="#cb1-237"></a>:::</span>
<span id="cb1-238"><a href="#cb1-238"></a></span>
<span id="cb1-239"><a href="#cb1-239"></a><span class="fu">## 🤖 ALCF AI Testbed {background-color="white"}</span></span>
<span id="cb1-240"><a href="#cb1-240"></a></span>
<span id="cb1-241"><a href="#cb1-241"></a><span class="ss">- </span>ALCF AI Testbed Systems are in production and</span>
<span id="cb1-242"><a href="#cb1-242"></a>  <span class="co">[</span><span class="ot">available for allocations</span><span class="co">](https://accounts.alcf.anl.gov/#/allocationRequests)</span></span>
<span id="cb1-243"><a href="#cb1-243"></a>  to the research community</span>
<span id="cb1-244"><a href="#cb1-244"></a><span class="ss">- </span>Significant improvement in time-to-solution and energy-efficiency for diverse</span>
<span id="cb1-245"><a href="#cb1-245"></a>  AI for science applications.</span>
<span id="cb1-246"><a href="#cb1-246"></a><span class="ss">- </span><span class="co">[</span><span class="ot">NAIRR Pilot</span><span class="co">](https://nairrpilot.org/)</span></span>
<span id="cb1-247"><a href="#cb1-247"></a></span>
<span id="cb1-248"><a href="#cb1-248"></a>::: {.red-card style="color: #FF5252; font-size:90%;"}</span>
<span id="cb1-249"><a href="#cb1-249"></a></span>
<span id="cb1-250"><a href="#cb1-250"></a>Up to **25**$\times$ improvement for genomic foundation</span>
<span id="cb1-251"><a href="#cb1-251"></a>models with **6.5**$\times$ energy efficiency</span>
<span id="cb1-252"><a href="#cb1-252"></a></span>
<span id="cb1-253"><a href="#cb1-253"></a>:::</span>
<span id="cb1-254"><a href="#cb1-254"></a></span>
<span id="cb1-255"><a href="#cb1-255"></a>::: {.flex-container style="align-items: flex-end;"}</span>
<span id="cb1-256"><a href="#cb1-256"></a></span>
<span id="cb1-257"><a href="#cb1-257"></a>::: {#fig-sambanova}</span>
<span id="cb1-258"><a href="#cb1-258"></a></span>
<span id="cb1-259"><a href="#cb1-259"></a><span class="al">![](./assets/sambanova.jpeg)</span></span>
<span id="cb1-260"><a href="#cb1-260"></a></span>
<span id="cb1-261"><a href="#cb1-261"></a>**SambaNova SN-30**: 2nd Gen, 8 nodes with 64 AI Accelerators</span>
<span id="cb1-262"><a href="#cb1-262"></a>:::</span>
<span id="cb1-263"><a href="#cb1-263"></a></span>
<span id="cb1-264"><a href="#cb1-264"></a>::: {#fig-graphcore .column style="text-align:center;"}</span>
<span id="cb1-265"><a href="#cb1-265"></a></span>
<span id="cb1-266"><a href="#cb1-266"></a><span class="al">![](./assets/graphcore.png)</span></span>
<span id="cb1-267"><a href="#cb1-267"></a></span>
<span id="cb1-268"><a href="#cb1-268"></a>**Graphcore Bow**: generation accelerators: Pod-64 configuration with 64 accelerators</span>
<span id="cb1-269"><a href="#cb1-269"></a>:::</span>
<span id="cb1-270"><a href="#cb1-270"></a></span>
<span id="cb1-271"><a href="#cb1-271"></a>::: {#fig-cerebras .column style="text-align:center;"}</span>
<span id="cb1-272"><a href="#cb1-272"></a></span>
<span id="cb1-273"><a href="#cb1-273"></a><span class="al">![](./assets/cerebras.jpeg)</span></span>
<span id="cb1-274"><a href="#cb1-274"></a></span>
<span id="cb1-275"><a href="#cb1-275"></a>**Cerebras**: 2x CS-2 WSE with Memory-X and Swarm-X technologies</span>
<span id="cb1-276"><a href="#cb1-276"></a>:::</span>
<span id="cb1-277"><a href="#cb1-277"></a></span>
<span id="cb1-278"><a href="#cb1-278"></a>::: {#fig-groq .column style="text-align:center;"}</span>
<span id="cb1-279"><a href="#cb1-279"></a></span>
<span id="cb1-280"><a href="#cb1-280"></a><span class="al">![](./assets/groq.jpeg)</span></span>
<span id="cb1-281"><a href="#cb1-281"></a></span>
<span id="cb1-282"><a href="#cb1-282"></a>**GroqRack**: 9 nodes, 8 GroqChip v1.5 Tensor streaming processors accelerators per node</span>
<span id="cb1-283"><a href="#cb1-283"></a>:::</span>
<span id="cb1-284"><a href="#cb1-284"></a></span>
<span id="cb1-285"><a href="#cb1-285"></a>:::</span>
<span id="cb1-286"><a href="#cb1-286"></a></span>
<span id="cb1-287"><a href="#cb1-287"></a><span class="fu">## 👥 Team Leads {.smaller background-color="white"}</span></span>
<span id="cb1-288"><a href="#cb1-288"></a></span>
<span id="cb1-289"><a href="#cb1-289"></a><span class="co">&lt;!--</span></span>
<span id="cb1-290"><a href="#cb1-290"></a></span>
<span id="cb1-291"><a href="#cb1-291"></a><span class="co">| Team                  | Lead(s)           |                                                            |</span></span>
<span id="cb1-292"><a href="#cb1-292"></a><span class="co">| :----:                | :--------         | :--------------------------------------------------------: |</span></span>
<span id="cb1-293"><a href="#cb1-293"></a><span class="co">| **Planning**          | Rick Stevens      | ![](./assets/team/rick-stevens.png){height="40pt"}         |</span></span>
<span id="cb1-294"><a href="#cb1-294"></a><span class="co">|                       | Ian Foster        | ![](./assets/team/ian-foster.png){height="40pt"}           |</span></span>
<span id="cb1-295"><a href="#cb1-295"></a><span class="co">|                       | Rinku Gupta       | ![](./assets/team/rinku-gupta.png){height="40pt"}          |</span></span>
<span id="cb1-296"><a href="#cb1-296"></a><span class="co">|                       | Mike Papka        | ![](./assets/team/mike-papka.png){height="40pt"}           |</span></span>
<span id="cb1-297"><a href="#cb1-297"></a><span class="co">|                       | Fangfang Xia      | ![](./assets/team/fangfang-xia.png){height="40pt"}         |</span></span>
<span id="cb1-298"><a href="#cb1-298"></a><span class="co">| **Data**              | Ian Foster        | ![](./assets/team/ian-foster.png){height="40pt"}           |</span></span>
<span id="cb1-299"><a href="#cb1-299"></a><span class="co">|                       | Robert Underwood  | ![](./assets/team/robert-underwood.png){height="40pt"} |</span></span>
<span id="cb1-300"><a href="#cb1-300"></a><span class="co">| **Models + Training** | Venkat Vishwanath | ![](./assets/team/venkat.jpg){height="40pt"}               |</span></span>
<span id="cb1-301"><a href="#cb1-301"></a><span class="co">|                       | Sam Foreman       | ![](./assets/team/sam-foreman.png){height="40pt"}          |</span></span>
<span id="cb1-302"><a href="#cb1-302"></a><span class="co">|                       | Sam Foreman       | ![](./assets/team/sam-foreman.png){height="40pt"}          |</span></span>
<span id="cb1-303"><a href="#cb1-303"></a><span class="co">| **Inference**         | Eliu Huerta       | ![](./assets/team/eliu-huerta.png){height="40pt"}          |</span></span>
<span id="cb1-304"><a href="#cb1-304"></a><span class="co">|                       | Azton Wells       | ![](./assets/team/azton-wells.png){height="40pt"}          |</span></span>
<span id="cb1-305"><a href="#cb1-305"></a><span class="co">: Team Leads {#tbl-team-leads}</span></span>
<span id="cb1-306"><a href="#cb1-306"></a><span class="co">| **Models / Training** | Venkat Vishwanath | ![](./assets/team/venkat-vishwanath.png){height="40pt"} |</span></span>
<span id="cb1-307"><a href="#cb1-307"></a><span class="co">|                       | Robert Underwood  | ![](./assets/team/robert-underwood.png){height="40pt"}     |</span></span>
<span id="cb1-308"><a href="#cb1-308"></a><span class="co">--&gt;</span></span>
<span id="cb1-309"><a href="#cb1-309"></a></span>
<span id="cb1-310"><a href="#cb1-310"></a>::: {style="font-size: 100%;"}</span>
<span id="cb1-311"><a href="#cb1-311"></a></span>
<span id="cb1-312"><a href="#cb1-312"></a>::: {.flex-container style="text-align: center; align-items: center;"}</span>
<span id="cb1-313"><a href="#cb1-313"></a>**Planning**</span>
<span id="cb1-314"><a href="#cb1-314"></a></span>
<span id="cb1-315"><a href="#cb1-315"></a>!<span class="co">[</span><span class="ot">Rick Stevens[^lead]</span><span class="co">](./assets/team/rick-stevens.png)</span>{height="75pt"}</span>
<span id="cb1-316"><a href="#cb1-316"></a></span>
<span id="cb1-317"><a href="#cb1-317"></a><span class="al">![Ian Foster](./assets/team/ian-foster.png)</span>{height="75pt"}</span>
<span id="cb1-318"><a href="#cb1-318"></a></span>
<span id="cb1-319"><a href="#cb1-319"></a><span class="al">![Rinku Gupta](./assets/team/rinku-gupta.png)</span>{height="75pt"}</span>
<span id="cb1-320"><a href="#cb1-320"></a></span>
<span id="cb1-321"><a href="#cb1-321"></a><span class="al">![Mike Papka](./assets/team/mike-papka.png)</span>{height="75pt"}</span>
<span id="cb1-322"><a href="#cb1-322"></a></span>
<span id="cb1-323"><a href="#cb1-323"></a><span class="al">![Arvind Ramanathan](./assets/team/arvind-ramanathan.png)</span>{height="75pt"}</span>
<span id="cb1-324"><a href="#cb1-324"></a></span>
<span id="cb1-325"><a href="#cb1-325"></a><span class="al">![Fangfang Xia](./assets/team/fangfang-xia.png)</span>{height="75pt"}</span>
<span id="cb1-326"><a href="#cb1-326"></a>:::</span>
<span id="cb1-327"><a href="#cb1-327"></a></span>
<span id="cb1-328"><a href="#cb1-328"></a>::: {.flex-container style="text-align: center;"}</span>
<span id="cb1-329"><a href="#cb1-329"></a>::: {.col}</span>
<span id="cb1-330"><a href="#cb1-330"></a>**Data**</span>
<span id="cb1-331"><a href="#cb1-331"></a></span>
<span id="cb1-332"><a href="#cb1-332"></a><span class="al">![Ian Foster](./assets/team/ian-foster.png)</span>{height="75pt"}</span>
<span id="cb1-333"><a href="#cb1-333"></a></span>
<span id="cb1-334"><a href="#cb1-334"></a><span class="al">![Robert Underwood](./assets/team/robert-underwood.png)</span>{height="75pt"}</span>
<span id="cb1-335"><a href="#cb1-335"></a>:::</span>
<span id="cb1-336"><a href="#cb1-336"></a></span>
<span id="cb1-337"><a href="#cb1-337"></a>::: {.col}</span>
<span id="cb1-338"><a href="#cb1-338"></a>**Training**</span>
<span id="cb1-339"><a href="#cb1-339"></a></span>
<span id="cb1-340"><a href="#cb1-340"></a><span class="al">![Venkat Vishwanath](./assets/team/venkat-vishwanath.png)</span>{height="75pt"}  </span>
<span id="cb1-341"><a href="#cb1-341"></a></span>
<span id="cb1-342"><a href="#cb1-342"></a>![<span class="co">[</span><span class="ot">Sam Foreman</span><span class="co">]</span>{style="color: #ff1a8f; background-color: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); font-weight: 500;"}](./assets/team/sam-foreman.png){height="75pt"}</span>
<span id="cb1-343"><a href="#cb1-343"></a>:::</span>
<span id="cb1-344"><a href="#cb1-344"></a></span>
<span id="cb1-345"><a href="#cb1-345"></a>::: {.col}</span>
<span id="cb1-346"><a href="#cb1-346"></a>**Evaluation**</span>
<span id="cb1-347"><a href="#cb1-347"></a></span>
<span id="cb1-348"><a href="#cb1-348"></a><span class="al">![Franck Cappello](./assets/team/franck-cappello.png)</span>{height="75pt"}</span>
<span id="cb1-349"><a href="#cb1-349"></a></span>
<span id="cb1-350"><a href="#cb1-350"></a><span class="al">![Sandeep Madireddy](./assets/team/sandeep-madireddy.png)</span>{height="75pt"}  </span>
<span id="cb1-351"><a href="#cb1-351"></a></span>
<span id="cb1-352"><a href="#cb1-352"></a><span class="al">![Bo Li](./assets/team/bo-li.png)</span>{height="75pt"}</span>
<span id="cb1-353"><a href="#cb1-353"></a>:::</span>
<span id="cb1-354"><a href="#cb1-354"></a></span>
<span id="cb1-355"><a href="#cb1-355"></a>::: {.col}</span>
<span id="cb1-356"><a href="#cb1-356"></a>**Post**</span>
<span id="cb1-357"><a href="#cb1-357"></a></span>
<span id="cb1-358"><a href="#cb1-358"></a><span class="al">![Eliu Huerta](./assets/team/eliu-huerta.png)</span>{height="75pt"}</span>
<span id="cb1-359"><a href="#cb1-359"></a></span>
<span id="cb1-360"><a href="#cb1-360"></a><span class="al">![Azton Wells](./assets/team/azton-wells.png)</span>{height="75pt"}</span>
<span id="cb1-361"><a href="#cb1-361"></a>:::</span>
<span id="cb1-362"><a href="#cb1-362"></a></span>
<span id="cb1-363"><a href="#cb1-363"></a>::: {.col}</span>
<span id="cb1-364"><a href="#cb1-364"></a>**Inference**</span>
<span id="cb1-365"><a href="#cb1-365"></a></span>
<span id="cb1-366"><a href="#cb1-366"></a><span class="al">![Rajeev Thakur](./assets/team/rajeev-thakur.png)</span>{height="75pt"}</span>
<span id="cb1-367"><a href="#cb1-367"></a>:::</span>
<span id="cb1-368"><a href="#cb1-368"></a></span>
<span id="cb1-369"><a href="#cb1-369"></a>::: {.col}</span>
<span id="cb1-370"><a href="#cb1-370"></a>**Comms**</span>
<span id="cb1-371"><a href="#cb1-371"></a></span>
<span id="cb1-372"><a href="#cb1-372"></a><span class="al">![Charlie Catlett](./assets/team/charlie-catlett.png)</span>{height="75pt"}</span>
<span id="cb1-373"><a href="#cb1-373"></a></span>
<span id="cb1-374"><a href="#cb1-374"></a><span class="al">![David Martin](./assets/team/david-martin.png)</span>{height="75pt"}</span>
<span id="cb1-375"><a href="#cb1-375"></a>:::</span>
<span id="cb1-376"><a href="#cb1-376"></a></span>
<span id="cb1-377"><a href="#cb1-377"></a>::: {.col}</span>
<span id="cb1-378"><a href="#cb1-378"></a>**Distribution**</span>
<span id="cb1-379"><a href="#cb1-379"></a></span>
<span id="cb1-380"><a href="#cb1-380"></a><span class="al">![Brad Ullrich](./assets/team/brad-ullrich.png)</span>{height="75pt"}</span>
<span id="cb1-381"><a href="#cb1-381"></a>:::</span>
<span id="cb1-382"><a href="#cb1-382"></a></span>
<span id="cb1-383"><a href="#cb1-383"></a>:::</span>
<span id="cb1-384"><a href="#cb1-384"></a></span>
<span id="cb1-385"><a href="#cb1-385"></a>:::</span>
<span id="cb1-386"><a href="#cb1-386"></a></span>
<span id="cb1-387"><a href="#cb1-387"></a><span class="ot">[^lead]: </span>Lead</span>
<span id="cb1-388"><a href="#cb1-388"></a></span>
<span id="cb1-389"><a href="#cb1-389"></a><span class="fu">## 🤝 Teams {auto-animate=true background-color="white"}</span></span>
<span id="cb1-390"><a href="#cb1-390"></a></span>
<span id="cb1-391"><a href="#cb1-391"></a>::: {.flex-container}</span>
<span id="cb1-392"><a href="#cb1-392"></a></span>
<span id="cb1-393"><a href="#cb1-393"></a>::: {.column}</span>
<span id="cb1-394"><a href="#cb1-394"></a><span class="ss">- </span>**Planning**</span>
<span id="cb1-395"><a href="#cb1-395"></a><span class="ss">- </span>**Data Prep**</span>
<span id="cb1-396"><a href="#cb1-396"></a><span class="ss">    - </span>Accumulate 20+ T tokens of high-quality scientific text and structured data</span>
<span id="cb1-397"><a href="#cb1-397"></a><span class="ss">- </span><span class="co">[</span><span class="ot">**Models / Training**</span><span class="co">]</span>{style="background: oklch(from #ff1a8f calc(l * 1.15) c h / 0.1); border: 1px solid #ff1a8f; border-radius: 0.25px;"}<span class="ot">[^me]</span></span>
<span id="cb1-398"><a href="#cb1-398"></a><span class="ss">    - </span>Train (entirely from scratch) a series of models on publicly available data</span>
<span id="cb1-399"><a href="#cb1-399"></a><span class="ss">- </span>**Evaluation**</span>
<span id="cb1-400"><a href="#cb1-400"></a><span class="ss">    - </span>Skills, trustworthiness, safety, robustness, privacy, machine ethics</span>
<span id="cb1-401"><a href="#cb1-401"></a></span>
<span id="cb1-402"><a href="#cb1-402"></a><span class="ot">[^me]: </span>Co-led by: Venkat Vishwanath, Sam Foreman</span>
<span id="cb1-403"><a href="#cb1-403"></a>:::</span>
<span id="cb1-404"><a href="#cb1-404"></a></span>
<span id="cb1-405"><a href="#cb1-405"></a>::: {.column}</span>
<span id="cb1-406"><a href="#cb1-406"></a><span class="ss">- </span>**Post-Training**</span>
<span id="cb1-407"><a href="#cb1-407"></a><span class="ss">    - </span>Fine-tuning, alignment</span>
<span id="cb1-408"><a href="#cb1-408"></a><span class="ss">- </span>**Inference**</span>
<span id="cb1-409"><a href="#cb1-409"></a><span class="ss">    - </span>Model serving, API development / public-facing web services</span>
<span id="cb1-410"><a href="#cb1-410"></a><span class="ss">- </span>**Distribution**</span>
<span id="cb1-411"><a href="#cb1-411"></a><span class="ss">    - </span>Licensing, generating and distributing artifacts for public consumption</span>
<span id="cb1-412"><a href="#cb1-412"></a><span class="ss">- </span>**Communication**</span>
<span id="cb1-413"><a href="#cb1-413"></a>:::</span>
<span id="cb1-414"><a href="#cb1-414"></a></span>
<span id="cb1-415"><a href="#cb1-415"></a>:::</span>
<span id="cb1-416"><a href="#cb1-416"></a></span>
<span id="cb1-417"><a href="#cb1-417"></a><span class="fu">## 🦜 Model Training {.smaller background-color="white"}</span></span>
<span id="cb1-418"><a href="#cb1-418"></a></span>
<span id="cb1-419"><a href="#cb1-419"></a>:::: {.flex-container style="text-align: left; width: 100%; justify-content: space-around; line-height: 1em; gap: 5pt;"}</span>
<span id="cb1-420"><a href="#cb1-420"></a></span>
<span id="cb1-421"><a href="#cb1-421"></a>::: {.column style="background: oklch(from #03BD00 calc(l * 1.15) c h / 0.1); border: 1px solid #03BD00; border-radius: 0.25em; padding: 3pt 8pt;"}</span>
<span id="cb1-422"><a href="#cb1-422"></a></span>
<span id="cb1-423"><a href="#cb1-423"></a>✅ <span class="co">[</span><span class="ot">**Goals**</span><span class="co">]</span>{style="color: #03BD00;"}</span>
<span id="cb1-424"><a href="#cb1-424"></a></span>
<span id="cb1-425"><a href="#cb1-425"></a><span class="ss">- </span>Want training runs at scale to be:</span>
<span id="cb1-426"><a href="#cb1-426"></a><span class="ss">    - </span>efficient</span>
<span id="cb1-427"><a href="#cb1-427"></a><span class="ss">    - </span>stable</span>
<span id="cb1-428"><a href="#cb1-428"></a><span class="ss">    - </span>reproducible</span>
<span id="cb1-429"><a href="#cb1-429"></a><span class="ss">- </span>This requires:</span>
<span id="cb1-430"><a href="#cb1-430"></a><span class="ss">    - </span>robust data pipelines / file IO</span>
<span id="cb1-431"><a href="#cb1-431"></a><span class="ss">    - </span>effectively overlapping compute with communication</span>
<span id="cb1-432"><a href="#cb1-432"></a><span class="ss">    - </span>stability across {network, filesystem, machine}</span>
<span id="cb1-433"><a href="#cb1-433"></a><span class="ss">- </span>3D / Multi-dimensional Parallelism strategies</span>
<span id="cb1-434"><a href="#cb1-434"></a><span class="ss">- </span>Large batch training</span>
<span id="cb1-435"><a href="#cb1-435"></a><span class="ss">- </span>Second order optimizers</span>
<span id="cb1-436"><a href="#cb1-436"></a><span class="ss">- </span>Sub-quadratic attention</span>
<span id="cb1-437"><a href="#cb1-437"></a><span class="ss">- </span>State space models</span>
<span id="cb1-438"><a href="#cb1-438"></a><span class="ss">- </span>_Highly optimized GPU kernels_</span>
<span id="cb1-439"><a href="#cb1-439"></a></span>
<span id="cb1-440"><a href="#cb1-440"></a>:::</span>
<span id="cb1-441"><a href="#cb1-441"></a></span>
<span id="cb1-442"><a href="#cb1-442"></a>::: {.column style="background: oklch(from #E90102 calc(l * 1.15) c h / 0.1); border: 1px solid #E90102; border-radius: 0.25em; padding: 3pt 8pt;"}</span>
<span id="cb1-443"><a href="#cb1-443"></a></span>
<span id="cb1-444"><a href="#cb1-444"></a>❌ <span class="co">[</span><span class="ot">**Challenges**</span><span class="co">]</span>{style="color: #E90102;"}</span>
<span id="cb1-445"><a href="#cb1-445"></a></span>
<span id="cb1-446"><a href="#cb1-446"></a><span class="ss">- </span>_Looong time_ to train, can be:</span>
<span id="cb1-447"><a href="#cb1-447"></a><span class="ss">    - </span>weeks (even months) of continuous training</span>
<span id="cb1-448"><a href="#cb1-448"></a><span class="ss">    - </span>order of magnitude longer than typical NN training jobs</span>
<span id="cb1-449"><a href="#cb1-449"></a><span class="ss">- </span>Stability issues:</span>
<span id="cb1-450"><a href="#cb1-450"></a><span class="ss">    - </span>failures are expensive (but inevitable)</span>
<span id="cb1-451"><a href="#cb1-451"></a><span class="ss">    - </span>stragglers common at scale</span>
<span id="cb1-452"><a href="#cb1-452"></a><span class="ss">- </span>Individual jobs are:</span>
<span id="cb1-453"><a href="#cb1-453"></a><span class="ss">    - </span>**fragile**</span>
<span id="cb1-454"><a href="#cb1-454"></a><span class="ss">    - </span>only as good as the worst rank</span>
<span id="cb1-455"><a href="#cb1-455"></a><span class="ss">    - </span>one hang or bad worker can crash job</span>
<span id="cb1-456"><a href="#cb1-456"></a><span class="ss">    - </span>network / filesystem / other-user(s) dependent</span>
<span id="cb1-457"><a href="#cb1-457"></a><span class="ss">- </span>Cost / benefits of different collective communication algorithms</span>
<span id="cb1-458"><a href="#cb1-458"></a><span class="ss">    - </span>depend on optimized / efficient implementations</span>
<span id="cb1-459"><a href="#cb1-459"></a><span class="ss">- </span>Network performance</span>
<span id="cb1-460"><a href="#cb1-460"></a><span class="ss">- </span>_Highly optimized GPU kernels_</span>
<span id="cb1-461"><a href="#cb1-461"></a></span>
<span id="cb1-462"><a href="#cb1-462"></a>:::</span>
<span id="cb1-463"><a href="#cb1-463"></a></span>
<span id="cb1-464"><a href="#cb1-464"></a>::::</span>
<span id="cb1-465"><a href="#cb1-465"></a></span>
<span id="cb1-466"><a href="#cb1-466"></a>::: aside</span>
<span id="cb1-467"><a href="#cb1-467"></a>{{&lt; iconify fa github &gt;}} <span class="co">[</span><span class="ot">argonne-lcf / `Megatron-DeepSpeed`</span><span class="co">](https://github.com/argonne-lcf/Megatron-DeepSpeed)</span></span>
<span id="cb1-468"><a href="#cb1-468"></a>:::</span>
<span id="cb1-469"><a href="#cb1-469"></a></span>
<span id="cb1-470"><a href="#cb1-470"></a></span>
<span id="cb1-471"><a href="#cb1-471"></a><span class="fu">## 🚀 Accelerating Dataset Processing at Scale for Training {background-color="white"}</span></span>
<span id="cb1-472"><a href="#cb1-472"></a></span>
<span id="cb1-473"><a href="#cb1-473"></a><span class="ss">- </span>To train a fixed model on trillions of tokens requires:</span>
<span id="cb1-474"><a href="#cb1-474"></a><span class="ss">    - </span>Aggregating data from multiple different _corpora_ (e.g. Reddit, StackExchange, GitHub, etc.)</span>
<span id="cb1-475"><a href="#cb1-475"></a><span class="ss">    - </span>Sampling _each training batch_ according to a fixed distribution across corpora</span>
<span id="cb1-476"><a href="#cb1-476"></a><span class="ss">    - </span>Building indices that map batches of tokens into these files (indexing)</span>
<span id="cb1-477"><a href="#cb1-477"></a></span>
<span id="cb1-478"><a href="#cb1-478"></a><span class="ss">- </span>The original implementation was slow, and designed to run on a single device</span>
<span id="cb1-479"><a href="#cb1-479"></a><span class="ss">    - </span>Major bottleneck when debugging data pipeline at scale</span>
<span id="cb1-480"><a href="#cb1-480"></a></span>
<span id="cb1-481"><a href="#cb1-481"></a><span class="ss">- </span><span class="va">[x]</span> Completely re-wrote an asynchronous, distributed implementation that _significantly_ improves performance</span>
<span id="cb1-482"><a href="#cb1-482"></a></span>
<span id="cb1-483"><a href="#cb1-483"></a><span class="fu">## 🚀 Accelerating Dataset Processing: Results {background-color="white"}</span></span>
<span id="cb1-484"><a href="#cb1-484"></a></span>
<span id="cb1-485"><a href="#cb1-485"></a><span class="ss">- </span><span class="va">[x]</span> Completely re-wrote an asynchronous, distributed implementation that</span>
<span id="cb1-486"><a href="#cb1-486"></a>_significantly_ improves performance (~~60 min~~ $\rightarrow$ 4 min)</span>
<span id="cb1-487"><a href="#cb1-487"></a></span>
<span id="cb1-488"><a href="#cb1-488"></a>::: {.flex-container}</span>
<span id="cb1-489"><a href="#cb1-489"></a></span>
<span id="cb1-490"><a href="#cb1-490"></a><span class="al">![Time spent building `BlendableDataset`](./assets/blendable.svg)</span>{#fig-data-blendable .r-stretch}</span>
<span id="cb1-491"><a href="#cb1-491"></a></span>
<span id="cb1-492"><a href="#cb1-492"></a><span class="al">![Time spent building `GPTDataset`](./assets/gpt.svg)</span>{#fig-data-gpt .r-stretch}</span>
<span id="cb1-493"><a href="#cb1-493"></a></span>
<span id="cb1-494"><a href="#cb1-494"></a>:::</span>
<span id="cb1-495"><a href="#cb1-495"></a></span>
<span id="cb1-496"><a href="#cb1-496"></a><span class="fu">## 📓 References  {background-color="white"}</span></span>
<span id="cb1-497"><a href="#cb1-497"></a></span>
<span id="cb1-498"><a href="#cb1-498"></a>::: {.flex-container style="gap: 2pt;"}</span>
<span id="cb1-499"><a href="#cb1-499"></a></span>
<span id="cb1-500"><a href="#cb1-500"></a>::: {.column}</span>
<span id="cb1-501"><a href="#cb1-501"></a><span class="ss">- </span>See my other slides at <span class="co">[</span><span class="ot">samforeman.me/talks</span><span class="co">](https://samforeman.me/talks)</span></span>
<span id="cb1-502"><a href="#cb1-502"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">LLMs from Scratch</span><span class="co">](https://saforem2.github.io/llm-workshop-talk)</span></span>
<span id="cb1-503"><a href="#cb1-503"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Creating Small(\~ish) LLMs</span><span class="co">](https://saforem2.github.io/LLM-tutorial)</span></span>
<span id="cb1-504"><a href="#cb1-504"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Parallel Training Techniques</span><span class="co">](https://saforem2.github.io/parallel-training-slides)</span></span>
<span id="cb1-505"><a href="#cb1-505"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">LLMs on Polaris</span><span class="co">](https://samforeman.me/talks/llms-on-polaris/#/title-slide)</span></span>
<span id="cb1-506"><a href="#cb1-506"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Training LLMs at Scale</span><span class="co">](https://samforeman.me/talks/llms-at-scale/)</span></span>
<span id="cb1-507"><a href="#cb1-507"></a><span class="ss">- </span>{{&lt; fa brands github &gt;}} <span class="co">[</span><span class="ot">argonne-lcf / `Megatron-DeepSpeed`</span><span class="co">](https://github.com/argonne-lcf/Megatron-DeepSpeed)</span>  </span>
<span id="cb1-508"><a href="#cb1-508"></a>    <span class="co">[</span><span class="ot">For the largest of large language models.</span><span class="co">]</span>{.dim-text}</span>
<span id="cb1-509"><a href="#cb1-509"></a><span class="ss">- </span>{{&lt; fa brands github &gt;}} <span class="co">[</span><span class="ot">saforem2 / `ezpz`</span><span class="co">](https://github.com/saforem2/ezpz)</span>  </span>
<span id="cb1-510"><a href="#cb1-510"></a>    <span class="co">[</span><span class="ot">Distributed training, ezpz. 🍋</span><span class="co">]</span>{.dim-text}</span>
<span id="cb1-511"><a href="#cb1-511"></a>:::</span>
<span id="cb1-512"><a href="#cb1-512"></a></span>
<span id="cb1-513"><a href="#cb1-513"></a>::: {.column}</span>
<span id="cb1-514"><a href="#cb1-514"></a><span class="ss">- </span>👀 See also:</span>
<span id="cb1-515"><a href="#cb1-515"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">New international consortium for generative AI models for science</span><span class="co">](https://www.anl.gov/article/new-international-consortium-formed-to-create-trustworthy-and-reliable-generative-ai-models-for)</span></span>
<span id="cb1-516"><a href="#cb1-516"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">PyTorch Distributed Overview</span><span class="co">](https://pytorch.org/tutorials/beginner/dist_overview.html)</span></span>
<span id="cb1-517"><a href="#cb1-517"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Distributed Data Parallel — PyTorch master documentation</span><span class="co">](https://pytorch.org/docs/master/notes/ddp.html)</span></span>
<span id="cb1-518"><a href="#cb1-518"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">🤗 Efficient Training on Multiple GPUs</span><span class="co">](https://huggingface.co/docs/transformers/en/perf_train_gpu_many)</span></span>
<span id="cb1-519"><a href="#cb1-519"></a><span class="ss">    - </span><span class="co">[</span><span class="ot">Getting Started - DeepSpeed</span><span class="co">](https://www.deepspeed.ai/getting-started/)</span></span>
<span id="cb1-520"><a href="#cb1-520"></a>:::</span>
<span id="cb1-521"><a href="#cb1-521"></a></span>
<span id="cb1-522"><a href="#cb1-522"></a>:::</span>
<span id="cb1-523"><a href="#cb1-523"></a></span>
<span id="cb1-524"><a href="#cb1-524"></a><span class="fu">## ❤️ Thank you! {background-color="white"}</span></span>
<span id="cb1-525"><a href="#cb1-525"></a></span>
<span id="cb1-526"><a href="#cb1-526"></a><span class="ss">- </span>Organizers</span>
<span id="cb1-527"><a href="#cb1-527"></a><span class="ss">- </span>Feel free to reach out!</span>
<span id="cb1-528"><a href="#cb1-528"></a></span>
<span id="cb1-529"><a href="#cb1-529"></a>    <span class="dt">&lt;</span><span class="kw">split</span><span class="ot"> even</span><span class="dt">&gt;</span></span>
<span id="cb1-530"><a href="#cb1-530"></a></span>
<span id="cb1-531"><a href="#cb1-531"></a>    <span class="co">[</span><span class="ot">&lt;i class="fas fa-home"&gt;&lt;/i&gt;</span><span class="co">](https://samforeman.me)</span></span>
<span id="cb1-532"><a href="#cb1-532"></a>    <span class="co">[</span><span class="ot">&lt;i class="far fa-paper-plane"&gt;&lt;/i&gt;</span><span class="co">](mailto:///foremans@anl.gov)</span></span>
<span id="cb1-533"><a href="#cb1-533"></a>    <span class="co">[</span><span class="ot">&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;</span><span class="co">](https://www.twitter.com/saforem2)</span></span>
<span id="cb1-534"><a href="#cb1-534"></a></span>
<span id="cb1-535"><a href="#cb1-535"></a>    <span class="dt">&lt;/</span><span class="kw">split</span><span class="dt">&gt;</span></span>
<span id="cb1-536"><a href="#cb1-536"></a></span>
<span id="cb1-537"><a href="#cb1-537"></a>::: {.callout-note icon=false title="🙏 Acknowledgements" collapse="false"}</span>
<span id="cb1-538"><a href="#cb1-538"></a></span>
<span id="cb1-539"><a href="#cb1-539"></a>This research used resources of the Argonne Leadership Computing Facility,</span>
<span id="cb1-540"><a href="#cb1-540"></a>which is a DOE Office of Science User Facility supported under Contract</span>
<span id="cb1-541"><a href="#cb1-541"></a>DE-AC02-06CH11357.</span>
<span id="cb1-542"><a href="#cb1-542"></a></span>
<span id="cb1-543"><a href="#cb1-543"></a>:::</span>
<span id="cb1-544"><a href="#cb1-544"></a></span>
<span id="cb1-545"><a href="#cb1-545"></a><span class="fu">## 📑 Bibliography {background-color="white"}</span></span>
<span id="cb1-546"><a href="#cb1-546"></a></span>
<span id="cb1-547"><a href="#cb1-547"></a><span class="ss">- </span>Refs:</span>
<span id="cb1-548"><a href="#cb1-548"></a><span class="ss">    - </span>@wei2022emergentabilitieslargelanguage</span>
<span id="cb1-549"><a href="#cb1-549"></a><span class="ss">    - </span>Animations from <span class="co">[</span><span class="ot">The Illustrated Transformer</span><span class="co">](http://jalammar.github.io/illustrated-transformer/)</span></span>
<span id="cb1-550"><a href="#cb1-550"></a></span>
<span id="cb1-551"><a href="#cb1-551"></a>::: {#refs}</span>
<span id="cb1-552"><a href="#cb1-552"></a>:::</span>
<span id="cb1-553"><a href="#cb1-553"></a></span>
<span id="cb1-554"><a href="#cb1-554"></a><span class="fu">## 🎁 Extras {background-color="white"}</span></span>
<span id="cb1-555"><a href="#cb1-555"></a></span>
<span id="cb1-556"><a href="#cb1-556"></a><span class="fu">### 🚂 Loooooooooong Sequence Lengths {.smaller background-color="#1c1c1c"}</span></span>
<span id="cb1-557"><a href="#cb1-557"></a></span>
<span id="cb1-558"><a href="#cb1-558"></a></span>
<span id="cb1-559"><a href="#cb1-559"></a><span class="co">&lt;!-- ::: {.flex-container style="text-align: center; align-items: center;"} --&gt;</span></span>
<span id="cb1-560"><a href="#cb1-560"></a><span class="co">&lt;!-- ![](../../assets/anl.svg){style="width:48%;"} --&gt;</span></span>
<span id="cb1-561"><a href="#cb1-561"></a></span>
<span id="cb1-562"><a href="#cb1-562"></a>::: {.flex-container style="align-items: center; justify-content: center;"}</span>
<span id="cb1-563"><a href="#cb1-563"></a></span>
<span id="cb1-564"><a href="#cb1-564"></a><span class="al">![](/assets/anl.svg)</span>{style="height:50pt;"}</span>
<span id="cb1-565"><a href="#cb1-565"></a></span>
<span id="cb1-566"><a href="#cb1-566"></a><span class="co">[</span><span class="ot">{{&lt; iconify ic baseline-plus &gt;}}</span><span class="co">]</span>{.dim-text style="font-size: 2.0em;"}</span>
<span id="cb1-567"><a href="#cb1-567"></a></span>
<span id="cb1-568"><a href="#cb1-568"></a><span class="al">![](/assets/deepspeed-logo-transparent.svg)</span>{style="height:50pt;"}</span>
<span id="cb1-569"><a href="#cb1-569"></a></span>
<span id="cb1-570"><a href="#cb1-570"></a>:::</span>
<span id="cb1-571"><a href="#cb1-571"></a></span>
<span id="cb1-572"><a href="#cb1-572"></a><span class="co">&lt;!--</span></span>
<span id="cb1-573"><a href="#cb1-573"></a><span class="co">[{{&lt; iconify ph arrows-left-right &gt;}}]{.dim-text style="font-size: 2.0em; padding-left: 15pt;"}</span></span>
<span id="cb1-574"><a href="#cb1-574"></a><span class="co">![](../../assets/deepspeed-logo-transparent.svg){style="width: 60%"}</span></span>
<span id="cb1-575"><a href="#cb1-575"></a><span class="co">:::</span></span>
<span id="cb1-576"><a href="#cb1-576"></a><span class="co">--&gt;</span></span>
<span id="cb1-577"><a href="#cb1-577"></a></span>
<span id="cb1-578"><a href="#cb1-578"></a><span class="ss">- </span>Working with</span>
<span id="cb1-579"><a href="#cb1-579"></a>  <span class="co">[</span><span class="ot">{{&lt; fa brands microsoft &gt;}} Microsoft/DeepSpeed</span><span class="co">](https://github.com/microsoft/DeepSpeed)</span></span>
<span id="cb1-580"><a href="#cb1-580"></a>  team to enable longer sequence lengths (context windows) for LLMs</span>
<span id="cb1-581"><a href="#cb1-581"></a><span class="ss">    - </span>See my <span class="co">[</span><span class="ot">blog post</span><span class="co">](https://samforeman.me/posts/auroragpt/long-sequences/)</span> for additional details</span>
<span id="cb1-582"><a href="#cb1-582"></a></span>
<span id="cb1-583"><a href="#cb1-583"></a>::: {#fig-long-seq}</span>
<span id="cb1-584"><a href="#cb1-584"></a></span>
<span id="cb1-585"><a href="#cb1-585"></a>::: {.flex-container}</span>
<span id="cb1-586"><a href="#cb1-586"></a></span>
<span id="cb1-587"><a href="#cb1-587"></a><span class="al">![25B](https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/25B.svg)</span></span>
<span id="cb1-588"><a href="#cb1-588"></a></span>
<span id="cb1-589"><a href="#cb1-589"></a><span class="al">![33B](https://raw.githubusercontent.com/saforem2/scaling4science/main/assets/33B.svg)</span></span>
<span id="cb1-590"><a href="#cb1-590"></a></span>
<span id="cb1-591"><a href="#cb1-591"></a>:::</span>
<span id="cb1-592"><a href="#cb1-592"></a></span>
<span id="cb1-593"><a href="#cb1-593"></a>Maximum (achievable) <span class="in">`SEQ_LEN`</span> for both <span class="in">`25B`</span> and <span class="in">`33B`</span> models (See: @song2023ds4sci)</span>
<span id="cb1-594"><a href="#cb1-594"></a></span>
<span id="cb1-595"><a href="#cb1-595"></a>:::</span>
<span id="cb1-596"><a href="#cb1-596"></a></span>
<span id="cb1-597"><a href="#cb1-597"></a>::: aside</span>
<span id="cb1-598"><a href="#cb1-598"></a><span class="co">[</span><span class="ot">{{&lt; fa brands github &gt;}} `scaling4science`</span><span class="co">](https://github.com/saforem2/scaling4science)</span>  </span>
<span id="cb1-599"><a href="#cb1-599"></a><span class="co">[</span><span class="ot">{{&lt; fa brands github &gt;}} `Megatron-DS-Benchmarking`</span><span class="co">](https://github.com/saforem2/Megatron-DS-Benchmarking)</span></span>
<span id="cb1-600"><a href="#cb1-600"></a>:::</span>
<span id="cb1-601"><a href="#cb1-601"></a></span>
<span id="cb1-602"><a href="#cb1-602"></a></span>
<span id="cb1-603"><a href="#cb1-603"></a><span class="fu">### ♻️  Life Cycle of the LLM {background-color="white"}</span></span>
<span id="cb1-604"><a href="#cb1-604"></a></span>
<span id="cb1-605"><a href="#cb1-605"></a>::: {.panel-tabset style="text-align:center"}</span>
<span id="cb1-606"><a href="#cb1-606"></a></span>
<span id="cb1-607"><a href="#cb1-607"></a><span class="fu">### 📝 Pre-training {background-color="white"}</span></span>
<span id="cb1-608"><a href="#cb1-608"></a></span>
<span id="cb1-609"><a href="#cb1-609"></a></span>
<span id="cb1-610"><a href="#cb1-610"></a>::: {#fig-pretraining style="width:90%; text-align: center; margin-left: auto; margin-right: auto;"}</span>
<span id="cb1-611"><a href="#cb1-611"></a></span>
<span id="cb1-612"><a href="#cb1-612"></a><span class="al">![](https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif)</span></span>
<span id="cb1-613"><a href="#cb1-613"></a></span>
<span id="cb1-614"><a href="#cb1-614"></a>**Pre-training**: Virtually all of the compute used during pretraining phase</span>
<span id="cb1-615"><a href="#cb1-615"></a>:::</span>
<span id="cb1-616"><a href="#cb1-616"></a></span>
<span id="cb1-617"><a href="#cb1-617"></a><span class="fu">### 🎀 Fine-Tuning {background-color="white"}</span></span>
<span id="cb1-618"><a href="#cb1-618"></a></span>
<span id="cb1-619"><a href="#cb1-619"></a>::: {#fig-fine-tuning style="width:90%; text-align: center; margin-left: auto; margin-right: auto;"}</span>
<span id="cb1-620"><a href="#cb1-620"></a></span>
<span id="cb1-621"><a href="#cb1-621"></a><span class="al">![](https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif)</span></span>
<span id="cb1-622"><a href="#cb1-622"></a></span>
<span id="cb1-623"><a href="#cb1-623"></a>**Fine-tuning**: Fine-tuning actually updates the model's weights to make the model better at a certain task.</span>
<span id="cb1-624"><a href="#cb1-624"></a>:::</span>
<span id="cb1-625"><a href="#cb1-625"></a></span>
<span id="cb1-626"><a href="#cb1-626"></a>:::</span>
<span id="cb1-627"><a href="#cb1-627"></a></span>
<span id="cb1-628"><a href="#cb1-628"></a><span class="fu">### 🍎 Training LLMs {.smaller background-color="white"}</span></span>
<span id="cb1-629"><a href="#cb1-629"></a></span>
<span id="cb1-630"><a href="#cb1-630"></a>:::: {.flex-container style="align-items: flex-end;"}</span>
<span id="cb1-631"><a href="#cb1-631"></a></span>
<span id="cb1-632"><a href="#cb1-632"></a>::: {.column style="width:33%;"}</span>
<span id="cb1-633"><a href="#cb1-633"></a></span>
<span id="cb1-634"><a href="#cb1-634"></a>::: {#fig-it-hungers}</span>
<span id="cb1-635"><a href="#cb1-635"></a></span>
<span id="cb1-636"><a href="#cb1-636"></a><span class="al">![](https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true)</span></span>
<span id="cb1-637"><a href="#cb1-637"></a></span>
<span id="cb1-638"><a href="#cb1-638"></a>It's hungry!</span>
<span id="cb1-639"><a href="#cb1-639"></a>:::</span>
<span id="cb1-640"><a href="#cb1-640"></a></span>
<span id="cb1-641"><a href="#cb1-641"></a>:::</span>
<span id="cb1-642"><a href="#cb1-642"></a></span>
<span id="cb1-643"><a href="#cb1-643"></a>::: {.column style="width:60%;"}</span>
<span id="cb1-644"><a href="#cb1-644"></a></span>
<span id="cb1-645"><a href="#cb1-645"></a>::: {#fig-evolution}</span>
<span id="cb1-646"><a href="#cb1-646"></a></span>
<span id="cb1-647"><a href="#cb1-647"></a><span class="al">![](https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif)</span></span>
<span id="cb1-648"><a href="#cb1-648"></a></span>
<span id="cb1-649"><a href="#cb1-649"></a>Visualization from @yang2023harnessing</span>
<span id="cb1-650"><a href="#cb1-650"></a>:::</span>
<span id="cb1-651"><a href="#cb1-651"></a></span>
<span id="cb1-652"><a href="#cb1-652"></a>:::</span>
<span id="cb1-653"><a href="#cb1-653"></a></span>
<span id="cb1-654"><a href="#cb1-654"></a>::::</span>
<span id="cb1-655"><a href="#cb1-655"></a></span>
<span id="cb1-656"><a href="#cb1-656"></a><span class="co">&lt;!--</span></span>
<span id="cb1-657"><a href="#cb1-657"></a><span class="al">###</span><span class="co"> 💾 Evaluating Checkpoints {background-color="white"}</span></span>
<span id="cb1-658"><a href="#cb1-658"></a></span>
<span id="cb1-659"><a href="#cb1-659"></a><span class="co">```python</span></span>
<span id="cb1-660"><a href="#cb1-660"></a><span class="co">from typing import Optional</span></span>
<span id="cb1-661"><a href="#cb1-661"></a><span class="co">import os</span></span>
<span id="cb1-662"><a href="#cb1-662"></a><span class="co">from pathlib import Path</span></span>
<span id="cb1-663"><a href="#cb1-663"></a></span>
<span id="cb1-664"><a href="#cb1-664"></a><span class="co">from transformers import LlamaForCausalLM, AutoTokenizer</span></span>
<span id="cb1-665"><a href="#cb1-665"></a></span>
<span id="cb1-666"><a href="#cb1-666"></a><span class="co">tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7B-hf")</span></span>
<span id="cb1-667"><a href="#cb1-667"></a></span>
<span id="cb1-668"><a href="#cb1-668"></a><span class="co">def load_model(ckpt_dir) -&gt; LlamaForCausalLM:</span></span>
<span id="cb1-669"><a href="#cb1-669"></a><span class="co">    return LlamaForCausalLM.from_pretrained(ckpt_dir)</span></span>
<span id="cb1-670"><a href="#cb1-670"></a></span>
<span id="cb1-671"><a href="#cb1-671"></a><span class="co">def eval_model(model, max_length: int, prompt: str) -&gt; str:</span></span>
<span id="cb1-672"><a href="#cb1-672"></a><span class="co">    return (</span></span>
<span id="cb1-673"><a href="#cb1-673"></a><span class="co">        tokenizer.batch_decode(</span></span>
<span id="cb1-674"><a href="#cb1-674"></a><span class="co">            model.generate(</span></span>
<span id="cb1-675"><a href="#cb1-675"></a><span class="co">                **tokenizer(prompt, return_tensors="pt"),</span></span>
<span id="cb1-676"><a href="#cb1-676"></a><span class="co">                 max_length=max_length,</span></span>
<span id="cb1-677"><a href="#cb1-677"></a><span class="co">            ),</span></span>
<span id="cb1-678"><a href="#cb1-678"></a><span class="co">            clean_up_tokenization_spaces=True,</span></span>
<span id="cb1-679"><a href="#cb1-679"></a><span class="co">            skip_special_tokens=True,</span></span>
<span id="cb1-680"><a href="#cb1-680"></a><span class="co">        )[0]</span></span>
<span id="cb1-681"><a href="#cb1-681"></a><span class="co">    )</span></span>
<span id="cb1-682"><a href="#cb1-682"></a></span>
<span id="cb1-683"><a href="#cb1-683"></a><span class="co">def load_and_eval_model_from_checkpoint(</span></span>
<span id="cb1-684"><a href="#cb1-684"></a><span class="co">        step: int,</span></span>
<span id="cb1-685"><a href="#cb1-685"></a><span class="co">        max_length: int = 64,</span></span>
<span id="cb1-686"><a href="#cb1-686"></a><span class="co">        prompt: Optional[str] = None,</span></span>
<span id="cb1-687"><a href="#cb1-687"></a><span class="co">        ckpt_root: Optional[os.PathLike | Path | str] = None,</span></span>
<span id="cb1-688"><a href="#cb1-688"></a><span class="co">) -&gt; str:</span></span>
<span id="cb1-689"><a href="#cb1-689"></a><span class="co">    print(f"Loading model from checkpoint at global step: {step}")</span></span>
<span id="cb1-690"><a href="#cb1-690"></a><span class="co">    prompt = "What is it like in there?" if prompt is None else prompt</span></span>
<span id="cb1-691"><a href="#cb1-691"></a><span class="co">    ckpt_root = Path("checkpoints") if ckpt_root is None else Path(ckpt_root)</span></span>
<span id="cb1-692"><a href="#cb1-692"></a><span class="co">    ckpt_dir = ckpt_root.joinpath(f"global_step{step}")</span></span>
<span id="cb1-693"><a href="#cb1-693"></a><span class="co">    return (</span></span>
<span id="cb1-694"><a href="#cb1-694"></a><span class="co">        eval_model(</span></span>
<span id="cb1-695"><a href="#cb1-695"></a><span class="co">            model=load_model(ckpt_dir.as_posix())</span></span>
<span id="cb1-696"><a href="#cb1-696"></a><span class="co">            max_length=max_length,</span></span>
<span id="cb1-697"><a href="#cb1-697"></a><span class="co">            prompt=prompt,</span></span>
<span id="cb1-698"><a href="#cb1-698"></a><span class="co">        )</span></span>
<span id="cb1-699"><a href="#cb1-699"></a><span class="co">    )</span></span>
<span id="cb1-700"><a href="#cb1-700"></a><span class="co">```</span></span>
<span id="cb1-701"><a href="#cb1-701"></a></span>
<span id="cb1-702"><a href="#cb1-702"></a><span class="al">###</span><span class="co"> Model Evaluations {background-color="white"}</span></span>
<span id="cb1-703"><a href="#cb1-703"></a></span>
<span id="cb1-704"><a href="#cb1-704"></a><span class="co">::: {.panel-tabset}</span></span>
<span id="cb1-705"><a href="#cb1-705"></a></span>
<span id="cb1-706"><a href="#cb1-706"></a><span class="co">#### 7000</span></span>
<span id="cb1-707"><a href="#cb1-707"></a></span>
<span id="cb1-708"><a href="#cb1-708"></a><span class="co">Tokens: 88B</span></span>
<span id="cb1-709"><a href="#cb1-709"></a></span>
<span id="cb1-710"><a href="#cb1-710"></a><span class="co">```python</span></span>
<span id="cb1-711"><a href="#cb1-711"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(7000))</span></span>
<span id="cb1-712"><a href="#cb1-712"></a><span class="co">Loading model from checkpoint at global step: 7000</span></span>
<span id="cb1-713"><a href="#cb1-713"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-714"><a href="#cb1-714"></a><span class="co">"""</span></span>
<span id="cb1-715"><a href="#cb1-715"></a><span class="co">I'm not sure if it's a good idea to use a different name for the same thing,</span></span>
<span id="cb1-716"><a href="#cb1-716"></a><span class="co">but I'm sure it's a good idea to use a different name for the same thing.</span></span>
<span id="cb1-717"><a href="#cb1-717"></a><span class="co">I'm not sure if it's a good idea to use a different name for the same thing,</span></span>
<span id="cb1-718"><a href="#cb1-718"></a><span class="co">but I'm sure it's a good idea to use a different name for the same thing.</span></span>
<span id="cb1-719"><a href="#cb1-719"></a><span class="co">I'm not sure if it's a good idea to use a different name for the same thing,</span></span>
<span id="cb1-720"><a href="#cb1-720"></a><span class="co">but I'm sure it</span></span>
<span id="cb1-721"><a href="#cb1-721"></a><span class="co">"""</span></span>
<span id="cb1-722"><a href="#cb1-722"></a><span class="co">```</span></span>
<span id="cb1-723"><a href="#cb1-723"></a></span>
<span id="cb1-724"><a href="#cb1-724"></a><span class="co">#### 12000</span></span>
<span id="cb1-725"><a href="#cb1-725"></a></span>
<span id="cb1-726"><a href="#cb1-726"></a><span class="co">Tokens: 150B</span></span>
<span id="cb1-727"><a href="#cb1-727"></a></span>
<span id="cb1-728"><a href="#cb1-728"></a><span class="co">```python</span></span>
<span id="cb1-729"><a href="#cb1-729"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(12000))</span></span>
<span id="cb1-730"><a href="#cb1-730"></a><span class="co">Loading model from checkpoint at global step: 12000</span></span>
<span id="cb1-731"><a href="#cb1-731"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-732"><a href="#cb1-732"></a><span class="co">"""</span></span>
<span id="cb1-733"><a href="#cb1-733"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-734"><a href="#cb1-734"></a><span class="co">The people are very friendly and helpful.</span></span>
<span id="cb1-735"><a href="#cb1-735"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-736"><a href="#cb1-736"></a><span class="co">The people are very friendly and helpful.</span></span>
<span id="cb1-737"><a href="#cb1-737"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-738"><a href="#cb1-738"></a><span class="co">The people are very friendly and helpful.</span></span>
<span id="cb1-739"><a href="#cb1-739"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-740"><a href="#cb1-740"></a><span class="co">The people are very friendly and helpful.</span></span>
<span id="cb1-741"><a href="#cb1-741"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-742"><a href="#cb1-742"></a><span class="co">The people are very friendly and helpful.</span></span>
<span id="cb1-743"><a href="#cb1-743"></a><span class="co">What is it like in there?</span></span>
<span id="cb1-744"><a href="#cb1-744"></a><span class="co">"""</span></span>
<span id="cb1-745"><a href="#cb1-745"></a><span class="co">```</span></span>
<span id="cb1-746"><a href="#cb1-746"></a></span>
<span id="cb1-747"><a href="#cb1-747"></a><span class="co">#### 17000</span></span>
<span id="cb1-748"><a href="#cb1-748"></a></span>
<span id="cb1-749"><a href="#cb1-749"></a><span class="co">Tokens: 215B</span></span>
<span id="cb1-750"><a href="#cb1-750"></a></span>
<span id="cb1-751"><a href="#cb1-751"></a><span class="co">```python</span></span>
<span id="cb1-752"><a href="#cb1-752"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(17000))</span></span>
<span id="cb1-753"><a href="#cb1-753"></a><span class="co">Loading model from checkpoint at global step: 17000</span></span>
<span id="cb1-754"><a href="#cb1-754"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-755"><a href="#cb1-755"></a><span class="co">"""</span></span>
<span id="cb1-756"><a href="#cb1-756"></a><span class="co">I’m not sure what to expect. I’m not sure what to expect from the people I’m</span></span>
<span id="cb1-757"><a href="#cb1-757"></a><span class="co">with. I’m not sure what to expect from the people I’m with. I’m not sure what</span></span>
<span id="cb1-758"><a href="#cb1-758"></a><span class="co">to expect from the people I’m with. I’m not sure what to expect from the people</span></span>
<span id="cb1-759"><a href="#cb1-759"></a><span class="co">I’m with.</span></span>
<span id="cb1-760"><a href="#cb1-760"></a><span class="co">I’m not sure what to expect from the people I’m with.</span></span>
<span id="cb1-761"><a href="#cb1-761"></a><span class="co">I’m not sure what to expect from the people I’m with.</span></span>
<span id="cb1-762"><a href="#cb1-762"></a><span class="co">I’m not sure what to expect from the people</span></span>
<span id="cb1-763"><a href="#cb1-763"></a><span class="co">"""</span></span>
<span id="cb1-764"><a href="#cb1-764"></a><span class="co">```</span></span>
<span id="cb1-765"><a href="#cb1-765"></a></span>
<span id="cb1-766"><a href="#cb1-766"></a><span class="co">#### 22000</span></span>
<span id="cb1-767"><a href="#cb1-767"></a></span>
<span id="cb1-768"><a href="#cb1-768"></a><span class="co">Tokens: 277B</span></span>
<span id="cb1-769"><a href="#cb1-769"></a></span>
<span id="cb1-770"><a href="#cb1-770"></a><span class="co">```python</span></span>
<span id="cb1-771"><a href="#cb1-771"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(22000))</span></span>
<span id="cb1-772"><a href="#cb1-772"></a><span class="co">Loading model from checkpoint at global step: 22000</span></span>
<span id="cb1-773"><a href="#cb1-773"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-774"><a href="#cb1-774"></a><span class="co">"""</span></span>
<span id="cb1-775"><a href="#cb1-775"></a><span class="co">I’m a 20 year old guy from the UK. I’m a student at the University of</span></span>
<span id="cb1-776"><a href="#cb1-776"></a><span class="co">Manchester, studying Computer Science. I’m a big fan of the band, The Beatles,</span></span>
<span id="cb1-777"><a href="#cb1-777"></a><span class="co">and I’m a huge fan of the movie, The Wizard of Oz. I’m a huge fan of the band,</span></span>
<span id="cb1-778"><a href="#cb1-778"></a><span class="co">The Beatles, and I’m a huge fan of the movie, The Wizard of Oz.</span></span>
<span id="cb1-779"><a href="#cb1-779"></a><span class="co">I’m a big fan of the band, The Beatles, and I’m a huge fan of the movie</span></span>
<span id="cb1-780"><a href="#cb1-780"></a><span class="co">"""</span></span>
<span id="cb1-781"><a href="#cb1-781"></a><span class="co">```</span></span>
<span id="cb1-782"><a href="#cb1-782"></a></span>
<span id="cb1-783"><a href="#cb1-783"></a><span class="co">#### 32000</span></span>
<span id="cb1-784"><a href="#cb1-784"></a></span>
<span id="cb1-785"><a href="#cb1-785"></a><span class="co">Tokens: 400B</span></span>
<span id="cb1-786"><a href="#cb1-786"></a></span>
<span id="cb1-787"><a href="#cb1-787"></a><span class="co">```python</span></span>
<span id="cb1-788"><a href="#cb1-788"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(32000))</span></span>
<span id="cb1-789"><a href="#cb1-789"></a><span class="co">Loading model from checkpoint at global step: 32000</span></span>
<span id="cb1-790"><a href="#cb1-790"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-791"><a href="#cb1-791"></a><span class="co">"""</span></span>
<span id="cb1-792"><a href="#cb1-792"></a><span class="co">I've been to the US and I've been to Canada.</span></span>
<span id="cb1-793"><a href="#cb1-793"></a><span class="co">In the US, it's a lot like the US.</span></span>
<span id="cb1-794"><a href="#cb1-794"></a><span class="co">In Canada, it's a lot like the US.</span></span>
<span id="cb1-795"><a href="#cb1-795"></a><span class="co">In the US, it's a lot like the US.</span></span>
<span id="cb1-796"><a href="#cb1-796"></a><span class="co">In Canada, it's a lot like the US.</span></span>
<span id="cb1-797"><a href="#cb1-797"></a><span class="co">In the US, it's a lot like the US.</span></span>
<span id="cb1-798"><a href="#cb1-798"></a><span class="co">In Canada, it's a lot like the US.</span></span>
<span id="cb1-799"><a href="#cb1-799"></a><span class="co">In the US, it's</span></span>
<span id="cb1-800"><a href="#cb1-800"></a><span class="co">"""</span></span>
<span id="cb1-801"><a href="#cb1-801"></a><span class="co">```</span></span>
<span id="cb1-802"><a href="#cb1-802"></a></span>
<span id="cb1-803"><a href="#cb1-803"></a><span class="co">#### 40000</span></span>
<span id="cb1-804"><a href="#cb1-804"></a></span>
<span id="cb1-805"><a href="#cb1-805"></a><span class="co">Tokens: 503B</span></span>
<span id="cb1-806"><a href="#cb1-806"></a></span>
<span id="cb1-807"><a href="#cb1-807"></a><span class="co">```python</span></span>
<span id="cb1-808"><a href="#cb1-808"></a><span class="co">&gt;&gt;&gt; print(load_checkpoint(40000))</span></span>
<span id="cb1-809"><a href="#cb1-809"></a><span class="co">Loading model from checkpoint at global step: 40000</span></span>
<span id="cb1-810"><a href="#cb1-810"></a><span class="co">"What is it like in there?"</span></span>
<span id="cb1-811"><a href="#cb1-811"></a><span class="co">"""</span></span>
<span id="cb1-812"><a href="#cb1-812"></a><span class="co">The first thing you notice when you enter the room is the size. It’s huge. It’s</span></span>
<span id="cb1-813"><a href="#cb1-813"></a><span class="co">like a football field. It’s a lot of space.</span></span>
<span id="cb1-814"><a href="#cb1-814"></a><span class="co">The second thing you notice is the light. It’s bright. It’s bright.</span></span>
<span id="cb1-815"><a href="#cb1-815"></a><span class="co">The third thing you notice is the sound. It’s loud. It’s loud.</span></span>
<span id="cb1-816"><a href="#cb1-816"></a><span class="co">The fourth thing you notice is the smell. It’s a lot of smells. It’s a lot of smells.</span></span>
<span id="cb1-817"><a href="#cb1-817"></a><span class="co">The fifth thing you notice is the temperature. It’s hot.</span></span>
<span id="cb1-818"><a href="#cb1-818"></a><span class="co">"""</span></span>
<span id="cb1-819"><a href="#cb1-819"></a><span class="co">```</span></span>
<span id="cb1-820"><a href="#cb1-820"></a></span>
<span id="cb1-821"><a href="#cb1-821"></a><span class="co">:::</span></span>
<span id="cb1-822"><a href="#cb1-822"></a><span class="co">--&gt;</span></span>
<span id="cb1-823"><a href="#cb1-823"></a></span>
<span id="cb1-824"><a href="#cb1-824"></a><span class="co">&lt;!-- ::: --&gt;</span></span>
<span id="cb1-825"><a href="#cb1-825"></a></span>
<span id="cb1-826"><a href="#cb1-826"></a><span class="co">&lt;!--</span></span>
<span id="cb1-827"><a href="#cb1-827"></a><span class="co">- Being trained on:</span></span>
<span id="cb1-828"><a href="#cb1-828"></a></span>
<span id="cb1-829"><a href="#cb1-829"></a><span class="co">  :::: {.flex-container style="flex-direction:row; justify-content: space-around;"}</span></span>
<span id="cb1-830"><a href="#cb1-830"></a></span>
<span id="cb1-831"><a href="#cb1-831"></a><span class="co">  ::: {.flex-container style="flex-direction:column;"}</span></span>
<span id="cb1-832"><a href="#cb1-832"></a></span>
<span id="cb1-833"><a href="#cb1-833"></a><span class="co">   🇺🇸English  </span></span>
<span id="cb1-834"><a href="#cb1-834"></a><span class="co">   🇯🇵日本語  </span></span>
<span id="cb1-835"><a href="#cb1-835"></a><span class="co">   🇫🇷French  </span></span>
<span id="cb1-836"><a href="#cb1-836"></a><span class="co">   🇩🇪Deutsch  </span></span>
<span id="cb1-837"><a href="#cb1-837"></a><span class="co">   🇪🇸Español[^bsc]  </span></span>
<span id="cb1-838"><a href="#cb1-838"></a><span class="co">   🇮🇹Italian  </span></span>
<span id="cb1-839"><a href="#cb1-839"></a></span>
<span id="cb1-840"><a href="#cb1-840"></a><span class="co">  :::</span></span>
<span id="cb1-841"><a href="#cb1-841"></a></span>
<span id="cb1-842"><a href="#cb1-842"></a><span class="co">  ::: {.flex-container style="flex-direction:column;"}</span></span>
<span id="cb1-843"><a href="#cb1-843"></a></span>
<span id="cb1-844"><a href="#cb1-844"></a><span class="co">  🧪 scientific text  </span></span>
<span id="cb1-845"><a href="#cb1-845"></a><span class="co">  🖼️ images  </span></span>
<span id="cb1-846"><a href="#cb1-846"></a><span class="co">  📊 tables  </span></span>
<span id="cb1-847"><a href="#cb1-847"></a><span class="co">  ➕ equations  </span></span>
<span id="cb1-848"><a href="#cb1-848"></a><span class="co">  📖 proofs</span></span>
<span id="cb1-849"><a href="#cb1-849"></a></span>
<span id="cb1-850"><a href="#cb1-850"></a><span class="co">  :::</span></span>
<span id="cb1-851"><a href="#cb1-851"></a></span>
<span id="cb1-852"><a href="#cb1-852"></a><span class="co">  ::: {.flex-container style="flex-direction:column;"}</span></span>
<span id="cb1-853"><a href="#cb1-853"></a></span>
<span id="cb1-854"><a href="#cb1-854"></a><span class="co">  📆 structured data  </span></span>
<span id="cb1-855"><a href="#cb1-855"></a><span class="co">  ⛓️ sequences  </span></span>
<span id="cb1-856"><a href="#cb1-856"></a><span class="co">  ⏰ time-series  </span></span>
<span id="cb1-857"><a href="#cb1-857"></a><span class="co">  🕸️ graphs  </span></span>
<span id="cb1-858"><a href="#cb1-858"></a><span class="co">  🌀 fields</span></span>
<span id="cb1-859"><a href="#cb1-859"></a></span>
<span id="cb1-860"><a href="#cb1-860"></a><span class="co">  :::</span></span>
<span id="cb1-861"><a href="#cb1-861"></a></span>
<span id="cb1-862"><a href="#cb1-862"></a><span class="co">  ::::</span></span>
<span id="cb1-863"><a href="#cb1-863"></a></span>
<span id="cb1-864"><a href="#cb1-864"></a><span class="co">[^riken]:|</span></span>
<span id="cb1-865"><a href="#cb1-865"></a><span class="co">    [Argonne and RIKEN sign a MOU in support of AI for science](https://www.anl.gov/article/argonne-and-riken-sign-a-memorandum-of-understanding-in-support-of-ai-for-science)</span></span>
<span id="cb1-866"><a href="#cb1-866"></a></span>
<span id="cb1-867"><a href="#cb1-867"></a><span class="co">[^bsc]:|</span></span>
<span id="cb1-868"><a href="#cb1-868"></a><span class="co">    Collaborations with Barcelona Supercomputing Center</span></span>
<span id="cb1-869"><a href="#cb1-869"></a></span>
<span id="cb1-870"><a href="#cb1-870"></a><span class="co">--&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/saforem2/personal_site/blob/main/talks/AuroraGPT/alcf-hpc-workshop-2024/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/saforem2/personal_site/edit/main/talks/AuroraGPT/alcf-hpc-workshop-2024/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/personal_site/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer><script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>