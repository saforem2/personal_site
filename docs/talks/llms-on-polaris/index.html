<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sam Foreman">
<meta name="dcterms.date" content="2024-07-17">

<title>LLMs on Polaris – Sam Foreman</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../talks/test/slides.html" rel="next">
<link href="../../talks/llms-at-scale/index.html" rel="prev">
<link href="../../assets/favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-d10c3a9e6902322a4770c56db7863b79.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-3cb719820af5089d15fca36804308e9d.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "?",
    "H"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-E72QE53WSY"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-E72QE53WSY', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=IBM+Plex+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans&amp;family=IBM+Plex+Sans+Condensed&amp;family=IBM+Plex+Mono&amp;display=swap" rel="stylesheet">
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-TC329HJ');</script>
<!-- End Google Tag Manager -->
<link rel="preconnect" href="https://fonts.googleapis.com">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../css/colors-oklch.min.css">
<link rel="stylesheet" href="../../css/custom.css">
<link rel="stylesheet" href="../../css/svgbob.css">
<link rel="stylesheet" href="../../static/fonts/MIosevkaQp/MIosevkaQp.css">
<link rel="stylesheet" href="../../static/fonts/MIosevkaterm/MIosevkaTerm.css">
<meta property="og:title" content="LLMs On Polaris">
<meta property="og:description" content="Training LLMs at Scale on Polaris at ALCF">
<meta property="og:image" content="https://raw.githubusercontent.com/saforem2/personal_site/main/talks/llms-on-polaris/assets/thumbnail.png">
<meta property="og:site_name" content="Sam Foreman">
<meta name="twitter:title" content="LLMs On Polaris">
<meta name="twitter:description" content="Training LLMs at Scale on Polaris at ALCF">
<meta name="twitter:image" content="https://raw.githubusercontent.com/saforem2/personal_site/main/talks/llms-on-polaris/assets/thumbnail.png">
<meta name="twitter:creator" content="saforem2">
<meta name="twitter:site" content="saforem2">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="LLMs on Polaris">
<meta name="citation_author" content="Sam Foreman">
<meta name="citation_publication_date" content="2024-07-17">
<meta name="citation_cover_date" content="2024-07-17">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-07-17">
<meta name="citation_fulltext_html_url" content="https://samforeman.me/talks/llms-on-polaris/">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_abstract=We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &amp;amp;amp;gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinö Hatanpää;,citation_author=Varuni K. Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=Bharat Kale;,citation_author=Carla M. Mann;,citation_author=Heng Ma;,citation_author=Yun-Hsuan Cheng;,citation_author=Yuliana Zamora;,citation_author=Shengchao Liu;,citation_author=Chaowei Xiao;,citation_author=Murali Emani;,citation_author=Tom Gibbs;,citation_author=Mahidhar Tatineni;,citation_author=Deepak Canchi;,citation_author=Jerome Mitchell;,citation_author=Koichi Yamada;,citation_author=Maria Garzaran;,citation_author=Michael E. Papka;,citation_author=Ian Foster;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1109/SC41406.2024.00013;,citation_doi=10.1109/SC41406.2024.00013;,citation_isbn=9798350352917;,citation_conference_title=Proceedings of the international conference for high performance computing, networking, storage, and analysis;,citation_conference=IEEE Press;,citation_series_title=SC ’24;">
<meta name="citation_reference" content="citation_title=Quality measures for dynamic graph generative models;,citation_author=Ryien Hosseini;,citation_author=Filippo Simini;,citation_author=Venkatram Vishwanath;,citation_author=Rebecca Willett;,citation_author=Henry Hoffmann;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://openreview.net/forum?id=8bjspmAMBk;,citation_conference_title=The thirteenth international conference on learning representations;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RG-inspired machine learning for lattice field theory;,citation_author=Sam Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=175;,citation_conference_title=EPJ web of conferences;,citation_conference=EDP Sciences;">
<meta name="citation_reference" content="citation_title=Large energy density in three-plate nanocapacitors due to coulomb blockade;,citation_author=A Hubler;,citation_author=S Foreman;,citation_author=J Liu;,citation_author=L Wortsmann;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=10;,citation_volume=123;,citation_journal_title=Journal of Applied Physics;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Examples of renormalization group transformations for image sets;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=5;,citation_volume=98;,citation_journal_title=Physical Review E;,citation_publisher=American Physical Society;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the Ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.22323/1.334.0245;,citation_volume=LATTICE2018;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Machine learning inspired analysis of the ising model transition;,citation_author=Samuel Foreman;,citation_author=Joel Giedt;,citation_author=Yannick Meurice;,citation_author=Judah Unmuth-Yockey;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Lattice 2018;">
<meta name="citation_reference" content="citation_title=Learning better physics: A machine learning approach to lattice gauge theory;,citation_author=Samuel Alfred Foreman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_dissertation_institution=University of Iowa;">
<meta name="citation_reference" content="citation_title=Machine learning and neural networks for field theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=HMC with normalizing flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01586;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy storage in quantum resonators;,citation_author=Jiaqi Liu;,citation_author=Alfred W Hubler;,citation_author=Samuel Alfred Foreman;,citation_author=Katharina Ott;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Applications of machine learning to lattice quantum field theory;,citation_author=Denis Boyda;,citation_author=Salvatore Calı̀;,citation_author=Sam Foreman;,citation_author=Lena Funcke;,citation_author=Daniel C Hackett;,citation_author=Yin Lin;,citation_author=Gert Aarts;,citation_author=Andrei Alexandru;,citation_author=Xiao-Yong Jin;,citation_author=Biagio Lucini;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2202.05838;">
<meta name="citation_reference" content="citation_title=Lattice QCD and particle physics;,citation_author=Andreas S Kronfeld;,citation_author=Tanmoy Bhattacharya;,citation_author=Thomas Blum;,citation_author=Norman H Christ;,citation_author=Carleton DeTar;,citation_author=William Detmold;,citation_author=Robert Edwards;,citation_author=Anna Hasenfratz;,citation_author=Huey-Wen Lin;,citation_author=Swagato Mukherjee;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2207.07641;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=6;,citation_volume=37;,citation_journal_title=The International Journal of High Performance Computing Applications;,citation_publisher=SAGE Publications Sage UK: London, England;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=The international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=Superconductivity of in and sn samples;,citation_author=George Deamont;,citation_author=Sam Foreman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A comprehensive performance study of large language models on novel AI accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04607;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2310.04610;">
<meta name="citation_reference" content="citation_title=Protein generation via genome-scale language models with bio-physical scoring;,citation_author=Gautham Dharuman;,citation_author=Logan Ward;,citation_author=Heng Ma;,citation_author=Priyanka V Setty;,citation_author=Ozan Gokdemir;,citation_author=Sam Foreman;,citation_author=Murali Emani;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Kristopher Keipert;,citation_author=others;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the SC’23 workshops of the international conference on high performance computing, network, storage, and analysis;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=arXiv preprint arXiv:2312.08936;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 computational frontier CompF03 topical group report: Machine learning;,citation_author=Phiala Shanahan;,citation_author=Kazuhiro Terao;,citation_author=Daniel Whiteson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=arXiv preprint arXiv:2209.07559;">
<meta name="citation_reference" content="citation_title=Thorough characterization and analysis of large transformer model training at-scale;,citation_author=Scott Cheng;,citation_author=Jun-Liang Lin;,citation_author=Murali Emani;,citation_author=Siddhisanket Raskar;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Venkatram Vishwanath;,citation_author=Mahmut Taylan Kandemir;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=8;,citation_journal_title=Proceedings of the ACM on Measurement and Analysis of Computing Systems;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Communities through energy justice projects;,citation_author=Mary Ann Leung;,citation_author=Katharine Cahill;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois Curfman McInnes;,citation_author=Suzanne Parete-Koon;,citation_author=Subil Abraham;,citation_author=Lacy Beach Barrier;,citation_author=Gladys Chen;,citation_author=Lizanne DeStefano;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science;">
<meta name="citation_reference" content="citation_title=Applications of a foundation model approach for weather and climate;,citation_author=Troy Arcomano;,citation_author=Alexander Wikner;,citation_author=Romit Maulik;,citation_author=Veerabhadra Rao Kotamarthi;,citation_author=Sam Foreman;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=2023;,citation_conference_title=AGU fall meeting abstracts;">
<meta name="citation_reference" content="citation_title=Toward a holistic performance evaluation of large language models across diverse ai accelerators;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Varuni Sastry;,citation_author=Zhen Xie;,citation_author=Siddhisanket Raskar;,citation_author=William Arnold;,citation_author=Rajeev Thakur;,citation_author=Venkatram Vishwanath;,citation_author=Michael E Papka;,citation_author=Sanjif Shanmugavelu;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 IEEE international parallel and distributed processing symposium workshops (IPDPSW);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Intro to HPC bootcamp: Engaging new communities through energy justice projects;,citation_author=Suzanne Parete-Koon;,citation_author=Michael Sandoval;,citation_author=Kellen Leland;,citation_author=Subil Abraham;,citation_author=Mary Ann Leung;,citation_author=Rebecca Hartman-Baker;,citation_author=Paige Kinsley;,citation_author=Lois McInnes;,citation_author=Sreeranjani Ramprakash;,citation_author=Lacy Beach Barrier;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=15;,citation_journal_title=Journal of Computational Science Education;,citation_publisher=Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States);">
<meta name="citation_reference" content="citation_title=MProt-DPO: Breaking the ExaFLOPS barrier for multimodal protein design workflows with direct preference optimization;,citation_author=Gautham Dharuman;,citation_author=Kyle Hippe;,citation_author=Alexander Brace;,citation_author=Sam Foreman;,citation_author=Väinä Hatanpää;,citation_author=Varuni K Sastry;,citation_author=Huihuo Zheng;,citation_author=Logan Ward;,citation_author=Servesh Muralidharan;,citation_author=Archit Vasan;,citation_author=others;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=2024 SC24: International conference for high performance computing, networking, storage and analysis SC;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=DeepSpeed4Science initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;,citation_author=Shuaiwen Leon Song;,citation_author=Bonnie Kruft;,citation_author=Minjia Zhang;,citation_author=Conglong Li;,citation_author=Shiyang Chen;,citation_author=Chengming Zhang;,citation_author=Masahiro Tanaka;,citation_author=Xiaoxia Wu;,citation_author=Jeff Rasley;,citation_author=Ammar Ahmad Awan;,citation_author=Connor Holmes;,citation_author=Martin Cai;,citation_author=Adam Ghanem;,citation_author=Zhongzhu Zhou;,citation_author=Yuxiong He;,citation_author=Pete Luferenko;,citation_author=Divya Kumar;,citation_author=Jonathan Weyn;,citation_author=Ruixiong Zhang;,citation_author=Sylwester Klocek;,citation_author=Volodymyr Vragov;,citation_author=Mohammed AlQuraishi;,citation_author=Gustaf Ahdritz;,citation_author=Christina Floristean;,citation_author=Cristina Negri;,citation_author=Rao Kotamarthi;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_author=Sam Foreman;,citation_author=Kyle Hippe;,citation_author=Troy Arcomano;,citation_author=Romit Maulik;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot;,citation_author=Murali Emani;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Prasanna Balaprakash;,citation_author=Gina Tourassi;,citation_author=John Gounley;,citation_author=Heidi Hanson;,citation_author=Thomas E Potok;,citation_author=Massimiliano Lupo Pasini;,citation_author=Kate Evans;,citation_author=Dan Lu;,citation_author=Dalton Lunga;,citation_author=Junqi Yin;,citation_author=Sajal Dash;,citation_author=Feiyi Wang;,citation_author=Mallikarjun Shankar;,citation_author=Isaac Lyngaas;,citation_author=Xiao Wang;,citation_author=Guojing Cong;,citation_author=Pei Zhang;,citation_author=Ming Fan;,citation_author=Siyan Liu;,citation_author=Adolfy Hoisie;,citation_author=Shinjae Yoo;,citation_author=Yihui Ren;,citation_author=William Tang;,citation_author=Kyle Felker;,citation_author=Alexey Svyatkovskiy;,citation_author=Hang Liu;,citation_author=Ashwin Aji;,citation_author=Angela Dalton;,citation_author=Michael Schulte;,citation_author=Karl Schulz;,citation_author=Yuntian Deng;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Anima Anandkumar;,citation_author=Rick Stevens;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2310.04610;">
<meta name="citation_reference" content="citation_title=Emergent abilities of large language models;,citation_author=Jason Wei;,citation_author=Yi Tay;,citation_author=Rishi Bommasani;,citation_author=Colin Raffel;,citation_author=Barret Zoph;,citation_author=Sebastian Borgeaud;,citation_author=Dani Yogatama;,citation_author=Maarten Bosma;,citation_author=Denny Zhou;,citation_author=Donald Metzler;,citation_author=Ed H. Chi;,citation_author=Tatsunori Hashimoto;,citation_author=Oriol Vinyals;,citation_author=Percy Liang;,citation_author=Jeff Dean;,citation_author=William Fedus;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.07682;">
<meta name="citation_reference" content="citation_title=The climate risk &amp;amp;amp; resilience portal (ClimRR) metadata and data dictionary;,citation_author=C. Burdi;,citation_author=Wall. T Branham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://dub.sh/ClimRR-Metadata;">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;">
<meta name="citation_reference" content="citation_title=Deep Learning Hamiltonian Monte Carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_publication_date=2021-05;,citation_cover_date=2021-05;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2105.03418;,citation_conference_title=9th International Conference on Learning Representations;">
<meta name="citation_reference" content="citation_title=Deep learning hamiltonian monte carlo;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2105.03418;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A trainable framework for effective topological sampling;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James C Osborn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2112.01582;">
<meta name="citation_reference" content="citation_title=Energy Justice Analysis of Climate Data with ClimRR;,citation_author=Sam Foreman;,citation_publication_date=2023-08-07;,citation_cover_date=2023-08-07;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/climate-analysis;,citation_language=en;">
<meta name="citation_reference" content="citation_author=Sam Foreman;,citation_publication_date=2023-08-19;,citation_cover_date=2023-08-19;,citation_year=2023;,citation_fulltext_html_url=https://saforem2.github.io/l2hmc-qcd;,citation_language=en;">
<meta name="citation_reference" content="citation_title=MLMC: Machine learning monte carlo for lattice gauge theory;,citation_author=Sam Foreman;,citation_author=Xiao-Yong Jin;,citation_author=James Osborn;,citation_publication_date=00;,citation_cover_date=00;,citation_year=0;,citation_conference_title=40th international symposium on lattice field theory (lattice 2023) (batavia, IL, united states, 07/31/2023 - 08/04/2023);">
<meta name="citation_reference" content="citation_title=Progress on $(g-2)_\mu$ from lattice QCD;,citation_author=Hartmut Wittig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.04165;">
<meta name="citation_reference" content="citation_title=Hybrid Monte Carlo;,citation_author=S. Duane;,citation_author=A. D. Kennedy;,citation_author=B. J. Pendleton;,citation_author=D. Roweth;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_doi=10.1016/0370-2693(87)91197-X;,citation_volume=195;,citation_journal_title=Phys. Lett. B;">
<meta name="citation_reference" content="citation_title=Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning;,citation_author=Phiala Shanahan;,citation_author=others;,citation_publication_date=2022-09;,citation_cover_date=2022-09;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2209.07559;">
<meta name="citation_reference" content="citation_title=Applications of Machine Learning to Lattice Quantum Field Theory;,citation_author=Denis Boyda;,citation_author=others;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2202.05838;,citation_conference_title=Snowmass 2021;">
<meta name="citation_reference" content="citation_title=LeapfrogLayers: A Trainable Framework for Effective Topological Sampling;,citation_author=S. Foreman;,citation_author=X. Jin;,citation_author=J. Osborn;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01582;,citation_doi=10.22323/1.396.0508;,citation_conference_title=The 38th international symposium on lattice field theory;">
<meta name="citation_reference" content="citation_title=HMC with Normalizing Flows;,citation_author=Sam Foreman;,citation_author=Taku Izubuchi;,citation_author=Luchang Jin;,citation_author=Xiao-Yong Jin;,citation_author=James C. Osborn;,citation_author=Akio Tomiya;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2112.01586;,citation_doi=10.22323/1.396.0073;,citation_volume=LATTICE2021;,citation_journal_title=PoS;">
<meta name="citation_reference" content="citation_title=Mastering language models;,citation_author=Samuel Montgomery;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://towardsdatascience.com/mastering-language-models-32e1d891511a
           ;,citation_journal_title=Medium;,citation_publisher=Towards Data Science;">
<meta name="citation_reference" content="citation_title=Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond;,citation_author=Jingfeng Yang;,citation_author=Hongye Jin;,citation_author=Ruixiang Tang;,citation_author=Xiaotian Han;,citation_author=Qizhang Feng;,citation_author=Haoming Jiang;,citation_author=Bing Yin;,citation_author=Xia Hu;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.13712;">
<meta name="citation_reference" content="citation_title=Training tips for the transformer model;,citation_author=Martin Popel;,citation_author=Ondřej Bojar;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.2478%2Fpralin-2018-0002;,citation_issue=1;,citation_doi=10.2478/pralin-2018-0002;,citation_volume=110;,citation_journal_title=The Prague Bulletin of Mathematical Linguistics;,citation_publisher=Charles University in Prague, Karolinum Press;">
<meta name="citation_reference" content="citation_title=Attention is all you need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/abs/1706.03762;">
<meta name="citation_reference" content="citation_title=Tree of thoughts: Deliberate problem solving with large language models;,citation_author=Shunyu Yao;,citation_author=Dian Yu;,citation_author=Jeffrey Zhao;,citation_author=Izhak Shafran;,citation_author=Thomas L. Griffiths;,citation_author=Yuan Cao;,citation_author=Karthik Narasimhan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2305.10601;">
<meta name="citation_reference" content="citation_title=GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics;,citation_abstract=We seek to transform how new and emergent variants of pandemiccausing viruses, specifically SARS-CoV-2, are identified and classified. By adapting large language models (LLMs) for genomic data, we build genome-scale language models (GenSLMs) which can learn the evolutionary landscape of SARS-CoV-2 genomes. By pretraining on over 110 million prokaryotic gene sequences and finetuning a SARS-CoV-2-specific model on 1.5 million genomes, we show that GenSLMs can accurately and rapidly identify variants of concern. Thus, to our knowledge, GenSLMs represents one of the first whole genome scale foundation models which can generalize to other prediction tasks. We demonstrate scaling of GenSLMs on GPU-based supercomputers and AI-hardware accelerators utilizing 1.63 Zettaflops in training runs with a sustained performance of 121 PFLOPS in mixed precision and peak of 850 PFLOPS. We present initial scientific insights from examining GenSLMs in tracking evolutionary dynamics of SARS-CoV-2, paving the path to realizing this on large biological data.Competing Interest StatementThe authors have declared no competing interest.;,citation_author=Maxim Zvyagin;,citation_author=Alexander Brace;,citation_author=Kyle Hippe;,citation_author=Yuntian Deng;,citation_author=Bin Zhang;,citation_author=Cindy Orozco Bohorquez;,citation_author=Austin Clyde;,citation_author=Bharat Kale;,citation_author=Danilo Perez-Rivera;,citation_author=Heng Ma;,citation_author=Carla M. Mann;,citation_author=Michael Irvin;,citation_author=J. Gregory Pauloski;,citation_author=Logan Ward;,citation_author=Valerie Hayot-Sasson;,citation_author=Murali Emani;,citation_author=Sam Foreman;,citation_author=Zhen Xie;,citation_author=Diangen Lin;,citation_author=Maulik Shukla;,citation_author=Weili Nie;,citation_author=Josh Romero;,citation_author=Christian Dallago;,citation_author=Arash Vahdat;,citation_author=Chaowei Xiao;,citation_author=Thomas Gibbs;,citation_author=Ian Foster;,citation_author=James J. Davis;,citation_author=Michael E. Papka;,citation_author=Thomas Brettin;,citation_author=Rick Stevens;,citation_author=Anima Anandkumar;,citation_author=Venkatram Vishwanath;,citation_author=Arvind Ramanathan;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://www.biorxiv.org/content/early/2022/11/23/2022.10.10.511571;,citation_doi=10.1101/2022.10.10.511571;,citation_journal_title=bioRxiv;,citation_publisher=Cold Spring Harbor Laboratory;">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/signature-navbar-orig.svg" alt="Sam Foreman" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../talks/index.html" aria-current="page"> 
<span class="menu-text">talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/index.html"> 
<span class="menu-text">posts</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">projects</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="../../projects/index.html">
 <span class="dropdown-text">📚 All Projects</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ezpz">
 <span class="dropdown-text">🍋 <code>ezpz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/l2hmc-qcd">
 <span class="dropdown-text">🟥 <code>l2hmc-qcd</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/argonne-lcf/Megatron-DeepSpeed)">
 <span class="dropdown-text">🤖 <code>Megatron-DeepSpeed</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/wordplay">
 <span class="dropdown-text">💬 <code>wordplay</code> 🎮</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://www.alcf.anl.gov/alcf-ai-science-training-series?">
 <span class="dropdown-text">🎓 <code>ai-science-training</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/enrich">
 <span class="dropdown-text">💸 <code>enrich</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/ambivalent">
 <span class="dropdown-text">🤷🏻‍♂️<code>ambivalent</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://saforem2.github.io/climate-analysis">
 <span class="dropdown-text">🌍 <code>climate-analysis</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/glitz">
 <span class="dropdown-text">🎨 <code>glitz</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/personal_site">
 <span class="dropdown-text">🙋🏻<code>personal_site</code></span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/saforem2/notes-demo">
 <span class="dropdown-text">🗒️ <code>Notes-Demo</code></span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/saforem2/personal_site"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:github-logo" aria-label="Icon github-logo from ph Iconify.design set." title="Icon github-logo from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.xml"> 
<span class="menu-text"><span class="icon" style="font-size: 1.25rem; color:var(--bs-nav-link-color);"><iconify-icon role="img" inline="" icon="ph:rss" aria-label="Icon rss from ph Iconify.design set." title="Icon rss from ph Iconify.design set."></iconify-icon></span></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../talks/index.html">🎙️ Talks</a></li><li class="breadcrumb-item"><a href="../../talks/llms-on-polaris/index.html">LLMs on Polaris</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../projects/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📚 Projects</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📬 Posts</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/aurora-frameworks-2025-numpy-2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚧 Frameworks Issue with <code>numpy &gt; 2</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/dope-slides/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">💅 How to Make Dope Slides</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ezpz-at-alcf/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🍋 <code>ezpz</code> @ ALCF</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ezpz-v1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📝 ezpz-v1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/installing-pytorch-on-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🔥 Building PyTorch from Source on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/resume/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">👤 Résumé</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/svgbob/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🫥 svgbob</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/torchtune-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🪛 Torchtune on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/torchtune-patch-aurora/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚑 Torchtune Patch on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../posts/AuroraGPT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🤖 AuroraGPT</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/aurora-gpt/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏎️ Megatron-DeepSpeed on Intel XPU</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/checkpoints/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">💾 Converting Checkpoints</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/determinstic-flash-attn/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎰 Deterministic <code>flash-attn</code></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/flash-attn-sunspot/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📸 <code>flash-attn</code> on Sunspot</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/long-sequences/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🚂 Loooooooong Sequence Lengths</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/mpi4py-reproducer/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🐛 <code>mpi4py</code> bug on Sunspot</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/spike-skipper/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏔️ Spike Skipper</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/AuroraGPT/startup-times/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🐢 Starting Up Distributed Training on Aurora</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">⚛️ AI for Physics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ai-for-physics/diffusion/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎲 MCMC + Diffusion Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">🎢 L2HMC for LQCD</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ai-for-physics/l2hmc-qcd/2dU1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎢 <code>l2hmc-qcd</code> Example: 2D U(1)</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">4dSU3nb</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🕸️ l2hmc-qcd Example: 4D SU(3)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">📗 Jupyter</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/jupyter/test/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🏁 <code>l2hmc</code> Example: 2D <span class="math inline">U(1)</span></span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">L2hmc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/jupyter/l2hmc/4dSU3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🔳 <code>l2hmc-qcd</code> Example: 4D SU(3)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../talks/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">🎙️ Talks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/ai-for-science-2024/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parallel Training Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/alcf-hpc-workshop-2024/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning and Foundation Models at Scale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/aurora-gpt-fm-for-electric-grid/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AuroraGPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/hpc-user-forum/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AuroraGPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/incite-hackathon-2025/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Large Language Models on Aurora</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/lattice23/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MLMC: Machine Learning Monte Carlo</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/llms-at-scale/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training LLMs at Scale</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/llms-on-polaris/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">LLMs on Polaris</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/test/slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test Rendering on Mobile</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">AuroraGPT</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../talks/AuroraGPT/alcf-hpc-workshop-2024/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AuroraGPT</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    <div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TC329HJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../talks/index.html">🎙️ Talks</a></li><li class="breadcrumb-item"><a href="../../talks/llms-on-polaris/index.html">LLMs on Polaris</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">LLMs on Polaris</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://samforeman.me">Sam Foreman</a> <a href="mailto:foremans@anl.gov" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://alcf.anl.gov/about/people/sam-foreman">
            </a><a href="https://alcf.anl.gov/about/people/sam-foreman">ALCF</a>
            
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 17, 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">March 29, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="section" class="level1 centeredslide" data-background-color="white" data-background-iframe="https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html" loading="lazy">
<h1 class="centeredslide" data-background-color="white" data-background-iframe="https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html" loading="lazy"></h1>
<div style="background-color: #f5f5f5; opacity:0.97; border-radius: 10px; text-align:center; padding: 0px; padding-left: 1.5em; padding-right: 1.5em; max-width: min-content; min-width: max-content; margin-left: auto; margin-right: auto; padding-top: 0.2em; padding-bottom: 0.2em; line-height: 1.5em!important;">
<p><span style="color:#333333; font-size:1.5em; font-weight: bold;">LLMs on Polaris</span> <span style="padding-bottom: 0.5rem;"><br>&nbsp;</span><br>
<a href="https://samforeman.me">🏡 Sam Foreman</a><br>
<span class="dim-text" style="font-size: 0.8em"><a href="https://indico.fnal.gov/event/57249/contributions/271305/">SciFM Summer School 24</a></span></p>
</div>
<div class="footer">
<p><span class="dim-text">2024-07-17</span></p>
</div>
</section>
<section id="sam-foreman" class="level1" style="font-size: 0.9em;" data-background-color="white">
<h1 style="font-size: 0.9em;" data-background-color="white">👤 <a href="https://samforeman.me">Sam Foreman</a></h1>
<ul>
<li>I’m a Computational Scientist in the <a href="https://www.alcf.anl.gov/about/people/group/506">Data Science Group</a> at <a href="https://alcf.anl.gov">ALCF</a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.
<ul>
<li>Personal Website: <a href="https://samforeman.me">samforeman.me</a></li>
<li>Background: <span><code>{ML, LLMs, AI4Science, HEP, Lattice QCD, MCMC, Generative Modeling, ...}</code></span></li>
</ul></li>
</ul>
<p>Ongoing / recent work:</p>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><a href="https://github.com/saforem2/">AI + Science</a>
<ul>
<li><a href="https://github.com/saforem2/l2hmc-qcd">Building better sampling methods for Lattice QCD</a></li>
<li><a href="https://www.biorxiv.org/content/10.1101/2022.10.10.511571v2">GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics</a></li>
<li><a href="https://saforem2.github.io/climate-analysis">Foundation models for long term climate forecasting</a></li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<ul>
<li><a href="https://github.com/saforem2/Megatron-DS-Benchmarking">Scaling Large Language Models</a></li>
<li><a href="https://github.com/argonne-lcf/mlprof">Optimizing distibuted training across thousands of GPUs</a></li>
<li>Building new parallelism techniques for efficient scaling</li>
<li>Generative modeling (esp.&nbsp;for physical systems)</li>
</ul>
</div>
</div>
</section>
<section id="polaris-alcf" class="level1" data-background-color="white">
<h1 data-background-color="white">Polaris @ ALCF</h1>
<p>Refer to <a href="https://docs.alcf.anl.gov/polaris/getting-started/">Getting Started</a> for additional information.</p>
<ul>
<li><p>Login:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu">ssh</span> <span class="op">&lt;</span>username<span class="op">&gt;</span>@polaris.alcf.anl.gov</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Modules (+ using <code>conda</code>):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="ex">module</span> use /soft/modulefiles</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="ex">module</span> load conda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="getting-started" class="level1" data-background-color="white">
<h1 data-background-color="white">Getting Started</h1>
<ul>
<li><p><a href="https://docs.alcf.anl.gov/running-jobs/job-and-queue-scheduling/">Running Jobs</a></p>
<ul>
<li><a href="https://docs.alcf.anl.gov/running-jobs/example-job-scripts/">example job scripts</a></li>
</ul></li>
<li><p><a href="https://docs.alcf.anl.gov/polaris/getting-started/#proxy">Proxy</a>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># proxy settings</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="bu">export</span> <span class="va">HTTP_PROXY</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="bu">export</span> <span class="va">HTTPS_PROXY</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="bu">export</span> <span class="va">http_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="bu">export</span> <span class="va">https_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="bu">export</span> <span class="va">ftp_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="bu">export</span> <span class="va">no_proxy</span><span class="op">=</span><span class="st">"admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Getting Help:</p>
<p><a href="mailto:support@alcf.anl.gov">support@alcf.anl.gov</a></p></li>
</ul>
</section>
<section id="polaris" class="level1" data-background-color="white">
<h1 data-background-color="white">Polaris</h1>
<ul>
<li><p>Polaris is a 560 node HPE Apollo 6500 Gen 10+ based system.</p></li>
<li><p>Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32 core CPU with:</p>
<ul>
<li>512 GB of DDR4 RAM</li>
<li>4 (four) NVIDIA A100 GPUs connected via NVLink</li>
<li>2 (a pair) of local 1.6TB of SSDs in RAID0 for the users use</li>
<li>2 (a pair) of Slingshot 11 network adapters.</li>
</ul></li>
<li><p>There are two nodes per chassis, seven chassis per rack, and 40 racks for a total of 560 nodes.</p></li>
</ul>
</section>
<section id="polaris-compute-nodes" class="level1 page-columns page-full" data-background-color="white">
<h1 data-background-color="white">Polaris Compute Nodes</h1>
<table class="table-striped table-hover caption-top table">
<caption>Details</caption>
<thead>
<tr class="header">
<th>POLARIS COMPUTE</th>
<th>DESCRIPTION</th>
<th>PER NODE</th>
<th>AGGREGATE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Processor<span class="math inline">^{1}</span></td>
<td>2.8 GHz 7543P</td>
<td>1</td>
<td>560</td>
</tr>
<tr class="even">
<td>Cores/Threads</td>
<td>AMD Zen 3 (Milan)</td>
<td>32/64</td>
<td>17,920/35,840</td>
</tr>
<tr class="odd">
<td>RAM<span class="math inline">^{2}</span></td>
<td>DDR4</td>
<td>512 GiB</td>
<td>280 TiB</td>
</tr>
<tr class="even">
<td>GPUS</td>
<td>NVIDIA A100</td>
<td>4</td>
<td>2240</td>
</tr>
<tr class="odd">
<td>Local SSD</td>
<td>1.6 TB</td>
<td>2/3.2 TB</td>
<td>1120/1.8PB</td>
</tr>
</tbody>
</table>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<ol type="1">
<li>256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core</li>
<li>8 memory channels rated at 204.8 GiB/s</li>
</ol>
</div></div></section>
<section id="polaris-a100-gpu-information" class="level1" data-background-color="white">
<h1 data-background-color="white">Polaris A100 GPU Information</h1>
<table class="caption-top table">
<thead>
<tr class="header">
<th>DESCRIPTION</th>
<th>A100 PCIe</th>
<th>A100 HGX (Polaris)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GPU Memory</td>
<td>40 GiB HBM2</td>
<td>160 GiB HBM2</td>
</tr>
<tr class="even">
<td>GPU Memory BW</td>
<td>1.6 TB/s</td>
<td>6.4 TB/s</td>
</tr>
<tr class="odd">
<td>Interconnect</td>
<td>PCIe Gen4 64 GB/s</td>
<td>NVLink 600 GB/s</td>
</tr>
<tr class="even">
<td>FP 64</td>
<td>9.7 TF</td>
<td>38.8 TF</td>
</tr>
<tr class="odd">
<td>FP64 Tensor Core</td>
<td>19.5 TF</td>
<td>78 TF</td>
</tr>
<tr class="even">
<td>FP 32</td>
<td>19.5 TF</td>
<td>78 TF</td>
</tr>
<tr class="odd">
<td>BF16 Tensor Core</td>
<td>312 TF</td>
<td>1.3 PF</td>
</tr>
<tr class="even">
<td>FP16 Tensor Core</td>
<td>312 TF</td>
<td>1.3 PF</td>
</tr>
<tr class="odd">
<td>INT8 Tensor Core</td>
<td>624 TOPS</td>
<td>2496 TOPS</td>
</tr>
<tr class="even">
<td>Max TDP Power</td>
<td>250 W</td>
<td>400 W</td>
</tr>
</tbody>
</table>
</section>
<section id="using-conda" class="level1" data-background-color="white">
<h1 data-background-color="white">Using Conda</h1>
<ul>
<li><p>Additional information in our <a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/python/">user guide</a></p></li>
<li><p>We provide prebuilt <code>conda</code> environment containing GPU-supported builds of:</p>
<ul>
<li><a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/pytorch/">Pytorch - ALCF User Guides</a></li>
<li><a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/deepspeed/">DeepSped - ALCF User Guides</a></li>
<li><a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/jax/">JAX - ALCF User Guides</a></li>
<li><a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/tensorflow/">Tensorflow - ALCF User Guides</a></li>
</ul></li>
<li><p>To activate / use: (either from an interactive job or inside a job script):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">$</span> module use /soft/modulefiles</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="ex">$</span> module load conda<span class="kw">;</span> <span class="ex">conda</span> activate base</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="virtual-environments-venv" class="level1" data-background-color="white">
<h1 data-background-color="white">Virtual Environments: <code>venv</code></h1>
<ul>
<li><p>To install additional libraries, we can create a virtual environment using <code>venv</code></p></li>
<li><p>Make sure you’re currently inside the <strong>base</strong> <code>conda</code> environment:</p>
<ul>
<li><code>module load conda; conda activate base</code></li>
</ul></li>
<li><p>Now, create <code>venv</code> <strong>on top of</strong> <code>base</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="ex">$</span> python3 <span class="at">-m</span> venv /path/to/venv <span class="at">--system-site-packages</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="ex">$</span> source /path/to/venv/bin/activate</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="ex">$</span> which python3</span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="ex">/path/to/venv/bin/python3</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="ex">$</span> <span class="co"># Now you can `python3 -m pip install ...` etc</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-simple callout-warning no-icon callout-titled" aria-title="Recent Talks" title="🚧 [Warning]{style='color:#fd971f!important;'}" style="text-align: left!important; width: 80%; opacity:100%;">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
🚧 <span style="color:#fd971f!important;">Warning</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li><code>--system-site-packages</code> tells the <code>venv</code> to use system packages</li>
<li>You must replace the path <code>/path/to/venv</code> in the above commands with a suitably chosen directory which you are able to write to.</li>
</ol>
</div>
</div>
</div></li>
</ul>
</section>
<section id="note-about-venvs" class="level1" data-background-color="white">
<h1 data-background-color="white">Note about <code>venv</code>’s</h1>
<ul>
<li><p>The value of <code>--system-site-packages</code> can be changed by modifying its value in <code>/path/to/venv/pyvenv.cfg</code></p></li>
<li><p>To install a <strong>different</strong> version of a package that is already installed in the base environment:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1"></a><span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">--ignore-installed</span> ... <span class="co"># or -I</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>The shared <code>base</code> environment is not writable</p>
<ul>
<li>Impossible to remove or uninstall packages</li>
</ul></li>
<li><p>If you need additional flexibility, we can <strong>clone</strong> the base environment</p></li>
</ul>
</section>
<section id="clone-base-conda-environment" class="level1" data-background-color="white">
<h1 data-background-color="white">Clone base <code>conda</code> environment</h1>
<ul>
<li><p>If we need additional flexibility or to install packages which <strong>require</strong> a <code>conda</code> install, we can clone the base environment</p>
<ul>
<li>requires copying the entirety of the base environment</li>
<li><strong>large storage requirement</strong>, can get out of hand quickly</li>
</ul></li>
<li><p>The shared <code>base</code> environment is not writable</p>
<ul>
<li>Impossible to remove or uninstall packages</li>
</ul></li>
<li><p>This can be done by:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="ex">$</span> module load conda</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="ex">$</span> conda activate base</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="kw">(</span><span class="ex">base</span><span class="kw">)</span> <span class="ex">$</span> conda create <span class="at">--clone</span> base <span class="at">--prefix</span><span class="op">=</span><span class="st">"/path/to/envs/base-clone"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="containers-on-polaris" class="level1" data-background-color="white">
<h1 data-background-color="white">Containers on Polaris</h1>
<ul>
<li><p>Polaris uses Nvidia A100 GPUs ==&gt;</p>
<ul>
<li>We can take advantage of Nvidia optimized containers</li>
</ul></li>
<li><p>The container system on Polaris is <a href="https://docs.sylabs.io/guides/3.5/user-guide/introduction.html"><code>singularity</code></a>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1"></a><span class="ex">module</span> avail singularity <span class="co"># see available</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="ex">module</span> load singularity  <span class="co"># load default version</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># To load a specific version:</span></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="ex">module</span> load singularity/3.8.7</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Singularity: two options for creating containers:</p>
<ol type="1">
<li>Using Docker on local machine and publishing to DockerHub</li>
<li>Using a Singularity recipe file and building on a Polaris worker node</li>
</ol></li>
<li><p>See also: <a href="https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/containers/containers/">Containers - ALCF User Guides</a></p></li>
</ul>
</section>
<section id="large-language-models" class="level1" data-background-color="white">
<h1 data-background-color="white">Large Language Models</h1>
</section>
<section id="status-of-large-language-models" class="level1" data-background-color="white">
<h1 data-background-color="white">Status of Large Language Models</h1>
<div id="fig-llms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/Hannibal046/Awesome-LLM/raw/main/resources/image8.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Large Language Models have (LLM)s have taken the NLP community world by storm"><img src="https://github.com/Hannibal046/Awesome-LLM/raw/main/resources/image8.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-llms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Large Language Models have (LLM)s have taken the <del>NLP community</del> <strong>world</strong> by storm<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
</figcaption>
</figure>
</div>
</section>
<section id="emergent-abilities" class="level1" data-background-color="#FBFBFD">
<h1 data-background-color="#FBFBFD">Emergent Abilities</h1>
<div width="66%" style="text-align: center;">
<p><img src="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/emergent-abilities.gif?raw=true" height="75%"></p>
<p><a href="https://arxiv.org/abs/2206.07682">Emergent abilities of Large Language Models</a> <span class="citation" data-cites="yao2023tree">Yao et al. (<a href="#ref-yao2023tree" role="doc-biblioref">2023</a>)</span></p>
</div>
</section>
<section id="training-llms" class="level1" data-background-color="#FFFFFF">
<h1 data-background-color="#FFFFFF">Training LLMs</h1>
<div class="quarto-layout-panel" data-layout="[ 50, 40 ]">
<div class="quarto-layout-row quarto-layout-valign-center">
<div class="quarto-layout-cell" style="flex-basis: 55.6%;justify-content: flex-start;">
<div id="fig-evolution" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Visualization from @yang2023harnessing"><img src="https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Visualization from <span class="citation" data-cites="yang2023harnessing">Yang et al. (<a href="#ref-yang2023harnessing" role="doc-biblioref">2023</a>)</span>
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 44.4%;justify-content: center;">
<p><a href="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
<section id="recent-work-2017-now" class="level1 scrollable" style="max-height: 95%; height: 100%; font-size: 0.75em;" data-background-color="white">
<h1 class="scrollable" style="max-height: 95%; height: 100%; font-size: 0.75em;" data-background-color="white">Recent Work (2017 – Now)</h1>
<div style="font-size: 0.9em;">
<table class="table-striped table-hover caption-top table">
<caption>Papers, 2017–*</caption>
<colgroup>
<col style="width: 5%">
<col style="width: 73%">
<col style="width: 14%">
<col style="width: 5%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Date</th>
<th style="text-align: left;">Paper</th>
<th style="text-align: left;">keywords</th>
<th style="text-align: left;">Institute</th>
<th style="text-align: left;">Publication</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">06/2017</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a></td>
<td style="text-align: left;">Transformers</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">NeurIPS<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F204e3073870fae3d05bcbc2f6a8e263d9b72e776%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">06/2018</td>
<td style="text-align: left;"><a href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf">Improving Language Understanding by Generative Pre-Training</a></td>
<td style="text-align: left;">GPT 1.0</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcd18800a0fe0b668a1cc19f2ec95b5003d0a5035%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">10/2018</td>
<td style="text-align: left;"><a href="https://aclanthology.org/N19-1423.pdf">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></td>
<td style="text-align: left;">BERT</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">NAACL <br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdf2b0e26d0599ce3e70df8a9da02e51594e0e992%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">02/2019</td>
<td style="text-align: left;"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></td>
<td style="text-align: left;">GPT 2.0</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9405cc0d6169988371b2755e573cc28650d14dfe%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">09/2019</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/1909.08053.pdf">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></td>
<td style="text-align: left;">Megatron-LM</td>
<td style="text-align: left;">NVIDIA</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8323c591e119eb09b28b29fd6c7bc76bd889df7a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">10/2019</td>
<td style="text-align: left;"><a href="https://jmlr.org/papers/v21/20-074.html">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></td>
<td style="text-align: left;">T5</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">JMLR<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3cfb319689f06bf04c2e28399361f414ca32c4b3%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">10/2019</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/1910.02054.pdf">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></td>
<td style="text-align: left;">ZeRO</td>
<td style="text-align: left;">Microsoft</td>
<td style="text-align: left;">SC<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F00c957711b12468cb38424caccdf5291bb354033%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">01/2020</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2001.08361.pdf">Scaling Laws for Neural Language Models</a></td>
<td style="text-align: left;">Scaling Law</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe6c561d02500b2596a230b341a8eb8b921ca5bf2%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">05/2020</td>
<td style="text-align: left;"><a href="https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">Language models are few-shot learners</a></td>
<td style="text-align: left;">GPT 3.0</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;">NeurIPS <br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6b85b63579a916f705a8e10a49bd8d849d91b1fc%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">01/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2101.03961.pdf">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</a></td>
<td style="text-align: left;">Switch Transformers</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">JMLR<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffdacf2a732f55befdc410ea927091cad3b791f13%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">08/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2107.03374.pdf">Evaluating Large Language Models Trained on Code</a></td>
<td style="text-align: left;">Codex</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Facbdbf49f9bc3f151b93d9ca9a06009f4f6eb269%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">08/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2108.07258.pdf">On the Opportunities and Risks of Foundation Models</a></td>
<td style="text-align: left;">Foundation Models</td>
<td style="text-align: left;">Stanford</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4f68e07c6c3173480053fd52391851d6f80d651b%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">09/2021</td>
<td style="text-align: left;"><a href="https://openreview.net/forum?id=gEZrGCozdqR">Finetuned Language Models are Zero-Shot Learners</a></td>
<td style="text-align: left;">FLAN</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">ICLR <br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fff0b2681d7b05e16c46dfb71d980cc2f605907cd%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">10/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2110.08207">Multitask Prompted Training Enables Zero-Shot Task Generalization</a></td>
<td style="text-align: left;">T0</td>
<td style="text-align: left;">HuggingFace et al.</td>
<td style="text-align: left;">ICLR <br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F17dd3555fd1ccf1141cf984347fa1b3fd6b009ca%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">12/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2112.06905.pdf">GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</a></td>
<td style="text-align: left;">GLaM</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">ICML<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F80d0116d77beeded0c23cf48946d9d10d4faee14%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">12/2021</td>
<td style="text-align: left;"><a href="https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-answering-with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22">WebGPT: Browser-assisted question-answering with human feedback</a></td>
<td style="text-align: left;">WebGPT</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2f3efe44083af91cef562c1a3451eee2f8601d22%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">12/2021</td>
<td style="text-align: left;"><a href="https://www.deepmind.com/publications/improving-language-models-by-retrieving-from-trillions-of-tokens">Improving language models by retrieving from trillions of tokens</a></td>
<td style="text-align: left;">Retro</td>
<td style="text-align: left;">DeepMind</td>
<td style="text-align: left;">ICML<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F002c256d30d6be4b23d365a8de8ae0e67e4c9641%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">12/2021</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2112.11446.pdf">Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher</a></td>
<td style="text-align: left;">Gopher</td>
<td style="text-align: left;">DeepMind</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F68f141724814839d556a989646194be88641b143%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">01/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2201.11903.pdf">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></td>
<td style="text-align: left;">COT</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">NeurIPS<br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b6e810ce0afd0dd093f789d2b2742d047e316d5%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">01/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2201.08239.pdf">LaMDA: Language Models for Dialog Applications</a></td>
<td style="text-align: left;">LaMDA</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb3848d32f7294ec708627897833c4097eb4d8778%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">01/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2206.14858">Solving Quantitative Reasoning Problems with Language Models</a></td>
<td style="text-align: left;">Minerva</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">NeurIPS<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fab0e3d3e4d42369de5933a3b4c237780b41c0d77%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">01/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2201.11990.pdf">Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model</a></td>
<td style="text-align: left;">Megatron-Turing NLG</td>
<td style="text-align: left;">Microsoft&amp;NVIDIA</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7cbc2a7843411a1768ab762930707af0a3c33a19%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">03/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2203.02155.pdf">Training language models to follow instructions with human feedback</a></td>
<td style="text-align: left;">InstructGPT</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd766bffc357127e0dc86dd69561d5aeb520d6f4c%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">04/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2204.02311.pdf">PaLM: Scaling Language Modeling with Pathways</a></td>
<td style="text-align: left;">PaLM</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F094ff971d6a8b8ff870946c9b3ce5aa173617bfb%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">04/2022</td>
<td style="text-align: left;"><a href="https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training">An empirical analysis of compute-optimal large language model training</a></td>
<td style="text-align: left;">Chinchilla</td>
<td style="text-align: left;">DeepMind</td>
<td style="text-align: left;">NeurIPS<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbb0656031cb17adf6bac5fd0fe8d53dd9c291508%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">05/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2205.01068.pdf">OPT: Open Pre-trained Transformer Language Models</a></td>
<td style="text-align: left;">OPT</td>
<td style="text-align: left;">Meta</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F13a0d8bb38f739990c8cd65a44061c6534f17221%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">05/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2205.05131v1">Unifying Language Learning Paradigms</a></td>
<td style="text-align: left;">UL2</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff40aeae3e522ada1f6a9f326841b01ef5c8657b6%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">06/2022</td>
<td style="text-align: left;"><a href="https://openreview.net/pdf?id=yzkSU5zdwD">Emergent Abilities of Large Language Models</a></td>
<td style="text-align: left;">Emergent Abilities</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;">TMLR<br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdac3a172b504f4e33c029655e9befb3386e5f63a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">06/2022</td>
<td style="text-align: left;"><a href="https://github.com/google/BIG-bench">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</a></td>
<td style="text-align: left;">BIG-bench</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F34503c0b6a615124eaf82cb0e4a1dab2866e8980%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">06/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2206.06336.pdf">Language Models are General-Purpose Interfaces</a></td>
<td style="text-align: left;">METALM</td>
<td style="text-align: left;">Microsoft</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa8fd9c1625011741f74401ff9bdc1c584e25c86d%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">09/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2209.14375.pdf">Improving alignment of dialogue agents via targeted human judgements</a></td>
<td style="text-align: left;">Sparrow</td>
<td style="text-align: left;">DeepMind</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F74eae12620bd1c1393e268bddcb6f129a5025166%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">10/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2210.11416.pdf">Scaling Instruction-Finetuned Language Models</a></td>
<td style="text-align: left;">Flan-T5/PaLM</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5484d228bfc50efbac6e86677bc2ec2ee4ede1a6%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">10/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2210.02414.pdf">GLM-130B: An Open Bilingual Pre-trained Model</a></td>
<td style="text-align: left;">GLM-130B</td>
<td style="text-align: left;">Tsinghua</td>
<td style="text-align: left;">ICLR<br> <img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1d26c947406173145a4665dd7ab255e03494ea28%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">11/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2211.09110.pdf">Holistic Evaluation of Language Models</a></td>
<td style="text-align: left;">HELM</td>
<td style="text-align: left;">Stanford</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5032c0946ee96ff11a292762f23e6377a6cf2731%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">11/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2211.05100.pdf">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</a></td>
<td style="text-align: left;">BLOOM</td>
<td style="text-align: left;">BigScience</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F964bd39b546f0f6625ff3b9ef1083f797807ef2e%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">11/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2211.09085.pdf">Galactica: A Large Language Model for Science</a></td>
<td style="text-align: left;">Galactica</td>
<td style="text-align: left;">Meta</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7d645a3fd276918374fd9483fd675c28e46506d1%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">12/2022</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2212.12017">OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization</a></td>
<td style="text-align: left;">OPT-IML</td>
<td style="text-align: left;">Meta</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe965e93e76a9e6c4e4863d145b5c007b540d575d%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">01/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2301.13688.pdf">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</a></td>
<td style="text-align: left;">Flan 2022 Collection</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff2b0017ddd77fa38760a18145e63553105a1a236%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">02/2023</td>
<td style="text-align: left;"><a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/">LLaMA: Open and Efficient Foundation Language Models</a></td>
<td style="text-align: left;">LLaMA</td>
<td style="text-align: left;">Meta</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F57e849d0de13ed5f91d086936296721d4ff75a75%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">02/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2302.14045">Language Is Not All You Need: Aligning Perception with Language Models</a></td>
<td style="text-align: left;">Kosmos-1</td>
<td style="text-align: left;">Microsoft</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffbfef4723d8c8467d7bd523e1d0b703cce0e0f9c%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">03/2023</td>
<td style="text-align: left;"><a href="https://palm-e.github.io">PaLM-E: An Embodied Multimodal Language Model</a></td>
<td style="text-align: left;">PaLM-E</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F38fe8f324d2162e63a967a9ac6648974fc4c66f3%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">03/2023</td>
<td style="text-align: left;"><a href="https://openai.com/research/gpt-4">GPT-4 Technical Report</a></td>
<td style="text-align: left;">GPT 4</td>
<td style="text-align: left;">OpenAI</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8ca62fdf4c276ea3052dc96dcfd8ee96ca425a48%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">04/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2304.01373">Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</a></td>
<td style="text-align: left;">Pythia</td>
<td style="text-align: left;">EleutherAI et al.</td>
<td style="text-align: left;">ICML<br><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbe55e8ec4213868db08f2c3168ae666001bea4b8%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">05/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2305.03047">Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision</a></td>
<td style="text-align: left;">Dromedary</td>
<td style="text-align: left;">CMU et al.</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe01515c6138bc525f7aec30fc85f2adf028d4156%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">05/2023</td>
<td style="text-align: left;"><a href="https://ai.google/static/documents/palm2techreport.pdf">PaLM 2 Technical Report</a></td>
<td style="text-align: left;">PaLM 2</td>
<td style="text-align: left;">Google</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Feccee350691708972370b7a12c2a78ad3bddd159%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">05/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/abs/2305.13048">RWKV: Reinventing RNNs for the Transformer Era</a></td>
<td style="text-align: left;">RWKV</td>
<td style="text-align: left;">Bo Peng</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F026b3396a63ed5772329708b7580d633bb86bec9%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">05/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2305.18290.pdf">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a></td>
<td style="text-align: left;">DPO</td>
<td style="text-align: left;">Stanford</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0d1c76d45afa012ded7ab741194baf142117c495%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
<tr class="even">
<td style="text-align: right;">07/2023</td>
<td style="text-align: left;"><a href="https://arxiv.org/pdf/2307.09288.pdf">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></td>
<td style="text-align: left;">LLaMA 2</td>
<td style="text-align: left;">Meta</td>
<td style="text-align: left;"><img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F104b0bb1da562d53cbda87aec79ef6a2827d191a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation" class="img-fluid" alt="Dynamic JSON Badge"></td>
</tr>
</tbody>
</table>
</div>
<div class="footer">
<ol type="1">
<li><a href="https://github.com/Hannibal046/Awesome-LLM/blob/main/README.md"><i class="fa-brands fa-github" aria-label="github"></i> Hannibal046/Awesome-LLM</a> <span class="inline-image"><a href="https://awesome.re"><img src="https://awesome.re/badge.svg" class="img-fluid" alt="Awesome"></a></span></li>
</ol>
</div>
</section>
<section id="life-cycle-of-the-llm" class="level1" data-auto-animate="true" data-background-color="white">
<h1 data-auto-animate="true" data-background-color="white">Life-Cycle of the LLM</h1>
<div class="quarto-layout-panel" data-layout="[ 45, 55 ]">
<div class="quarto-layout-row quarto-layout-valign-center">
<div id="column-one" class="quarto-layout-cell" style="flex-basis: 45.0%;justify-content: flex-start;">
<ol type="1">
<li><p>Data collection + preprocessing</p></li>
<li><p><strong>Pre-training</strong></p>
<ul>
<li>Architecture decisions:<br>
<code>{model_size, hyperparameters,</code><br>
<code>parallelism, lr_schedule, ...}</code></li>
</ul></li>
<li><p>Supervised Fine-Tuning</p>
<ul>
<li>Instruction Tuning</li>
<li>Alignment</li>
</ul></li>
<li><p>Deploy (+ monitor, re-evaluate, etc.)</p></li>
</ol>
</div>
<div id="column-two" class="quarto-layout-cell" style="flex-basis: 55.0%;justify-content: flex-start;">
<div id="fig-pretrain-two" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;3: Pre-training: Virtually all of the compute used during pretraining phase."><img src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <strong>Pre-training</strong>: Virtually all of the compute used during pretraining phase<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="life-cycle-of-the-llm-pre-training" class="level1" data-auto-animate="true" data-background-color="white">
<h1 data-auto-animate="true" data-background-color="white">Life-Cycle of the LLM: Pre-training</h1>
<div id="fig-pretrain-two" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;4: Pre-training: Virtually all of the compute used during pretraining phase"><img src="https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <strong>Pre-training</strong>: Virtually all of the compute used during pretraining phase
</figcaption>
</figure>
</div>
</section>
<section id="life-cycle-of-the-llm-fine-tuning" class="level1" data-auto-animate="true" style="font-size: 0.8em;" data-background-color="white">
<h1 data-auto-animate="true" style="font-size: 0.8em;" data-background-color="white">Life-Cycle of the LLM: Fine-Tuning</h1>
<div id="fig-pretrain-two" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;5: Fine-tuning: Fine-tuning actually updates the model’s weights to make the model better at a certain task."><img src="https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pretrain-two-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: <strong>Fine-tuning</strong><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>: Fine-tuning actually updates the model’s weights to make the model better at a certain task.
</figcaption>
</figure>
</div>
</section>
<section id="forward-pass" class="level1" data-background-color="white">
<h1 data-background-color="white">Forward Pass</h1>
<div id="fig-forward-pass" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-forward-pass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<video data-autoplay="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_1_1080p.mov">
</video>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-forward-pass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Language Model trained for causal language modeling. Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">🤗 Generation with LLMs</a>
</figcaption>
</figure>
</div>
</section>
<section id="generating-text" class="level1" data-background-color="white">
<h1 data-background-color="white">Generating Text</h1>
<div id="fig-generating-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<video data-autoplay="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_2_1080p.mov">
</video>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-generating-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Language Model trained for causal language modeling. Video from: <a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial">🤗 Generation with LLMs</a>
</figcaption>
</figure>
</div>
</section>
<section id="parallelism-overview" class="level1 page-columns page-full" data-background-color="white">
<h1 data-background-color="white">Parallelism Overview</h1>
<blockquote class="blockquote">
<p><em><strong>Modern parallelism techniques</strong> enable the training of large language models</em></p>
</blockquote>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p>See my slides on <a href="https://saforem2.github.io/parallel-training-slides/#/title-slide">Parallel Training Techniques</a> for additional details</p>
</div></div></section>
<section id="parallelism-concepts" class="level1 page-columns page-full" style="font-size: 0.9em;" data-background-color="white">
<h1 style="font-size: 0.9em;" data-background-color="white">Parallelism Concepts</h1>
<ul>
<li><strong>DataParallel (DP)</strong>:
<ul>
<li><p>The same setup is replicated multiple times, and each being fed a slice of the data.</p></li>
<li><p>The processing is done in parallel and all setups are synchronized at the end of each training step.</p></li>
</ul></li>
<li><strong>TensorParallel (TP)</strong>:
<ul>
<li>Each tensor is split up into multiple chunks.</li>
<li>So, instead of having the whole tensor reside on a single gpu, each shard of the tensor resides on its designated gpu.
<ul>
<li>During processing each shard gets processed separately and in parallel on different GPUs and the results are synced at the end of the step.</li>
<li>This is what one may call horizontal parallelism, as he splitting happens on horizontal level.</li>
</ul></li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p><a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">🤗 Model Parallelism</a></p>
</div></div></section>
<section id="parallelism-conceptshf-mp1" class="level1" style="font-size: 0.9em;" data-background-color="white">
<h1 style="font-size: 0.9em;" data-background-color="white">Parallelism Concepts<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></h1>
<ul>
<li><strong>PipelineParallel (PP)</strong>:
<ul>
<li>Model is split up vertically (layer-level) across multiple GPUs, so that only one or several layers of the model are places on a single gpu.
<ul>
<li>Each gpu processes in parallel different stages of the pipeline and working on a small chunk of the batch.</li>
</ul></li>
</ul></li>
<li><strong>Zero Redundancy Optimizer (ZeRO)</strong>:
<ul>
<li>Also performs sharding of the tensors somewhat similar to TP, except the whole tensor gets reconstructed in time for a forward or backward computation, therefore the model doesn’t need to be modified.</li>
<li>It also supports various offloading techniques to compensate for limited GPU memory.</li>
</ul></li>
<li><strong>Sharded DDP</strong>:
<ul>
<li>Another name for the foundational ZeRO concept as used by various other implementations of ZeRO.</li>
</ul></li>
</ul>
</section>
<section id="data-parallelism" class="level1" style="font-size: 0.9em;" data-background-color="white">
<h1 style="font-size: 0.9em;" data-background-color="white">Data Parallelism</h1>
<ul>
<li><strong>Data Parallelism</strong>:
<ul>
<li>The simplest and most common parallelism technique. Workers maintain <em>identical copies</em> of the <em>complete</em> model and work on a <em>subset of the data</em>.</li>
<li><code>DDP</code> supported in PyTorch native.</li>
</ul></li>
<li>ZeRO Data Parallel
<ul>
<li>ZeRO powered data parallelism is shown below<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></li>
</ul></li>
</ul>
<div style="text-align: center;">
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-zero.png" width="75%"></p>
</div>
</section>
<section id="tensor-parallelismefficient-large-scale" class="level1" data-background-color="white">
<h1 data-background-color="white">Tensor Parallelism<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></h1>
<ul>
<li><p>In <strong>Tensor Paralleism</strong> each GPU processes only a slice of a tensor and only aggregates the full tensor for operations that require the whole thing.</p>
<ul>
<li><p>The main building block of any transformer is a fully connected nn.Linear followed by a nonlinear activation GeLU.</p>
<ul>
<li><code>Y = GeLU(XA)</code>, where X and Y are the input and output vectors, and A is the weight matrix.</li>
</ul></li>
<li><p>If we look at the computation in matrix form, it’s easy to see how the matrix multiplication can be split between multiple GPUs:</p></li>
</ul></li>
</ul>
</section>
<section id="tensor-parallelism" class="level1" style="font-size: 0.9em;" data-background-color="white">
<h1 style="font-size: 0.9em;" data-background-color="white">Tensor Parallelism</h1>
<div style="text-align: center;">
<p><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-parallel_gemm.png" width="66%" style="text-align: center;"></p>
</div>
<div class="footer">
<p>This information is based on (the much more in-depth) <a href="https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530">TP Overview</a> by <a href="https://github.com/anton-l">@anton-l</a></p>
</div>
</section>
<section id="d-parallelism" class="level1" style="font-size:0.9em;" data-background-color="white">
<h1 style="font-size:0.9em;" data-background-color="white">3D Parallelism</h1>
<ul>
<li><code>DP</code> + <code>TP</code> + <code>PP</code> (3D) Parallelism</li>
</ul>
<div id="fig-3dparallel-1" class="quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center!important; width:90%;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3dparallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.microsoft.com/en-us/research/uploads/prod/2020/09/Blog_DeepSpeed3_Figure-1_highres-2048x1230.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;8: 3D Parallelism illustration. Figure from: https://www.deepspeed.ai/"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2020/09/Blog_DeepSpeed3_Figure-1_highres-2048x1230.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3dparallel-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: 3D Parallelism illustration. Figure from: <a href="https://www.deepspeed.ai/">https://www.deepspeed.ai/</a>
</figcaption>
</figure>
</div>
</section>
<section id="d-parallelism-1" class="level1" data-background-color="white">
<h1 data-background-color="white">3D Parallelism</h1>
<ul>
<li><code>DP</code> + <code>TP</code> + <code>PP</code> (3D) Parallelism</li>
</ul>
<div id="fig-3dparallel" class="quarto-float quarto-figure quarto-figure-center anchored" style="text-align:center!important;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-deepspeed-3d.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;9: Figure taken from 3D parallelism: Scaling to trillion-parameter models"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-deepspeed-3d.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3dparallel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Figure taken from <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/">3D parallelism: Scaling to trillion-parameter models</a>
</figcaption>
</figure>
</div>
</section>
<section id="ezpz" class="level1" data-background-color="white">
<h1 data-background-color="white">🍋 <a href="https://github.com/saforem2/ezpz"><code>ezpz</code></a></h1>
</section>
<section id="clone-repos" class="level1" data-background-color="white">
<h1 data-background-color="white">Clone Repo(s)</h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">#[⭐][07:33:08 AM][foremans@x3101c0s13b0n0][~/tmp]</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="ex">$</span> mkdir ~/tmp/polaris-talk</span>
<span id="cb9-3"><a href="#cb9-3"></a></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="co">#[⭐][07:33:21 AM][foremans@x3101c0s13b0n0][~/tmp]</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="ex">$</span> cd ~/tmp/polaris-talk</span>
<span id="cb9-6"><a href="#cb9-6"></a></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co">#[⭐][07:33:25 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk]</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="ex">$</span> NOW=<span class="va">$(</span><span class="ex">tstamp</span><span class="va">)</span> <span class="kw">&amp;&amp;</span> <span class="fu">mkdir</span> <span class="st">"</span><span class="va">${NOW}</span><span class="st">"</span> <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> <span class="st">"</span><span class="va">${NOW}</span><span class="st">"</span> <span class="co"># &amp;&amp; mkdir "core-dumps-${NOW}" &amp;&amp; mv -v **core\.** "core-dumps-${NOW}" &amp;&amp; mv "core-dumps-${NOW}" core-dumps</span></span>
<span id="cb9-9"><a href="#cb9-9"></a></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="co">#[⭐][07:33:27 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="ex">$</span> pwd</span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="ex">/home/foremans/tmp/polaris-talk/2024-07-17-073327</span></span>
<span id="cb9-13"><a href="#cb9-13"></a></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="co">#[⭐][07:33:31 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb9-15"><a href="#cb9-15"></a><span class="ex">$</span> git clone https://github.com/saforem2/ezpz ezpz <span class="kw">&amp;&amp;</span> <span class="fu">git</span> clone https://github.com/saforem2/wordplay wordplay</span>
<span id="cb9-16"><a href="#cb9-16"></a><span class="ex">Cloning</span> into <span class="st">'ezpz'</span>...</span>
<span id="cb9-17"><a href="#cb9-17"></a><span class="ex">remote:</span> Enumerating objects: 2134, done.<span class="kw">`</span></span>
<span id="cb9-18"><a href="#cb9-18"></a><span class="ex">remote:</span> Counting objects: 100% <span class="er">(</span><span class="ex">363/363</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb9-19"><a href="#cb9-19"></a><span class="ex">remote:</span> Compressing objects: 100% <span class="er">(</span><span class="ex">169/169</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb9-20"><a href="#cb9-20"></a><span class="ex">remote:</span> Total 2134 <span class="er">(</span><span class="ex">delta</span> 197<span class="kw">)</span><span class="ex">,</span> reused 265 <span class="er">(</span><span class="ex">delta</span> 141<span class="kw">)</span><span class="ex">,</span> pack-reused 1771</span>
<span id="cb9-21"><a href="#cb9-21"></a><span class="ex">Receiving</span> objects: 100% <span class="er">(</span><span class="ex">2134/2134</span><span class="kw">)</span><span class="ex">,</span> 4.27 MiB <span class="kw">|</span> <span class="ex">25.01</span> MiB/s, done.</span>
<span id="cb9-22"><a href="#cb9-22"></a><span class="ex">Resolving</span> deltas: 100% <span class="er">(</span><span class="ex">1117/1117</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb9-23"><a href="#cb9-23"></a><span class="ex">Cloning</span> into <span class="st">'wordplay'</span>...</span>
<span id="cb9-24"><a href="#cb9-24"></a><span class="ex">remote:</span> Enumerating objects: 869, done.</span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="ex">remote:</span> Counting objects: 100% <span class="er">(</span><span class="ex">72/72</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb9-26"><a href="#cb9-26"></a><span class="ex">remote:</span> Compressing objects: 100% <span class="er">(</span><span class="ex">37/37</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb9-27"><a href="#cb9-27"></a><span class="ex">remote:</span> Total 869 <span class="er">(</span><span class="ex">delta</span> 29<span class="kw">)</span><span class="ex">,</span> reused 56 <span class="er">(</span><span class="ex">delta</span> 23<span class="kw">)</span><span class="ex">,</span> pack-reused 797</span>
<span id="cb9-28"><a href="#cb9-28"></a><span class="ex">Receiving</span> objects: 100% <span class="er">(</span><span class="ex">869/869</span><span class="kw">)</span><span class="ex">,</span> 14.36 MiB <span class="kw">|</span> <span class="ex">46.54</span> MiB/s, done.</span>
<span id="cb9-29"><a href="#cb9-29"></a><span class="ex">Resolving</span> deltas: 100% <span class="er">(</span><span class="ex">395/395</span><span class="kw">)</span><span class="ex">,</span> done.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="setup-python" class="level1 scrollable" data-background-color="white">
<h1 class="scrollable" data-background-color="white">Setup Python</h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1"></a><span class="co">#[⭐][07:33:53 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="ex">$</span> source ezpz/src/ezpz/bin/utils.sh <span class="kw">&amp;&amp;</span> <span class="ex">ezpz_setup_python</span> <span class="kw">&amp;&amp;</span> <span class="ex">ezpz_setup_alcf</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="ex">Unable</span> to detect PBS or SLURM working directory info...</span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="ex">Using</span> /home/foremans/tmp/polaris-talk/2024-07-17-073327 as working directory...</span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="ex">Using</span> WORKING_DIR: /home/foremans/tmp/polaris-talk/2024-07-17-073327</span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="ex">No</span> conda_prefix OR virtual_env found in environment...</span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="ex">Setting</span> up conda...</span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="ex">Lmod</span> is automatically replacing <span class="st">"nvhpc/23.9"</span> with <span class="st">"gcc-native/12.3"</span>.</span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="ex">Lmod</span> is automatically replacing <span class="st">"PrgEnv-nvhpc/8.5.0"</span> with <span class="st">"PrgEnv-gnu/8.5.0"</span>.</span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="ex">Due</span> to MODULEPATH changes, the following have been reloaded:</span>
<span id="cb10-11"><a href="#cb10-11"></a>  <span class="ex">1</span><span class="er">)</span> <span class="ex">cray-mpich/8.1.28</span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="ex">Found</span> conda at: /soft/applications/conda/2024-04-29/mconda3</span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="ex">No</span> VIRTUAL_ENV found in environment!</span>
<span id="cb10-14"><a href="#cb10-14"></a>    <span class="ex">-</span> Trying to setup from /soft/applications/conda/2024-04-29/mconda3</span>
<span id="cb10-15"><a href="#cb10-15"></a>    <span class="ex">-</span> Using VENV_DIR=/home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb10-16"><a href="#cb10-16"></a>    <span class="ex">-</span> Creating a new virtual env on top of 2024-04-29 in /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb10-17"><a href="#cb10-17"></a><span class="ex">[python]</span> Using /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span>
<span id="cb10-18"><a href="#cb10-18"></a></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="ex">[ezpz/bin/utils.sh]</span></span>
<span id="cb10-20"><a href="#cb10-20"></a></span>
<span id="cb10-21"><a href="#cb10-21"></a><span class="ex">[2024-07-17-073407]</span></span>
<span id="cb10-22"><a href="#cb10-22"></a>    <span class="ex">•</span> USER=foremans</span>
<span id="cb10-23"><a href="#cb10-23"></a>    <span class="ex">•</span> MACHINE=polaris</span>
<span id="cb10-24"><a href="#cb10-24"></a>    <span class="ex">•</span> HOST=x3101c0s13b0n0</span>
<span id="cb10-25"><a href="#cb10-25"></a></span>
<span id="cb10-26"><a href="#cb10-26"></a><span class="ex">[ezpz_setup_host]</span></span>
<span id="cb10-27"><a href="#cb10-27"></a>    <span class="ex">•</span> Using hostfile: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb10-28"><a href="#cb10-28"></a>    <span class="ex">•</span> Found in environment:</span>
<span id="cb10-29"><a href="#cb10-29"></a>        <span class="ex">•</span> HOSTFILE: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb10-30"><a href="#cb10-30"></a>        <span class="ex">•</span> Writing PBS vars to: /home/foremans/.pbsenv</span>
<span id="cb10-31"><a href="#cb10-31"></a></span>
<span id="cb10-32"><a href="#cb10-32"></a><span class="ex">[ezpz_save_pbs_env]</span></span>
<span id="cb10-33"><a href="#cb10-33"></a>    <span class="ex">•</span> Setting:</span>
<span id="cb10-34"><a href="#cb10-34"></a>        <span class="ex">•</span> HOSTFILE: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb10-35"><a href="#cb10-35"></a>        <span class="ex">•</span> JOBENV_FILE: /home/foremans/.pbsenv</span>
<span id="cb10-36"><a href="#cb10-36"></a></span>
<span id="cb10-37"><a href="#cb10-37"></a><span class="ex">[HOSTS]</span></span>
<span id="cb10-38"><a href="#cb10-38"></a>    <span class="ex">•</span> <span class="pp">[</span><span class="ss">host:0</span><span class="pp">]</span> <span class="at">-</span> x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb10-39"><a href="#cb10-39"></a></span>
<span id="cb10-40"><a href="#cb10-40"></a><span class="ex">[DIST</span> INFO]</span>
<span id="cb10-41"><a href="#cb10-41"></a>    <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb10-42"><a href="#cb10-42"></a>    <span class="ex">•</span> NHOSTS=1</span>
<span id="cb10-43"><a href="#cb10-43"></a>    <span class="ex">•</span> NGPU_PER_HOST=4</span>
<span id="cb10-44"><a href="#cb10-44"></a>    <span class="ex">•</span> NGPUS=4</span>
<span id="cb10-45"><a href="#cb10-45"></a>    <span class="ex">•</span> DIST_LAUNCH=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb10-46"><a href="#cb10-46"></a></span>
<span id="cb10-47"><a href="#cb10-47"></a><span class="ex">[LAUNCH]:</span></span>
<span id="cb10-48"><a href="#cb10-48"></a>    <span class="ex">•</span> To launch across all available GPUs, use: launch</span>
<span id="cb10-49"><a href="#cb10-49"></a>      <span class="ex">launch</span> = mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="install-ezpz-wordplay" class="level1 scrollable" data-background-color="white">
<h1 class="scrollable" data-background-color="white">Install <code>{ezpz, wordplay}</code></h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">#[⭐][07:34:13 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">-e</span> ezpz wordplay <span class="at">--require-virtualenv</span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="ex">Looking</span> in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com</span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="ex">Obtaining</span> file:///home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz</span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="ex">Installing</span> build dependencies ... done</span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="ex">Checking</span> if build backend supports build_editable ... done</span>
<span id="cb11-7"><a href="#cb11-7"></a>  <span class="ex">Getting</span> requirements to build editable ... done</span>
<span id="cb11-8"><a href="#cb11-8"></a>  <span class="ex">Installing</span> backend dependencies ... done</span>
<span id="cb11-9"><a href="#cb11-9"></a>  <span class="ex">Preparing</span> editable metadata <span class="er">(</span><span class="ex">pyproject.toml</span><span class="kw">)</span> <span class="ex">...</span> done</span>
<span id="cb11-10"><a href="#cb11-10"></a></span>
<span id="cb11-11"><a href="#cb11-11"></a><span class="co"># ...[clipped]...</span></span>
<span id="cb11-12"><a href="#cb11-12"></a></span>
<span id="cb11-13"><a href="#cb11-13"></a><span class="ex">Successfully</span> built ezpz</span>
<span id="cb11-14"><a href="#cb11-14"></a><span class="ex">Installing</span> collected packages: enum34, wordplay, pyinstrument, ezpz</span>
<span id="cb11-15"><a href="#cb11-15"></a>  <span class="ex">Attempting</span> uninstall: ezpz</span>
<span id="cb11-16"><a href="#cb11-16"></a>    <span class="ex">Found</span> existing installation: ezpz 0.1</span>
<span id="cb11-17"><a href="#cb11-17"></a>    <span class="ex">Not</span> uninstalling ezpz at /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages, outside environment /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb11-18"><a href="#cb11-18"></a>    <span class="ex">Cant</span> uninstall <span class="st">'ezpz'</span>. No files were found to uninstall.</span>
<span id="cb11-19"><a href="#cb11-19"></a><span class="ex">Successfully</span> installed enum34-1.1.10 ezpz pyinstrument-4.6.2 wordplay-1.0.0a4</span>
<span id="cb11-20"><a href="#cb11-20"></a><span class="ex">[notice]</span> A new release of pip is available: 24.0 <span class="at">-</span><span class="op">&gt;</span> 24.1.2</span>
<span id="cb11-21"><a href="#cb11-21"></a><span class="ex">[notice]</span> To update, run: pip install <span class="at">--upgrade</span> pip</span>
<span id="cb11-22"><a href="#cb11-22"></a><span class="ex">9.62s</span> user 1.11s system 61% cpu 17.505s total</span>
<span id="cb11-23"><a href="#cb11-23"></a></span>
<span id="cb11-24"><a href="#cb11-24"></a><span class="co">#[⭐][07:34:53 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb11-25"><a href="#cb11-25"></a><span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">--upgrade</span> wandb</span>
<span id="cb11-26"><a href="#cb11-26"></a><span class="ex">Looking</span> in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com</span>
<span id="cb11-27"><a href="#cb11-27"></a><span class="ex">Requirement</span> already satisfied: wandb in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages <span class="er">(</span><span class="ex">0.16.6</span><span class="kw">)</span></span>
<span id="cb11-28"><a href="#cb11-28"></a><span class="ex">Collecting</span> wandb</span>
<span id="cb11-29"><a href="#cb11-29"></a>  <span class="ex">Downloading</span> wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata <span class="er">(</span><span class="ex">10</span> kB<span class="kw">)</span></span>
<span id="cb11-30"><a href="#cb11-30"></a><span class="ex">Downloading</span> wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl <span class="er">(</span><span class="ex">6.9</span> MB<span class="kw">)</span></span>
<span id="cb11-31"><a href="#cb11-31"></a>   <span class="ex">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 6.9/6.9 MB 2.1 MB/s eta 0:00:00</span>
<span id="cb11-32"><a href="#cb11-32"></a><span class="ex">Installing</span> collected packages: wandb</span>
<span id="cb11-33"><a href="#cb11-33"></a>  <span class="ex">Attempting</span> uninstall: wandb</span>
<span id="cb11-34"><a href="#cb11-34"></a>    <span class="ex">Found</span> existing installation: wandb 0.16.6</span>
<span id="cb11-35"><a href="#cb11-35"></a>    <span class="ex">Not</span> uninstalling wandb at /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages, outside environment /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb11-36"><a href="#cb11-36"></a>    <span class="ex">Cant</span> uninstall <span class="st">'wandb'</span>. No files were found to uninstall.</span>
<span id="cb11-37"><a href="#cb11-37"></a><span class="ex">Successfully</span> installed wandb-0.17.4</span>
<span id="cb11-38"><a href="#cb11-38"></a><span class="ex">[notice]</span> A new release of pip is available: 24.0 <span class="at">-</span><span class="op">&gt;</span> 24.1.2</span>
<span id="cb11-39"><a href="#cb11-39"></a><span class="ex">[notice]</span> To update, run: pip install <span class="at">--upgrade</span> pip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="launch-ezpz.test_dist" class="level1 scrollable" data-background-color="white">
<h1 class="scrollable" data-background-color="white">Launch <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py"><code>ezpz.test_dist</code></a></h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="co">#[⭐][07:34:07 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 7s]</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="ex">$</span> which launch</span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="ex">launch:</span> aliased to mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="co">#[⭐][07:34:11 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="ex">$</span> which python3</span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="ex">/home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span></span>
<span id="cb12-10"><a href="#cb12-10"></a></span>
<span id="cb12-11"><a href="#cb12-11"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb12-12"><a href="#cb12-12"></a><span class="co">#[⭐][07:35:21 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 14s]</span></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="ex">$</span> launch python3 <span class="at">-m</span> ezpz.test_dist <span class="kw">|</span> <span class="fu">tee</span> ezpz-test-dist-DDP.log</span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="ex">Connected</span> to tcp://x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov:7919</span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="ex">Found</span> executable /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span>
<span id="cb12-16"><a href="#cb12-16"></a><span class="ex">Launching</span> application cff755ee-557e-4df2-a987-db85a8b7dbe7</span>
<span id="cb12-17"><a href="#cb12-17"></a><span class="ex">[2024-07-17</span> 07:35:30.304306]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:156</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb12-18"><a href="#cb12-18"></a><span class="ex">[2024-07-17</span> 07:35:30.307036]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:157</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb12-19"><a href="#cb12-19"></a><span class="ex">[2024-07-17</span> 07:35:30.307494]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:160</span><span class="pp">]</span> <span class="at">-</span> To disable this behavior, and log from ALL ranks <span class="er">(</span><span class="ex">not</span> recommended<span class="kw">)</span><span class="ex">,</span> set: <span class="st">'export LOG_FROM_ALL_RANKS=1'</span>  in your environment, and re-run.</span>
<span id="cb12-20"><a href="#cb12-20"></a><span class="ex">[2024-07-17</span> 07:35:32.116037]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=2/3</span><span class="pp">][</span><span class="ss">local_rank=2/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb12-21"><a href="#cb12-21"></a><span class="ex">[2024-07-17</span> 07:35:32.116089]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=3/3</span><span class="pp">][</span><span class="ss">local_rank=3/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb12-22"><a href="#cb12-22"></a><span class="ex">[2024-07-17</span> 07:35:32.116940]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=1/3</span><span class="pp">][</span><span class="ss">local_rank=1/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb12-23"><a href="#cb12-23"></a><span class="ex">[2024-07-17</span> 07:35:32.122726]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb12-24"><a href="#cb12-24"></a><span class="ex">[dist_info]:</span></span>
<span id="cb12-25"><a href="#cb12-25"></a>  <span class="ex">•</span> DEVICE=cuda</span>
<span id="cb12-26"><a href="#cb12-26"></a>  <span class="ex">•</span> DEVICE_ID=cuda:0</span>
<span id="cb12-27"><a href="#cb12-27"></a>  <span class="ex">•</span> DISTRIBUTED_BACKEND=nccl</span>
<span id="cb12-28"><a href="#cb12-28"></a>  <span class="ex">•</span> GPUS_PER_NODE=4</span>
<span id="cb12-29"><a href="#cb12-29"></a>  <span class="ex">•</span> HOSTS=<span class="pp">[</span><span class="st">'x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov'</span><span class="pp">]</span></span>
<span id="cb12-30"><a href="#cb12-30"></a>  <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb12-31"><a href="#cb12-31"></a>  <span class="ex">•</span> HOSTNAME=x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb12-32"><a href="#cb12-32"></a>  <span class="ex">•</span> LOCAL_RANK=0</span>
<span id="cb12-33"><a href="#cb12-33"></a>  <span class="ex">•</span> MACHINE=Polaris</span>
<span id="cb12-34"><a href="#cb12-34"></a>  <span class="ex">•</span> NUM_NODES=1</span>
<span id="cb12-35"><a href="#cb12-35"></a>  <span class="ex">•</span> NGPUS=4</span>
<span id="cb12-36"><a href="#cb12-36"></a>  <span class="ex">•</span> NGPUS_AVAILABLE=4</span>
<span id="cb12-37"><a href="#cb12-37"></a>  <span class="ex">•</span> NODE_ID=0</span>
<span id="cb12-38"><a href="#cb12-38"></a>  <span class="ex">•</span> RANK=0</span>
<span id="cb12-39"><a href="#cb12-39"></a>  <span class="ex">•</span> SCHEDULER=PBS</span>
<span id="cb12-40"><a href="#cb12-40"></a>  <span class="ex">•</span> WORLD_SIZE_TOTAL=4</span>
<span id="cb12-41"><a href="#cb12-41"></a>  <span class="ex">•</span> WORLD_SIZE_IN_USE=4</span>
<span id="cb12-42"><a href="#cb12-42"></a>  <span class="ex">•</span> LAUNCH_CMD=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb12-43"><a href="#cb12-43"></a><span class="ex">[2024-07-17</span> 07:35:32.124800]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:725</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0/4</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'DDP'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb12-44"><a href="#cb12-44"></a><span class="ex">[2024-07-17</span> 07:35:32.129169]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=0/3</span><span class="pp">][</span><span class="ss">local_rank=0/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb12-45"><a href="#cb12-45"></a><span class="ex">[2024-07-17</span> 07:35:32.129674]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">dist:364</span><span class="pp">]</span> <span class="at">-</span> Using [4 / 4] available <span class="st">"cuda"</span> devices !!</span>
<span id="cb12-46"><a href="#cb12-46"></a><span class="ex">[2024-07-17</span> 07:35:32.130219]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:874</span><span class="pp">]</span> <span class="at">-</span> Setting up wandb from rank: 0</span>
<span id="cb12-47"><a href="#cb12-47"></a><span class="ex">[2024-07-17</span> 07:35:32.130638]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:875</span><span class="pp">]</span> <span class="at">-</span> Using: WB PROJECT: ezpz.test_dist</span>
<span id="cb12-48"><a href="#cb12-48"></a><span class="ex">wandb:</span> Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.</span>
<span id="cb12-49"><a href="#cb12-49"></a><span class="ex">wandb:</span> Currently logged in as: foremans <span class="er">(</span><span class="ex">aurora_gpt</span><span class="kw">)</span><span class="bu">.</span> Use <span class="kw">`</span><span class="ex">wandb</span> login <span class="at">--relogin</span><span class="kw">`</span> to force relogin</span>
<span id="cb12-50"><a href="#cb12-50"></a><span class="ex">wandb:</span> Tracking run with wandb version 0.17.4</span>
<span id="cb12-51"><a href="#cb12-51"></a><span class="ex">wandb:</span> Run data is saved locally in /home/foremans/tmp/polaris-talk/2024-07-17-073327/wandb/run-20240717_073532-p49rzxtv</span>
<span id="cb12-52"><a href="#cb12-52"></a><span class="ex">wandb:</span> Run <span class="kw">`</span><span class="ex">wandb</span> offline<span class="kw">`</span> to turn off syncing.</span>
<span id="cb12-53"><a href="#cb12-53"></a><span class="ex">wandb:</span> Syncing run vibrant-river-284</span>
<span id="cb12-54"><a href="#cb12-54"></a><span class="ex">wandb:</span> ⭐️ View project at https://wandb.ai/aurora_gpt/ezpz.test_dist</span>
<span id="cb12-55"><a href="#cb12-55"></a><span class="ex">wandb:</span> 🚀 View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span>
<span id="cb12-56"><a href="#cb12-56"></a><span class="ex">[2024-07-17</span> 07:35:33.171085]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:905</span><span class="pp">]</span> <span class="at">-</span> W<span class="kw">&amp;</span><span class="ex">B</span> RUN: <span class="pp">[</span><span class="ss">vibrant</span><span class="pp">-</span><span class="ss">river</span><span class="pp">-</span><span class="ss">284</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span><span class="kw">)</span></span>
<span id="cb12-57"><a href="#cb12-57"></a><span class="ex">[2024-07-17</span> 07:35:33.182307]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:312</span><span class="pp">]</span> <span class="at">-</span> Updating wandb.run: vibrant-river-284 config with <span class="st">"DIST_INFO"</span></span>
<span id="cb12-58"><a href="#cb12-58"></a><span class="ex">[2024-07-17</span> 07:35:33.186499]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:938</span><span class="pp">]</span> <span class="at">-</span> Running on machine=<span class="st">'Polaris'</span></span>
<span id="cb12-59"><a href="#cb12-59"></a><span class="ex">[2024-07-17</span> 07:35:33.187790]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb12-60"><a href="#cb12-60"></a><span class="ex">[timers_import]:</span></span>
<span id="cb12-61"><a href="#cb12-61"></a>  <span class="ex">•</span> os=1.082196831703186e-06</span>
<span id="cb12-62"><a href="#cb12-62"></a>  <span class="ex">•</span> logging=4.507601261138916e-07</span>
<span id="cb12-63"><a href="#cb12-63"></a>  <span class="ex">•</span> typing=2.9457733035087585e-06</span>
<span id="cb12-64"><a href="#cb12-64"></a>  <span class="ex">•</span> pathlib=1.3122335076332092e-06</span>
<span id="cb12-65"><a href="#cb12-65"></a>  <span class="ex">•</span> ezpz=6.109476089477539e-07</span>
<span id="cb12-66"><a href="#cb12-66"></a>  <span class="ex">•</span> torch=2.9457733035087585e-06</span>
<span id="cb12-67"><a href="#cb12-67"></a>  <span class="ex">•</span> torch_ddp=2.314336597919464e-06</span>
<span id="cb12-68"><a href="#cb12-68"></a>  <span class="ex">•</span> wandb=1.842435449361801e-05</span>
<span id="cb12-69"><a href="#cb12-69"></a>  <span class="ex">•</span> total=3.0086375772953033e-05</span>
<span id="cb12-70"><a href="#cb12-70"></a></span>
<span id="cb12-71"><a href="#cb12-71"></a><span class="ex">[2024-07-17</span> 07:35:33.188979]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb12-72"><a href="#cb12-72"></a></span>
<span id="cb12-73"><a href="#cb12-73"></a><span class="ex">[CONFIG]:</span></span>
<span id="cb12-74"><a href="#cb12-74"></a>  <span class="ex">•</span> warmup=0</span>
<span id="cb12-75"><a href="#cb12-75"></a>  <span class="ex">•</span> log_freq=1</span>
<span id="cb12-76"><a href="#cb12-76"></a>  <span class="ex">•</span> batch_size=64</span>
<span id="cb12-77"><a href="#cb12-77"></a>  <span class="ex">•</span> input_size=128</span>
<span id="cb12-78"><a href="#cb12-78"></a>  <span class="ex">•</span> output_size=128</span>
<span id="cb12-79"><a href="#cb12-79"></a>  <span class="ex">•</span> dtype=torch.float32</span>
<span id="cb12-80"><a href="#cb12-80"></a>  <span class="ex">•</span> device=cuda</span>
<span id="cb12-81"><a href="#cb12-81"></a>  <span class="ex">•</span> world_size=4</span>
<span id="cb12-82"><a href="#cb12-82"></a>  <span class="ex">•</span> train_iters=100</span>
<span id="cb12-83"><a href="#cb12-83"></a></span>
<span id="cb12-84"><a href="#cb12-84"></a><span class="ex">[2024-07-17</span> 07:35:34.761945]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:183</span><span class="pp">]</span> <span class="at">-</span> model=Network<span class="er">(</span></span>
<span id="cb12-85"><a href="#cb12-85"></a>  <span class="kw">(</span><span class="ex">layers</span><span class="kw">)</span><span class="bu">:</span> Sequential<span class="er">(</span></span>
<span id="cb12-86"><a href="#cb12-86"></a>    <span class="kw">(</span><span class="ex">0</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>128, <span class="va">out_features</span><span class="op">=</span>1024, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb12-87"><a href="#cb12-87"></a>    <span class="kw">(</span><span class="ex">1</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>1024, <span class="va">out_features</span><span class="op">=</span>512, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb12-88"><a href="#cb12-88"></a>    <span class="kw">(</span><span class="ex">2</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>512, <span class="va">out_features</span><span class="op">=</span>256, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb12-89"><a href="#cb12-89"></a>    <span class="kw">(</span><span class="ex">3</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>256, <span class="va">out_features</span><span class="op">=</span>128, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb12-90"><a href="#cb12-90"></a>    <span class="kw">(</span><span class="ex">4</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>128, <span class="va">out_features</span><span class="op">=</span>128, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb12-91"><a href="#cb12-91"></a>  <span class="kw">)</span></span>
<span id="cb12-92"><a href="#cb12-92"></a><span class="kw">)</span></span>
<span id="cb12-93"><a href="#cb12-93"></a><span class="ex">[2024-07-17</span> 07:35:36.943300]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=1, loss=2152.41, sps=1.697e+04, dt=0.00377066, dtf=0.001003, dtb=0.002768</span>
<span id="cb12-94"><a href="#cb12-94"></a><span class="ex">[2024-07-17</span> 07:35:36.948048]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=2, loss=1577.24, sps=3.611e+04, dt=0.00177221, dtf=0.0005256, dtb=0.001247</span>
<span id="cb12-95"><a href="#cb12-95"></a><span class="ex">[2024-07-17</span> 07:35:36.952085]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=3, loss=1201.25, sps=3.59e+04, dt=0.00178271, dtf=0.0004875, dtb=0.001295</span>
<span id="cb12-96"><a href="#cb12-96"></a><span class="ex">[2024-07-17</span> 07:35:36.956071]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=4, loss=1034.03, sps=3.704e+04, dt=0.0017279, dtf=0.0005082, dtb=0.00122</span>
<span id="cb12-97"><a href="#cb12-97"></a><span class="ex">[2024-07-17</span> 07:35:36.959944]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=5, loss=875.796, sps=3.825e+04, dt=0.00167313, dtf=0.0005121, dtb=0.001161</span>
<span id="cb12-98"><a href="#cb12-98"></a><span class="ex">[2024-07-17</span> 07:35:36.963806]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=6, loss=817.544, sps=3.804e+04, dt=0.00168248, dtf=0.0004651, dtb=0.001217</span>
<span id="cb12-99"><a href="#cb12-99"></a><span class="ex">[2024-07-17</span> 07:35:36.967806]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=7, loss=734.838, sps=3.536e+04, dt=0.0018099, dtf=0.0004969, dtb=0.001313</span>
<span id="cb12-100"><a href="#cb12-100"></a><span class="ex">[2024-07-17</span> 07:35:36.971741]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=8, loss=741.583, sps=3.682e+04, dt=0.00173809, dtf=0.0004537, dtb=0.001284</span>
<span id="cb12-101"><a href="#cb12-101"></a><span class="ex">[2024-07-17</span> 07:35:36.975672]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=9, loss=738.157, sps=3.717e+04, dt=0.0017217, dtf=0.0004635, dtb=0.001258</span>
<span id="cb12-102"><a href="#cb12-102"></a><span class="ex">[2024-07-17</span> 07:35:36.979537]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=10, loss=727.255, sps=3.857e+04, dt=0.00165911, dtf=0.0004897, dtb=0.001169</span>
<span id="cb12-103"><a href="#cb12-103"></a><span class="ex">[2024-07-17</span> 07:35:36.983367]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=11, loss=715.534, sps=3.979e+04, dt=0.00160845, dtf=0.0004246, dtb=0.001184</span>
<span id="cb12-104"><a href="#cb12-104"></a><span class="ex">[2024-07-17</span> 07:35:36.987262]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=12, loss=693.96, sps=3.791e+04, dt=0.00168827, dtf=0.0004543, dtb=0.001234</span>
<span id="cb12-105"><a href="#cb12-105"></a><span class="ex">[2024-07-17</span> 07:35:36.991156]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=13, loss=693.518, sps=3.815e+04, dt=0.00167748, dtf=0.0004182, dtb=0.001259</span>
<span id="cb12-106"><a href="#cb12-106"></a><span class="ex">[2024-07-17</span> 07:35:36.994942]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=14, loss=675.289, sps=4.003e+04, dt=0.00159879, dtf=0.0004048, dtb=0.001194</span>
<span id="cb12-107"><a href="#cb12-107"></a><span class="ex">[2024-07-17</span> 07:35:36.999681]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=15, loss=677.706, sps=4.062e+04, dt=0.0015755, dtf=0.0004248, dtb=0.001151</span>
<span id="cb12-108"><a href="#cb12-108"></a><span class="ex">[2024-07-17</span> 07:35:37.003599]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=16, loss=671.639, sps=3.754e+04, dt=0.00170499, dtf=0.000416, dtb=0.001289</span>
<span id="cb12-109"><a href="#cb12-109"></a><span class="ex">[2024-07-17</span> 07:35:37.007565]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=17, loss=652.219, sps=3.704e+04, dt=0.00172777, dtf=0.0004208, dtb=0.001307</span>
<span id="cb12-110"><a href="#cb12-110"></a><span class="ex">[2024-07-17</span> 07:35:37.011753]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=18, loss=633.308, sps=3.191e+04, dt=0.00200554, dtf=0.0004193, dtb=0.001586</span>
<span id="cb12-111"><a href="#cb12-111"></a><span class="ex">[2024-07-17</span> 07:35:37.015595]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=19, loss=635.459, sps=3.845e+04, dt=0.0016645, dtf=0.0004236, dtb=0.001241</span>
<span id="cb12-112"><a href="#cb12-112"></a><span class="ex">[2024-07-17</span> 07:35:37.019356]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=20, loss=626.979, sps=4.033e+04, dt=0.00158685, dtf=0.0004225, dtb=0.001164</span>
<span id="cb12-113"><a href="#cb12-113"></a><span class="ex">[2024-07-17</span> 07:35:37.023081]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=21, loss=612.352, sps=4.105e+04, dt=0.00155914, dtf=0.0004169, dtb=0.001142</span>
<span id="cb12-114"><a href="#cb12-114"></a><span class="ex">[2024-07-17</span> 07:35:37.026861]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=22, loss=609.89, sps=4.004e+04, dt=0.00159827, dtf=0.0004155, dtb=0.001183</span>
<span id="cb12-115"><a href="#cb12-115"></a><span class="ex">[2024-07-17</span> 07:35:37.030555]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=23, loss=602.673, sps=4.258e+04, dt=0.00150295, dtf=0.0004166, dtb=0.001086</span>
<span id="cb12-116"><a href="#cb12-116"></a><span class="ex">[2024-07-17</span> 07:35:37.034382]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=24, loss=613.106, sps=3.918e+04, dt=0.00163367, dtf=0.0004164, dtb=0.001217</span>
<span id="cb12-117"><a href="#cb12-117"></a><span class="ex">[2024-07-17</span> 07:35:37.038129]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=25, loss=644.755, sps=4.173e+04, dt=0.00153368, dtf=0.0004175, dtb=0.001116</span>
<span id="cb12-118"><a href="#cb12-118"></a><span class="ex">[2024-07-17</span> 07:35:37.041943]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=26, loss=789.106, sps=4.049e+04, dt=0.00158053, dtf=0.0004397, dtb=0.001141</span>
<span id="cb12-119"><a href="#cb12-119"></a><span class="ex">[2024-07-17</span> 07:35:37.045705]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=27, loss=691.36, sps=4.166e+04, dt=0.00153641, dtf=0.0004157, dtb=0.001121</span>
<span id="cb12-120"><a href="#cb12-120"></a><span class="ex">[2024-07-17</span> 07:35:37.049496]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=28, loss=657.228, sps=4.018e+04, dt=0.00159288, dtf=0.0004209, dtb=0.001172</span>
<span id="cb12-121"><a href="#cb12-121"></a><span class="ex">[2024-07-17</span> 07:35:37.053229]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=29, loss=633.212, sps=4.19e+04, dt=0.0015274, dtf=0.0004288, dtb=0.001099</span>
<span id="cb12-122"><a href="#cb12-122"></a><span class="ex">[2024-07-17</span> 07:35:37.057013]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=30, loss=640.29, sps=4.012e+04, dt=0.00159538, dtf=0.0004144, dtb=0.001181</span>
<span id="cb12-123"><a href="#cb12-123"></a><span class="ex">[2024-07-17</span> 07:35:37.060722]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=31, loss=604.287, sps=4.21e+04, dt=0.00152018, dtf=0.000398, dtb=0.001122</span>
<span id="cb12-124"><a href="#cb12-124"></a><span class="ex">[2024-07-17</span> 07:35:37.064489]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=32, loss=640.15, sps=4.079e+04, dt=0.00156912, dtf=0.0004007, dtb=0.001168</span>
<span id="cb12-125"><a href="#cb12-125"></a><span class="ex">[2024-07-17</span> 07:35:37.068206]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=33, loss=585.789, sps=4.238e+04, dt=0.00151007, dtf=0.0004199, dtb=0.00109</span>
<span id="cb12-126"><a href="#cb12-126"></a><span class="ex">[2024-07-17</span> 07:35:37.071974]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=34, loss=591.99, sps=4.053e+04, dt=0.00157917, dtf=0.000434, dtb=0.001145</span>
<span id="cb12-127"><a href="#cb12-127"></a><span class="ex">[2024-07-17</span> 07:35:37.075702]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=35, loss=618.223, sps=4.168e+04, dt=0.00153538, dtf=0.0004152, dtb=0.00112</span>
<span id="cb12-128"><a href="#cb12-128"></a><span class="ex">[2024-07-17</span> 07:35:37.079496]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=36, loss=572.365, sps=3.998e+04, dt=0.0016008, dtf=0.0004108, dtb=0.00119</span>
<span id="cb12-129"><a href="#cb12-129"></a><span class="ex">[2024-07-17</span> 07:35:37.083250]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=37, loss=573.749, sps=4.276e+04, dt=0.00149675, dtf=0.0004123, dtb=0.001084</span>
<span id="cb12-130"><a href="#cb12-130"></a><span class="ex">[2024-07-17</span> 07:35:37.086969]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=38, loss=580.662, sps=4.136e+04, dt=0.00154751, dtf=0.0004129, dtb=0.001135</span>
<span id="cb12-131"><a href="#cb12-131"></a><span class="ex">[2024-07-17</span> 07:35:37.090636]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=39, loss=568.836, sps=4.311e+04, dt=0.0014847, dtf=0.000409, dtb=0.001076</span>
<span id="cb12-132"><a href="#cb12-132"></a><span class="ex">[2024-07-17</span> 07:35:37.094396]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=40, loss=551.294, sps=4.145e+04, dt=0.00154388, dtf=0.0004118, dtb=0.001132</span>
<span id="cb12-133"><a href="#cb12-133"></a><span class="ex">[2024-07-17</span> 07:35:37.098103]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=41, loss=573.647, sps=4.352e+04, dt=0.00147048, dtf=0.0003977, dtb=0.001073</span>
<span id="cb12-134"><a href="#cb12-134"></a><span class="ex">[2024-07-17</span> 07:35:37.101867]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=42, loss=545.584, sps=4.257e+04, dt=0.00150354, dtf=0.000433, dtb=0.001071</span>
<span id="cb12-135"><a href="#cb12-135"></a><span class="ex">[2024-07-17</span> 07:35:37.105639]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=43, loss=544.877, sps=4.322e+04, dt=0.00148085, dtf=0.0004117, dtb=0.001069</span>
<span id="cb12-136"><a href="#cb12-136"></a><span class="ex">[2024-07-17</span> 07:35:37.109471]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=44, loss=559.886, sps=4.028e+04, dt=0.00158879, dtf=0.0004254, dtb=0.001163</span>
<span id="cb12-137"><a href="#cb12-137"></a><span class="ex">[2024-07-17</span> 07:35:37.113186]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=45, loss=534.895, sps=4.311e+04, dt=0.00148444, dtf=0.0004153, dtb=0.001069</span>
<span id="cb12-138"><a href="#cb12-138"></a><span class="ex">[2024-07-17</span> 07:35:37.116972]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=46, loss=536.457, sps=4.099e+04, dt=0.00156151, dtf=0.0004113, dtb=0.00115</span>
<span id="cb12-139"><a href="#cb12-139"></a><span class="ex">[2024-07-17</span> 07:35:37.120710]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=47, loss=548.508, sps=4.183e+04, dt=0.00152993, dtf=0.0004151, dtb=0.001115</span>
<span id="cb12-140"><a href="#cb12-140"></a><span class="ex">[2024-07-17</span> 07:35:37.124552]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=48, loss=532.186, sps=4.051e+04, dt=0.0015798, dtf=0.0004379, dtb=0.001142</span>
<span id="cb12-141"><a href="#cb12-141"></a><span class="ex">[2024-07-17</span> 07:35:37.128266]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=49, loss=519.254, sps=4.272e+04, dt=0.0014981, dtf=0.0004164, dtb=0.001082</span>
<span id="cb12-142"><a href="#cb12-142"></a><span class="ex">[2024-07-17</span> 07:35:37.131975]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=50, loss=535.535, sps=4.16e+04, dt=0.00153862, dtf=0.0004304, dtb=0.001108</span>
<span id="cb12-143"><a href="#cb12-143"></a><span class="ex">[2024-07-17</span> 07:35:37.135717]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=51, loss=520.722, sps=4.136e+04, dt=0.00154757, dtf=0.0004158, dtb=0.001132</span>
<span id="cb12-144"><a href="#cb12-144"></a><span class="ex">[2024-07-17</span> 07:35:37.139451]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=52, loss=513.063, sps=4.147e+04, dt=0.00154317, dtf=0.0004138, dtb=0.001129</span>
<span id="cb12-145"><a href="#cb12-145"></a><span class="ex">[2024-07-17</span> 07:35:37.143231]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=53, loss=514.546, sps=4.038e+04, dt=0.0015848, dtf=0.0004149, dtb=0.00117</span>
<span id="cb12-146"><a href="#cb12-146"></a><span class="ex">[2024-07-17</span> 07:35:37.146971]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=54, loss=506.488, sps=4.137e+04, dt=0.00154701, dtf=0.0004132, dtb=0.001134</span>
<span id="cb12-147"><a href="#cb12-147"></a><span class="ex">[2024-07-17</span> 07:35:37.150659]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=55, loss=503.01, sps=4.319e+04, dt=0.0014817, dtf=0.000415, dtb=0.001067</span>
<span id="cb12-148"><a href="#cb12-148"></a><span class="ex">[2024-07-17</span> 07:35:37.154441]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=56, loss=506.116, sps=4.06e+04, dt=0.00157637, dtf=0.0004211, dtb=0.001155</span>
<span id="cb12-149"><a href="#cb12-149"></a><span class="ex">[2024-07-17</span> 07:35:37.158180]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=57, loss=485.523, sps=4.287e+04, dt=0.00149301, dtf=0.000414, dtb=0.001079</span>
<span id="cb12-150"><a href="#cb12-150"></a><span class="ex">[2024-07-17</span> 07:35:37.161931]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=58, loss=489.076, sps=4.185e+04, dt=0.00152915, dtf=0.0004162, dtb=0.001113</span>
<span id="cb12-151"><a href="#cb12-151"></a><span class="ex">[2024-07-17</span> 07:35:37.165759]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=59, loss=484.844, sps=4.134e+04, dt=0.00154802, dtf=0.0004119, dtb=0.001136</span>
<span id="cb12-152"><a href="#cb12-152"></a><span class="ex">[2024-07-17</span> 07:35:37.169483]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=60, loss=496.104, sps=4.209e+04, dt=0.00152069, dtf=0.0003993, dtb=0.001121</span>
<span id="cb12-153"><a href="#cb12-153"></a><span class="ex">[2024-07-17</span> 07:35:37.173190]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=61, loss=467.599, sps=4.221e+04, dt=0.00151621, dtf=0.0004142, dtb=0.001102</span>
<span id="cb12-154"><a href="#cb12-154"></a><span class="ex">[2024-07-17</span> 07:35:37.176950]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=62, loss=480.055, sps=4.187e+04, dt=0.00152868, dtf=0.0004138, dtb=0.001115</span>
<span id="cb12-155"><a href="#cb12-155"></a><span class="ex">[2024-07-17</span> 07:35:37.181194]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=63, loss=483.146, sps=3.656e+04, dt=0.00175062, dtf=0.0006253, dtb=0.001125</span>
<span id="cb12-156"><a href="#cb12-156"></a><span class="ex">[2024-07-17</span> 07:35:37.185018]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=64, loss=479.273, sps=4.099e+04, dt=0.00156151, dtf=0.0004447, dtb=0.001117</span>
<span id="cb12-157"><a href="#cb12-157"></a><span class="ex">[2024-07-17</span> 07:35:37.188752]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=65, loss=464.753, sps=4.189e+04, dt=0.00152781, dtf=0.0004161, dtb=0.001112</span>
<span id="cb12-158"><a href="#cb12-158"></a><span class="ex">[2024-07-17</span> 07:35:37.192464]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=66, loss=462.583, sps=4.188e+04, dt=0.00152824, dtf=0.0004138, dtb=0.001114</span>
<span id="cb12-159"><a href="#cb12-159"></a><span class="ex">[2024-07-17</span> 07:35:37.196126]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=67, loss=461.665, sps=4.272e+04, dt=0.00149801, dtf=0.0004293, dtb=0.001069</span>
<span id="cb12-160"><a href="#cb12-160"></a><span class="ex">[2024-07-17</span> 07:35:37.199838]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=68, loss=465.25, sps=4.118e+04, dt=0.00155412, dtf=0.0004298, dtb=0.001124</span>
<span id="cb12-161"><a href="#cb12-161"></a><span class="ex">[2024-07-17</span> 07:35:37.203602]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=69, loss=460.897, sps=4.01e+04, dt=0.00159593, dtf=0.0004131, dtb=0.001183</span>
<span id="cb12-162"><a href="#cb12-162"></a><span class="ex">[2024-07-17</span> 07:35:37.207372]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=70, loss=456.136, sps=4.106e+04, dt=0.00155887, dtf=0.00041, dtb=0.001149</span>
<span id="cb12-163"><a href="#cb12-163"></a><span class="ex">[2024-07-17</span> 07:35:37.211089]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=71, loss=447.565, sps=4.158e+04, dt=0.00153923, dtf=0.0004113, dtb=0.001128</span>
<span id="cb12-164"><a href="#cb12-164"></a><span class="ex">[2024-07-17</span> 07:35:37.214861]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=72, loss=444.733, sps=4.05e+04, dt=0.00158026, dtf=0.0004127, dtb=0.001168</span>
<span id="cb12-165"><a href="#cb12-165"></a><span class="ex">[2024-07-17</span> 07:35:37.218601]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=73, loss=459.152, sps=4.123e+04, dt=0.00155234, dtf=0.0004201, dtb=0.001132</span>
<span id="cb12-166"><a href="#cb12-166"></a><span class="ex">[2024-07-17</span> 07:35:37.222334]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=74, loss=444.6, sps=4.226e+04, dt=0.00151444, dtf=0.0004371, dtb=0.001077</span>
<span id="cb12-167"><a href="#cb12-167"></a><span class="ex">[2024-07-17</span> 07:35:37.226042]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=75, loss=439.884, sps=4.29e+04, dt=0.001492, dtf=0.0004154, dtb=0.001077</span>
<span id="cb12-168"><a href="#cb12-168"></a><span class="ex">[2024-07-17</span> 07:35:37.229838]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=76, loss=438.578, sps=4.086e+04, dt=0.00156632, dtf=0.0004418, dtb=0.001125</span>
<span id="cb12-169"><a href="#cb12-169"></a><span class="ex">[2024-07-17</span> 07:35:37.233560]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=77, loss=431.993, sps=4.327e+04, dt=0.00147909, dtf=0.0004096, dtb=0.00107</span>
<span id="cb12-170"><a href="#cb12-170"></a><span class="ex">[2024-07-17</span> 07:35:37.237367]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=78, loss=422.338, sps=4.057e+04, dt=0.00157754, dtf=0.0004468, dtb=0.001131</span>
<span id="cb12-171"><a href="#cb12-171"></a><span class="ex">[2024-07-17</span> 07:35:37.241117]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=79, loss=427.973, sps=4.288e+04, dt=0.00149254, dtf=0.000415, dtb=0.001077</span>
<span id="cb12-172"><a href="#cb12-172"></a><span class="ex">[2024-07-17</span> 07:35:37.244895]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=80, loss=418.703, sps=4.06e+04, dt=0.00157617, dtf=0.0004137, dtb=0.001162</span>
<span id="cb12-173"><a href="#cb12-173"></a><span class="ex">[2024-07-17</span> 07:35:37.248740]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=81, loss=427.645, sps=4.031e+04, dt=0.00158766, dtf=0.000415, dtb=0.001173</span>
<span id="cb12-174"><a href="#cb12-174"></a><span class="ex">[2024-07-17</span> 07:35:37.252447]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=82, loss=417.629, sps=4.227e+04, dt=0.00151406, dtf=0.0004149, dtb=0.001099</span>
<span id="cb12-175"><a href="#cb12-175"></a><span class="ex">[2024-07-17</span> 07:35:37.256190]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=83, loss=411.667, sps=4.189e+04, dt=0.00152778, dtf=0.0004357, dtb=0.001092</span>
<span id="cb12-176"><a href="#cb12-176"></a><span class="ex">[2024-07-17</span> 07:35:37.259935]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=84, loss=409.366, sps=4.144e+04, dt=0.0015445, dtf=0.0004575, dtb=0.001087</span>
<span id="cb12-177"><a href="#cb12-177"></a><span class="ex">[2024-07-17</span> 07:35:37.263677]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=85, loss=409.511, sps=4.232e+04, dt=0.00151228, dtf=0.0004035, dtb=0.001109</span>
<span id="cb12-178"><a href="#cb12-178"></a><span class="ex">[2024-07-17</span> 07:35:37.267463]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=86, loss=409.593, sps=4.101e+04, dt=0.00156049, dtf=0.0004028, dtb=0.001158</span>
<span id="cb12-179"><a href="#cb12-179"></a><span class="ex">[2024-07-17</span> 07:35:37.271174]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=87, loss=408.794, sps=4.3e+04, dt=0.00148828, dtf=0.0004006, dtb=0.001088</span>
<span id="cb12-180"><a href="#cb12-180"></a><span class="ex">[2024-07-17</span> 07:35:37.274926]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=88, loss=403.151, sps=4.091e+04, dt=0.00156441, dtf=0.000415, dtb=0.001149</span>
<span id="cb12-181"><a href="#cb12-181"></a><span class="ex">[2024-07-17</span> 07:35:37.278633]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=89, loss=402.182, sps=4.26e+04, dt=0.00150243, dtf=0.0004147, dtb=0.001088</span>
<span id="cb12-182"><a href="#cb12-182"></a><span class="ex">[2024-07-17</span> 07:35:37.282372]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=90, loss=387.829, sps=4.216e+04, dt=0.00151793, dtf=0.0004411, dtb=0.001077</span>
<span id="cb12-183"><a href="#cb12-183"></a><span class="ex">[2024-07-17</span> 07:35:37.286102]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=91, loss=393.108, sps=4.308e+04, dt=0.00148558, dtf=0.0004167, dtb=0.001069</span>
<span id="cb12-184"><a href="#cb12-184"></a><span class="ex">[2024-07-17</span> 07:35:37.289904]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=92, loss=389.039, sps=4.103e+04, dt=0.00155996, dtf=0.0004359, dtb=0.001124</span>
<span id="cb12-185"><a href="#cb12-185"></a><span class="ex">[2024-07-17</span> 07:35:37.293618]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=93, loss=383.54, sps=4.322e+04, dt=0.00148092, dtf=0.0004147, dtb=0.001066</span>
<span id="cb12-186"><a href="#cb12-186"></a><span class="ex">[2024-07-17</span> 07:35:37.297401]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=94, loss=384.459, sps=4.1e+04, dt=0.00156106, dtf=0.0004164, dtb=0.001145</span>
<span id="cb12-187"><a href="#cb12-187"></a><span class="ex">[2024-07-17</span> 07:35:37.301172]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=95, loss=376.397, sps=4.191e+04, dt=0.0015272, dtf=0.0004129, dtb=0.001114</span>
<span id="cb12-188"><a href="#cb12-188"></a><span class="ex">[2024-07-17</span> 07:35:37.304924]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=96, loss=389.544, sps=4.091e+04, dt=0.00156433, dtf=0.0004139, dtb=0.00115</span>
<span id="cb12-189"><a href="#cb12-189"></a><span class="ex">[2024-07-17</span> 07:35:37.308641]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=97, loss=365.041, sps=4.343e+04, dt=0.00147362, dtf=0.0004165, dtb=0.001057</span>
<span id="cb12-190"><a href="#cb12-190"></a><span class="ex">[2024-07-17</span> 07:35:37.312398]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=98, loss=358.427, sps=4.134e+04, dt=0.00154796, dtf=0.0004143, dtb=0.001134</span>
<span id="cb12-191"><a href="#cb12-191"></a><span class="ex">[2024-07-17</span> 07:35:37.561881]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=99, loss=375.596, sps=258.9, dt=0.247161, dtf=0.1969, dtb=0.05026</span>
<span id="cb12-192"><a href="#cb12-192"></a></span>
<span id="cb12-193"><a href="#cb12-193"></a>                            <span class="ex">train/dt</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-194"><a href="#cb12-194"></a>     <span class="ex">┌─────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-195"><a href="#cb12-195"></a><span class="ex">0.247┤</span>                                                                        ▝│</span>
<span id="cb12-196"><a href="#cb12-196"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-197"><a href="#cb12-197"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-198"><a href="#cb12-198"></a><span class="ex">0.206┤</span>                                                                         │</span>
<span id="cb12-199"><a href="#cb12-199"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-200"><a href="#cb12-200"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-201"><a href="#cb12-201"></a><span class="ex">0.165┤</span>                                                                         │</span>
<span id="cb12-202"><a href="#cb12-202"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-203"><a href="#cb12-203"></a><span class="ex">0.124┤</span>                                                                         │</span>
<span id="cb12-204"><a href="#cb12-204"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-205"><a href="#cb12-205"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-206"><a href="#cb12-206"></a><span class="ex">0.083┤</span>                                                                         │</span>
<span id="cb12-207"><a href="#cb12-207"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-208"><a href="#cb12-208"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-209"><a href="#cb12-209"></a><span class="ex">0.042┤</span>                                                                         │</span>
<span id="cb12-210"><a href="#cb12-210"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-211"><a href="#cb12-211"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-212"><a href="#cb12-212"></a><span class="ex">0.001┤▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb12-213"><a href="#cb12-213"></a>     <span class="ex">└┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb12-214"><a href="#cb12-214"></a>     <span class="ex">1.0</span>              25.5              50.0              74.5             99.0</span>
<span id="cb12-215"><a href="#cb12-215"></a><span class="ex">train/dt</span>                                iter</span>
<span id="cb12-216"><a href="#cb12-216"></a><span class="ex">[2024-07-17</span> 07:35:37.589287]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dt.txt</span>
<span id="cb12-217"><a href="#cb12-217"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dt.txt</span>
<span id="cb12-218"><a href="#cb12-218"></a>                            <span class="ex">train/dtf</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-219"><a href="#cb12-219"></a>     <span class="ex">┌─────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-220"><a href="#cb12-220"></a><span class="ex">0.197┤</span>                                                                        ▝│</span>
<span id="cb12-221"><a href="#cb12-221"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-222"><a href="#cb12-222"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-223"><a href="#cb12-223"></a><span class="ex">0.164┤</span>                                                                         │</span>
<span id="cb12-224"><a href="#cb12-224"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-225"><a href="#cb12-225"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-226"><a href="#cb12-226"></a><span class="ex">0.131┤</span>                                                                         │</span>
<span id="cb12-227"><a href="#cb12-227"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-228"><a href="#cb12-228"></a><span class="ex">0.099┤</span>                                                                         │</span>
<span id="cb12-229"><a href="#cb12-229"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-230"><a href="#cb12-230"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-231"><a href="#cb12-231"></a><span class="ex">0.066┤</span>                                                                         │</span>
<span id="cb12-232"><a href="#cb12-232"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-233"><a href="#cb12-233"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-234"><a href="#cb12-234"></a><span class="ex">0.033┤</span>                                                                         │</span>
<span id="cb12-235"><a href="#cb12-235"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-236"><a href="#cb12-236"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb12-237"><a href="#cb12-237"></a><span class="ex">0.000┤▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb12-238"><a href="#cb12-238"></a>     <span class="ex">└┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb12-239"><a href="#cb12-239"></a>     <span class="ex">1.0</span>              25.5              50.0              74.5             99.0</span>
<span id="cb12-240"><a href="#cb12-240"></a><span class="ex">train/dtf</span>                               iter</span>
<span id="cb12-241"><a href="#cb12-241"></a><span class="ex">[2024-07-17</span> 07:35:37.603242]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtf.txt</span>
<span id="cb12-242"><a href="#cb12-242"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtf.txt</span>
<span id="cb12-243"><a href="#cb12-243"></a>                             <span class="ex">train/dtb</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-244"><a href="#cb12-244"></a>      <span class="ex">┌────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-245"><a href="#cb12-245"></a><span class="ex">0.0503┤</span>                                                                       ▝│</span>
<span id="cb12-246"><a href="#cb12-246"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-247"><a href="#cb12-247"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-248"><a href="#cb12-248"></a><span class="ex">0.0421┤</span>                                                                        │</span>
<span id="cb12-249"><a href="#cb12-249"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-250"><a href="#cb12-250"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-251"><a href="#cb12-251"></a><span class="ex">0.0339┤</span>                                                                        │</span>
<span id="cb12-252"><a href="#cb12-252"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-253"><a href="#cb12-253"></a><span class="ex">0.0257┤</span>                                                                        │</span>
<span id="cb12-254"><a href="#cb12-254"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-255"><a href="#cb12-255"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-256"><a href="#cb12-256"></a><span class="ex">0.0175┤</span>                                                                        │</span>
<span id="cb12-257"><a href="#cb12-257"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-258"><a href="#cb12-258"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-259"><a href="#cb12-259"></a><span class="ex">0.0093┤</span>                                                                        │</span>
<span id="cb12-260"><a href="#cb12-260"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-261"><a href="#cb12-261"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-262"><a href="#cb12-262"></a><span class="ex">0.0011┤▚▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb12-263"><a href="#cb12-263"></a>      <span class="ex">└┬─────────────────┬─────────────────┬────────────────┬─────────────────┬┘</span></span>
<span id="cb12-264"><a href="#cb12-264"></a>      <span class="ex">1.0</span>              25.5              50.0             74.5             99.0</span>
<span id="cb12-265"><a href="#cb12-265"></a><span class="ex">train/dtb</span>                                iter</span>
<span id="cb12-266"><a href="#cb12-266"></a><span class="ex">[2024-07-17</span> 07:35:37.615896]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtb.txt</span>
<span id="cb12-267"><a href="#cb12-267"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtb.txt</span>
<span id="cb12-268"><a href="#cb12-268"></a>                            <span class="ex">train/loss</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-269"><a href="#cb12-269"></a>      <span class="ex">┌────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-270"><a href="#cb12-270"></a><span class="ex">2152.4┤▘</span>                                                                       │</span>
<span id="cb12-271"><a href="#cb12-271"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-272"><a href="#cb12-272"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-273"><a href="#cb12-273"></a><span class="ex">1853.4┤</span>                                                                        │</span>
<span id="cb12-274"><a href="#cb12-274"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-275"><a href="#cb12-275"></a>      <span class="ex">│▗</span>                                                                       │</span>
<span id="cb12-276"><a href="#cb12-276"></a><span class="ex">1554.4┤</span>                                                                        │</span>
<span id="cb12-277"><a href="#cb12-277"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-278"><a href="#cb12-278"></a><span class="ex">1255.4┤</span>                                                                        │</span>
<span id="cb12-279"><a href="#cb12-279"></a>      <span class="ex">│</span> ▗                                                                      │</span>
<span id="cb12-280"><a href="#cb12-280"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb12-281"><a href="#cb12-281"></a> <span class="ex">956.4┤</span>  ▘                                                                     │</span>
<span id="cb12-282"><a href="#cb12-282"></a>      <span class="ex">│</span>   ▖                                                                    │</span>
<span id="cb12-283"><a href="#cb12-283"></a>      <span class="ex">│</span>   ▝              ▖                                                     │</span>
<span id="cb12-284"><a href="#cb12-284"></a> <span class="ex">657.4┤</span>    ▝▘▀▝▘▚▖▄     ▗ ▄                                                    │</span>
<span id="cb12-285"><a href="#cb12-285"></a>      <span class="ex">│</span>            ▝▘▀▝▘▘  ▝▘▀▗▘▚▗▄▗▖▄▗ ▗                                      │</span>
<span id="cb12-286"><a href="#cb12-286"></a>      <span class="ex">│</span>                                ▘▘▝▘▀▘▀▝▘▞▗▘▄▖▄▗▖▄▗▖▄▗▄                 │</span>
<span id="cb12-287"><a href="#cb12-287"></a> <span class="ex">358.4┤</span>                                                       ▝▘▀▝▘▀▝▀▝▘▀▝▖▚▝▖▄│</span>
<span id="cb12-288"><a href="#cb12-288"></a>      <span class="ex">└┬─────────────────┬─────────────────┬────────────────┬─────────────────┬┘</span></span>
<span id="cb12-289"><a href="#cb12-289"></a>      <span class="ex">1.0</span>              25.5              50.0             74.5             99.0</span>
<span id="cb12-290"><a href="#cb12-290"></a><span class="ex">train/loss</span>                               iter</span>
<span id="cb12-291"><a href="#cb12-291"></a><span class="ex">[2024-07-17</span> 07:35:37.655339]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/loss.txt</span>
<span id="cb12-292"><a href="#cb12-292"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/loss.txt</span>
<span id="cb12-293"><a href="#cb12-293"></a>                           <span class="ex">train/iter</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-294"><a href="#cb12-294"></a>    <span class="ex">┌──────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-295"><a href="#cb12-295"></a><span class="ex">99.0┤</span>                                                                      ▗▗▖▀│</span>
<span id="cb12-296"><a href="#cb12-296"></a>    <span class="ex">│</span>                                                                   ▄▝▘▘   │</span>
<span id="cb12-297"><a href="#cb12-297"></a>    <span class="ex">│</span>                                                              ▗▖▞▝▘       │</span>
<span id="cb12-298"><a href="#cb12-298"></a><span class="ex">82.7┤</span>                                                          ▄▗▘▀            │</span>
<span id="cb12-299"><a href="#cb12-299"></a>    <span class="ex">│</span>                                                      ▖▄▝▘                │</span>
<span id="cb12-300"><a href="#cb12-300"></a>    <span class="ex">│</span>                                                 ▗▗▖▀▝                    │</span>
<span id="cb12-301"><a href="#cb12-301"></a><span class="ex">66.3┤</span>                                              ▄▝▘▘                        │</span>
<span id="cb12-302"><a href="#cb12-302"></a>    <span class="ex">│</span>                                         ▗▖▞▝▘                            │</span>
<span id="cb12-303"><a href="#cb12-303"></a><span class="ex">50.0┤</span>                                     ▄▗▘▀                                 │</span>
<span id="cb12-304"><a href="#cb12-304"></a>    <span class="ex">│</span>                                 ▖▄▝▘                                     │</span>
<span id="cb12-305"><a href="#cb12-305"></a>    <span class="ex">│</span>                            ▗▗▖▀▝                                         │</span>
<span id="cb12-306"><a href="#cb12-306"></a><span class="ex">33.7┤</span>                         ▄▝▘▘                                             │</span>
<span id="cb12-307"><a href="#cb12-307"></a>    <span class="ex">│</span>                    ▗▖▞▝▘                                                 │</span>
<span id="cb12-308"><a href="#cb12-308"></a>    <span class="ex">│</span>                ▄▗▘▀                                                      │</span>
<span id="cb12-309"><a href="#cb12-309"></a><span class="ex">17.3┤</span>            ▖▄▝▘                                                          │</span>
<span id="cb12-310"><a href="#cb12-310"></a>    <span class="ex">│</span>       ▗▗▖▀▝                                                              │</span>
<span id="cb12-311"><a href="#cb12-311"></a>    <span class="ex">│</span>    ▄▝▘▘                                                                  │</span>
<span id="cb12-312"><a href="#cb12-312"></a> <span class="ex">1.0┤▖▞▝▘</span>                                                                      │</span>
<span id="cb12-313"><a href="#cb12-313"></a>    <span class="ex">└┬─────────────────┬──────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb12-314"><a href="#cb12-314"></a>    <span class="ex">1.0</span>              25.5               50.0              74.5             99.0</span>
<span id="cb12-315"><a href="#cb12-315"></a><span class="ex">train/iter</span>                              iter</span>
<span id="cb12-316"><a href="#cb12-316"></a><span class="ex">[2024-07-17</span> 07:35:37.669214]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/iter.txt</span>
<span id="cb12-317"><a href="#cb12-317"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/iter.txt</span>
<span id="cb12-318"><a href="#cb12-318"></a>                             <span class="ex">train/sps</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb12-319"><a href="#cb12-319"></a>       <span class="ex">┌───────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb12-320"><a href="#cb12-320"></a><span class="ex">43523.3┤</span>                ▖▗  ▖▗ ▖▗ ▖▝ ▚▘▝ ▖▗    ▘▗▖▗▖▖ ▖▄    ▗▖▝ ▖ ▗▖▗ ▘▗▞ ▘▗ ▘ │</span>
<span id="cb12-321"><a href="#cb12-321"></a>       <span class="ex">│</span>       ▖ ▗▘  ▗▝▖  ▀▗ ▖▝▝ ▖▝ ▘  ▖▝ ▘▝▀▗▘▝ ▝   ▝  ▘▞▝▘▘ ▘▝ ▚ ▝ ▘▝  ▝ ▘▝ ▘│</span>
<span id="cb12-322"><a href="#cb12-322"></a>       <span class="ex">│</span>  ▖▀ ▖▞ ▞  ▄ ▘  ▝                                                      │</span>
<span id="cb12-323"><a href="#cb12-323"></a><span class="ex">36312.5┤▝▝</span>  ▗                                       ▝                          │</span>
<span id="cb12-324"><a href="#cb12-324"></a>       <span class="ex">│</span>            ▖                                                          │</span>
<span id="cb12-325"><a href="#cb12-325"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-326"><a href="#cb12-326"></a><span class="ex">29101.8┤</span>                                                                       │</span>
<span id="cb12-327"><a href="#cb12-327"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-328"><a href="#cb12-328"></a><span class="ex">21891.1┤</span>                                                                       │</span>
<span id="cb12-329"><a href="#cb12-329"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-330"><a href="#cb12-330"></a>       <span class="ex">│▖</span>                                                                      │</span>
<span id="cb12-331"><a href="#cb12-331"></a><span class="ex">14680.4┤</span>                                                                       │</span>
<span id="cb12-332"><a href="#cb12-332"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-333"><a href="#cb12-333"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-334"><a href="#cb12-334"></a> <span class="ex">7469.7┤</span>                                                                       │</span>
<span id="cb12-335"><a href="#cb12-335"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-336"><a href="#cb12-336"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb12-337"><a href="#cb12-337"></a>  <span class="ex">258.9┤</span>                                                                      ▗│</span>
<span id="cb12-338"><a href="#cb12-338"></a>       <span class="ex">└┬─────────────────┬────────────────┬─────────────────┬────────────────┬┘</span></span>
<span id="cb12-339"><a href="#cb12-339"></a>       <span class="ex">1.0</span>              25.5             50.0              74.5            99.0</span>
<span id="cb12-340"><a href="#cb12-340"></a><span class="ex">train/sps</span>                                iter</span>
<span id="cb12-341"><a href="#cb12-341"></a><span class="ex">[2024-07-17</span> 07:35:37.681268]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/sps.txt</span>
<span id="cb12-342"><a href="#cb12-342"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/sps.txt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="pyinstrument-profile" class="level1" data-background-color="white">
<h1 data-background-color="white">PyInstrument Profile</h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1"></a><span class="ex">Recorded:</span> 07:35:34  Samples:  2227</span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="ex">Duration:</span> 2.948     CPU time: 5.441</span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="ex">PyInstrument:</span> v4.6.2</span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="ex">Program:</span> /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz/src/ezpz/test_dist.py</span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="ex">2.948</span> <span class="op">&lt;</span>module<span class="op">&gt;</span>  ezpz/test_dist.py:1</span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="ex">└─</span> 2.946 main  ezpz/test_dist.py:217</span>
<span id="cb13-7"><a href="#cb13-7"></a>   <span class="ex">├─</span> 2.043 build_model_and_optimizer  ezpz/test_dist.py:171</span>
<span id="cb13-8"><a href="#cb13-8"></a>   <span class="ex">│</span>  └─ 2.011 Adam.__init__  torch/optim/adam.py:15</span>
<span id="cb13-9"><a href="#cb13-9"></a>   <span class="ex">│</span>        [129 frames hidden]  torch, wandb, transformers, jax, func...</span>
<span id="cb13-10"><a href="#cb13-10"></a>   <span class="ex">├─</span> 0.326 _forward_step  ezpz/test_dist.py:231</span>
<span id="cb13-11"><a href="#cb13-11"></a>   <span class="ex">│</span>  ├─ 0.279 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528</span>
<span id="cb13-12"><a href="#cb13-12"></a>   <span class="ex">│</span>  │     [13 frames hidden]  torch, wandb, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb13-13"><a href="#cb13-13"></a>   <span class="ex">│</span>  │        0.273 Network._call_impl  torch/nn/modules/module.py:1534</span>
<span id="cb13-14"><a href="#cb13-14"></a>   <span class="ex">│</span>  │        └─ 0.076 Network.forward  ezpz/test_dist.py:164</span>
<span id="cb13-15"><a href="#cb13-15"></a>   <span class="ex">│</span>  │           └─ 0.076 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528</span>
<span id="cb13-16"><a href="#cb13-16"></a>   <span class="ex">│</span>  │                 [7 frames hidden]  torch, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb13-17"><a href="#cb13-17"></a>   <span class="ex">│</span>  └─ 0.046 calc_loss  ezpz/test_dist.py:168</span>
<span id="cb13-18"><a href="#cb13-18"></a>   <span class="ex">├─</span> 0.254 _backward_step  ezpz/test_dist.py:236</span>
<span id="cb13-19"><a href="#cb13-19"></a>   <span class="ex">│</span>  ├─ 0.177 Tensor.backward  torch/_tensor.py:466</span>
<span id="cb13-20"><a href="#cb13-20"></a>   <span class="ex">│</span>  │     [4 frames hidden]  torch, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb13-21"><a href="#cb13-21"></a>   <span class="ex">│</span>  └─ 0.077 wrapper  torch/optim/optimizer.py:374</span>
<span id="cb13-22"><a href="#cb13-22"></a>   <span class="ex">│</span>        [5 frames hidden]  torch</span>
<span id="cb13-23"><a href="#cb13-23"></a>   <span class="ex">├─</span> 0.119 tplot_dict  ezpz/plot.py:136</span>
<span id="cb13-24"><a href="#cb13-24"></a>   <span class="ex">│</span>  └─ 0.069 show  plotext/_core.py:292</span>
<span id="cb13-25"><a href="#cb13-25"></a>   <span class="ex">│</span>        [5 frames hidden]  plotext</span>
<span id="cb13-26"><a href="#cb13-26"></a>   <span class="ex">├─</span> 0.102 Logger.info  logging/__init__.py:1479</span>
<span id="cb13-27"><a href="#cb13-27"></a>   <span class="ex">│</span>     [6 frames hidden]  logging, rich</span>
<span id="cb13-28"><a href="#cb13-28"></a>   <span class="ex">│</span>        0.102 RichHandler.emit  rich/logging.py:126</span>
<span id="cb13-29"><a href="#cb13-29"></a>   <span class="ex">│</span>        └─ 0.100 Console.print  ezpz/log/console.py:79</span>
<span id="cb13-30"><a href="#cb13-30"></a>   <span class="ex">│</span>           └─ 0.100 Console.print  rich/console.py:1624</span>
<span id="cb13-31"><a href="#cb13-31"></a>   <span class="ex">│</span>                 [5 frames hidden]  rich</span>
<span id="cb13-32"><a href="#cb13-32"></a>   <span class="ex">└─</span> 0.099 Run.wrapper  wandb/sdk/wandb_run.py:418</span>
<span id="cb13-33"><a href="#cb13-33"></a>         <span class="ex">[13</span> frames hidden]  wandb, json</span>
<span id="cb13-34"><a href="#cb13-34"></a><span class="ex">[2024-07-17</span> 07:35:37.876629]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:115</span><span class="pp">]</span> <span class="at">-</span> Saving pyinstrument profile output to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles</span>
<span id="cb13-35"><a href="#cb13-35"></a><span class="ex">[2024-07-17</span> 07:35:37.877255]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:123</span><span class="pp">]</span> <span class="at">-</span> PyInstrument profile saved <span class="er">(</span><span class="fu">as</span> html<span class="kw">)</span> <span class="ex">to:</span>  /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-17-073537.html</span>
<span id="cb13-36"><a href="#cb13-36"></a><span class="ex">[2024-07-17</span> 07:35:37.877936]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:131</span><span class="pp">]</span> <span class="at">-</span> PyInstrument profile saved <span class="er">(</span><span class="fu">as</span> text<span class="kw">)</span> <span class="ex">to:</span>  /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-17-073537.txt</span>
<span id="cb13-37"><a href="#cb13-37"></a><span class="ex">[2024-07-17</span> 07:35:38.391628]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:143</span><span class="pp">]</span> <span class="at">-</span> Finished with pyinstrument profiler. Took: 2.94768s</span>
<span id="cb13-38"><a href="#cb13-38"></a><span class="ex">[2024-07-17</span> 07:35:38.392519]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:318</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0</span><span class="pp">]</span> runtime=8.075730s</span>
<span id="cb13-39"><a href="#cb13-39"></a><span class="ex">wandb:</span> 🚀 View run vibrant-river-284 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span>
<span id="cb13-40"><a href="#cb13-40"></a><span class="ex">wandb:</span> Find logs at: wandb/run-20240717_073532-p49rzxtv/logs</span>
<span id="cb13-41"><a href="#cb13-41"></a><span class="ex">Application</span> cff755ee resources: utime=25s stime=23s maxrss=1434396KB inblock=32 oublock=4320 minflt=670179 majflt=864 nvcsw=195893 nivcsw=1331214</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="example-ezpz" class="level1 centeredslide smaller page-columns page-full" height="100%" style="max-height: 100%;" data-slide-background="#FFFFFF">
<h1 class="centeredslide smaller" height="100%" style="max-height: 100%;" data-slide-background="#FFFFFF">Example: <a href="https://github.com/saforem2/ezpz"><code>ezpz</code> 🍋</a></h1>
<div class="flex-container page-columns page-full">
<div id="fig-ezpz-asciinema" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<script src="https://asciinema.org/a/668460.js" id="asciicast-668460" async="true" style="max-height: 90%!important;"></script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ezpz-asciinema-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Example: using <a href="https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py">🍋 <code>ezpz.test_dist</code></a> to train a small model using DDP
</figcaption>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="margin-aside">
<p>Link to <a href="https://asciinema.org/a/668460">video</a></p>
</div></div></div>
</section>
<section id="example-wordplay" class="level1" data-background-color="white">
<h1 data-background-color="white">Example: <a href="https://github.com/saforem2/wordplay"><code>wordplay</code> 🎮💬</a></h1>
</section>
<section id="prepare-data" class="level1" data-background-color="white">
<h1 data-background-color="white">Prepare Data</h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">#[⭐][07:41:20 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 29s]</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="ex">$</span> python3 wordplay/data/shakespeare_char/prepare.py</span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="ex">Using</span> HF_DATASETS_CACHE=/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/.cache/huggingface</span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="ex">length</span> of dataset in characters: 1,115,394</span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="ex">all</span> the unique characters:</span>
<span id="cb14-6"><a href="#cb14-6"></a> <span class="ex">!$</span><span class="kw">&amp;</span><span class="ex">\',-.3:</span><span class="kw">;</span><span class="ex">?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz</span></span>
<span id="cb14-7"><a href="#cb14-7"></a><span class="ex">vocab</span> size: 65</span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="ex">train</span> has 1,003,854 tokens</span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="ex">val</span> has 111,540 tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="launch-training-ddp" class="level1" data-background-color="white">
<h1 data-background-color="white">Launch Training (DDP)</h1>
<div style="font-size: 0.8em; line-height: 1.0em;">
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="co">#[⭐][07:42:02 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="ex">$</span> launch python3 <span class="at">-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=64 model.block_size=1024 train.max_iters=1000 train.log_interval=10 train.compile=false <span class="kw">|</span> <span class="fu">tee</span> wordplay-gpt2-DDP.log</span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="ex">[2024-07-17</span> 07:42:11.746540]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:156</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb15-5"><a href="#cb15-5"></a><span class="ex">[2024-07-17</span> 07:42:11.748763]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:157</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb15-6"><a href="#cb15-6"></a><span class="ex">[2024-07-17</span> 07:42:11.749453]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:160</span><span class="pp">]</span> <span class="at">-</span> To disable this behavior, and log from ALL ranks <span class="er">(</span><span class="ex">not</span> recommended<span class="kw">)</span><span class="ex">,</span> set: <span class="st">'export LOG_FROM_ALL_RANKS=1'</span>  in your environment, and re-run.</span>
<span id="cb15-7"><a href="#cb15-7"></a><span class="ex">[2024-07-17</span> 07:42:11.772718]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:81</span><span class="pp">]</span> <span class="at">-</span> Setting HF_DATASETS_CACHE to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/.cache/huggingface/datasets</span>
<span id="cb15-8"><a href="#cb15-8"></a><span class="ex">[2024-07-17</span> 07:42:15.341532]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=2/3</span><span class="pp">][</span><span class="ss">local_rank=2/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb15-9"><a href="#cb15-9"></a><span class="ex">[2024-07-17</span> 07:42:15.342381]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=1/3</span><span class="pp">][</span><span class="ss">local_rank=1/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb15-10"><a href="#cb15-10"></a><span class="ex">[2024-07-17</span> 07:42:15.342430]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=3/3</span><span class="pp">][</span><span class="ss">local_rank=3/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb15-11"><a href="#cb15-11"></a><span class="ex">[2024-07-17</span> 07:42:15.348657]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb15-12"><a href="#cb15-12"></a></span>
<span id="cb15-13"><a href="#cb15-13"></a><span class="ex">[dist_info]:</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>  <span class="ex">•</span> DEVICE=cuda</span>
<span id="cb15-15"><a href="#cb15-15"></a>  <span class="ex">•</span> DEVICE_ID=cuda:0</span>
<span id="cb15-16"><a href="#cb15-16"></a>  <span class="ex">•</span> DISTRIBUTED_BACKEND=nccl</span>
<span id="cb15-17"><a href="#cb15-17"></a>  <span class="ex">•</span> GPUS_PER_NODE=4</span>
<span id="cb15-18"><a href="#cb15-18"></a>  <span class="ex">•</span> HOSTS=<span class="pp">[</span><span class="st">'x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov'</span><span class="pp">]</span></span>
<span id="cb15-19"><a href="#cb15-19"></a>  <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb15-20"><a href="#cb15-20"></a>  <span class="ex">•</span> HOSTNAME=x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb15-21"><a href="#cb15-21"></a>  <span class="ex">•</span> LOCAL_RANK=0</span>
<span id="cb15-22"><a href="#cb15-22"></a>  <span class="ex">•</span> MACHINE=Polaris</span>
<span id="cb15-23"><a href="#cb15-23"></a>  <span class="ex">•</span> NUM_NODES=1</span>
<span id="cb15-24"><a href="#cb15-24"></a>  <span class="ex">•</span> NGPUS=4</span>
<span id="cb15-25"><a href="#cb15-25"></a>  <span class="ex">•</span> NGPUS_AVAILABLE=4</span>
<span id="cb15-26"><a href="#cb15-26"></a>  <span class="ex">•</span> NODE_ID=0</span>
<span id="cb15-27"><a href="#cb15-27"></a>  <span class="ex">•</span> RANK=0</span>
<span id="cb15-28"><a href="#cb15-28"></a>  <span class="ex">•</span> SCHEDULER=PBS</span>
<span id="cb15-29"><a href="#cb15-29"></a>  <span class="ex">•</span> WORLD_SIZE_TOTAL=4</span>
<span id="cb15-30"><a href="#cb15-30"></a>  <span class="ex">•</span> WORLD_SIZE_IN_USE=4</span>
<span id="cb15-31"><a href="#cb15-31"></a>  <span class="ex">•</span> LAUNCH_CMD=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb15-32"><a href="#cb15-32"></a></span>
<span id="cb15-33"><a href="#cb15-33"></a></span>
<span id="cb15-34"><a href="#cb15-34"></a><span class="ex">[2024-07-17</span> 07:42:15.351446]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:725</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0/4</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'DDP'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb15-35"><a href="#cb15-35"></a><span class="ex">[2024-07-17</span> 07:42:15.356169]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=0/3</span><span class="pp">][</span><span class="ss">local_rank=0/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb15-36"><a href="#cb15-36"></a><span class="ex">[2024-07-17</span> 07:42:15.356692]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">dist:364</span><span class="pp">]</span> <span class="at">-</span> Using [4 / 4] available <span class="st">"cuda"</span> devices !!</span>
<span id="cb15-37"><a href="#cb15-37"></a><span class="ex">[2024-07-17</span> 07:42:15.359571]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:317</span><span class="pp">]</span> <span class="at">-</span> Loading val from /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/val.bin</span>
<span id="cb15-38"><a href="#cb15-38"></a><span class="ex">[2024-07-17</span> 07:42:15.360138]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:317</span><span class="pp">]</span> <span class="at">-</span> Loading train from /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/train.bin</span>
<span id="cb15-39"><a href="#cb15-39"></a><span class="ex">[2024-07-17</span> 07:42:15.361154]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:442</span><span class="pp">]</span> <span class="at">-</span> Tokens per iteration: 262,144</span>
<span id="cb15-40"><a href="#cb15-40"></a><span class="ex">[2024-07-17</span> 07:42:15.361574]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:465</span><span class="pp">]</span> <span class="at">-</span> Using self.ptdtype=torch.float16 on self.device_type=<span class="st">'cuda'</span></span>
<span id="cb15-41"><a href="#cb15-41"></a><span class="ex">[2024-07-17</span> 07:42:15.362002]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:471</span><span class="pp">]</span> <span class="at">-</span> Initializing a new model from scratch</span>
<span id="cb15-42"><a href="#cb15-42"></a><span class="ex">[2024-07-17</span> 07:42:15.362529]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:874</span><span class="pp">]</span> <span class="at">-</span> Setting up wandb from rank: 0</span>
<span id="cb15-43"><a href="#cb15-43"></a><span class="ex">[2024-07-17</span> 07:42:15.362896]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:875</span><span class="pp">]</span> <span class="at">-</span> Using: WB PROJECT: WordPlay</span>
<span id="cb15-44"><a href="#cb15-44"></a><span class="ex">[2024-07-17</span> 07:42:16.451786]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:905</span><span class="pp">]</span> <span class="at">-</span> W<span class="kw">&amp;</span><span class="ex">B</span> RUN: <span class="pp">[</span><span class="ss">still</span><span class="pp">-</span><span class="ss">frog</span><span class="pp">-</span><span class="ss">17</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/WordPlay/runs/6by9vpcj</span><span class="kw">)</span></span>
<span id="cb15-45"><a href="#cb15-45"></a><span class="ex">[2024-07-17</span> 07:42:16.464106]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:312</span><span class="pp">]</span> <span class="at">-</span> Updating wandb.run: still-frog-17 config with <span class="st">"DIST_INFO"</span></span>
<span id="cb15-46"><a href="#cb15-46"></a><span class="ex">[2024-07-17</span> 07:42:16.469424]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:938</span><span class="pp">]</span> <span class="at">-</span> Running on machine=<span class="st">'Polaris'</span></span>
<span id="cb15-47"><a href="#cb15-47"></a><span class="ex">[2024-07-17</span> 07:42:16.471151]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">__main__:89</span><span class="pp">]</span> <span class="at">-</span> {</span>
<span id="cb15-48"><a href="#cb15-48"></a>    <span class="st">"train"</span><span class="ex">:</span> {</span>
<span id="cb15-49"><a href="#cb15-49"></a>        <span class="st">"framework"</span><span class="ex">:</span> <span class="st">"pytorch"</span>,</span>
<span id="cb15-50"><a href="#cb15-50"></a>        <span class="st">"backend"</span><span class="ex">:</span> <span class="st">"DDP"</span>,</span>
<span id="cb15-51"><a href="#cb15-51"></a>        <span class="st">"device"</span><span class="ex">:</span> null,</span>
<span id="cb15-52"><a href="#cb15-52"></a>        <span class="st">"seed"</span><span class="ex">:</span> null,</span>
<span id="cb15-53"><a href="#cb15-53"></a>        <span class="st">"port"</span><span class="ex">:</span> null,</span>
<span id="cb15-54"><a href="#cb15-54"></a>        <span class="st">"ds_config_path"</span><span class="ex">:</span> null,</span>
<span id="cb15-55"><a href="#cb15-55"></a>        <span class="st">"precision"</span><span class="ex">:</span> null,</span>
<span id="cb15-56"><a href="#cb15-56"></a>        <span class="st">"ngpus"</span><span class="ex">:</span> null,</span>
<span id="cb15-57"><a href="#cb15-57"></a>        <span class="st">"use_wandb"</span><span class="ex">:</span> true,</span>
<span id="cb15-58"><a href="#cb15-58"></a>        <span class="st">"eval_interval"</span><span class="ex">:</span> 100,</span>
<span id="cb15-59"><a href="#cb15-59"></a>        <span class="st">"log_interval"</span><span class="ex">:</span> 10,</span>
<span id="cb15-60"><a href="#cb15-60"></a>        <span class="st">"eval_iters"</span><span class="ex">:</span> 200,</span>
<span id="cb15-61"><a href="#cb15-61"></a>        <span class="st">"eval_only"</span><span class="ex">:</span> false,</span>
<span id="cb15-62"><a href="#cb15-62"></a>        <span class="st">"always_save_checkpoint"</span><span class="ex">:</span> false,</span>
<span id="cb15-63"><a href="#cb15-63"></a>        <span class="st">"init_from"</span><span class="ex">:</span> <span class="st">"scratch"</span>,</span>
<span id="cb15-64"><a href="#cb15-64"></a>        <span class="st">"wandb_project"</span><span class="ex">:</span> <span class="st">"WordPlay"</span>,</span>
<span id="cb15-65"><a href="#cb15-65"></a>        <span class="st">"max_iters"</span><span class="ex">:</span> 1000,</span>
<span id="cb15-66"><a href="#cb15-66"></a>        <span class="st">"warmup_iters"</span><span class="ex">:</span> 100,</span>
<span id="cb15-67"><a href="#cb15-67"></a>        <span class="st">"dtype"</span><span class="ex">:</span> <span class="st">"bf16"</span>,</span>
<span id="cb15-68"><a href="#cb15-68"></a>        <span class="st">"compile"</span><span class="ex">:</span> false</span>
<span id="cb15-69"><a href="#cb15-69"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb15-70"><a href="#cb15-70"></a>    <span class="st">"model"</span><span class="ex">:</span> {</span>
<span id="cb15-71"><a href="#cb15-71"></a>        <span class="st">"n_layer"</span><span class="ex">:</span> 12,</span>
<span id="cb15-72"><a href="#cb15-72"></a>        <span class="st">"n_head"</span><span class="ex">:</span> 12,</span>
<span id="cb15-73"><a href="#cb15-73"></a>        <span class="st">"n_embd"</span><span class="ex">:</span> 768,</span>
<span id="cb15-74"><a href="#cb15-74"></a>        <span class="st">"batch_size"</span><span class="ex">:</span> 64,</span>
<span id="cb15-75"><a href="#cb15-75"></a>        <span class="st">"block_size"</span><span class="ex">:</span> 1024,</span>
<span id="cb15-76"><a href="#cb15-76"></a>        <span class="st">"activation"</span><span class="ex">:</span> <span class="st">"gelu"</span>,</span>
<span id="cb15-77"><a href="#cb15-77"></a>        <span class="st">"dropout"</span><span class="ex">:</span> 0.0,</span>
<span id="cb15-78"><a href="#cb15-78"></a>        <span class="st">"bias"</span><span class="ex">:</span> false,</span>
<span id="cb15-79"><a href="#cb15-79"></a>        <span class="st">"vocab_size"</span><span class="ex">:</span> 65</span>
<span id="cb15-80"><a href="#cb15-80"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb15-81"><a href="#cb15-81"></a>    <span class="st">"data"</span><span class="ex">:</span> {</span>
<span id="cb15-82"><a href="#cb15-82"></a>        <span class="st">"dataset"</span><span class="ex">:</span> <span class="st">"shakespeare_char"</span>,</span>
<span id="cb15-83"><a href="#cb15-83"></a>        <span class="st">"out_dir"</span><span class="ex">:</span> <span class="st">"out-shakespeare-char"</span>,</span>
<span id="cb15-84"><a href="#cb15-84"></a>        <span class="st">"root_path"</span><span class="ex">:</span> null</span>
<span id="cb15-85"><a href="#cb15-85"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb15-86"><a href="#cb15-86"></a>    <span class="st">"optimizer"</span><span class="ex">:</span> {</span>
<span id="cb15-87"><a href="#cb15-87"></a>        <span class="st">"gas"</span><span class="ex">:</span> 1,</span>
<span id="cb15-88"><a href="#cb15-88"></a>        <span class="st">"name"</span><span class="ex">:</span> <span class="st">"AdamW"</span>,</span>
<span id="cb15-89"><a href="#cb15-89"></a>        <span class="st">"learning_rate"</span><span class="ex">:</span> 0.0006,</span>
<span id="cb15-90"><a href="#cb15-90"></a>        <span class="st">"weight_decay"</span><span class="ex">:</span> 0.1,</span>
<span id="cb15-91"><a href="#cb15-91"></a>        <span class="st">"beta1"</span><span class="ex">:</span> 0.9,</span>
<span id="cb15-92"><a href="#cb15-92"></a>        <span class="st">"beta2"</span><span class="ex">:</span> 0.95,</span>
<span id="cb15-93"><a href="#cb15-93"></a>        <span class="st">"grad_clip"</span><span class="ex">:</span> 1.0,</span>
<span id="cb15-94"><a href="#cb15-94"></a>        <span class="st">"decay_lr"</span><span class="ex">:</span> true,</span>
<span id="cb15-95"><a href="#cb15-95"></a>        <span class="st">"lr_decay_iters"</span><span class="ex">:</span> 600000,</span>
<span id="cb15-96"><a href="#cb15-96"></a>        <span class="st">"min_lr"</span><span class="ex">:</span> 6e-05</span>
<span id="cb15-97"><a href="#cb15-97"></a>    <span class="er">}</span></span>
<span id="cb15-98"><a href="#cb15-98"></a><span class="er">}</span></span>
<span id="cb15-99"><a href="#cb15-99"></a><span class="ex">[2024-07-17</span> 07:42:16.474305]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">__main__:90</span><span class="pp">]</span> <span class="at">-</span> Output dir: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb15-100"><a href="#cb15-100"></a><span class="ex">[2024-07-17</span> 07:42:16.474922]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:246</span><span class="pp">]</span> <span class="at">-</span> Initializing a new model from scratch</span>
<span id="cb15-101"><a href="#cb15-101"></a><span class="ex">[2024-07-17</span> 07:42:17.258904]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:255</span><span class="pp">]</span> <span class="at">-</span> number of parameters: 85.00M</span>
<span id="cb15-102"><a href="#cb15-102"></a><span class="ex">[2024-07-17</span> 07:42:17.290004]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:264</span><span class="pp">]</span> <span class="at">-</span> Model size: num_params=85003776</span>
<span id="cb15-103"><a href="#cb15-103"></a><span class="ex">[2024-07-17</span> 07:42:17.292626]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:445</span><span class="pp">]</span> <span class="at">-</span> num decayed parameter tensors: 50, with 85,771,008 parameters</span>
<span id="cb15-104"><a href="#cb15-104"></a><span class="ex">[2024-07-17</span> 07:42:17.293296]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:449</span><span class="pp">]</span> <span class="at">-</span> num non-decayed parameter tensors: 25, with 19,200 parameters</span>
<span id="cb15-105"><a href="#cb15-105"></a><span class="ex">[2024-07-17</span> 07:42:17.515324]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:1'"</span></span>
<span id="cb15-106"><a href="#cb15-106"></a><span class="ex">[2024-07-17</span> 07:42:17.515340]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:2'"</span></span>
<span id="cb15-107"><a href="#cb15-107"></a><span class="ex">[2024-07-17</span> 07:42:17.515465]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:3'"</span></span>
<span id="cb15-108"><a href="#cb15-108"></a><span class="ex">[2024-07-17</span> 07:42:18.431814]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:465</span><span class="pp">]</span> <span class="at">-</span> using fused AdamW: True</span>
<span id="cb15-109"><a href="#cb15-109"></a><span class="ex">[2024-07-17</span> 07:42:18.432620]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:0'"</span></span>
<span id="cb15-110"><a href="#cb15-110"></a><span class="ex">[2024-07-17</span> 07:42:19.951020]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:356</span><span class="pp">]</span> <span class="at">-</span> • self.model=GPT<span class="er">(</span></span>
<span id="cb15-111"><a href="#cb15-111"></a>  <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb15-112"><a href="#cb15-112"></a>    <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb15-113"><a href="#cb15-113"></a>    <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">1024,</span> 768<span class="kw">)</span></span>
<span id="cb15-114"><a href="#cb15-114"></a>    <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-115"><a href="#cb15-115"></a>    <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb15-116"><a href="#cb15-116"></a>      <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb15-117"><a href="#cb15-117"></a>        <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-118"><a href="#cb15-118"></a>        <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb15-119"><a href="#cb15-119"></a>          <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-120"><a href="#cb15-120"></a>          <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-121"><a href="#cb15-121"></a>          <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-122"><a href="#cb15-122"></a>          <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-123"><a href="#cb15-123"></a>        <span class="kw">)</span></span>
<span id="cb15-124"><a href="#cb15-124"></a>        <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-125"><a href="#cb15-125"></a>        <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb15-126"><a href="#cb15-126"></a>          <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-127"><a href="#cb15-127"></a>          <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb15-128"><a href="#cb15-128"></a>          <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-129"><a href="#cb15-129"></a>          <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-130"><a href="#cb15-130"></a>        <span class="kw">)</span></span>
<span id="cb15-131"><a href="#cb15-131"></a>      <span class="kw">)</span></span>
<span id="cb15-132"><a href="#cb15-132"></a>    <span class="kw">)</span></span>
<span id="cb15-133"><a href="#cb15-133"></a>    <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-134"><a href="#cb15-134"></a>  <span class="kw">)</span></span>
<span id="cb15-135"><a href="#cb15-135"></a>  <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-136"><a href="#cb15-136"></a><span class="kw">)</span></span>
<span id="cb15-137"><a href="#cb15-137"></a><span class="ex">[2024-07-17</span> 07:42:19.955340]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:357</span><span class="pp">]</span> <span class="at">-</span> • self.grad_scaler=<span class="op">&lt;</span>torch.cuda.amp.grad_scaler.GradScaler object at 0x145a38f0f090<span class="op">&gt;</span></span>
<span id="cb15-138"><a href="#cb15-138"></a><span class="ex">[2024-07-17</span> 07:42:19.956897]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:358</span><span class="pp">]</span> <span class="at">-</span> • self.model_engine=DistributedDataParallel<span class="er">(</span></span>
<span id="cb15-139"><a href="#cb15-139"></a>  <span class="kw">(</span><span class="ex">module</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb15-140"><a href="#cb15-140"></a>    <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb15-141"><a href="#cb15-141"></a>      <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb15-142"><a href="#cb15-142"></a>      <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">1024,</span> 768<span class="kw">)</span></span>
<span id="cb15-143"><a href="#cb15-143"></a>      <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-144"><a href="#cb15-144"></a>      <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb15-145"><a href="#cb15-145"></a>        <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb15-146"><a href="#cb15-146"></a>          <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-147"><a href="#cb15-147"></a>          <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb15-148"><a href="#cb15-148"></a>            <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-149"><a href="#cb15-149"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-150"><a href="#cb15-150"></a>            <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-151"><a href="#cb15-151"></a>            <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-152"><a href="#cb15-152"></a>          <span class="kw">)</span></span>
<span id="cb15-153"><a href="#cb15-153"></a>          <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-154"><a href="#cb15-154"></a>          <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb15-155"><a href="#cb15-155"></a>            <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-156"><a href="#cb15-156"></a>            <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb15-157"><a href="#cb15-157"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-158"><a href="#cb15-158"></a>            <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-159"><a href="#cb15-159"></a>          <span class="kw">)</span></span>
<span id="cb15-160"><a href="#cb15-160"></a>        <span class="kw">)</span></span>
<span id="cb15-161"><a href="#cb15-161"></a>      <span class="kw">)</span></span>
<span id="cb15-162"><a href="#cb15-162"></a>      <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb15-163"><a href="#cb15-163"></a>    <span class="kw">)</span></span>
<span id="cb15-164"><a href="#cb15-164"></a>    <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb15-165"><a href="#cb15-165"></a>  <span class="kw">)</span></span>
<span id="cb15-166"><a href="#cb15-166"></a><span class="kw">)</span></span>
<span id="cb15-167"><a href="#cb15-167"></a><span class="ex">[2024-07-17</span> 07:42:19.961066]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:359</span><span class="pp">]</span> <span class="at">-</span> • self.optimizer=AdamW <span class="er">(</span></span>
<span id="cb15-168"><a href="#cb15-168"></a><span class="ex">Parameter</span> Group 0</span>
<span id="cb15-169"><a href="#cb15-169"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb15-170"><a href="#cb15-170"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb15-171"><a href="#cb15-171"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb15-172"><a href="#cb15-172"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb15-173"><a href="#cb15-173"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb15-174"><a href="#cb15-174"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb15-175"><a href="#cb15-175"></a>    <span class="ex">fused:</span> True</span>
<span id="cb15-176"><a href="#cb15-176"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb15-177"><a href="#cb15-177"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb15-178"><a href="#cb15-178"></a>    <span class="ex">weight_decay:</span> 0.1</span>
<span id="cb15-179"><a href="#cb15-179"></a></span>
<span id="cb15-180"><a href="#cb15-180"></a><span class="ex">Parameter</span> Group 1</span>
<span id="cb15-181"><a href="#cb15-181"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb15-182"><a href="#cb15-182"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb15-183"><a href="#cb15-183"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb15-184"><a href="#cb15-184"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb15-185"><a href="#cb15-185"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb15-186"><a href="#cb15-186"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb15-187"><a href="#cb15-187"></a>    <span class="ex">fused:</span> True</span>
<span id="cb15-188"><a href="#cb15-188"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb15-189"><a href="#cb15-189"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb15-190"><a href="#cb15-190"></a>    <span class="ex">weight_decay:</span> 0.0</span>
<span id="cb15-191"><a href="#cb15-191"></a><span class="kw">)</span></span>
<span id="cb15-192"><a href="#cb15-192"></a><span class="ex">[2024-07-17</span> 07:42:19.988827]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:802</span><span class="pp">]</span> <span class="at">-</span> Startup time: 6.7125</span>
<span id="cb15-193"><a href="#cb15-193"></a>                <span class="ex">Training</span> Legend</span>
<span id="cb15-194"><a href="#cb15-194"></a><span class="ex">┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span></span>
<span id="cb15-195"><a href="#cb15-195"></a><span class="ex">┃</span>    abbr     ┃ desc                           ┃</span>
<span id="cb15-196"><a href="#cb15-196"></a><span class="ex">┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩</span></span>
<span id="cb15-197"><a href="#cb15-197"></a><span class="ex">│</span>    step     │ Current training iteration     │</span>
<span id="cb15-198"><a href="#cb15-198"></a><span class="ex">│</span>    loss     │ Loss value                     │</span>
<span id="cb15-199"><a href="#cb15-199"></a><span class="ex">│</span>     dt      │ Elapsed time per training step │</span>
<span id="cb15-200"><a href="#cb15-200"></a><span class="ex">│</span>     dtf     │ Elapsed time per forward step  │</span>
<span id="cb15-201"><a href="#cb15-201"></a><span class="ex">│</span>     dtb     │ Elapsed time per backward step │</span>
<span id="cb15-202"><a href="#cb15-202"></a><span class="ex">│</span>     sps     │ Samples per second             │</span>
<span id="cb15-203"><a href="#cb15-203"></a><span class="ex">│</span> sps_per_gpu │ Samples per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>   <span class="ex">│</span></span>
<span id="cb15-204"><a href="#cb15-204"></a><span class="ex">│</span>     tps     │ Tokens per second              │</span>
<span id="cb15-205"><a href="#cb15-205"></a><span class="ex">│</span> tps_per_gpu │ Tokens per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>    <span class="ex">│</span></span>
<span id="cb15-206"><a href="#cb15-206"></a><span class="ex">│</span>     mfu     │ Model flops utilization        │</span>
<span id="cb15-207"><a href="#cb15-207"></a><span class="ex">│</span> train_loss  │ Training loss value            │</span>
<span id="cb15-208"><a href="#cb15-208"></a><span class="ex">│</span>  val_loss   │ Validation loss value          │</span>
<span id="cb15-209"><a href="#cb15-209"></a><span class="ex">└─────────────┴────────────────────────────────┘</span></span>
<span id="cb15-210"><a href="#cb15-210"></a><span class="ex">[2024-07-17</span> 07:42:21.451865]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb15-211"><a href="#cb15-211"></a><span class="ex">[2024-07-17</span> 07:42:21.452667]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb15-212"><a href="#cb15-212"></a><span class="ex">What</span> is an LLM<span class="pp">?</span>eelEl\'<span class="va">$nltPwBSWal</span>,<span class="kw">;</span><span class="ex">PWw</span> bbu<span class="dt">\'</span>HiyP<span class="dt">\'</span>FWwF <span class="kw">&amp;</span><span class="ex">AhW:ygrn</span> kk-<span class="dt">\'\'</span>KFlMwnlEfflkc,elpWaWtgml<span class="va">$Pgglhllw</span> lglhFllzczPAFHpeAAPPSltgkrWPPhlEMgcrN ggPWt-WPSSzHSkkrzzk.FFrtSSkgMll<span class="kw">&amp;</span><span class="ex">gFXr,hghaueaVPW-pHFF-gg,,,FF,,kbApgg</span> gg<span class="dt">\'</span>aWWzzkk<span class="dt">\'</span>a<span class="dt">\'</span>CggHl<span class="va">$bGeA</span>,FFk,,SF<span class="kw">;</span><span class="ex">UF,,aZ</span> <span class="kw">;</span><span class="ex">gglee$,k.US</span><span class="kw">&amp;</span><span class="ex">kg:S,,zVzzc</span></span>
<span id="cb15-213"><a href="#cb15-213"></a><span class="ex">[2024-07-17</span> 07:43:01.573073]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=10 loss=3.154310 dt=0.282833 dtf=0.005247 dtb=0.011417 sps=14.142633 sps_per_gpu=3.535658 tps=926851.609409 tps_per_gpu=231712.902352 mfu=46.288281 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-214"><a href="#cb15-214"></a><span class="ex">[2024-07-17</span> 07:43:04.402750]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=20 loss=2.660851 dt=0.306263 dtf=0.005233 dtb=0.011419 sps=13.060678 sps_per_gpu=3.265170 tps=855944.613638 tps_per_gpu=213986.153409 mfu=45.934162 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-215"><a href="#cb15-215"></a><span class="ex">[2024-07-17</span> 07:43:07.237507]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=30 loss=2.543283 dt=0.283021 dtf=0.005238 dtb=0.011245 sps=14.133211 sps_per_gpu=3.533303 tps=926234.088226 tps_per_gpu=231558.522057 mfu=45.966490 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-216"><a href="#cb15-216"></a><span class="ex">[2024-07-17</span> 07:43:10.077248]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=40 loss=2.503963 dt=0.285001 dtf=0.005213 dtb=0.011471 sps=14.035061 sps_per_gpu=3.508765 tps=919801.749941 tps_per_gpu=229950.437485 mfu=45.963461 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-217"><a href="#cb15-217"></a><span class="ex">[2024-07-17</span> 07:43:12.917039]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=50 loss=2.477469 dt=0.283532 dtf=0.005166 dtb=0.011294 sps=14.107763 sps_per_gpu=3.526941 tps=924566.380009 tps_per_gpu=231141.595002 mfu=45.984530 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-218"><a href="#cb15-218"></a><span class="ex">[2024-07-17</span> 07:43:15.760749]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=60 loss=2.471083 dt=0.284630 dtf=0.005140 dtb=0.011224 sps=14.053326 sps_per_gpu=3.513332 tps=920998.786204 tps_per_gpu=230249.696551 mfu=45.985675 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-219"><a href="#cb15-219"></a><span class="ex">[2024-07-17</span> 07:43:18.602785]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=70 loss=2.458894 dt=0.283926 dtf=0.005219 dtb=0.010383 sps=14.088155 sps_per_gpu=3.522039 tps=923281.352698 tps_per_gpu=230820.338174 mfu=45.998106 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-220"><a href="#cb15-220"></a><span class="ex">[2024-07-17</span> 07:43:21.451433]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=80 loss=2.489088 dt=0.285537 dtf=0.005183 dtb=0.011373 sps=14.008683 sps_per_gpu=3.502171 tps=918073.060430 tps_per_gpu=229518.265108 mfu=45.983282 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-221"><a href="#cb15-221"></a><span class="ex">[2024-07-17</span> 07:43:24.302241]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=90 loss=2.471990 dt=0.300767 dtf=0.005445 dtb=0.010290 sps=13.299337 sps_per_gpu=3.324834 tps=871585.359388 tps_per_gpu=217896.339847 mfu=45.737774 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-222"><a href="#cb15-222"></a><span class="ex">[2024-07-17</span> 07:43:27.153275]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=100 loss=2.445556 dt=0.285869 dtf=0.005182 dtb=0.011251 sps=13.992403 sps_per_gpu=3.498101 tps=917006.151328 tps_per_gpu=229251.537832 mfu=45.743655 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb15-223"><a href="#cb15-223"></a><span class="ex">[2024-07-17</span> 07:43:28.182553]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb15-224"><a href="#cb15-224"></a><span class="ex">[2024-07-17</span> 07:43:28.183179]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb15-225"><a href="#cb15-225"></a></span>
<span id="cb15-226"><a href="#cb15-226"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb15-227"><a href="#cb15-227"></a></span>
<span id="cb15-228"><a href="#cb15-228"></a><span class="ex">Goupay</span> my winghimithell bls ger t bon sinthard ht omind be,</span>
<span id="cb15-229"><a href="#cb15-229"></a><span class="ex">And</span> lereind h py balithand frd oforondof wimon me hageas thinero mand,</span>
<span id="cb15-230"><a href="#cb15-230"></a><span class="ex">Thacanes,</span></span>
<span id="cb15-231"><a href="#cb15-231"></a><span class="ex">An</span> frift ghik med d herthecke ntore thack couthen ale, t thit ang d m t h chy me fache ag, wit my hathan glat ng</span>
<span id="cb15-232"><a href="#cb15-232"></a><span class="ex">[2024-07-17</span> 07:44:06.025837]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:760</span><span class="pp">]</span> <span class="at">-</span> Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb15-233"><a href="#cb15-233"></a><span class="ex">[2024-07-17</span> 07:44:06.026607]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:761</span><span class="pp">]</span> <span class="at">-</span> Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span>
<span id="cb15-234"><a href="#cb15-234"></a><span class="ex">[2024-07-17</span> 07:44:07.682968]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:141</span><span class="pp">]</span> <span class="at">-</span> Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb15-235"><a href="#cb15-235"></a><span class="ex">[2024-07-17</span> 07:44:10.519506]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=110 loss=2.433923 dt=0.285038 dtf=0.005757 dtb=0.011762 sps=14.033209 sps_per_gpu=3.508302 tps=919680.367894 tps_per_gpu=229920.091974 mfu=45.762304 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-236"><a href="#cb15-236"></a><span class="ex">[2024-07-17</span> 07:44:13.362148]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=120 loss=2.429014 dt=0.284445 dtf=0.005222 dtb=0.011486 sps=14.062460 sps_per_gpu=3.515615 tps=921597.361532 tps_per_gpu=230399.340383 mfu=45.788661 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-237"><a href="#cb15-237"></a><span class="ex">[2024-07-17</span> 07:44:16.210694]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=130 loss=2.402059 dt=0.285559 dtf=0.005199 dtb=0.011765 sps=14.007633 sps_per_gpu=3.501908 tps=918004.211586 tps_per_gpu=229501.052897 mfu=45.794438 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-238"><a href="#cb15-238"></a><span class="ex">[2024-07-17</span> 07:44:19.061546]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=140 loss=2.374062 dt=0.285476 dtf=0.005239 dtb=0.011453 sps=14.011662 sps_per_gpu=3.502916 tps=918268.297093 tps_per_gpu=229567.074273 mfu=45.800956 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-239"><a href="#cb15-239"></a><span class="ex">[2024-07-17</span> 07:44:21.917283]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=150 loss=2.365385 dt=0.285846 dtf=0.005125 dtb=0.011320 sps=13.993568 sps_per_gpu=3.498392 tps=917082.475791 tps_per_gpu=229270.618948 mfu=45.800900 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-240"><a href="#cb15-240"></a><span class="ex">[2024-07-17</span> 07:44:24.771924]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=160 loss=2.317337 dt=0.280788 dtf=0.005173 dtb=0.011249 sps=14.245602 sps_per_gpu=3.561401 tps=933599.792506 tps_per_gpu=233399.948127 mfu=45.883340 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-241"><a href="#cb15-241"></a><span class="ex">[2024-07-17</span> 07:44:27.626812]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=170 loss=2.256231 dt=0.284973 dtf=0.005141 dtb=0.011299 sps=14.036416 sps_per_gpu=3.509104 tps=919890.544506 tps_per_gpu=229972.636126 mfu=45.889069 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-242"><a href="#cb15-242"></a><span class="ex">[2024-07-17</span> 07:44:30.480952]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=180 loss=2.216419 dt=0.286555 dtf=0.005180 dtb=0.011402 sps=13.958906 sps_per_gpu=3.489726 tps=914810.852170 tps_per_gpu=228702.713043 mfu=45.868857 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-243"><a href="#cb15-243"></a><span class="ex">[2024-07-17</span> 07:44:33.337342]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=190 loss=2.145123 dt=0.291456 dtf=0.005409 dtb=0.019347 sps=13.724205 sps_per_gpu=3.431051 tps=899429.467247 tps_per_gpu=224857.366812 mfu=45.773849 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-244"><a href="#cb15-244"></a><span class="ex">[2024-07-17</span> 07:44:36.194584]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=200 loss=2.068149 dt=0.285703 dtf=0.005153 dtb=0.011286 sps=14.000555 sps_per_gpu=3.500139 tps=917540.393411 tps_per_gpu=229385.098353 mfu=45.778791 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb15-245"><a href="#cb15-245"></a><span class="ex">[2024-07-17</span> 07:44:37.224149]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb15-246"><a href="#cb15-246"></a><span class="ex">[2024-07-17</span> 07:44:37.224745]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb15-247"><a href="#cb15-247"></a></span>
<span id="cb15-248"><a href="#cb15-248"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb15-249"><a href="#cb15-249"></a></span>
<span id="cb15-250"><a href="#cb15-250"></a><span class="ex">LORTESS</span> LA:</span>
<span id="cb15-251"><a href="#cb15-251"></a><span class="ex">No,</span> sighappat selace<span class="pp">?</span> don downd sourciceans note cancen up sof liond</span>
<span id="cb15-252"><a href="#cb15-252"></a><span class="ex">This</span> and my man, werame, of re thee</span>
<span id="cb15-253"><a href="#cb15-253"></a><span class="ex">Thise</span> not will I on land brond sul me a fingore<span class="pp">?</span></span>
<span id="cb15-254"><a href="#cb15-254"></a></span>
<span id="cb15-255"><a href="#cb15-255"></a><span class="ex">FLER:</span></span>
<span id="cb15-256"><a href="#cb15-256"></a><span class="ex">Tisint</span> your not nare lame o igen,-to brorst.</span>
<span id="cb15-257"><a href="#cb15-257"></a></span>
<span id="cb15-258"><a href="#cb15-258"></a><span class="ex">SamERS:</span></span>
<span id="cb15-259"><a href="#cb15-259"></a><span class="ex">Sin:</span></span>
<span id="cb15-260"><a href="#cb15-260"></a><span class="ex">I\'l</span> hell she lor hen w</span>
<span id="cb15-261"><a href="#cb15-261"></a><span class="ex">[2024-07-17</span> 07:45:14.409129]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:760</span><span class="pp">]</span> <span class="at">-</span> Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb15-262"><a href="#cb15-262"></a><span class="ex">[2024-07-17</span> 07:45:14.409820]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:761</span><span class="pp">]</span> <span class="at">-</span> Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span>
<span id="cb15-263"><a href="#cb15-263"></a><span class="ex">[2024-07-17</span> 07:45:16.366935]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:141</span><span class="pp">]</span> <span class="at">-</span> Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb15-264"><a href="#cb15-264"></a><span class="ex">[2024-07-17</span> 07:45:19.245061]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=210 loss=1.982169 dt=0.283305 dtf=0.005223 dtb=0.011284 sps=14.119042 sps_per_gpu=3.529760 tps=925305.515083 tps_per_gpu=231326.378771 mfu=45.822019 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-265"><a href="#cb15-265"></a><span class="ex">[2024-07-17</span> 07:45:22.092430]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=220 loss=1.897731 dt=0.284759 dtf=0.005217 dtb=0.011187 sps=14.046945 sps_per_gpu=3.511736 tps=920580.608106 tps_per_gpu=230145.152026 mfu=45.837327 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-266"><a href="#cb15-266"></a><span class="ex">[2024-07-17</span> 07:45:24.942639]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=230 loss=1.817213 dt=0.285266 dtf=0.005208 dtb=0.011446 sps=14.022003 sps_per_gpu=3.505501 tps=918945.985503 tps_per_gpu=229736.496376 mfu=45.842940 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-267"><a href="#cb15-267"></a><span class="ex">[2024-07-17</span> 07:45:27.797910]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=240 loss=1.779287 dt=0.285465 dtf=0.005189 dtb=0.011220 sps=14.012250 sps_per_gpu=3.503062 tps=918306.793546 tps_per_gpu=229576.698387 mfu=45.844800 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-268"><a href="#cb15-268"></a><span class="ex">[2024-07-17</span> 07:45:30.653597]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=250 loss=1.704220 dt=0.289284 dtf=0.005471 dtb=0.010346 sps=13.827253 sps_per_gpu=3.456813 tps=906182.836379 tps_per_gpu=226545.709095 mfu=45.785926 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-269"><a href="#cb15-269"></a><span class="ex">[2024-07-17</span> 07:45:33.512769]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=260 loss=1.671318 dt=0.287679 dtf=0.005125 dtb=0.011250 sps=13.904380 sps_per_gpu=3.476095 tps=911237.442617 tps_per_gpu=227809.360654 mfu=45.758182 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-270"><a href="#cb15-270"></a><span class="ex">[2024-07-17</span> 07:45:36.373461]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=270 loss=1.650952 dt=0.298661 dtf=0.005118 dtb=0.011520 sps=13.393107 sps_per_gpu=3.348277 tps=877730.651421 tps_per_gpu=219432.662855 mfu=45.565875 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-271"><a href="#cb15-271"></a><span class="ex">[2024-07-17</span> 07:45:39.236930]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=280 loss=1.573242 dt=0.285970 dtf=0.005171 dtb=0.011290 sps=13.987477 sps_per_gpu=3.496869 tps=916683.279847 tps_per_gpu=229170.819962 mfu=45.587333 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-272"><a href="#cb15-272"></a><span class="ex">[2024-07-17</span> 07:45:42.100605]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=290 loss=1.533265 dt=0.286487 dtf=0.005432 dtb=0.011288 sps=13.962259 sps_per_gpu=3.490565 tps=915030.617828 tps_per_gpu=228757.654457 mfu=45.598392 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-273"><a href="#cb15-273"></a><span class="ex">[2024-07-17</span> 07:45:44.964424]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=300 loss=1.492064 dt=0.288480 dtf=0.005355 dtb=0.011480 sps=13.865774 sps_per_gpu=3.466443 tps=908707.340870 tps_per_gpu=227176.835218 mfu=45.576766 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb15-274"><a href="#cb15-274"></a><span class="ex">[2024-07-17</span> 07:45:45.995833]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb15-275"><a href="#cb15-275"></a><span class="ex">[2024-07-17</span> 07:45:45.996497]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb15-276"><a href="#cb15-276"></a></span>
<span id="cb15-277"><a href="#cb15-277"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb15-278"><a href="#cb15-278"></a></span>
<span id="cb15-279"><a href="#cb15-279"></a><span class="ex">RICHMORD:</span></span>
<span id="cb15-280"><a href="#cb15-280"></a><span class="ex">Char</span> stire<span class="pp">?</span> how in those are name the range hone.</span>
<span id="cb15-281"><a href="#cb15-281"></a></span>
<span id="cb15-282"><a href="#cb15-282"></a><span class="ex">GLOUCESTER:</span></span>
<span id="cb15-283"><a href="#cb15-283"></a><span class="ex">Nay,</span> in lond<span class="st">'s time the palt are worder more</span></span>
<span id="cb15-284"><a href="#cb15-284"></a><span class="st">That wilt in the purpose be a pey</span></span>
<span id="cb15-285"><a href="#cb15-285"></a><span class="st">And thou thine onter hands, and the which broth.</span></span>
<span id="cb15-286"><a href="#cb15-286"></a></span>
<span id="cb15-287"><a href="#cb15-287"></a><span class="st">ELBOWINCA:</span></span>
<span id="cb15-288"><a href="#cb15-288"></a><span class="st">At lie my lord with the me an arms be a s</span></span>
<span id="cb15-289"><a href="#cb15-289"></a><span class="st">[2024-07-17 07:46:23.549987][INFO][trainer:760] - Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span></span>
<span id="cb15-290"><a href="#cb15-290"></a><span class="st">[2024-07-17 07:46:23.550696][INFO][trainer:761] - Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span></span>
<span id="cb15-291"><a href="#cb15-291"></a><span class="st">[2024-07-17 07:46:25.496559][INFO][configs:141] - Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span></span>
<span id="cb15-292"><a href="#cb15-292"></a><span class="st">[2024-07-17 07:46:28.374854][INFO][trainer:885] - step=310 loss=1.444200 dt=0.299907 dtf=0.005333 dtb=0.010637 sps=13.337481 sps_per_gpu=3.334370 tps=874085.133345 tps_per_gpu=218521.283336 mfu=45.384395 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb15-293"><a href="#cb15-293"></a><span class="st">[2024-07-17 07:46:31.223079][INFO][trainer:885] - step=320 loss=1.429350 dt=0.285238 dtf=0.005245 dtb=0.011485 sps=14.023353 sps_per_gpu=3.505838 tps=919034.479880 tps_per_gpu=229758.619970 mfu=45.435743 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb15-294"><a href="#cb15-294"></a><span class="st">[2024-07-17 07:46:34.074957][INFO][trainer:885] - step=330 loss=1.362220 dt=0.285027 dtf=0.005165 dtb=0.011407 sps=14.033736 sps_per_gpu=3.508434 tps=919714.904826 tps_per_gpu=229928.726207 mfu=45.485355 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb15-295"><a href="#cb15-295"></a><span class="st">[2024-07-17 07:46:36.929464][INFO][trainer:885] - step=340 loss=1.350888 dt=0.284436 dtf=0.005199 dtb=0.011287 sps=14.062893 sps_per_gpu=3.515723 tps=921625.744709 tps_per_gpu=230406.436177 mfu=45.539549 train_loss=1.495372 val_loss=1.713714</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="wordplay" class="level1 centeredslide" height="100%" data-backgound-color="white">
<h1 class="centeredslide" height="100%" data-backgound-color="white"><a href="https://github.com/saforem2/wordplay"><code>wordplay</code> 🎮💬</a></h1>
<ul>
<li>Link<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> to <a href="https://asciinema.org/a/668462">video</a></li>
</ul>
<script src="https://asciinema.org/a/668462.js" id="asciicast-668462" async="true" style="max-height: 90%!important;"></script>
<p>Example: Training a LLM to talk like Shakespeare using <a href="https://github.com/saforem2/wordplay"><code>saforem2/wordplay</code> 🎮💬</a></p>
</section>
<section id="thank-you" class="level1" data-background-color="white">
<h1 data-background-color="white">❤️ Thank you!</h1>
<ul>
<li><p>Organizers</p></li>
<li><p>Feel free to reach out!</p>
<p><split even=""></split></p>
<p><a href="https://samforeman.me"><i class="fas fa-home"></i></a> <a href="mailto:///foremans@anl.gov"><i class="far fa-paper-plane"></i></a> <a href="https://www.twitter.com/saforem2"><i class="fab fa-twitter"></i></a></p>
<p></p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="🙏 Acknowledgements">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
🙏 Acknowledgements
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357.</p>
</div>
</div>
</div>
</section>
<section id="extras" class="level1" data-background-color="white">
<h1 data-background-color="white">Extras</h1>
<section id="transformer-architecture" class="level2" data-background-color="white">
<h2 data-background-color="white" class="anchored" data-anchor-id="transformer-architecture">Transformer Architecture</h2>
<div id="fig-transformer" class="quarto-float quarto-figure quarto-figure-center anchored" style="height:auto; text-align:center;">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<p><img src="https://raw.githubusercontent.com/saforem2/llm-lunch-talk/main/docs/assets/diagrams/transformer.svg" width="20%" align="center" class="figure-img"></p>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: <span class="citation" data-cites="vaswani2017attention">Vaswani et al. (<a href="#ref-vaswani2017attention" role="doc-biblioref">2017</a>)</span>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="references" class="level1" data-background-color="white">
<h1 data-background-color="white">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
<div id="ref-yang2023harnessing" class="csl-entry" role="listitem">
Yang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. <span>“Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.”</span> <a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a>.
</div>
<div id="ref-yao2023tree" class="csl-entry" role="listitem">
Yao, Shunyu, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. <span>“Tree of Thoughts: Deliberate Problem Solving with Large Language Models.”</span> <a href="https://arxiv.org/abs/2305.10601">https://arxiv.org/abs/2305.10601</a>.
</div>
</div>



</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Mostly getting supercomputers to stop yelling at each other <i class="fa-solid fa-network-wired" aria-label="network-wired"></i><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://github.com/Hannibal046/Awesome-LLM"><i class="fa-brands fa-github" aria-label="github"></i> <code>Hannibal046/Awesome-LLM</code></a> <a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Figure from <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://huggingface.co/docs/transformers/v4.15.0/parallelism">🤗 Model Parallelism</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/">Blog Post</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://arxiv.org/abs/2104.04473">Efficient Large-Scale Language Model Training on GPU Clusters</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>idk why it doesn’t render correctly in the slide (seems like refreshing helps?)<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-foreman2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Foreman, Sam. 2024. <span>“LLMs on Polaris.”</span> July 17. <a href="https://samforeman.me/talks/llms-on-polaris/">https://samforeman.me/talks/llms-on-polaris/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/samforeman\.me");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="dark">
<input type="hidden" id="giscus-alt-theme" value="light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "saforem2/personal_site";
    script.dataset.repoId = "R_kgDOGbjyRw";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOGbjyR84CjWfk";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../talks/llms-at-scale/index.html" class="pagination-link" aria-label="Training LLMs at Scale">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Training LLMs at Scale</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../talks/test/slides.html" class="pagination-link" aria-label="Test Rendering on Mobile">
        <span class="nav-page-text">Test Rendering on Mobile</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb16" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><a href="#cb16-1"></a><span class="co">---</span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="an">title:</span><span class="co"> "LLMs on Polaris"</span></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="an">location:</span><span class="co"> SciFM Summer School '24</span></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="an">location-url:</span><span class="co"> "https://scifm.ai/summer_school.html"</span></span>
<span id="cb16-5"><a href="#cb16-5"></a><span class="co"># location: "[SciFM Summer School '24](https://scifm.ai/summer_school.html)"</span></span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="an">image:</span><span class="co"> "https://raw.githubusercontent.com/saforem2/personal_site/main/talks/llms-on-polaris/assets/thumbnail.png"</span></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="an">toc:</span><span class="co"> false</span></span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="an">date:</span><span class="co"> 2024-07-17</span></span>
<span id="cb16-9"><a href="#cb16-9"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb16-10"><a href="#cb16-10"></a><span class="co"># author-title: ""</span></span>
<span id="cb16-11"><a href="#cb16-11"></a><span class="co"># affiliation-title: ""</span></span>
<span id="cb16-12"><a href="#cb16-12"></a><span class="co"># published-title: ""</span></span>
<span id="cb16-13"><a href="#cb16-13"></a><span class="co"># modified-title: ""</span></span>
<span id="cb16-14"><a href="#cb16-14"></a><span class="an">title-block-categories:</span><span class="co"> false</span></span>
<span id="cb16-15"><a href="#cb16-15"></a><span class="an">number-sections:</span><span class="co"> false</span></span>
<span id="cb16-16"><a href="#cb16-16"></a><span class="co"># ascii: true</span></span>
<span id="cb16-17"><a href="#cb16-17"></a><span class="co"># bibliography: references.bib</span></span>
<span id="cb16-18"><a href="#cb16-18"></a><span class="an">appendix-cite-as:</span><span class="co"> display</span></span>
<span id="cb16-19"><a href="#cb16-19"></a><span class="an">editor:</span></span>
<span id="cb16-20"><a href="#cb16-20"></a><span class="co">  render-on-save: true</span></span>
<span id="cb16-21"><a href="#cb16-21"></a><span class="an">twitter-card:</span></span>
<span id="cb16-22"><a href="#cb16-22"></a><span class="co">  image: "https://raw.githubusercontent.com/saforem2/personal_site/main/talks/llms-on-polaris/assets/thumbnail.png"</span></span>
<span id="cb16-23"><a href="#cb16-23"></a><span class="co">  site: "saforem2"</span></span>
<span id="cb16-24"><a href="#cb16-24"></a><span class="co">  creator: "saforem2"</span></span>
<span id="cb16-25"><a href="#cb16-25"></a><span class="co">  title: "LLMs On Polaris"</span></span>
<span id="cb16-26"><a href="#cb16-26"></a><span class="co">  description: "Training LLMs at Scale on Polaris at ALCF"</span></span>
<span id="cb16-27"><a href="#cb16-27"></a><span class="an">open-graph:</span></span>
<span id="cb16-28"><a href="#cb16-28"></a><span class="co">  title: "LLMs On Polaris"</span></span>
<span id="cb16-29"><a href="#cb16-29"></a><span class="co">  description: "Training LLMs at Scale on Polaris at ALCF"</span></span>
<span id="cb16-30"><a href="#cb16-30"></a><span class="co">  image: "https://raw.githubusercontent.com/saforem2/personal_site/main/talks/llms-on-polaris/assets/thumbnail.png"</span></span>
<span id="cb16-31"><a href="#cb16-31"></a><span class="co"># author:</span></span>
<span id="cb16-32"><a href="#cb16-32"></a><span class="co">#   name: Sam Foreman</span></span>
<span id="cb16-33"><a href="#cb16-33"></a><span class="co">#   url: https://samforeman.me</span></span>
<span id="cb16-34"><a href="#cb16-34"></a><span class="co">#   orcid: 0000-0002-9981-0876</span></span>
<span id="cb16-35"><a href="#cb16-35"></a><span class="co">#   email: foremans@anl.gov</span></span>
<span id="cb16-36"><a href="#cb16-36"></a><span class="co">#   affiliation: Argonne National Laboratory</span></span>
<span id="cb16-37"><a href="#cb16-37"></a><span class="co">#   affiliation-url: https://alcf.anl.gov/about/people/sam-foreman</span></span>
<span id="cb16-38"><a href="#cb16-38"></a><span class="an">citation:</span></span>
<span id="cb16-39"><a href="#cb16-39"></a><span class="co">   author: Sam Foreman</span></span>
<span id="cb16-40"><a href="#cb16-40"></a><span class="co">   type: speech</span></span>
<span id="cb16-41"><a href="#cb16-41"></a><span class="co">   # genre: "Presentation at the 2023 International Symposium on Lattice Field Theory"</span></span>
<span id="cb16-42"><a href="#cb16-42"></a><span class="co">   # container-title: https://indico.fnal.gov/event/57249/contributions/271305/</span></span>
<span id="cb16-43"><a href="#cb16-43"></a><span class="co">   # title: "MLMC: Machine Learning Monte Carlo for Lattice Gauge Theory"</span></span>
<span id="cb16-44"><a href="#cb16-44"></a><span class="co">   # url: https://saforem2.github.io/lattice23</span></span>
<span id="cb16-45"><a href="#cb16-45"></a><span class="co">   # abstract: |</span></span>
<span id="cb16-46"><a href="#cb16-46"></a><span class="co">   #   We present a trainable framework for efficiently generating gauge</span></span>
<span id="cb16-47"><a href="#cb16-47"></a><span class="co">   #   configurations, and discuss ongoing work in this direction. In particular, we</span></span>
<span id="cb16-48"><a href="#cb16-48"></a><span class="co">   #   consider the problem of sampling configurations from a 4D 𝑆𝑈(3) lattice gauge</span></span>
<span id="cb16-49"><a href="#cb16-49"></a><span class="co">   #   theory, and consider a generalized leapfrog integrator in the molecular</span></span>
<span id="cb16-50"><a href="#cb16-50"></a><span class="co">   #   dynamics update that can be trained to improve sampling efficiency.</span></span>
<span id="cb16-51"><a href="#cb16-51"></a><span class="an">format:</span></span>
<span id="cb16-52"><a href="#cb16-52"></a><span class="co">  html: default</span></span>
<span id="cb16-53"><a href="#cb16-53"></a><span class="co">    # shift-heading-level-by: 1</span></span>
<span id="cb16-54"><a href="#cb16-54"></a><span class="co">  revealjs:</span></span>
<span id="cb16-55"><a href="#cb16-55"></a><span class="co">    pdf-separate-fragments: true</span></span>
<span id="cb16-56"><a href="#cb16-56"></a><span class="co">    center: true</span></span>
<span id="cb16-57"><a href="#cb16-57"></a><span class="co">    output-file: slides.html</span></span>
<span id="cb16-58"><a href="#cb16-58"></a><span class="co">    # shift-heading-level-by: 1</span></span>
<span id="cb16-59"><a href="#cb16-59"></a><span class="co">    # footer: "[samforeman.me/talks/hpc-user-forum/slides](https://samforeman.me/talks/hpc-user-forum/slides)"</span></span>
<span id="cb16-60"><a href="#cb16-60"></a><span class="co">    # slide-url: https://samforeman.me/talks/llms-on-polaris/slides.html</span></span>
<span id="cb16-61"><a href="#cb16-61"></a><span class="co">    # template-partials:</span></span>
<span id="cb16-62"><a href="#cb16-62"></a><span class="co">    #  - title-slide.html</span></span>
<span id="cb16-63"><a href="#cb16-63"></a><span class="co">    # title-slide-attributes:</span></span>
<span id="cb16-64"><a href="#cb16-64"></a><span class="co">    #   # data-background-iframe: "file:///iframes/center-of-universe/index.html"</span></span>
<span id="cb16-65"><a href="#cb16-65"></a><span class="co">    #   data-background-iframe: https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html</span></span>
<span id="cb16-66"><a href="#cb16-66"></a><span class="co">    #   data-background-size: contain</span></span>
<span id="cb16-67"><a href="#cb16-67"></a><span class="co">    #   # data-background-color: dark</span></span>
<span id="cb16-68"><a href="#cb16-68"></a><span class="co">    #   # background-color: dark</span></span>
<span id="cb16-69"><a href="#cb16-69"></a><span class="co">    # shift-heading-level-by: -1</span></span>
<span id="cb16-70"><a href="#cb16-70"></a><span class="co">  # revealjs:</span></span>
<span id="cb16-71"><a href="#cb16-71"></a><span class="co">  #   code-line-numbers: false</span></span>
<span id="cb16-72"><a href="#cb16-72"></a><span class="co">  #   code-link: false</span></span>
<span id="cb16-73"><a href="#cb16-73"></a><span class="co">  #   code-copy: false</span></span>
<span id="cb16-74"><a href="#cb16-74"></a><span class="co">  #   # callout-appearance: simple</span></span>
<span id="cb16-75"><a href="#cb16-75"></a><span class="co">  #   # syntax-definitions:</span></span>
<span id="cb16-76"><a href="#cb16-76"></a><span class="co">  #   #   - ./docs/python.xml</span></span>
<span id="cb16-77"><a href="#cb16-77"></a><span class="co">  #   scrollable: true</span></span>
<span id="cb16-78"><a href="#cb16-78"></a><span class="co">  #   title-block-style: none</span></span>
<span id="cb16-79"><a href="#cb16-79"></a><span class="co">  #   slide-number: c</span></span>
<span id="cb16-80"><a href="#cb16-80"></a><span class="co">  #   title-slide-style: default</span></span>
<span id="cb16-81"><a href="#cb16-81"></a><span class="co">  #   chalkboard:</span></span>
<span id="cb16-82"><a href="#cb16-82"></a><span class="co">  #     buttons: false</span></span>
<span id="cb16-83"><a href="#cb16-83"></a><span class="co">  #   auto-animate: true</span></span>
<span id="cb16-84"><a href="#cb16-84"></a><span class="co">  #   reference-location: section</span></span>
<span id="cb16-85"><a href="#cb16-85"></a><span class="co">  #   touch: true</span></span>
<span id="cb16-86"><a href="#cb16-86"></a><span class="co">  #   link-external-newwindow: true</span></span>
<span id="cb16-87"><a href="#cb16-87"></a><span class="co">  #   pause: false</span></span>
<span id="cb16-88"><a href="#cb16-88"></a><span class="co">  #   footnotes-hover: true</span></span>
<span id="cb16-89"><a href="#cb16-89"></a><span class="co">  #   citations-hover: true</span></span>
<span id="cb16-90"><a href="#cb16-90"></a><span class="co">  #   preview-links: auto</span></span>
<span id="cb16-91"><a href="#cb16-91"></a><span class="co">  #   controls-tutorial: true</span></span>
<span id="cb16-92"><a href="#cb16-92"></a><span class="co">  #   controls: false</span></span>
<span id="cb16-93"><a href="#cb16-93"></a><span class="co">  #   logo: "https://raw.githubusercontent.com/saforem2/llm-lunch-talk/main/docs/assets/anl.svg"</span></span>
<span id="cb16-94"><a href="#cb16-94"></a><span class="co">  #   history: false</span></span>
<span id="cb16-95"><a href="#cb16-95"></a><span class="co">  #   highlight-style: "atom-one"</span></span>
<span id="cb16-96"><a href="#cb16-96"></a><span class="co">  #   # theme: [css/dark.scss]</span></span>
<span id="cb16-97"><a href="#cb16-97"></a><span class="co">  #   # callout-style: default</span></span>
<span id="cb16-98"><a href="#cb16-98"></a><span class="co">  #   css:</span></span>
<span id="cb16-99"><a href="#cb16-99"></a><span class="co">  #     # - ../../css/text.css</span></span>
<span id="cb16-100"><a href="#cb16-100"></a><span class="co">  #     # - ../../css/default.css</span></span>
<span id="cb16-101"><a href="#cb16-101"></a><span class="co">  #     - ../../css/custom.css</span></span>
<span id="cb16-102"><a href="#cb16-102"></a><span class="co">  #     # - ../../css/reveal/_callouts.scss</span></span>
<span id="cb16-103"><a href="#cb16-103"></a><span class="co">  #     # - ../../css/reveal/light/default.css</span></span>
<span id="cb16-104"><a href="#cb16-104"></a><span class="co">  #     # - ../../css/reveal/light/callouts.css</span></span>
<span id="cb16-105"><a href="#cb16-105"></a><span class="co">  #   theme:</span></span>
<span id="cb16-106"><a href="#cb16-106"></a><span class="co">  #     # - ../../css/reveal/light/light.scss</span></span>
<span id="cb16-107"><a href="#cb16-107"></a><span class="co">  #     - white</span></span>
<span id="cb16-108"><a href="#cb16-108"></a><span class="co">  #     - ../../css/reveal/reveal.scss</span></span>
<span id="cb16-109"><a href="#cb16-109"></a><span class="co">  #     - ../../css/common.scss</span></span>
<span id="cb16-110"><a href="#cb16-110"></a><span class="co">  #     - ../../css/light.scss</span></span>
<span id="cb16-111"><a href="#cb16-111"></a><span class="co">  #     - ../../css/syntax-light.scss</span></span>
<span id="cb16-112"><a href="#cb16-112"></a><span class="co">  #     - ../../css/callout-cards.scss</span></span>
<span id="cb16-113"><a href="#cb16-113"></a><span class="co">  #   self-contained: false</span></span>
<span id="cb16-114"><a href="#cb16-114"></a><span class="co">  #   embed-resources: false</span></span>
<span id="cb16-115"><a href="#cb16-115"></a><span class="co">  #   self-contained-math: false</span></span>
<span id="cb16-116"><a href="#cb16-116"></a><span class="co">  #   center: true</span></span>
<span id="cb16-117"><a href="#cb16-117"></a><span class="co">  #   default-image-extension: svg</span></span>
<span id="cb16-118"><a href="#cb16-118"></a><span class="co">  #   code-overflow: scroll</span></span>
<span id="cb16-119"><a href="#cb16-119"></a><span class="co">  #   html-math-method: katex</span></span>
<span id="cb16-120"><a href="#cb16-120"></a><span class="co">  #   fig-align: center</span></span>
<span id="cb16-121"><a href="#cb16-121"></a><span class="co">    # css:</span></span>
<span id="cb16-122"><a href="#cb16-122"></a><span class="co">    #   # - css/text.css</span></span>
<span id="cb16-123"><a href="#cb16-123"></a><span class="co">    #   # - css/bulma.css</span></span>
<span id="cb16-124"><a href="#cb16-124"></a><span class="co">    #   - css/default.css</span></span>
<span id="cb16-125"><a href="#cb16-125"></a><span class="co">    #   - css/custom.css</span></span>
<span id="cb16-126"><a href="#cb16-126"></a><span class="co">    #   # - css/lastfm.css</span></span>
<span id="cb16-127"><a href="#cb16-127"></a><span class="co">    #   # - css/quarto-callouts.css</span></span>
<span id="cb16-128"><a href="#cb16-128"></a><span class="co">    #   # - css/fonts.css</span></span>
<span id="cb16-129"><a href="#cb16-129"></a><span class="co">    #   # - css/callouts.css</span></span>
<span id="cb16-130"><a href="#cb16-130"></a><span class="co">    #   # - css/obsidian.css</span></span>
<span id="cb16-131"><a href="#cb16-131"></a><span class="co">    #   # - css/markdown.css</span></span>
<span id="cb16-132"><a href="#cb16-132"></a><span class="co">    #   # - css/profile.css</span></span>
<span id="cb16-133"><a href="#cb16-133"></a><span class="co">    # theme:</span></span>
<span id="cb16-134"><a href="#cb16-134"></a><span class="co">    #   dark:</span></span>
<span id="cb16-135"><a href="#cb16-135"></a><span class="co">    #     - pandoc</span></span>
<span id="cb16-136"><a href="#cb16-136"></a><span class="co">    #     # - css/quarto.scss</span></span>
<span id="cb16-137"><a href="#cb16-137"></a><span class="co">    #     - css/now_playing.scss</span></span>
<span id="cb16-138"><a href="#cb16-138"></a><span class="co">    #     # - css/_sketchy.scss</span></span>
<span id="cb16-139"><a href="#cb16-139"></a><span class="co">    #     # - css/code.scss</span></span>
<span id="cb16-140"><a href="#cb16-140"></a><span class="co">    #     - css/common.scss</span></span>
<span id="cb16-141"><a href="#cb16-141"></a><span class="co">    #     - css/dark.scss</span></span>
<span id="cb16-142"><a href="#cb16-142"></a><span class="co">    #     - css/syntax-dark.scss</span></span>
<span id="cb16-143"><a href="#cb16-143"></a><span class="co">    #     - css/callout-cards.scss</span></span>
<span id="cb16-144"><a href="#cb16-144"></a><span class="co">    #   light:</span></span>
<span id="cb16-145"><a href="#cb16-145"></a><span class="co">    #     - pandoc</span></span>
<span id="cb16-146"><a href="#cb16-146"></a><span class="co">    #     # - css/quarto.scss</span></span>
<span id="cb16-147"><a href="#cb16-147"></a><span class="co">    #     - css/now_playing.scss</span></span>
<span id="cb16-148"><a href="#cb16-148"></a><span class="co">    #     # - css/_sketchy.scss</span></span>
<span id="cb16-149"><a href="#cb16-149"></a><span class="co">    #     - css/common.scss</span></span>
<span id="cb16-150"><a href="#cb16-150"></a><span class="co">    #     - css/light.scss</span></span>
<span id="cb16-151"><a href="#cb16-151"></a><span class="co">    #     - css/syntax-light.scss</span></span>
<span id="cb16-152"><a href="#cb16-152"></a><span class="co">    #     - css/callout-cards.scss</span></span>
<span id="cb16-153"><a href="#cb16-153"></a><span class="co">    # css:</span></span>
<span id="cb16-154"><a href="#cb16-154"></a><span class="co">    #   - css/callouts-html.css</span></span>
<span id="cb16-155"><a href="#cb16-155"></a><span class="co">    # #   - css/default.css</span></span>
<span id="cb16-156"><a href="#cb16-156"></a><span class="co">    # theme:</span></span>
<span id="cb16-157"><a href="#cb16-157"></a><span class="co">    #   - white</span></span>
<span id="cb16-158"><a href="#cb16-158"></a><span class="co">    #   - css/light.scss</span></span>
<span id="cb16-159"><a href="#cb16-159"></a><span class="co">    #   - css/common.scss</span></span>
<span id="cb16-160"><a href="#cb16-160"></a><span class="co">    #   - css/syntax-light.scss</span></span>
<span id="cb16-161"><a href="#cb16-161"></a><span class="co">    # mermaid:</span></span>
<span id="cb16-162"><a href="#cb16-162"></a><span class="co">    #   theme: grey</span></span>
<span id="cb16-163"><a href="#cb16-163"></a><span class="co">  # gfm:</span></span>
<span id="cb16-164"><a href="#cb16-164"></a><span class="co">  #   author: Sam Foreman</span></span>
<span id="cb16-165"><a href="#cb16-165"></a><span class="co">  #   output-file: "README.md"</span></span>
<span id="cb16-166"><a href="#cb16-166"></a><span class="co">---</span></span>
<span id="cb16-167"><a href="#cb16-167"></a></span>
<span id="cb16-168"><a href="#cb16-168"></a><span class="fu"># {.centeredslide background-color="white" background-iframe="https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html" loading="lazy"}</span></span>
<span id="cb16-169"><a href="#cb16-169"></a></span>
<span id="cb16-170"><a href="#cb16-170"></a>::: {style="background-color: #f5f5f5; opacity:0.97; border-radius: 10px; text-align:center; padding: 0px; padding-left: 1.5em; padding-right: 1.5em; max-width: min-content; min-width: max-content; margin-left: auto; margin-right: auto; padding-top: 0.2em; padding-bottom: 0.2em; line-height: 1.5em!important;"}</span>
<span id="cb16-171"><a href="#cb16-171"></a><span class="co">[</span><span class="ot">LLMs on Polaris</span><span class="co">]</span>{style="color:#333333; font-size:1.5em; font-weight: bold;"}</span>
<span id="cb16-172"><a href="#cb16-172"></a><span class="co">[</span><span class="ot">&lt;br&gt;&amp;nbsp;</span><span class="co">]</span>{style="padding-bottom: 0.5rem;"}  </span>
<span id="cb16-173"><a href="#cb16-173"></a><span class="co">[</span><span class="ot">🏡 Sam Foreman</span><span class="co">](https://samforeman.me)</span>  </span>
<span id="cb16-174"><a href="#cb16-174"></a>[<span class="co">[</span><span class="ot">SciFM Summer School 24</span><span class="co">](https://indico.fnal.gov/event/57249/contributions/271305/)</span>]{.dim-text style="font-size: 0.8em"}  </span>
<span id="cb16-175"><a href="#cb16-175"></a>:::</span>
<span id="cb16-176"><a href="#cb16-176"></a></span>
<span id="cb16-177"><a href="#cb16-177"></a>::: footer</span>
<span id="cb16-178"><a href="#cb16-178"></a><span class="co">[</span><span class="ot">2024-07-17</span><span class="co">]</span>{.dim-text}</span>
<span id="cb16-179"><a href="#cb16-179"></a>:::</span>
<span id="cb16-180"><a href="#cb16-180"></a></span>
<span id="cb16-181"><a href="#cb16-181"></a><span class="fu"># 👤 [Sam Foreman](https://samforeman.me) {style="font-size: 0.9em;" background-color="white"}</span></span>
<span id="cb16-182"><a href="#cb16-182"></a></span>
<span id="cb16-183"><a href="#cb16-183"></a><span class="ss">- </span>I'm a Computational Scientist in the <span class="co">[</span><span class="ot">Data Science Group</span><span class="co">](https://www.alcf.anl.gov/about/people/group/506)</span> at <span class="co">[</span><span class="ot">ALCF</span><span class="co">](https://alcf.anl.gov)</span><span class="ot">[^1]</span>.</span>
<span id="cb16-184"><a href="#cb16-184"></a><span class="ss">  - </span>Personal Website: <span class="co">[</span><span class="ot">samforeman.me</span><span class="co">](https://samforeman.me)</span></span>
<span id="cb16-185"><a href="#cb16-185"></a><span class="ss">  - </span>Background: <span class="co">[</span><span class="ot">`{ML, LLMs, AI4Science, HEP, Lattice QCD, MCMC, Generative Modeling, ...}`</span><span class="co">]</span>{}</span>
<span id="cb16-186"><a href="#cb16-186"></a></span>
<span id="cb16-187"><a href="#cb16-187"></a><span class="ot">[^1]: </span>Mostly getting supercomputers to stop yelling at each other {{&lt; fa solid network-wired &gt;}}</span>
<span id="cb16-188"><a href="#cb16-188"></a></span>
<span id="cb16-189"><a href="#cb16-189"></a>Ongoing / recent work:</span>
<span id="cb16-190"><a href="#cb16-190"></a></span>
<span id="cb16-191"><a href="#cb16-191"></a>:::: {.columns}</span>
<span id="cb16-192"><a href="#cb16-192"></a></span>
<span id="cb16-193"><a href="#cb16-193"></a>::: {.column width="50%"}</span>
<span id="cb16-194"><a href="#cb16-194"></a></span>
<span id="cb16-195"><a href="#cb16-195"></a><span class="ss">- </span><span class="co">[</span><span class="ot">AI + Science</span><span class="co">](https://github.com/saforem2/)</span></span>
<span id="cb16-196"><a href="#cb16-196"></a><span class="ss">  - </span>[Building better sampling methods for Lattice</span>
<span id="cb16-197"><a href="#cb16-197"></a>  QCD](https://github.com/saforem2/l2hmc-qcd)</span>
<span id="cb16-198"><a href="#cb16-198"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics</span><span class="co">](https://www.biorxiv.org/content/10.1101/2022.10.10.511571v2)</span></span>
<span id="cb16-199"><a href="#cb16-199"></a><span class="ss">  - </span>[Foundation models for long term climate</span>
<span id="cb16-200"><a href="#cb16-200"></a>  forecasting](https://saforem2.github.io/climate-analysis)</span>
<span id="cb16-201"><a href="#cb16-201"></a></span>
<span id="cb16-202"><a href="#cb16-202"></a>:::</span>
<span id="cb16-203"><a href="#cb16-203"></a></span>
<span id="cb16-204"><a href="#cb16-204"></a>::: {.column width="50%"}</span>
<span id="cb16-205"><a href="#cb16-205"></a></span>
<span id="cb16-206"><a href="#cb16-206"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Scaling Large Language Models</span><span class="co">](https://github.com/saforem2/Megatron-DS-Benchmarking)</span></span>
<span id="cb16-207"><a href="#cb16-207"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Optimizing distibuted training across thousands of GPUs</span><span class="co">](https://github.com/argonne-lcf/mlprof)</span></span>
<span id="cb16-208"><a href="#cb16-208"></a><span class="ss">- </span>Building new parallelism techniques for efficient scaling</span>
<span id="cb16-209"><a href="#cb16-209"></a><span class="ss">- </span>Generative modeling (esp. for physical systems)</span>
<span id="cb16-210"><a href="#cb16-210"></a></span>
<span id="cb16-211"><a href="#cb16-211"></a>:::</span>
<span id="cb16-212"><a href="#cb16-212"></a></span>
<span id="cb16-213"><a href="#cb16-213"></a>::::</span>
<span id="cb16-214"><a href="#cb16-214"></a></span>
<span id="cb16-215"><a href="#cb16-215"></a><span class="fu"># Polaris @ ALCF {background-color="white"}</span></span>
<span id="cb16-216"><a href="#cb16-216"></a></span>
<span id="cb16-217"><a href="#cb16-217"></a>Refer to <span class="co">[</span><span class="ot">Getting Started</span><span class="co">](https://docs.alcf.anl.gov/polaris/getting-started/)</span></span>
<span id="cb16-218"><a href="#cb16-218"></a>for additional information.</span>
<span id="cb16-219"><a href="#cb16-219"></a></span>
<span id="cb16-220"><a href="#cb16-220"></a><span class="ss">- </span>Login:</span>
<span id="cb16-221"><a href="#cb16-221"></a></span>
<span id="cb16-222"><a href="#cb16-222"></a>  <span class="in">```bash</span></span>
<span id="cb16-223"><a href="#cb16-223"></a>  <span class="fu">ssh</span> <span class="op">&lt;</span>username<span class="op">&gt;</span>@polaris.alcf.anl.gov</span>
<span id="cb16-224"><a href="#cb16-224"></a>  <span class="in">```</span></span>
<span id="cb16-225"><a href="#cb16-225"></a></span>
<span id="cb16-226"><a href="#cb16-226"></a><span class="ss">- </span>Modules (+ using <span class="in">`conda`</span>):</span>
<span id="cb16-227"><a href="#cb16-227"></a></span>
<span id="cb16-228"><a href="#cb16-228"></a>  <span class="in">```bash</span></span>
<span id="cb16-229"><a href="#cb16-229"></a>  <span class="ex">module</span> use /soft/modulefiles</span>
<span id="cb16-230"><a href="#cb16-230"></a>  <span class="ex">module</span> load conda</span>
<span id="cb16-231"><a href="#cb16-231"></a>  <span class="in">```</span></span>
<span id="cb16-232"><a href="#cb16-232"></a></span>
<span id="cb16-233"><a href="#cb16-233"></a><span class="fu"># Getting Started {background-color="white"}</span></span>
<span id="cb16-234"><a href="#cb16-234"></a></span>
<span id="cb16-235"><a href="#cb16-235"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Running Jobs</span><span class="co">](https://docs.alcf.anl.gov/running-jobs/job-and-queue-scheduling/)</span></span>
<span id="cb16-236"><a href="#cb16-236"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">example job scripts</span><span class="co">](https://docs.alcf.anl.gov/running-jobs/example-job-scripts/)</span></span>
<span id="cb16-237"><a href="#cb16-237"></a></span>
<span id="cb16-238"><a href="#cb16-238"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Proxy</span><span class="co">](https://docs.alcf.anl.gov/polaris/getting-started/#proxy)</span>:</span>
<span id="cb16-239"><a href="#cb16-239"></a></span>
<span id="cb16-240"><a href="#cb16-240"></a>    <span class="in">```bash</span></span>
<span id="cb16-241"><a href="#cb16-241"></a>    <span class="co"># proxy settings</span></span>
<span id="cb16-242"><a href="#cb16-242"></a>    <span class="bu">export</span> <span class="va">HTTP_PROXY</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb16-243"><a href="#cb16-243"></a>    <span class="bu">export</span> <span class="va">HTTPS_PROXY</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb16-244"><a href="#cb16-244"></a>    <span class="bu">export</span> <span class="va">http_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb16-245"><a href="#cb16-245"></a>    <span class="bu">export</span> <span class="va">https_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb16-246"><a href="#cb16-246"></a>    <span class="bu">export</span> <span class="va">ftp_proxy</span><span class="op">=</span><span class="st">"http://proxy.alcf.anl.gov:3128"</span></span>
<span id="cb16-247"><a href="#cb16-247"></a>    <span class="bu">export</span> <span class="va">no_proxy</span><span class="op">=</span><span class="st">"admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov"</span></span>
<span id="cb16-248"><a href="#cb16-248"></a>    <span class="in">```</span></span>
<span id="cb16-249"><a href="#cb16-249"></a></span>
<span id="cb16-250"><a href="#cb16-250"></a><span class="ss">- </span>Getting Help:</span>
<span id="cb16-251"><a href="#cb16-251"></a></span>
<span id="cb16-252"><a href="#cb16-252"></a>  <span class="co">[</span><span class="ot">support@alcf.anl.gov</span><span class="co">](mailto:support@alcf.anl.gov)</span></span>
<span id="cb16-253"><a href="#cb16-253"></a></span>
<span id="cb16-254"><a href="#cb16-254"></a><span class="fu"># Polaris {background-color="white"}</span></span>
<span id="cb16-255"><a href="#cb16-255"></a></span>
<span id="cb16-256"><a href="#cb16-256"></a><span class="ss">- </span>Polaris is a 560 node HPE Apollo 6500 Gen 10+ based system.</span>
<span id="cb16-257"><a href="#cb16-257"></a></span>
<span id="cb16-258"><a href="#cb16-258"></a><span class="ss">- </span>Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32 core CPU with:</span>
<span id="cb16-259"><a href="#cb16-259"></a><span class="ss">  - </span>512 GB of DDR4 RAM</span>
<span id="cb16-260"><a href="#cb16-260"></a><span class="ss">  - </span>4 (four) NVIDIA A100 GPUs connected via NVLink</span>
<span id="cb16-261"><a href="#cb16-261"></a><span class="ss">  - </span>2 (a pair) of local 1.6TB of SSDs in RAID0 for the users use</span>
<span id="cb16-262"><a href="#cb16-262"></a><span class="ss">  - </span>2 (a pair) of Slingshot 11 network adapters.</span>
<span id="cb16-263"><a href="#cb16-263"></a></span>
<span id="cb16-264"><a href="#cb16-264"></a><span class="ss">- </span>There are two nodes per chassis, seven chassis per rack, and 40 racks for a</span>
<span id="cb16-265"><a href="#cb16-265"></a>total of 560 nodes.</span>
<span id="cb16-266"><a href="#cb16-266"></a></span>
<span id="cb16-267"><a href="#cb16-267"></a><span class="fu"># Polaris Compute Nodes {background-color="white"}</span></span>
<span id="cb16-268"><a href="#cb16-268"></a></span>
<span id="cb16-269"><a href="#cb16-269"></a><span class="pp">|</span> POLARIS COMPUTE <span class="pp">|</span> DESCRIPTION       <span class="pp">|</span> PER NODE <span class="pp">|</span>   AGGREGATE   <span class="pp">|</span></span>
<span id="cb16-270"><a href="#cb16-270"></a><span class="pp">|-----------------|-------------------|----------|---------------|</span></span>
<span id="cb16-271"><a href="#cb16-271"></a><span class="pp">|</span> Processor$^{1}$  <span class="pp">|</span> 2.8 GHz 7543P     <span class="pp">|</span>    1     <span class="pp">|</span>      560      <span class="pp">|</span></span>
<span id="cb16-272"><a href="#cb16-272"></a><span class="pp">|</span> Cores/Threads   <span class="pp">|</span> AMD Zen 3 (Milan) <span class="pp">|</span> 32/64    <span class="pp">|</span> 17,920/35,840 <span class="pp">|</span></span>
<span id="cb16-273"><a href="#cb16-273"></a><span class="pp">|</span> RAM$^{2}$       <span class="pp">|</span> DDR4              <span class="pp">|</span> 512 GiB  <span class="pp">|</span> 280 TiB       <span class="pp">|</span></span>
<span id="cb16-274"><a href="#cb16-274"></a><span class="pp">|</span> GPUS            <span class="pp">|</span> NVIDIA A100       <span class="pp">|</span>    4     <span class="pp">|</span>     2240      <span class="pp">|</span></span>
<span id="cb16-275"><a href="#cb16-275"></a><span class="pp">|</span> Local SSD       <span class="pp">|</span> 1.6 TB <span class="pp">|</span> 2/3.2 TB <span class="pp">|</span> 1120/1.8PB <span class="pp">|</span></span>
<span id="cb16-276"><a href="#cb16-276"></a></span>
<span id="cb16-277"><a href="#cb16-277"></a>: Details {.striped .hover}</span>
<span id="cb16-278"><a href="#cb16-278"></a></span>
<span id="cb16-279"><a href="#cb16-279"></a>::: aside</span>
<span id="cb16-280"><a href="#cb16-280"></a></span>
<span id="cb16-281"><a href="#cb16-281"></a><span class="ss">1. </span>256MB shared L3 cache, 512KB L2 cache per core, 32 KB L1 cache per core</span>
<span id="cb16-282"><a href="#cb16-282"></a><span class="ss">2. </span>8 memory channels rated at 204.8 GiB/s</span>
<span id="cb16-283"><a href="#cb16-283"></a></span>
<span id="cb16-284"><a href="#cb16-284"></a>:::</span>
<span id="cb16-285"><a href="#cb16-285"></a></span>
<span id="cb16-286"><a href="#cb16-286"></a><span class="co">&lt;!-- ::: --&gt;</span></span>
<span id="cb16-287"><a href="#cb16-287"></a></span>
<span id="cb16-288"><a href="#cb16-288"></a><span class="fu"># Polaris A100 GPU Information {background-color="white"}</span></span>
<span id="cb16-289"><a href="#cb16-289"></a></span>
<span id="cb16-290"><a href="#cb16-290"></a><span class="pp">|</span> DESCRIPTION <span class="pp">|</span> A100 PCIe <span class="pp">|</span> A100 HGX (Polaris) <span class="pp">|</span></span>
<span id="cb16-291"><a href="#cb16-291"></a><span class="pp">|-------------|----------|-----------|</span></span>
<span id="cb16-292"><a href="#cb16-292"></a><span class="pp">|</span> GPU Memory <span class="pp">|</span> 40 GiB HBM2 <span class="pp">|</span> 160 GiB HBM2 <span class="pp">|</span></span>
<span id="cb16-293"><a href="#cb16-293"></a><span class="pp">|</span> GPU Memory BW <span class="pp">|</span> 1.6 TB/s <span class="pp">|</span> 6.4 TB/s <span class="pp">|</span></span>
<span id="cb16-294"><a href="#cb16-294"></a><span class="pp">|</span> Interconnect <span class="pp">|</span> PCIe Gen4 64 GB/s <span class="pp">|</span> NVLink 600 GB/s <span class="pp">|</span></span>
<span id="cb16-295"><a href="#cb16-295"></a><span class="pp">|</span> FP 64 <span class="pp">|</span> 9.7 TF <span class="pp">|</span> 38.8 TF <span class="pp">|</span></span>
<span id="cb16-296"><a href="#cb16-296"></a><span class="pp">|</span> FP64 Tensor Core <span class="pp">|</span> 19.5 TF <span class="pp">|</span> 78 TF <span class="pp">|</span></span>
<span id="cb16-297"><a href="#cb16-297"></a><span class="pp">|</span> FP 32 <span class="pp">|</span> 19.5 TF <span class="pp">|</span> 78 TF <span class="pp">|</span></span>
<span id="cb16-298"><a href="#cb16-298"></a><span class="pp">|</span> BF16 Tensor Core <span class="pp">|</span> 312 TF <span class="pp">|</span> 1.3 PF <span class="pp">|</span></span>
<span id="cb16-299"><a href="#cb16-299"></a><span class="pp">|</span> FP16 Tensor Core <span class="pp">|</span> 312 TF <span class="pp">|</span> 1.3 PF <span class="pp">|</span></span>
<span id="cb16-300"><a href="#cb16-300"></a><span class="pp">|</span> INT8 Tensor Core <span class="pp">|</span> 624 TOPS <span class="pp">|</span> 2496 TOPS <span class="pp">|</span></span>
<span id="cb16-301"><a href="#cb16-301"></a><span class="pp">|</span> Max TDP Power <span class="pp">|</span> 250 W <span class="pp">|</span> 400 W <span class="pp">|</span></span>
<span id="cb16-302"><a href="#cb16-302"></a></span>
<span id="cb16-303"><a href="#cb16-303"></a><span class="fu"># Using Conda {background-color="white"}</span></span>
<span id="cb16-304"><a href="#cb16-304"></a></span>
<span id="cb16-305"><a href="#cb16-305"></a><span class="ss">- </span>Additional information in our <span class="co">[</span><span class="ot">user guide</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/python/)</span></span>
<span id="cb16-306"><a href="#cb16-306"></a><span class="ss">- </span>We provide prebuilt <span class="in">`conda`</span> environment containing GPU-supported builds of:</span>
<span id="cb16-307"><a href="#cb16-307"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">Pytorch - ALCF User Guides</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/pytorch/)</span></span>
<span id="cb16-308"><a href="#cb16-308"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">DeepSped - ALCF User Guides</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/deepspeed/)</span></span>
<span id="cb16-309"><a href="#cb16-309"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">JAX - ALCF User Guides</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/jax/)</span></span>
<span id="cb16-310"><a href="#cb16-310"></a><span class="ss">  - </span><span class="co">[</span><span class="ot">Tensorflow - ALCF User Guides</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/frameworks/tensorflow/)</span></span>
<span id="cb16-311"><a href="#cb16-311"></a></span>
<span id="cb16-312"><a href="#cb16-312"></a><span class="ss">- </span>To activate / use: (either from an interactive job or inside a job script):</span>
<span id="cb16-313"><a href="#cb16-313"></a></span>
<span id="cb16-314"><a href="#cb16-314"></a>    <span class="in">```bash</span></span>
<span id="cb16-315"><a href="#cb16-315"></a>    <span class="ex">$</span> module use /soft/modulefiles</span>
<span id="cb16-316"><a href="#cb16-316"></a>    <span class="ex">$</span> module load conda<span class="kw">;</span> <span class="ex">conda</span> activate base</span>
<span id="cb16-317"><a href="#cb16-317"></a>    <span class="in">```</span></span>
<span id="cb16-318"><a href="#cb16-318"></a></span>
<span id="cb16-319"><a href="#cb16-319"></a><span class="fu"># Virtual Environments: `venv` {background-color="white"}</span></span>
<span id="cb16-320"><a href="#cb16-320"></a></span>
<span id="cb16-321"><a href="#cb16-321"></a><span class="ss">- </span>To install additional libraries, we can create a virtual environment using <span class="in">`venv`</span></span>
<span id="cb16-322"><a href="#cb16-322"></a><span class="ss">- </span>Make sure you're currently inside the **base** <span class="in">`conda`</span> environment:</span>
<span id="cb16-323"><a href="#cb16-323"></a><span class="ss">  - </span><span class="in">`module load conda; conda activate base`</span></span>
<span id="cb16-324"><a href="#cb16-324"></a><span class="ss">- </span>Now, create <span class="in">`venv`</span> **on top of** <span class="in">`base`</span>:</span>
<span id="cb16-325"><a href="#cb16-325"></a></span>
<span id="cb16-326"><a href="#cb16-326"></a>  <span class="in">```bash</span></span>
<span id="cb16-327"><a href="#cb16-327"></a>  <span class="ex">$</span> python3 <span class="at">-m</span> venv /path/to/venv <span class="at">--system-site-packages</span></span>
<span id="cb16-328"><a href="#cb16-328"></a>  <span class="ex">$</span> source /path/to/venv/bin/activate</span>
<span id="cb16-329"><a href="#cb16-329"></a>  <span class="ex">$</span> which python3</span>
<span id="cb16-330"><a href="#cb16-330"></a>  <span class="ex">/path/to/venv/bin/python3</span></span>
<span id="cb16-331"><a href="#cb16-331"></a>  <span class="ex">$</span> <span class="co"># Now you can `python3 -m pip install ...` etc</span></span>
<span id="cb16-332"><a href="#cb16-332"></a>  <span class="in">```</span></span>
<span id="cb16-333"><a href="#cb16-333"></a></span>
<span id="cb16-334"><a href="#cb16-334"></a>  <span class="co">&lt;!-- ::: {.callout-warning icon=false title="🚧 [Warning]{style='color:#fd971f!important;'}"} --&gt;</span></span>
<span id="cb16-335"><a href="#cb16-335"></a>  <span class="co">&lt;!-- ::: {.callout-tip icon=false aria-title="last.fm" title=collapse="true" style='border: none!important; border: 1px solid rgba(212, 17, 9, 0.0)!important; background: oklch(from #D41109 calc(l * 1.15) c h / 0.11);  margin-top: -0.1em; opacity: 100% width: 100%!important;'} --&gt;</span></span>
<span id="cb16-336"><a href="#cb16-336"></a></span>
<span id="cb16-337"><a href="#cb16-337"></a>  ::: {.callout-warning icon=false aria-title="Recent Talks" title="🚧 <span class="co">[</span><span class="ot">Warning</span><span class="co">]</span>{style='color:#fd971f!important;'}" collapse="false" style="text-align: left!important; width: 80%; opacity:100%;"}</span>
<span id="cb16-338"><a href="#cb16-338"></a></span>
<span id="cb16-339"><a href="#cb16-339"></a><span class="ss">  1. </span><span class="in">`--system-site-packages`</span> tells the <span class="in">`venv`</span> to use system packages</span>
<span id="cb16-340"><a href="#cb16-340"></a><span class="ss">  2. </span>You must replace the path <span class="in">`/path/to/venv`</span> in the above commands with a suitably chosen directory which you are able to write to.</span>
<span id="cb16-341"><a href="#cb16-341"></a></span>
<span id="cb16-342"><a href="#cb16-342"></a>  :::</span>
<span id="cb16-343"><a href="#cb16-343"></a></span>
<span id="cb16-344"><a href="#cb16-344"></a><span class="fu"># Note about `venv`'s {background-color="white"}</span></span>
<span id="cb16-345"><a href="#cb16-345"></a></span>
<span id="cb16-346"><a href="#cb16-346"></a><span class="ss">- </span>The value of <span class="in">`--system-site-packages`</span> can be changed by modifying its value in <span class="in">`/path/to/venv/pyvenv.cfg`</span></span>
<span id="cb16-347"><a href="#cb16-347"></a><span class="ss">- </span>To install a **different** version of a package that is already installed in the base environment:</span>
<span id="cb16-348"><a href="#cb16-348"></a></span>
<span id="cb16-349"><a href="#cb16-349"></a>  <span class="in">```bash</span></span>
<span id="cb16-350"><a href="#cb16-350"></a>  <span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">--ignore-installed</span> ... <span class="co"># or -I</span></span>
<span id="cb16-351"><a href="#cb16-351"></a>  <span class="in">```</span></span>
<span id="cb16-352"><a href="#cb16-352"></a></span>
<span id="cb16-353"><a href="#cb16-353"></a><span class="ss">- </span>The shared <span class="in">`base`</span> environment is not writable</span>
<span id="cb16-354"><a href="#cb16-354"></a><span class="ss">  - </span>Impossible to remove or uninstall packages</span>
<span id="cb16-355"><a href="#cb16-355"></a></span>
<span id="cb16-356"><a href="#cb16-356"></a><span class="ss">- </span>If you need additional flexibility, we can **clone** the base environment</span>
<span id="cb16-357"><a href="#cb16-357"></a></span>
<span id="cb16-358"><a href="#cb16-358"></a><span class="fu"># Clone base `conda` environment {background-color="white"}</span></span>
<span id="cb16-359"><a href="#cb16-359"></a></span>
<span id="cb16-360"><a href="#cb16-360"></a><span class="ss">- </span>If we need additional flexibility or to install packages which **require** a <span class="in">`conda`</span> install, we can clone the base environment</span>
<span id="cb16-361"><a href="#cb16-361"></a><span class="ss">  - </span>requires copying the entirety of the base environment</span>
<span id="cb16-362"><a href="#cb16-362"></a><span class="ss">  - </span>**large storage requirement**, can get out of hand quickly</span>
<span id="cb16-363"><a href="#cb16-363"></a><span class="ss">- </span>The shared <span class="in">`base`</span> environment is not writable</span>
<span id="cb16-364"><a href="#cb16-364"></a><span class="ss">  - </span>Impossible to remove or uninstall packages</span>
<span id="cb16-365"><a href="#cb16-365"></a><span class="ss">- </span>This can be done by:</span>
<span id="cb16-366"><a href="#cb16-366"></a></span>
<span id="cb16-367"><a href="#cb16-367"></a>  <span class="in">```bash</span></span>
<span id="cb16-368"><a href="#cb16-368"></a>  <span class="ex">$</span> module load conda</span>
<span id="cb16-369"><a href="#cb16-369"></a>  <span class="ex">$</span> conda activate base</span>
<span id="cb16-370"><a href="#cb16-370"></a>  <span class="kw">(</span><span class="ex">base</span><span class="kw">)</span> <span class="ex">$</span> conda create <span class="at">--clone</span> base <span class="at">--prefix</span><span class="op">=</span><span class="st">"/path/to/envs/base-clone"</span></span>
<span id="cb16-371"><a href="#cb16-371"></a>  <span class="in">```</span></span>
<span id="cb16-372"><a href="#cb16-372"></a></span>
<span id="cb16-373"><a href="#cb16-373"></a><span class="fu"># Containers on Polaris {background-color="white"}</span></span>
<span id="cb16-374"><a href="#cb16-374"></a></span>
<span id="cb16-375"><a href="#cb16-375"></a><span class="ss">- </span>Polaris uses Nvidia A100 GPUs ==&gt;</span>
<span id="cb16-376"><a href="#cb16-376"></a><span class="ss">  - </span>We can take advantage of Nvidia optimized containers</span>
<span id="cb16-377"><a href="#cb16-377"></a></span>
<span id="cb16-378"><a href="#cb16-378"></a><span class="ss">- </span>The container system on Polaris is <span class="co">[</span><span class="ot">`singularity`</span><span class="co">](https://docs.sylabs.io/guides/3.5/user-guide/introduction.html)</span>:</span>
<span id="cb16-379"><a href="#cb16-379"></a></span>
<span id="cb16-380"><a href="#cb16-380"></a>  <span class="in">```bash</span></span>
<span id="cb16-381"><a href="#cb16-381"></a>  <span class="ex">module</span> avail singularity <span class="co"># see available</span></span>
<span id="cb16-382"><a href="#cb16-382"></a>  <span class="ex">module</span> load singularity  <span class="co"># load default version</span></span>
<span id="cb16-383"><a href="#cb16-383"></a>  <span class="co"># To load a specific version:</span></span>
<span id="cb16-384"><a href="#cb16-384"></a>  <span class="ex">module</span> load singularity/3.8.7</span>
<span id="cb16-385"><a href="#cb16-385"></a>  <span class="in">```</span></span>
<span id="cb16-386"><a href="#cb16-386"></a></span>
<span id="cb16-387"><a href="#cb16-387"></a><span class="ss">- </span>Singularity: two options for creating containers:</span>
<span id="cb16-388"><a href="#cb16-388"></a><span class="ss">    1. </span>Using Docker on local machine and publishing to DockerHub</span>
<span id="cb16-389"><a href="#cb16-389"></a><span class="ss">    2. </span>Using a Singularity recipe file and building on a Polaris worker node</span>
<span id="cb16-390"><a href="#cb16-390"></a></span>
<span id="cb16-391"><a href="#cb16-391"></a><span class="ss">- </span>See also: <span class="co">[</span><span class="ot">Containers - ALCF User Guides</span><span class="co">](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/containers/containers/)</span></span>
<span id="cb16-392"><a href="#cb16-392"></a></span>
<span id="cb16-393"><a href="#cb16-393"></a><span class="co">&lt;!-- [^1]: [Containers - ALCF User Guides](https://argonne-lcf.github.io/user-guides/polaris/data-science-workflows/containers/containers/) --&gt;</span></span>
<span id="cb16-394"><a href="#cb16-394"></a></span>
<span id="cb16-395"><a href="#cb16-395"></a><span class="co">&lt;!-- # Debugging Tools --&gt;</span></span>
<span id="cb16-396"><a href="#cb16-396"></a><span class="co">&lt;!----&gt;</span></span>
<span id="cb16-397"><a href="#cb16-397"></a><span class="co">&lt;!-- - [CUDA-GDB - ALCF User Guides](https://argonne-lcf.github.io/user-guides/polaris/debugging-tools/CUDA-GDB/) --&gt;</span></span>
<span id="cb16-398"><a href="#cb16-398"></a><span class="co">&lt;!----&gt;</span></span>
<span id="cb16-399"><a href="#cb16-399"></a><span class="co">&lt;!--   - `CUDA-GDB` is the Nvidia tool for debugging CUDA applications running on Polaris. --&gt;</span></span>
<span id="cb16-400"><a href="#cb16-400"></a><span class="co">&lt;!--   - `CUDA-GDB` is an extension to `GDB`, the GNU Project debugger. --&gt;</span></span>
<span id="cb16-401"><a href="#cb16-401"></a><span class="co">&lt;!--     - The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. --&gt;</span></span>
<span id="cb16-402"><a href="#cb16-402"></a><span class="co">&lt;!--     - This enables developers to debug applications without the potential variations introduced by simulation and emulation environments --&gt;</span></span>
<span id="cb16-403"><a href="#cb16-403"></a></span>
<span id="cb16-404"><a href="#cb16-404"></a></span>
<span id="cb16-405"><a href="#cb16-405"></a><span class="fu"># Large Language Models {background-color="white"}</span></span>
<span id="cb16-406"><a href="#cb16-406"></a></span>
<span id="cb16-407"><a href="#cb16-407"></a><span class="fu"># Status of Large Language Models {background-color="white"}</span></span>
<span id="cb16-408"><a href="#cb16-408"></a></span>
<span id="cb16-409"><a href="#cb16-409"></a>::: {#fig-llms}</span>
<span id="cb16-410"><a href="#cb16-410"></a></span>
<span id="cb16-411"><a href="#cb16-411"></a><span class="al">![](https://github.com/Hannibal046/Awesome-LLM/raw/main/resources/image8.gif)</span></span>
<span id="cb16-412"><a href="#cb16-412"></a></span>
<span id="cb16-413"><a href="#cb16-413"></a>Large Language Models have (LLM)s have taken the ~~NLP community~~ **world** by storm<span class="ot">[^llm-animation]</span></span>
<span id="cb16-414"><a href="#cb16-414"></a></span>
<span id="cb16-415"><a href="#cb16-415"></a>:::</span>
<span id="cb16-416"><a href="#cb16-416"></a></span>
<span id="cb16-417"><a href="#cb16-417"></a><span class="ot">[^llm-animation]: </span><span class="co">[</span><span class="ot">{{&lt; fa brands github &gt;}} `Hannibal046/Awesome-LLM`</span><span class="co">](https://github.com/Hannibal046/Awesome-LLM)</span></span>
<span id="cb16-418"><a href="#cb16-418"></a><span class="co">&lt;!-- [^slides-gh]: [{{&lt; fa brands github &gt;}} `saforem2/llm-lunch-talk`](https://github.com/Hannibal046/Awesome-LLM) [(slides)](https://saforem2.github.io/llm-lunch-talk) --&gt;</span></span>
<span id="cb16-419"><a href="#cb16-419"></a></span>
<span id="cb16-420"><a href="#cb16-420"></a></span>
<span id="cb16-421"><a href="#cb16-421"></a><span class="fu"># Emergent Abilities {background-color="#FBFBFD"}</span></span>
<span id="cb16-422"><a href="#cb16-422"></a></span>
<span id="cb16-423"><a href="#cb16-423"></a>::: {width="66%" style="text-align: center;"}</span>
<span id="cb16-424"><a href="#cb16-424"></a></span>
<span id="cb16-425"><a href="#cb16-425"></a><span class="dt">&lt;</span><span class="kw">img</span><span class="ot"> src</span><span class="op">=</span><span class="st">"https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/emergent-abilities.gif?raw=true"</span><span class="ot"> height</span><span class="op">=</span><span class="st">"75%"</span><span class="ot"> </span><span class="dt">/&gt;</span></span>
<span id="cb16-426"><a href="#cb16-426"></a></span>
<span id="cb16-427"><a href="#cb16-427"></a><span class="co">[</span><span class="ot">Emergent abilities of Large Language Models</span><span class="co">](https://arxiv.org/abs/2206.07682)</span> @yao2023tree</span>
<span id="cb16-428"><a href="#cb16-428"></a>:::</span>
<span id="cb16-429"><a href="#cb16-429"></a></span>
<span id="cb16-430"><a href="#cb16-430"></a></span>
<span id="cb16-431"><a href="#cb16-431"></a><span class="fu"># Training LLMs {background-color="#FFFFFF"}</span></span>
<span id="cb16-432"><a href="#cb16-432"></a></span>
<span id="cb16-433"><a href="#cb16-433"></a></span>
<span id="cb16-434"><a href="#cb16-434"></a>::: {layout="<span class="co">[</span><span class="ot"> 50, 40 </span><span class="co">]</span>" layout-valign="center"}</span>
<span id="cb16-435"><a href="#cb16-435"></a></span>
<span id="cb16-436"><a href="#cb16-436"></a>::: {#fig-evolution}</span>
<span id="cb16-437"><a href="#cb16-437"></a></span>
<span id="cb16-438"><a href="#cb16-438"></a><span class="al">![](https://github.com/Mooler0410/LLMsPracticalGuide/raw/main/imgs/survey-gif-test.gif)</span></span>
<span id="cb16-439"><a href="#cb16-439"></a></span>
<span id="cb16-440"><a href="#cb16-440"></a>Visualization from @yang2023harnessing</span>
<span id="cb16-441"><a href="#cb16-441"></a></span>
<span id="cb16-442"><a href="#cb16-442"></a>:::</span>
<span id="cb16-443"><a href="#cb16-443"></a></span>
<span id="cb16-444"><a href="#cb16-444"></a>::: {}</span>
<span id="cb16-445"><a href="#cb16-445"></a></span>
<span id="cb16-446"><a href="#cb16-446"></a><span class="al">![](https://github.com/saforem2/llm-lunch-talk/blob/main/docs/assets/it_hungers.jpeg?raw=true)</span></span>
<span id="cb16-447"><a href="#cb16-447"></a></span>
<span id="cb16-448"><a href="#cb16-448"></a></span>
<span id="cb16-449"><a href="#cb16-449"></a>:::</span>
<span id="cb16-450"><a href="#cb16-450"></a></span>
<span id="cb16-451"><a href="#cb16-451"></a>:::</span>
<span id="cb16-452"><a href="#cb16-452"></a></span>
<span id="cb16-453"><a href="#cb16-453"></a></span>
<span id="cb16-454"><a href="#cb16-454"></a><span class="fu"># Recent Work (2017 -- Now) {.scrollable style="max-height: 95%; height: 100%; font-size: 0.75em;" background-color="white"}</span></span>
<span id="cb16-455"><a href="#cb16-455"></a></span>
<span id="cb16-456"><a href="#cb16-456"></a>::: {style="font-size: 0.9em;"}</span>
<span id="cb16-457"><a href="#cb16-457"></a></span>
<span id="cb16-458"><a href="#cb16-458"></a><span class="pp">|</span>    Date <span class="pp">|</span> Paper                                                                                                                                                                                                              <span class="pp">|</span> keywords             <span class="pp">|</span> Institute          <span class="pp">|</span> Publication                                                                                                                                                                                                                                             <span class="pp">|</span></span>
<span id="cb16-459"><a href="#cb16-459"></a><span class="pp">| ------:</span> <span class="pp">| :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span> <span class="pp">| :-------------------</span> <span class="pp">| :-----------------</span> <span class="pp">| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span> <span class="pp">|</span></span>
<span id="cb16-460"><a href="#cb16-460"></a><span class="pp">|</span> 06/2017 <span class="pp">|</span> <span class="co">[</span><span class="ot">Attention Is All You Need</span><span class="co">](https://arxiv.org/pdf/1706.03762.pdf)</span>                                                                                                                                                  <span class="pp">|</span> Transformers         <span class="pp">|</span> Google             <span class="pp">|</span> NeurIPS<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span>  <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F204e3073870fae3d05bcbc2f6a8e263d9b72e776%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span> <span class="pp">|</span></span>
<span id="cb16-461"><a href="#cb16-461"></a><span class="pp">|</span> 06/2018 <span class="pp">|</span> <span class="co">[</span><span class="ot">Improving Language Understanding by Generative Pre-Training</span><span class="co">](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)</span>                                                                             <span class="pp">|</span> GPT 1.0              <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcd18800a0fe0b668a1cc19f2ec95b5003d0a5035%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-462"><a href="#cb16-462"></a><span class="pp">|</span> 10/2018 <span class="pp">|</span> <span class="co">[</span><span class="ot">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span><span class="co">](https://aclanthology.org/N19-1423.pdf)</span>                                                                                          <span class="pp">|</span> BERT                 <span class="pp">|</span> Google             <span class="pp">|</span> NAACL <span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdf2b0e26d0599ce3e70df8a9da02e51594e0e992%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>    <span class="pp">|</span></span>
<span id="cb16-463"><a href="#cb16-463"></a><span class="pp">|</span> 02/2019 <span class="pp">|</span> <span class="co">[</span><span class="ot">Language Models are Unsupervised Multitask Learners</span><span class="co">](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)</span>                                          <span class="pp">|</span> GPT 2.0              <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9405cc0d6169988371b2755e573cc28650d14dfe%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-464"><a href="#cb16-464"></a><span class="pp">|</span> 09/2019 <span class="pp">|</span> <span class="co">[</span><span class="ot">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</span><span class="co">](https://arxiv.org/pdf/1909.08053.pdf)</span>                                                                                      <span class="pp">|</span> Megatron-LM          <span class="pp">|</span> NVIDIA             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8323c591e119eb09b28b29fd6c7bc76bd889df7a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-465"><a href="#cb16-465"></a><span class="pp">|</span> 10/2019 <span class="pp">|</span> <span class="co">[</span><span class="ot">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</span><span class="co">](https://jmlr.org/papers/v21/20-074.html)</span>                                                                                       <span class="pp">|</span> T5                   <span class="pp">|</span> Google             <span class="pp">|</span> JMLR<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span>  <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3cfb319689f06bf04c2e28399361f414ca32c4b3%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>    <span class="pp">|</span></span>
<span id="cb16-466"><a href="#cb16-466"></a><span class="pp">|</span> 10/2019 <span class="pp">|</span> <span class="co">[</span><span class="ot">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</span><span class="co">](https://arxiv.org/pdf/1910.02054.pdf)</span>                                                                                                       <span class="pp">|</span> ZeRO                 <span class="pp">|</span> Microsoft          <span class="pp">|</span> SC<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F00c957711b12468cb38424caccdf5291bb354033%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>       <span class="pp">|</span></span>
<span id="cb16-467"><a href="#cb16-467"></a><span class="pp">|</span> 01/2020 <span class="pp">|</span> <span class="co">[</span><span class="ot">Scaling Laws for Neural Language Models</span><span class="co">](https://arxiv.org/pdf/2001.08361.pdf)</span>                                                                                                                                    <span class="pp">|</span> Scaling Law          <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe6c561d02500b2596a230b341a8eb8b921ca5bf2%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-468"><a href="#cb16-468"></a><span class="pp">|</span> 05/2020 <span class="pp">|</span> <span class="co">[</span><span class="ot">Language models are few-shot learners</span><span class="co">](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)</span>                                                                                         <span class="pp">|</span> GPT 3.0              <span class="pp">|</span> OpenAI             <span class="pp">|</span> NeurIPS <span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6b85b63579a916f705a8e10a49bd8d849d91b1fc%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span> <span class="pp">|</span></span>
<span id="cb16-469"><a href="#cb16-469"></a><span class="pp">|</span> 01/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</span><span class="co">](https://arxiv.org/pdf/2101.03961.pdf)</span>                                                                               <span class="pp">|</span> Switch Transformers  <span class="pp">|</span> Google             <span class="pp">|</span> JMLR<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffdacf2a732f55befdc410ea927091cad3b791f13%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-470"><a href="#cb16-470"></a><span class="pp">|</span> 08/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Evaluating Large Language Models Trained on Code</span><span class="co">](https://arxiv.org/pdf/2107.03374.pdf)</span>                                                                                                                           <span class="pp">|</span> Codex                <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Facbdbf49f9bc3f151b93d9ca9a06009f4f6eb269%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-471"><a href="#cb16-471"></a><span class="pp">|</span> 08/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">On the Opportunities and Risks of Foundation Models</span><span class="co">](https://arxiv.org/pdf/2108.07258.pdf)</span>                                                                                                                        <span class="pp">|</span> Foundation Models    <span class="pp">|</span> Stanford           <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4f68e07c6c3173480053fd52391851d6f80d651b%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-472"><a href="#cb16-472"></a><span class="pp">|</span> 09/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Finetuned Language Models are Zero-Shot Learners</span><span class="co">](https://openreview.net/forum?id=gEZrGCozdqR)</span>                                                                                                                    <span class="pp">|</span> FLAN                 <span class="pp">|</span> Google             <span class="pp">|</span> ICLR <span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fff0b2681d7b05e16c46dfb71d980cc2f605907cd%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-473"><a href="#cb16-473"></a><span class="pp">|</span> 10/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Multitask Prompted Training Enables Zero-Shot Task Generalization</span><span class="co">](https://arxiv.org/abs/2110.08207)</span>                                                                                                              <span class="pp">|</span> T0                   <span class="pp">|</span> HuggingFace et al. <span class="pp">|</span> ICLR <span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F17dd3555fd1ccf1141cf984347fa1b3fd6b009ca%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-474"><a href="#cb16-474"></a><span class="pp">|</span> 12/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">GLaM: Efficient Scaling of Language Models with Mixture-of-Experts</span><span class="co">](https://arxiv.org/pdf/2112.06905.pdf)</span>                                                                                                         <span class="pp">|</span> GLaM                 <span class="pp">|</span> Google             <span class="pp">|</span> ICML<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F80d0116d77beeded0c23cf48946d9d10d4faee14%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-475"><a href="#cb16-475"></a><span class="pp">|</span> 12/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">WebGPT: Browser-assisted question-answering with human feedback</span><span class="co">](https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-answering-with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22)</span> <span class="pp">|</span> WebGPT               <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2f3efe44083af91cef562c1a3451eee2f8601d22%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-476"><a href="#cb16-476"></a><span class="pp">|</span> 12/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Improving language models by retrieving from trillions of tokens</span><span class="co">](https://www.deepmind.com/publications/improving-language-models-by-retrieving-from-trillions-of-tokens)</span>                                         <span class="pp">|</span> Retro                <span class="pp">|</span> DeepMind           <span class="pp">|</span> ICML<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F002c256d30d6be4b23d365a8de8ae0e67e4c9641%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-477"><a href="#cb16-477"></a><span class="pp">|</span> 12/2021 <span class="pp">|</span> <span class="co">[</span><span class="ot">Scaling Language Models: Methods, Analysis &amp;amp; Insights from Training Gopher</span><span class="co">](https://arxiv.org/pdf/2112.11446.pdf)</span>                                                                                             <span class="pp">|</span> Gopher               <span class="pp">|</span> DeepMind           <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F68f141724814839d556a989646194be88641b143%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-478"><a href="#cb16-478"></a><span class="pp">|</span> 01/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</span><span class="co">](https://arxiv.org/pdf/2201.11903.pdf)</span>                                                                                                      <span class="pp">|</span> COT                  <span class="pp">|</span> Google             <span class="pp">|</span> NeurIPS<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b6e810ce0afd0dd093f789d2b2742d047e316d5%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>   <span class="pp">|</span></span>
<span id="cb16-479"><a href="#cb16-479"></a><span class="pp">|</span> 01/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">LaMDA: Language Models for Dialog Applications</span><span class="co">](https://arxiv.org/pdf/2201.08239.pdf)</span>                                                                                                                             <span class="pp">|</span> LaMDA                <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb3848d32f7294ec708627897833c4097eb4d8778%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-480"><a href="#cb16-480"></a><span class="pp">|</span> 01/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Solving Quantitative Reasoning Problems with Language Models</span><span class="co">](https://arxiv.org/abs/2206.14858)</span>                                                                                                                   <span class="pp">|</span> Minerva              <span class="pp">|</span> Google             <span class="pp">|</span> NeurIPS<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fab0e3d3e4d42369de5933a3b4c237780b41c0d77%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>  <span class="pp">|</span></span>
<span id="cb16-481"><a href="#cb16-481"></a><span class="pp">|</span> 01/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model</span><span class="co">](https://arxiv.org/pdf/2201.11990.pdf)</span>                                                                    <span class="pp">|</span> Megatron-Turing NLG  <span class="pp">|</span> Microsoft&amp;NVIDIA   <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7cbc2a7843411a1768ab762930707af0a3c33a19%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-482"><a href="#cb16-482"></a><span class="pp">|</span> 03/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Training language models to follow instructions with human feedback</span><span class="co">](https://arxiv.org/pdf/2203.02155.pdf)</span>                                                                                                        <span class="pp">|</span> InstructGPT          <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd766bffc357127e0dc86dd69561d5aeb520d6f4c%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-483"><a href="#cb16-483"></a><span class="pp">|</span> 04/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">PaLM: Scaling Language Modeling with Pathways</span><span class="co">](https://arxiv.org/pdf/2204.02311.pdf)</span>                                                                                                                              <span class="pp">|</span> PaLM                 <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F094ff971d6a8b8ff870946c9b3ce5aa173617bfb%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-484"><a href="#cb16-484"></a><span class="pp">|</span> 04/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">An empirical analysis of compute-optimal large language model training</span><span class="co">](https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training)</span>                             <span class="pp">|</span> Chinchilla           <span class="pp">|</span> DeepMind           <span class="pp">|</span> NeurIPS<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbb0656031cb17adf6bac5fd0fe8d53dd9c291508%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>  <span class="pp">|</span></span>
<span id="cb16-485"><a href="#cb16-485"></a><span class="pp">|</span> 05/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">OPT: Open Pre-trained Transformer Language Models</span><span class="co">](https://arxiv.org/pdf/2205.01068.pdf)</span>                                                                                                                          <span class="pp">|</span> OPT                  <span class="pp">|</span> Meta               <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F13a0d8bb38f739990c8cd65a44061c6534f17221%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-486"><a href="#cb16-486"></a><span class="pp">|</span> 05/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Unifying Language Learning Paradigms</span><span class="co">](https://arxiv.org/abs/2205.05131v1)</span>                                                                                                                                         <span class="pp">|</span> UL2                  <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff40aeae3e522ada1f6a9f326841b01ef5c8657b6%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-487"><a href="#cb16-487"></a><span class="pp">|</span> 06/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Emergent Abilities of Large Language Models</span><span class="co">](https://openreview.net/pdf?id=yzkSU5zdwD)</span>                                                                                                                            <span class="pp">|</span> Emergent Abilities   <span class="pp">|</span> Google             <span class="pp">|</span> TMLR<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdac3a172b504f4e33c029655e9befb3386e5f63a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>      <span class="pp">|</span></span>
<span id="cb16-488"><a href="#cb16-488"></a><span class="pp">|</span> 06/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</span><span class="co">](https://github.com/google/BIG-bench)</span>                                                                                <span class="pp">|</span> BIG-bench            <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F34503c0b6a615124eaf82cb0e4a1dab2866e8980%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-489"><a href="#cb16-489"></a><span class="pp">|</span> 06/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Language Models are General-Purpose Interfaces</span><span class="co">](https://arxiv.org/pdf/2206.06336.pdf)</span>                                                                                                                             <span class="pp">|</span> METALM               <span class="pp">|</span> Microsoft          <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa8fd9c1625011741f74401ff9bdc1c584e25c86d%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-490"><a href="#cb16-490"></a><span class="pp">|</span> 09/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Improving alignment of dialogue agents via targeted human judgements</span><span class="co">](https://arxiv.org/pdf/2209.14375.pdf)</span>                                                                                                       <span class="pp">|</span> Sparrow              <span class="pp">|</span> DeepMind           <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F74eae12620bd1c1393e268bddcb6f129a5025166%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-491"><a href="#cb16-491"></a><span class="pp">|</span> 10/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Scaling Instruction-Finetuned Language Models</span><span class="co">](https://arxiv.org/pdf/2210.11416.pdf)</span>                                                                                                                              <span class="pp">|</span> Flan-T5/PaLM         <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5484d228bfc50efbac6e86677bc2ec2ee4ede1a6%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-492"><a href="#cb16-492"></a><span class="pp">|</span> 10/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">GLM-130B: An Open Bilingual Pre-trained Model</span><span class="co">](https://arxiv.org/pdf/2210.02414.pdf)</span>                                                                                                                              <span class="pp">|</span> GLM-130B             <span class="pp">|</span> Tsinghua           <span class="pp">|</span> ICLR<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1d26c947406173145a4665dd7ab255e03494ea28%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>     <span class="pp">|</span></span>
<span id="cb16-493"><a href="#cb16-493"></a><span class="pp">|</span> 11/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Holistic Evaluation of Language Models</span><span class="co">](https://arxiv.org/pdf/2211.09110.pdf)</span>                                                                                                                                     <span class="pp">|</span> HELM                 <span class="pp">|</span> Stanford           <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5032c0946ee96ff11a292762f23e6377a6cf2731%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-494"><a href="#cb16-494"></a><span class="pp">|</span> 11/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</span><span class="co">](https://arxiv.org/pdf/2211.05100.pdf)</span>                                                                                                            <span class="pp">|</span> BLOOM                <span class="pp">|</span> BigScience         <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F964bd39b546f0f6625ff3b9ef1083f797807ef2e%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-495"><a href="#cb16-495"></a><span class="pp">|</span> 11/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">Galactica: A Large Language Model for Science</span><span class="co">](https://arxiv.org/pdf/2211.09085.pdf)</span>                                                                                                                              <span class="pp">|</span> Galactica            <span class="pp">|</span> Meta               <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7d645a3fd276918374fd9483fd675c28e46506d1%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-496"><a href="#cb16-496"></a><span class="pp">|</span> 12/2022 <span class="pp">|</span> <span class="co">[</span><span class="ot">OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization</span><span class="co">](https://arxiv.org/pdf/2212.12017)</span>                                                                                   <span class="pp">|</span> OPT-IML              <span class="pp">|</span> Meta               <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe965e93e76a9e6c4e4863d145b5c007b540d575d%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-497"><a href="#cb16-497"></a><span class="pp">|</span> 01/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</span><span class="co">](https://arxiv.org/pdf/2301.13688.pdf)</span>                                                                                           <span class="pp">|</span> Flan 2022 Collection <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff2b0017ddd77fa38760a18145e63553105a1a236%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-498"><a href="#cb16-498"></a><span class="pp">|</span> 02/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">LLaMA: Open and Efficient Foundation Language Models</span><span class="co">](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)</span>                                                            <span class="pp">|</span> LLaMA                <span class="pp">|</span> Meta               <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F57e849d0de13ed5f91d086936296721d4ff75a75%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-499"><a href="#cb16-499"></a><span class="pp">|</span> 02/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">Language Is Not All You Need: Aligning Perception with Language Models</span><span class="co">](https://arxiv.org/abs/2302.14045)</span>                                                                                                         <span class="pp">|</span> Kosmos-1             <span class="pp">|</span> Microsoft          <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffbfef4723d8c8467d7bd523e1d0b703cce0e0f9c%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-500"><a href="#cb16-500"></a><span class="pp">|</span> 03/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">PaLM-E: An Embodied Multimodal Language Model</span><span class="co">](https://palm-e.github.io)</span>                                                                                                                                          <span class="pp">|</span> PaLM-E               <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F38fe8f324d2162e63a967a9ac6648974fc4c66f3%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-501"><a href="#cb16-501"></a><span class="pp">|</span> 03/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">GPT-4 Technical Report</span><span class="co">](https://openai.com/research/gpt-4)</span>                                                                                                                                                        <span class="pp">|</span> GPT 4                <span class="pp">|</span> OpenAI             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8ca62fdf4c276ea3052dc96dcfd8ee96ca425a48%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-502"><a href="#cb16-502"></a><span class="pp">|</span> 04/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling</span><span class="co">](https://arxiv.org/abs/2304.01373)</span>                                                                                                <span class="pp">|</span> Pythia               <span class="pp">|</span> EleutherAI et al.  <span class="pp">|</span> ICML<span class="dt">&lt;</span><span class="kw">br</span><span class="dt">&gt;</span><span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbe55e8ec4213868db08f2c3168ae666001bea4b8%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>      <span class="pp">|</span></span>
<span id="cb16-503"><a href="#cb16-503"></a><span class="pp">|</span> 05/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision</span><span class="co">](https://arxiv.org/abs/2305.03047)</span>                                                                                 <span class="pp">|</span> Dromedary            <span class="pp">|</span> CMU et al.         <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe01515c6138bc525f7aec30fc85f2adf028d4156%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-504"><a href="#cb16-504"></a><span class="pp">|</span> 05/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">PaLM 2 Technical Report</span><span class="co">](https://ai.google/static/documents/palm2techreport.pdf)</span>                                                                                                                                  <span class="pp">|</span> PaLM 2               <span class="pp">|</span> Google             <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Feccee350691708972370b7a12c2a78ad3bddd159%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-505"><a href="#cb16-505"></a><span class="pp">|</span> 05/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">RWKV: Reinventing RNNs for the Transformer Era</span><span class="co">](https://arxiv.org/abs/2305.13048)</span>                                                                                                                                 <span class="pp">|</span> RWKV                 <span class="pp">|</span> Bo Peng            <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F026b3396a63ed5772329708b7580d633bb86bec9%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-506"><a href="#cb16-506"></a><span class="pp">|</span> 05/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</span><span class="co">](https://arxiv.org/pdf/2305.18290.pdf)</span>                                                                                             <span class="pp">|</span> DPO                  <span class="pp">|</span> Stanford           <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0d1c76d45afa012ded7ab741194baf142117c495%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-507"><a href="#cb16-507"></a><span class="pp">|</span> 07/2023 <span class="pp">|</span> <span class="co">[</span><span class="ot">Llama 2: Open Foundation and Fine-Tuned Chat Models</span><span class="co">](https://arxiv.org/pdf/2307.09288.pdf)</span>                                                                                                                        <span class="pp">|</span> LLaMA 2              <span class="pp">|</span> Meta               <span class="pp">|</span> <span class="al">![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F104b0bb1da562d53cbda87aec79ef6a2827d191a%3Ffields%3DcitationCount&amp;query=%24.citationCount&amp;label=citation)</span>              <span class="pp">|</span></span>
<span id="cb16-508"><a href="#cb16-508"></a></span>
<span id="cb16-509"><a href="#cb16-509"></a>: Papers, 2017--* {.striped .hover tbl-colwidths="<span class="co">[</span><span class="ot">5,80,15,5,5</span><span class="co">]</span>"}</span>
<span id="cb16-510"><a href="#cb16-510"></a></span>
<span id="cb16-511"><a href="#cb16-511"></a>:::</span>
<span id="cb16-512"><a href="#cb16-512"></a></span>
<span id="cb16-513"><a href="#cb16-513"></a>::: footer</span>
<span id="cb16-514"><a href="#cb16-514"></a></span>
<span id="cb16-515"><a href="#cb16-515"></a><span class="ss">1. </span><span class="co">[</span><span class="ot">{{&lt; fa brands github &gt;}} Hannibal046/Awesome-LLM</span><span class="co">](https://github.com/Hannibal046/Awesome-LLM/blob/main/README.md)</span> [<span class="co">[</span><span class="al">![Awesome](https://awesome.re/badge.svg)</span><span class="co">](https://awesome.re)</span>]{.inline-image}</span>
<span id="cb16-516"><a href="#cb16-516"></a></span>
<span id="cb16-517"><a href="#cb16-517"></a>:::</span>
<span id="cb16-518"><a href="#cb16-518"></a></span>
<span id="cb16-519"><a href="#cb16-519"></a><span class="fu"># Life-Cycle of the LLM {auto-animate=true background-color="white"}</span></span>
<span id="cb16-520"><a href="#cb16-520"></a></span>
<span id="cb16-521"><a href="#cb16-521"></a>::: {layout="<span class="co">[</span><span class="ot"> 45, 55 </span><span class="co">]</span>" layout-valign=center}</span>
<span id="cb16-522"><a href="#cb16-522"></a></span>
<span id="cb16-523"><a href="#cb16-523"></a>::: {#column-one}</span>
<span id="cb16-524"><a href="#cb16-524"></a></span>
<span id="cb16-525"><a href="#cb16-525"></a><span class="ss">1. </span>Data collection + preprocessing</span>
<span id="cb16-526"><a href="#cb16-526"></a></span>
<span id="cb16-527"><a href="#cb16-527"></a><span class="ss">2. </span>**Pre-training**</span>
<span id="cb16-528"><a href="#cb16-528"></a><span class="ss">    - </span>Architecture decisions:  </span>
<span id="cb16-529"><a href="#cb16-529"></a>      <span class="in">`{model_size, hyperparameters,`</span>  </span>
<span id="cb16-530"><a href="#cb16-530"></a>      <span class="in">`parallelism, lr_schedule, ...}`</span></span>
<span id="cb16-531"><a href="#cb16-531"></a></span>
<span id="cb16-532"><a href="#cb16-532"></a><span class="ss">3. </span>Supervised Fine-Tuning</span>
<span id="cb16-533"><a href="#cb16-533"></a><span class="ss">    - </span>Instruction Tuning</span>
<span id="cb16-534"><a href="#cb16-534"></a><span class="ss">    - </span>Alignment</span>
<span id="cb16-535"><a href="#cb16-535"></a></span>
<span id="cb16-536"><a href="#cb16-536"></a><span class="ss">4. </span>Deploy (+ monitor, re-evaluate, etc.)</span>
<span id="cb16-537"><a href="#cb16-537"></a></span>
<span id="cb16-538"><a href="#cb16-538"></a>:::</span>
<span id="cb16-539"><a href="#cb16-539"></a></span>
<span id="cb16-540"><a href="#cb16-540"></a>::: {#column-two}</span>
<span id="cb16-541"><a href="#cb16-541"></a></span>
<span id="cb16-542"><a href="#cb16-542"></a>::: {#fig-pretrain-two}</span>
<span id="cb16-543"><a href="#cb16-543"></a></span>
<span id="cb16-544"><a href="#cb16-544"></a><span class="al">![](https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif)</span></span>
<span id="cb16-545"><a href="#cb16-545"></a></span>
<span id="cb16-546"><a href="#cb16-546"></a>**Pre-training**: Virtually all of the compute used during pretraining phase<span class="ot">[^il-transf]</span>.</span>
<span id="cb16-547"><a href="#cb16-547"></a>:::</span>
<span id="cb16-548"><a href="#cb16-548"></a></span>
<span id="cb16-549"><a href="#cb16-549"></a>:::</span>
<span id="cb16-550"><a href="#cb16-550"></a></span>
<span id="cb16-551"><a href="#cb16-551"></a><span class="ot">[^il-transf]: </span>Figure from <span class="co">[</span><span class="ot">The Illustrated Transformer</span><span class="co">](http://jalammar.github.io/illustrated-transformer/)</span></span>
<span id="cb16-552"><a href="#cb16-552"></a></span>
<span id="cb16-553"><a href="#cb16-553"></a>:::</span>
<span id="cb16-554"><a href="#cb16-554"></a></span>
<span id="cb16-555"><a href="#cb16-555"></a><span class="fu"># Life-Cycle of the LLM: Pre-training {auto-animate=true background-color="white"}</span></span>
<span id="cb16-556"><a href="#cb16-556"></a></span>
<span id="cb16-557"><a href="#cb16-557"></a>::: {#fig-pretrain-two}</span>
<span id="cb16-558"><a href="#cb16-558"></a></span>
<span id="cb16-559"><a href="#cb16-559"></a><span class="al">![](https://jalammar.github.io/images/gpt3/03-gpt3-training-step-back-prop.gif)</span></span>
<span id="cb16-560"><a href="#cb16-560"></a></span>
<span id="cb16-561"><a href="#cb16-561"></a>**Pre-training**: Virtually all of the compute used during pretraining phase</span>
<span id="cb16-562"><a href="#cb16-562"></a>:::</span>
<span id="cb16-563"><a href="#cb16-563"></a></span>
<span id="cb16-564"><a href="#cb16-564"></a><span class="fu"># Life-Cycle of the LLM: Fine-Tuning {auto-animate=true style="font-size: 0.8em;" background-color="white"}</span></span>
<span id="cb16-565"><a href="#cb16-565"></a></span>
<span id="cb16-566"><a href="#cb16-566"></a>::: {#fig-pretrain-two}</span>
<span id="cb16-567"><a href="#cb16-567"></a></span>
<span id="cb16-568"><a href="#cb16-568"></a><span class="al">![](https://jalammar.github.io/images/gpt3/10-gpt3-fine-tuning.gif)</span></span>
<span id="cb16-569"><a href="#cb16-569"></a></span>
<span id="cb16-570"><a href="#cb16-570"></a>**Fine-tuning**<span class="ot">[^ill-transf1]</span>: Fine-tuning actually updates the model's weights to make the model better at a certain task.</span>
<span id="cb16-571"><a href="#cb16-571"></a></span>
<span id="cb16-572"><a href="#cb16-572"></a>:::</span>
<span id="cb16-573"><a href="#cb16-573"></a></span>
<span id="cb16-574"><a href="#cb16-574"></a><span class="ot">[^ill-transf1]: </span>Figure from <span class="co">[</span><span class="ot">The Illustrated Transformer</span><span class="co">](http://jalammar.github.io/illustrated-transformer/)</span></span>
<span id="cb16-575"><a href="#cb16-575"></a></span>
<span id="cb16-576"><a href="#cb16-576"></a><span class="fu"># Forward Pass {background-color="white"}</span></span>
<span id="cb16-577"><a href="#cb16-577"></a></span>
<span id="cb16-578"><a href="#cb16-578"></a>::: {#fig-forward-pass}</span>
<span id="cb16-579"><a href="#cb16-579"></a></span>
<span id="cb16-580"><a href="#cb16-580"></a><span class="dt">&lt;</span><span class="kw">video</span><span class="ot"> data-autoplay src</span><span class="op">=</span><span class="st">"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_1_1080p.mov"</span><span class="dt">&gt;&lt;/</span><span class="kw">video</span><span class="dt">&gt;</span></span>
<span id="cb16-581"><a href="#cb16-581"></a></span>
<span id="cb16-582"><a href="#cb16-582"></a>Language Model trained for causal language modeling. Video from: <span class="co">[</span><span class="ot">🤗 Generation with LLMs</span><span class="co">](https://huggingface.co/docs/transformers/main/en/llm_tutorial)</span></span>
<span id="cb16-583"><a href="#cb16-583"></a>:::</span>
<span id="cb16-584"><a href="#cb16-584"></a></span>
<span id="cb16-585"><a href="#cb16-585"></a></span>
<span id="cb16-586"><a href="#cb16-586"></a><span class="fu"># Generating Text {background-color="white"}</span></span>
<span id="cb16-587"><a href="#cb16-587"></a></span>
<span id="cb16-588"><a href="#cb16-588"></a>::: {#fig-generating-text}</span>
<span id="cb16-589"><a href="#cb16-589"></a></span>
<span id="cb16-590"><a href="#cb16-590"></a><span class="dt">&lt;</span><span class="kw">video</span><span class="ot"> data-autoplay src</span><span class="op">=</span><span class="st">"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_2_1080p.mov"</span><span class="dt">&gt;&lt;/</span><span class="kw">video</span><span class="dt">&gt;</span></span>
<span id="cb16-591"><a href="#cb16-591"></a></span>
<span id="cb16-592"><a href="#cb16-592"></a>Language Model trained for causal language modeling. Video from: <span class="co">[</span><span class="ot">🤗 Generation with LLMs</span><span class="co">](https://huggingface.co/docs/transformers/main/en/llm_tutorial)</span></span>
<span id="cb16-593"><a href="#cb16-593"></a>:::</span>
<span id="cb16-594"><a href="#cb16-594"></a></span>
<span id="cb16-595"><a href="#cb16-595"></a></span>
<span id="cb16-596"><a href="#cb16-596"></a><span class="fu"># Parallelism Overview {background-color="white"}</span></span>
<span id="cb16-597"><a href="#cb16-597"></a></span>
<span id="cb16-598"><a href="#cb16-598"></a><span class="at">&gt; _**Modern parallelism techniques** enable the training of large language models_</span></span>
<span id="cb16-599"><a href="#cb16-599"></a></span>
<span id="cb16-600"><a href="#cb16-600"></a>::: aside</span>
<span id="cb16-601"><a href="#cb16-601"></a>See my slides on <span class="co">[</span><span class="ot">Parallel Training Techniques</span><span class="co">](https://saforem2.github.io/parallel-training-slides/#/title-slide)</span> for additional details</span>
<span id="cb16-602"><a href="#cb16-602"></a>:::</span>
<span id="cb16-603"><a href="#cb16-603"></a></span>
<span id="cb16-604"><a href="#cb16-604"></a><span class="fu"># Parallelism Concepts {style="font-size: 0.9em;" background-color="white"}</span></span>
<span id="cb16-605"><a href="#cb16-605"></a></span>
<span id="cb16-606"><a href="#cb16-606"></a><span class="ss">- </span>**DataParallel (DP)**:</span>
<span id="cb16-607"><a href="#cb16-607"></a><span class="ss">  - </span>The same setup is replicated multiple times, and each being fed a slice of</span>
<span id="cb16-608"><a href="#cb16-608"></a>    the data.</span>
<span id="cb16-609"><a href="#cb16-609"></a></span>
<span id="cb16-610"><a href="#cb16-610"></a><span class="ss">  - </span>The processing is done in parallel and all setups are synchronized at the</span>
<span id="cb16-611"><a href="#cb16-611"></a>    end of each training step.</span>
<span id="cb16-612"><a href="#cb16-612"></a></span>
<span id="cb16-613"><a href="#cb16-613"></a><span class="ss">- </span>**TensorParallel (TP)**:</span>
<span id="cb16-614"><a href="#cb16-614"></a><span class="ss">  - </span>Each tensor is split up into multiple chunks.</span>
<span id="cb16-615"><a href="#cb16-615"></a><span class="ss">  - </span>So, instead of having the whole tensor reside on a single gpu, each shard</span>
<span id="cb16-616"><a href="#cb16-616"></a>    of the tensor resides on its designated gpu.</span>
<span id="cb16-617"><a href="#cb16-617"></a><span class="ss">      - </span>During processing each shard gets processed separately and in parallel</span>
<span id="cb16-618"><a href="#cb16-618"></a>        on different GPUs and the results are synced at the end of the step.</span>
<span id="cb16-619"><a href="#cb16-619"></a><span class="ss">      - </span>This is what one may call horizontal parallelism, as he splitting</span>
<span id="cb16-620"><a href="#cb16-620"></a>        happens on horizontal level.</span>
<span id="cb16-621"><a href="#cb16-621"></a></span>
<span id="cb16-622"><a href="#cb16-622"></a>::: aside</span>
<span id="cb16-623"><a href="#cb16-623"></a></span>
<span id="cb16-624"><a href="#cb16-624"></a><span class="co">[</span><span class="ot">🤗 Model Parallelism</span><span class="co">](https://huggingface.co/docs/transformers/v4.15.0/parallelism)</span></span>
<span id="cb16-625"><a href="#cb16-625"></a></span>
<span id="cb16-626"><a href="#cb16-626"></a>:::</span>
<span id="cb16-627"><a href="#cb16-627"></a></span>
<span id="cb16-628"><a href="#cb16-628"></a><span class="fu"># Parallelism Concepts[^hf-mp1] {style="font-size: 0.9em;" background-color="white"}</span></span>
<span id="cb16-629"><a href="#cb16-629"></a></span>
<span id="cb16-630"><a href="#cb16-630"></a><span class="ss">- </span>**PipelineParallel (PP)**: </span>
<span id="cb16-631"><a href="#cb16-631"></a><span class="ss">  - </span>Model is split up vertically (layer-level) across multiple GPUs, so that</span>
<span id="cb16-632"><a href="#cb16-632"></a>    only one or several layers of the model are places on a single gpu.</span>
<span id="cb16-633"><a href="#cb16-633"></a><span class="ss">    - </span>Each gpu processes in parallel different stages of the pipeline and</span>
<span id="cb16-634"><a href="#cb16-634"></a>      working on a small chunk of the batch.</span>
<span id="cb16-635"><a href="#cb16-635"></a></span>
<span id="cb16-636"><a href="#cb16-636"></a><span class="ss">- </span>**Zero Redundancy Optimizer (ZeRO)**: </span>
<span id="cb16-637"><a href="#cb16-637"></a><span class="ss">  - </span>Also performs sharding of the tensors somewhat similar to TP, except the</span>
<span id="cb16-638"><a href="#cb16-638"></a>    whole tensor gets reconstructed in time for a forward or backward</span>
<span id="cb16-639"><a href="#cb16-639"></a>    computation, therefore the model doesn’t need to be modified.</span>
<span id="cb16-640"><a href="#cb16-640"></a><span class="ss">  - </span>It also supports various offloading techniques to compensate for limited</span>
<span id="cb16-641"><a href="#cb16-641"></a>    GPU memory.</span>
<span id="cb16-642"><a href="#cb16-642"></a></span>
<span id="cb16-643"><a href="#cb16-643"></a><span class="ss">- </span>**Sharded DDP**: </span>
<span id="cb16-644"><a href="#cb16-644"></a><span class="ss">  - </span>Another name for the foundational ZeRO concept as used by various other</span>
<span id="cb16-645"><a href="#cb16-645"></a>    implementations of ZeRO.</span>
<span id="cb16-646"><a href="#cb16-646"></a></span>
<span id="cb16-647"><a href="#cb16-647"></a><span class="ot">[^hf-mp1]: </span><span class="co">[</span><span class="ot">🤗 Model Parallelism</span><span class="co">](https://huggingface.co/docs/transformers/v4.15.0/parallelism)</span></span>
<span id="cb16-648"><a href="#cb16-648"></a></span>
<span id="cb16-649"><a href="#cb16-649"></a><span class="fu"># Data Parallelism {style="font-size: 0.9em;" background-color="white"}</span></span>
<span id="cb16-650"><a href="#cb16-650"></a></span>
<span id="cb16-651"><a href="#cb16-651"></a><span class="ss">- </span>**Data Parallelism**:</span>
<span id="cb16-652"><a href="#cb16-652"></a><span class="ss">  - </span>The simplest and most common parallelism technique.</span>
<span id="cb16-653"><a href="#cb16-653"></a>    Workers maintain _identical copies_ of the _complete_ model and work on a</span>
<span id="cb16-654"><a href="#cb16-654"></a>    _subset of the data_.</span>
<span id="cb16-655"><a href="#cb16-655"></a><span class="ss">  - </span><span class="in">`DDP`</span> supported in PyTorch native.</span>
<span id="cb16-656"><a href="#cb16-656"></a></span>
<span id="cb16-657"><a href="#cb16-657"></a><span class="ss">- </span>ZeRO Data Parallel</span>
<span id="cb16-658"><a href="#cb16-658"></a><span class="ss">  -  </span>ZeRO powered data parallelism is shown below<span class="ot">[^zero-dp]</span></span>
<span id="cb16-659"><a href="#cb16-659"></a></span>
<span id="cb16-660"><a href="#cb16-660"></a></span>
<span id="cb16-661"><a href="#cb16-661"></a>::: {style="text-align: center;"}</span>
<span id="cb16-662"><a href="#cb16-662"></a></span>
<span id="cb16-663"><a href="#cb16-663"></a><span class="dt">&lt;</span><span class="kw">img</span><span class="ot"> src</span><span class="op">=</span><span class="st">"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-zero.png"</span><span class="ot"> width</span><span class="op">=</span><span class="st">"75%"</span><span class="ot"> </span><span class="dt">/&gt;</span></span>
<span id="cb16-664"><a href="#cb16-664"></a></span>
<span id="cb16-665"><a href="#cb16-665"></a>:::</span>
<span id="cb16-666"><a href="#cb16-666"></a></span>
<span id="cb16-667"><a href="#cb16-667"></a><span class="ot">[^zero-dp]: </span><span class="co">[</span><span class="ot">Blog Post</span><span class="co">](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)</span></span>
<span id="cb16-668"><a href="#cb16-668"></a></span>
<span id="cb16-669"><a href="#cb16-669"></a><span class="fu"># Tensor Parallelism[^efficient-large-scale] {background-color="white"}</span></span>
<span id="cb16-670"><a href="#cb16-670"></a></span>
<span id="cb16-671"><a href="#cb16-671"></a><span class="ss">- </span>In **Tensor Paralleism** each GPU processes only a slice of a tensor and only aggregates the full tensor for operations that require the whole thing.</span>
<span id="cb16-672"><a href="#cb16-672"></a></span>
<span id="cb16-673"><a href="#cb16-673"></a><span class="ss">  - </span>The main building block of any transformer is a fully connected nn.Linear followed by a nonlinear activation GeLU.</span>
<span id="cb16-674"><a href="#cb16-674"></a></span>
<span id="cb16-675"><a href="#cb16-675"></a><span class="ss">    - </span><span class="in">`Y = GeLU(XA)`</span>, where X and Y are the input and output vectors, and A is the weight matrix.</span>
<span id="cb16-676"><a href="#cb16-676"></a></span>
<span id="cb16-677"><a href="#cb16-677"></a><span class="ss">  - </span>If we look at the computation in matrix form, it’s easy to see how the matrix multiplication can be split between multiple GPUs:</span>
<span id="cb16-678"><a href="#cb16-678"></a></span>
<span id="cb16-679"><a href="#cb16-679"></a><span class="ot">[^efficient-large-scale]: </span><span class="co">[</span><span class="ot">Efficient Large-Scale Language Model Training on GPU Clusters</span><span class="co">](https://arxiv.org/abs/2104.04473)</span></span>
<span id="cb16-680"><a href="#cb16-680"></a></span>
<span id="cb16-681"><a href="#cb16-681"></a><span class="fu"># Tensor Parallelism {style="font-size: 0.9em;" background-color="white"}</span></span>
<span id="cb16-682"><a href="#cb16-682"></a></span>
<span id="cb16-683"><a href="#cb16-683"></a>::: {style="text-align: center;"}</span>
<span id="cb16-684"><a href="#cb16-684"></a></span>
<span id="cb16-685"><a href="#cb16-685"></a><span class="dt">&lt;</span><span class="kw">img</span><span class="ot"> src</span><span class="op">=</span><span class="st">"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-parallel_gemm.png"</span><span class="ot"> width</span><span class="op">=</span><span class="st">"66%"</span><span class="ot"> style</span><span class="op">=</span><span class="st">"text-align: center;"</span><span class="ot"> </span><span class="dt">/&gt;</span></span>
<span id="cb16-686"><a href="#cb16-686"></a></span>
<span id="cb16-687"><a href="#cb16-687"></a>:::</span>
<span id="cb16-688"><a href="#cb16-688"></a></span>
<span id="cb16-689"><a href="#cb16-689"></a>::: footer</span>
<span id="cb16-690"><a href="#cb16-690"></a></span>
<span id="cb16-691"><a href="#cb16-691"></a>This information is based on (the much more in-depth) [TP</span>
<span id="cb16-692"><a href="#cb16-692"></a>Overview](https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530)</span>
<span id="cb16-693"><a href="#cb16-693"></a>by <span class="co">[</span><span class="ot">\@anton-l</span><span class="co">](https://github.com/anton-l)</span></span>
<span id="cb16-694"><a href="#cb16-694"></a></span>
<span id="cb16-695"><a href="#cb16-695"></a>:::</span>
<span id="cb16-696"><a href="#cb16-696"></a></span>
<span id="cb16-697"><a href="#cb16-697"></a><span class="fu"># 3D Parallelism {style="font-size:0.9em;" background-color="white"}</span></span>
<span id="cb16-698"><a href="#cb16-698"></a></span>
<span id="cb16-699"><a href="#cb16-699"></a><span class="ss">- </span><span class="in">`DP`</span> + <span class="in">`TP`</span> + <span class="in">`PP`</span> (3D) Parallelism</span>
<span id="cb16-700"><a href="#cb16-700"></a></span>
<span id="cb16-701"><a href="#cb16-701"></a>::: {#fig-3dparallel-1 style="text-align:center!important; width:90%;"}</span>
<span id="cb16-702"><a href="#cb16-702"></a><span class="al">![](https://www.microsoft.com/en-us/research/uploads/prod/2020/09/Blog_DeepSpeed3_Figure-1_highres-2048x1230.png)</span></span>
<span id="cb16-703"><a href="#cb16-703"></a></span>
<span id="cb16-704"><a href="#cb16-704"></a>3D Parallelism illustration. Figure from: <span class="co">[</span><span class="ot">https://www.deepspeed.ai/</span><span class="co">](https://www.deepspeed.ai/)</span></span>
<span id="cb16-705"><a href="#cb16-705"></a>:::</span>
<span id="cb16-706"><a href="#cb16-706"></a></span>
<span id="cb16-707"><a href="#cb16-707"></a></span>
<span id="cb16-708"><a href="#cb16-708"></a><span class="fu"># 3D Parallelism {background-color="white"}</span></span>
<span id="cb16-709"><a href="#cb16-709"></a></span>
<span id="cb16-710"><a href="#cb16-710"></a><span class="ss">- </span><span class="in">`DP`</span> + <span class="in">`TP`</span> + <span class="in">`PP`</span> (3D) Parallelism</span>
<span id="cb16-711"><a href="#cb16-711"></a></span>
<span id="cb16-712"><a href="#cb16-712"></a></span>
<span id="cb16-713"><a href="#cb16-713"></a>::: {#fig-3dparallel style="text-align:center!important;"}</span>
<span id="cb16-714"><a href="#cb16-714"></a></span>
<span id="cb16-715"><a href="#cb16-715"></a><span class="al">![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-deepspeed-3d.png)</span></span>
<span id="cb16-716"><a href="#cb16-716"></a></span>
<span id="cb16-717"><a href="#cb16-717"></a>Figure taken from [3D parallelism: Scaling to trillion-parameter</span>
<span id="cb16-718"><a href="#cb16-718"></a>models](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)</span>
<span id="cb16-719"><a href="#cb16-719"></a></span>
<span id="cb16-720"><a href="#cb16-720"></a>:::</span>
<span id="cb16-721"><a href="#cb16-721"></a></span>
<span id="cb16-722"><a href="#cb16-722"></a><span class="fu"># 🍋 [`ezpz`](https://github.com/saforem2/ezpz) {background-color="white"}</span></span>
<span id="cb16-723"><a href="#cb16-723"></a></span>
<span id="cb16-724"><a href="#cb16-724"></a><span class="fu"># Clone Repo(s) {background-color="white"}</span></span>
<span id="cb16-725"><a href="#cb16-725"></a></span>
<span id="cb16-726"><a href="#cb16-726"></a>::: {style="font-size: 0.8em; line-height: 1.0em;"}</span>
<span id="cb16-727"><a href="#cb16-727"></a></span>
<span id="cb16-728"><a href="#cb16-728"></a><span class="in">```bash</span></span>
<span id="cb16-729"><a href="#cb16-729"></a><span class="co">#[⭐][07:33:08 AM][foremans@x3101c0s13b0n0][~/tmp]</span></span>
<span id="cb16-730"><a href="#cb16-730"></a><span class="ex">$</span> mkdir ~/tmp/polaris-talk</span>
<span id="cb16-731"><a href="#cb16-731"></a></span>
<span id="cb16-732"><a href="#cb16-732"></a><span class="co">#[⭐][07:33:21 AM][foremans@x3101c0s13b0n0][~/tmp]</span></span>
<span id="cb16-733"><a href="#cb16-733"></a><span class="ex">$</span> cd ~/tmp/polaris-talk</span>
<span id="cb16-734"><a href="#cb16-734"></a></span>
<span id="cb16-735"><a href="#cb16-735"></a><span class="co">#[⭐][07:33:25 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk]</span></span>
<span id="cb16-736"><a href="#cb16-736"></a><span class="ex">$</span> NOW=<span class="va">$(</span><span class="ex">tstamp</span><span class="va">)</span> <span class="kw">&amp;&amp;</span> <span class="fu">mkdir</span> <span class="st">"</span><span class="va">${NOW}</span><span class="st">"</span> <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> <span class="st">"</span><span class="va">${NOW}</span><span class="st">"</span> <span class="co"># &amp;&amp; mkdir "core-dumps-${NOW}" &amp;&amp; mv -v **core\.** "core-dumps-${NOW}" &amp;&amp; mv "core-dumps-${NOW}" core-dumps</span></span>
<span id="cb16-737"><a href="#cb16-737"></a></span>
<span id="cb16-738"><a href="#cb16-738"></a><span class="co">#[⭐][07:33:27 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-739"><a href="#cb16-739"></a><span class="ex">$</span> pwd</span>
<span id="cb16-740"><a href="#cb16-740"></a><span class="ex">/home/foremans/tmp/polaris-talk/2024-07-17-073327</span></span>
<span id="cb16-741"><a href="#cb16-741"></a></span>
<span id="cb16-742"><a href="#cb16-742"></a><span class="co">#[⭐][07:33:31 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-743"><a href="#cb16-743"></a><span class="ex">$</span> git clone https://github.com/saforem2/ezpz ezpz <span class="kw">&amp;&amp;</span> <span class="fu">git</span> clone https://github.com/saforem2/wordplay wordplay</span>
<span id="cb16-744"><a href="#cb16-744"></a><span class="ex">Cloning</span> into <span class="st">'ezpz'</span>...</span>
<span id="cb16-745"><a href="#cb16-745"></a><span class="ex">remote:</span> Enumerating objects: 2134, done.<span class="kw">`</span></span>
<span id="cb16-746"><a href="#cb16-746"></a><span class="ex">remote:</span> Counting objects: 100% <span class="er">(</span><span class="ex">363/363</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-747"><a href="#cb16-747"></a><span class="ex">remote:</span> Compressing objects: 100% <span class="er">(</span><span class="ex">169/169</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-748"><a href="#cb16-748"></a><span class="ex">remote:</span> Total 2134 <span class="er">(</span><span class="ex">delta</span> 197<span class="kw">)</span><span class="ex">,</span> reused 265 <span class="er">(</span><span class="ex">delta</span> 141<span class="kw">)</span><span class="ex">,</span> pack-reused 1771</span>
<span id="cb16-749"><a href="#cb16-749"></a><span class="ex">Receiving</span> objects: 100% <span class="er">(</span><span class="ex">2134/2134</span><span class="kw">)</span><span class="ex">,</span> 4.27 MiB <span class="kw">|</span> <span class="ex">25.01</span> MiB/s, done.</span>
<span id="cb16-750"><a href="#cb16-750"></a><span class="ex">Resolving</span> deltas: 100% <span class="er">(</span><span class="ex">1117/1117</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-751"><a href="#cb16-751"></a><span class="ex">Cloning</span> into <span class="st">'wordplay'</span>...</span>
<span id="cb16-752"><a href="#cb16-752"></a><span class="ex">remote:</span> Enumerating objects: 869, done.</span>
<span id="cb16-753"><a href="#cb16-753"></a><span class="ex">remote:</span> Counting objects: 100% <span class="er">(</span><span class="ex">72/72</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-754"><a href="#cb16-754"></a><span class="ex">remote:</span> Compressing objects: 100% <span class="er">(</span><span class="ex">37/37</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-755"><a href="#cb16-755"></a><span class="ex">remote:</span> Total 869 <span class="er">(</span><span class="ex">delta</span> 29<span class="kw">)</span><span class="ex">,</span> reused 56 <span class="er">(</span><span class="ex">delta</span> 23<span class="kw">)</span><span class="ex">,</span> pack-reused 797</span>
<span id="cb16-756"><a href="#cb16-756"></a><span class="ex">Receiving</span> objects: 100% <span class="er">(</span><span class="ex">869/869</span><span class="kw">)</span><span class="ex">,</span> 14.36 MiB <span class="kw">|</span> <span class="ex">46.54</span> MiB/s, done.</span>
<span id="cb16-757"><a href="#cb16-757"></a><span class="ex">Resolving</span> deltas: 100% <span class="er">(</span><span class="ex">395/395</span><span class="kw">)</span><span class="ex">,</span> done.</span>
<span id="cb16-758"><a href="#cb16-758"></a><span class="kw">```</span></span>
<span id="cb16-759"><a href="#cb16-759"></a></span>
<span id="cb16-760"><a href="#cb16-760"></a><span class="ex">:::</span></span>
<span id="cb16-761"><a href="#cb16-761"></a></span>
<span id="cb16-762"><a href="#cb16-762"></a><span class="co"># Setup Python {.scrollable background-color="white"}</span></span>
<span id="cb16-763"><a href="#cb16-763"></a></span>
<span id="cb16-764"><a href="#cb16-764"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-765"><a href="#cb16-765"></a></span>
<span id="cb16-766"><a href="#cb16-766"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-767"><a href="#cb16-767"></a><span class="co">#[⭐][07:33:53 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-768"><a href="#cb16-768"></a><span class="ex">$</span> source ezpz/src/ezpz/bin/utils.sh <span class="kw">&amp;&amp;</span> <span class="ex">ezpz_setup_python</span> <span class="kw">&amp;&amp;</span> <span class="ex">ezpz_setup_alcf</span></span>
<span id="cb16-769"><a href="#cb16-769"></a><span class="ex">Unable</span> to detect PBS or SLURM working directory info...</span>
<span id="cb16-770"><a href="#cb16-770"></a><span class="ex">Using</span> /home/foremans/tmp/polaris-talk/2024-07-17-073327 as working directory...</span>
<span id="cb16-771"><a href="#cb16-771"></a><span class="ex">Using</span> WORKING_DIR: /home/foremans/tmp/polaris-talk/2024-07-17-073327</span>
<span id="cb16-772"><a href="#cb16-772"></a><span class="ex">No</span> conda_prefix OR virtual_env found in environment...</span>
<span id="cb16-773"><a href="#cb16-773"></a><span class="ex">Setting</span> up conda...</span>
<span id="cb16-774"><a href="#cb16-774"></a><span class="ex">Lmod</span> is automatically replacing <span class="st">"nvhpc/23.9"</span> with <span class="st">"gcc-native/12.3"</span>.</span>
<span id="cb16-775"><a href="#cb16-775"></a><span class="ex">Lmod</span> is automatically replacing <span class="st">"PrgEnv-nvhpc/8.5.0"</span> with <span class="st">"PrgEnv-gnu/8.5.0"</span>.</span>
<span id="cb16-776"><a href="#cb16-776"></a><span class="ex">Due</span> to MODULEPATH changes, the following have been reloaded:</span>
<span id="cb16-777"><a href="#cb16-777"></a>  <span class="ex">1</span><span class="er">)</span> <span class="ex">cray-mpich/8.1.28</span></span>
<span id="cb16-778"><a href="#cb16-778"></a><span class="ex">Found</span> conda at: /soft/applications/conda/2024-04-29/mconda3</span>
<span id="cb16-779"><a href="#cb16-779"></a><span class="ex">No</span> VIRTUAL_ENV found in environment!</span>
<span id="cb16-780"><a href="#cb16-780"></a>    <span class="ex">-</span> Trying to setup from /soft/applications/conda/2024-04-29/mconda3</span>
<span id="cb16-781"><a href="#cb16-781"></a>    <span class="ex">-</span> Using VENV_DIR=/home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb16-782"><a href="#cb16-782"></a>    <span class="ex">-</span> Creating a new virtual env on top of 2024-04-29 in /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb16-783"><a href="#cb16-783"></a><span class="ex">[python]</span> Using /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span>
<span id="cb16-784"><a href="#cb16-784"></a></span>
<span id="cb16-785"><a href="#cb16-785"></a><span class="ex">[ezpz/bin/utils.sh]</span></span>
<span id="cb16-786"><a href="#cb16-786"></a></span>
<span id="cb16-787"><a href="#cb16-787"></a><span class="ex">[2024-07-17-073407]</span></span>
<span id="cb16-788"><a href="#cb16-788"></a>    <span class="ex">•</span> USER=foremans</span>
<span id="cb16-789"><a href="#cb16-789"></a>    <span class="ex">•</span> MACHINE=polaris</span>
<span id="cb16-790"><a href="#cb16-790"></a>    <span class="ex">•</span> HOST=x3101c0s13b0n0</span>
<span id="cb16-791"><a href="#cb16-791"></a></span>
<span id="cb16-792"><a href="#cb16-792"></a><span class="ex">[ezpz_setup_host]</span></span>
<span id="cb16-793"><a href="#cb16-793"></a>    <span class="ex">•</span> Using hostfile: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-794"><a href="#cb16-794"></a>    <span class="ex">•</span> Found in environment:</span>
<span id="cb16-795"><a href="#cb16-795"></a>        <span class="ex">•</span> HOSTFILE: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-796"><a href="#cb16-796"></a>        <span class="ex">•</span> Writing PBS vars to: /home/foremans/.pbsenv</span>
<span id="cb16-797"><a href="#cb16-797"></a></span>
<span id="cb16-798"><a href="#cb16-798"></a><span class="ex">[ezpz_save_pbs_env]</span></span>
<span id="cb16-799"><a href="#cb16-799"></a>    <span class="ex">•</span> Setting:</span>
<span id="cb16-800"><a href="#cb16-800"></a>        <span class="ex">•</span> HOSTFILE: /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-801"><a href="#cb16-801"></a>        <span class="ex">•</span> JOBENV_FILE: /home/foremans/.pbsenv</span>
<span id="cb16-802"><a href="#cb16-802"></a></span>
<span id="cb16-803"><a href="#cb16-803"></a><span class="ex">[HOSTS]</span></span>
<span id="cb16-804"><a href="#cb16-804"></a>    <span class="ex">•</span> <span class="pp">[</span><span class="ss">host:0</span><span class="pp">]</span> <span class="at">-</span> x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-805"><a href="#cb16-805"></a></span>
<span id="cb16-806"><a href="#cb16-806"></a><span class="ex">[DIST</span> INFO]</span>
<span id="cb16-807"><a href="#cb16-807"></a>    <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-808"><a href="#cb16-808"></a>    <span class="ex">•</span> NHOSTS=1</span>
<span id="cb16-809"><a href="#cb16-809"></a>    <span class="ex">•</span> NGPU_PER_HOST=4</span>
<span id="cb16-810"><a href="#cb16-810"></a>    <span class="ex">•</span> NGPUS=4</span>
<span id="cb16-811"><a href="#cb16-811"></a>    <span class="ex">•</span> DIST_LAUNCH=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb16-812"><a href="#cb16-812"></a></span>
<span id="cb16-813"><a href="#cb16-813"></a><span class="ex">[LAUNCH]:</span></span>
<span id="cb16-814"><a href="#cb16-814"></a>    <span class="ex">•</span> To launch across all available GPUs, use: launch</span>
<span id="cb16-815"><a href="#cb16-815"></a>      <span class="ex">launch</span> = mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb16-816"><a href="#cb16-816"></a><span class="kw">```</span></span>
<span id="cb16-817"><a href="#cb16-817"></a></span>
<span id="cb16-818"><a href="#cb16-818"></a><span class="ex">:::</span></span>
<span id="cb16-819"><a href="#cb16-819"></a></span>
<span id="cb16-820"><a href="#cb16-820"></a><span class="co"># Install `{ezpz, wordplay}` {.scrollable background-color="white"}</span></span>
<span id="cb16-821"><a href="#cb16-821"></a></span>
<span id="cb16-822"><a href="#cb16-822"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-823"><a href="#cb16-823"></a></span>
<span id="cb16-824"><a href="#cb16-824"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-825"><a href="#cb16-825"></a><span class="co">#[⭐][07:34:13 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-826"><a href="#cb16-826"></a><span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">-e</span> ezpz wordplay <span class="at">--require-virtualenv</span></span>
<span id="cb16-827"><a href="#cb16-827"></a><span class="ex">Looking</span> in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com</span>
<span id="cb16-828"><a href="#cb16-828"></a><span class="ex">Obtaining</span> file:///home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz</span>
<span id="cb16-829"><a href="#cb16-829"></a>  <span class="ex">Installing</span> build dependencies ... done</span>
<span id="cb16-830"><a href="#cb16-830"></a>  <span class="ex">Checking</span> if build backend supports build_editable ... done</span>
<span id="cb16-831"><a href="#cb16-831"></a>  <span class="ex">Getting</span> requirements to build editable ... done</span>
<span id="cb16-832"><a href="#cb16-832"></a>  <span class="ex">Installing</span> backend dependencies ... done</span>
<span id="cb16-833"><a href="#cb16-833"></a>  <span class="ex">Preparing</span> editable metadata <span class="er">(</span><span class="ex">pyproject.toml</span><span class="kw">)</span> <span class="ex">...</span> done</span>
<span id="cb16-834"><a href="#cb16-834"></a></span>
<span id="cb16-835"><a href="#cb16-835"></a><span class="co"># ...[clipped]...</span></span>
<span id="cb16-836"><a href="#cb16-836"></a></span>
<span id="cb16-837"><a href="#cb16-837"></a><span class="ex">Successfully</span> built ezpz</span>
<span id="cb16-838"><a href="#cb16-838"></a><span class="ex">Installing</span> collected packages: enum34, wordplay, pyinstrument, ezpz</span>
<span id="cb16-839"><a href="#cb16-839"></a>  <span class="ex">Attempting</span> uninstall: ezpz</span>
<span id="cb16-840"><a href="#cb16-840"></a>    <span class="ex">Found</span> existing installation: ezpz 0.1</span>
<span id="cb16-841"><a href="#cb16-841"></a>    <span class="ex">Not</span> uninstalling ezpz at /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages, outside environment /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb16-842"><a href="#cb16-842"></a>    <span class="ex">Cant</span> uninstall <span class="st">'ezpz'</span>. No files were found to uninstall.</span>
<span id="cb16-843"><a href="#cb16-843"></a><span class="ex">Successfully</span> installed enum34-1.1.10 ezpz pyinstrument-4.6.2 wordplay-1.0.0a4</span>
<span id="cb16-844"><a href="#cb16-844"></a><span class="ex">[notice]</span> A new release of pip is available: 24.0 <span class="at">-</span><span class="op">&gt;</span> 24.1.2</span>
<span id="cb16-845"><a href="#cb16-845"></a><span class="ex">[notice]</span> To update, run: pip install <span class="at">--upgrade</span> pip</span>
<span id="cb16-846"><a href="#cb16-846"></a><span class="ex">9.62s</span> user 1.11s system 61% cpu 17.505s total</span>
<span id="cb16-847"><a href="#cb16-847"></a></span>
<span id="cb16-848"><a href="#cb16-848"></a><span class="co">#[⭐][07:34:53 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-849"><a href="#cb16-849"></a><span class="ex">$</span> python3 <span class="at">-m</span> pip install <span class="at">--upgrade</span> wandb</span>
<span id="cb16-850"><a href="#cb16-850"></a><span class="ex">Looking</span> in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com</span>
<span id="cb16-851"><a href="#cb16-851"></a><span class="ex">Requirement</span> already satisfied: wandb in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages <span class="er">(</span><span class="ex">0.16.6</span><span class="kw">)</span></span>
<span id="cb16-852"><a href="#cb16-852"></a><span class="ex">Collecting</span> wandb</span>
<span id="cb16-853"><a href="#cb16-853"></a>  <span class="ex">Downloading</span> wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata <span class="er">(</span><span class="ex">10</span> kB<span class="kw">)</span></span>
<span id="cb16-854"><a href="#cb16-854"></a><span class="ex">Downloading</span> wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl <span class="er">(</span><span class="ex">6.9</span> MB<span class="kw">)</span></span>
<span id="cb16-855"><a href="#cb16-855"></a>   <span class="ex">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 6.9/6.9 MB 2.1 MB/s eta 0:00:00</span>
<span id="cb16-856"><a href="#cb16-856"></a><span class="ex">Installing</span> collected packages: wandb</span>
<span id="cb16-857"><a href="#cb16-857"></a>  <span class="ex">Attempting</span> uninstall: wandb</span>
<span id="cb16-858"><a href="#cb16-858"></a>    <span class="ex">Found</span> existing installation: wandb 0.16.6</span>
<span id="cb16-859"><a href="#cb16-859"></a>    <span class="ex">Not</span> uninstalling wandb at /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages, outside environment /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29</span>
<span id="cb16-860"><a href="#cb16-860"></a>    <span class="ex">Cant</span> uninstall <span class="st">'wandb'</span>. No files were found to uninstall.</span>
<span id="cb16-861"><a href="#cb16-861"></a><span class="ex">Successfully</span> installed wandb-0.17.4</span>
<span id="cb16-862"><a href="#cb16-862"></a><span class="ex">[notice]</span> A new release of pip is available: 24.0 <span class="at">-</span><span class="op">&gt;</span> 24.1.2</span>
<span id="cb16-863"><a href="#cb16-863"></a><span class="ex">[notice]</span> To update, run: pip install <span class="at">--upgrade</span> pip</span>
<span id="cb16-864"><a href="#cb16-864"></a><span class="kw">```</span></span>
<span id="cb16-865"><a href="#cb16-865"></a></span>
<span id="cb16-866"><a href="#cb16-866"></a><span class="ex">:::</span></span>
<span id="cb16-867"><a href="#cb16-867"></a></span>
<span id="cb16-868"><a href="#cb16-868"></a><span class="co"># Launch [`ezpz.test_dist`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py) {.scrollable background-color="white"}</span></span>
<span id="cb16-869"><a href="#cb16-869"></a></span>
<span id="cb16-870"><a href="#cb16-870"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-871"><a href="#cb16-871"></a></span>
<span id="cb16-872"><a href="#cb16-872"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-873"><a href="#cb16-873"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb16-874"><a href="#cb16-874"></a><span class="co">#[⭐][07:34:07 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 7s]</span></span>
<span id="cb16-875"><a href="#cb16-875"></a><span class="ex">$</span> which launch</span>
<span id="cb16-876"><a href="#cb16-876"></a><span class="ex">launch:</span> aliased to mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb16-877"><a href="#cb16-877"></a></span>
<span id="cb16-878"><a href="#cb16-878"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb16-879"><a href="#cb16-879"></a><span class="co">#[⭐][07:34:11 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-880"><a href="#cb16-880"></a><span class="ex">$</span> which python3</span>
<span id="cb16-881"><a href="#cb16-881"></a><span class="ex">/home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span></span>
<span id="cb16-882"><a href="#cb16-882"></a></span>
<span id="cb16-883"><a href="#cb16-883"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb16-884"><a href="#cb16-884"></a><span class="co">#[⭐][07:35:21 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 14s]</span></span>
<span id="cb16-885"><a href="#cb16-885"></a><span class="ex">$</span> launch python3 <span class="at">-m</span> ezpz.test_dist <span class="kw">|</span> <span class="fu">tee</span> ezpz-test-dist-DDP.log</span>
<span id="cb16-886"><a href="#cb16-886"></a><span class="ex">Connected</span> to tcp://x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov:7919</span>
<span id="cb16-887"><a href="#cb16-887"></a><span class="ex">Found</span> executable /home/foremans/tmp/polaris-talk/2024-07-17-073327/venvs/2024-04-29/bin/python3</span>
<span id="cb16-888"><a href="#cb16-888"></a><span class="ex">Launching</span> application cff755ee-557e-4df2-a987-db85a8b7dbe7</span>
<span id="cb16-889"><a href="#cb16-889"></a><span class="ex">[2024-07-17</span> 07:35:30.304306]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:156</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb16-890"><a href="#cb16-890"></a><span class="ex">[2024-07-17</span> 07:35:30.307036]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:157</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb16-891"><a href="#cb16-891"></a><span class="ex">[2024-07-17</span> 07:35:30.307494]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:160</span><span class="pp">]</span> <span class="at">-</span> To disable this behavior, and log from ALL ranks <span class="er">(</span><span class="ex">not</span> recommended<span class="kw">)</span><span class="ex">,</span> set: <span class="st">'export LOG_FROM_ALL_RANKS=1'</span>  in your environment, and re-run.</span>
<span id="cb16-892"><a href="#cb16-892"></a><span class="ex">[2024-07-17</span> 07:35:32.116037]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=2/3</span><span class="pp">][</span><span class="ss">local_rank=2/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-893"><a href="#cb16-893"></a><span class="ex">[2024-07-17</span> 07:35:32.116089]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=3/3</span><span class="pp">][</span><span class="ss">local_rank=3/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-894"><a href="#cb16-894"></a><span class="ex">[2024-07-17</span> 07:35:32.116940]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=1/3</span><span class="pp">][</span><span class="ss">local_rank=1/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-895"><a href="#cb16-895"></a><span class="ex">[2024-07-17</span> 07:35:32.122726]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb16-896"><a href="#cb16-896"></a><span class="ex">[dist_info]:</span></span>
<span id="cb16-897"><a href="#cb16-897"></a>  <span class="ex">•</span> DEVICE=cuda</span>
<span id="cb16-898"><a href="#cb16-898"></a>  <span class="ex">•</span> DEVICE_ID=cuda:0</span>
<span id="cb16-899"><a href="#cb16-899"></a>  <span class="ex">•</span> DISTRIBUTED_BACKEND=nccl</span>
<span id="cb16-900"><a href="#cb16-900"></a>  <span class="ex">•</span> GPUS_PER_NODE=4</span>
<span id="cb16-901"><a href="#cb16-901"></a>  <span class="ex">•</span> HOSTS=<span class="pp">[</span><span class="st">'x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov'</span><span class="pp">]</span></span>
<span id="cb16-902"><a href="#cb16-902"></a>  <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-903"><a href="#cb16-903"></a>  <span class="ex">•</span> HOSTNAME=x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-904"><a href="#cb16-904"></a>  <span class="ex">•</span> LOCAL_RANK=0</span>
<span id="cb16-905"><a href="#cb16-905"></a>  <span class="ex">•</span> MACHINE=Polaris</span>
<span id="cb16-906"><a href="#cb16-906"></a>  <span class="ex">•</span> NUM_NODES=1</span>
<span id="cb16-907"><a href="#cb16-907"></a>  <span class="ex">•</span> NGPUS=4</span>
<span id="cb16-908"><a href="#cb16-908"></a>  <span class="ex">•</span> NGPUS_AVAILABLE=4</span>
<span id="cb16-909"><a href="#cb16-909"></a>  <span class="ex">•</span> NODE_ID=0</span>
<span id="cb16-910"><a href="#cb16-910"></a>  <span class="ex">•</span> RANK=0</span>
<span id="cb16-911"><a href="#cb16-911"></a>  <span class="ex">•</span> SCHEDULER=PBS</span>
<span id="cb16-912"><a href="#cb16-912"></a>  <span class="ex">•</span> WORLD_SIZE_TOTAL=4</span>
<span id="cb16-913"><a href="#cb16-913"></a>  <span class="ex">•</span> WORLD_SIZE_IN_USE=4</span>
<span id="cb16-914"><a href="#cb16-914"></a>  <span class="ex">•</span> LAUNCH_CMD=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb16-915"><a href="#cb16-915"></a><span class="ex">[2024-07-17</span> 07:35:32.124800]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:725</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0/4</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'DDP'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb16-916"><a href="#cb16-916"></a><span class="ex">[2024-07-17</span> 07:35:32.129169]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=0/3</span><span class="pp">][</span><span class="ss">local_rank=0/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-917"><a href="#cb16-917"></a><span class="ex">[2024-07-17</span> 07:35:32.129674]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">dist:364</span><span class="pp">]</span> <span class="at">-</span> Using [4 / 4] available <span class="st">"cuda"</span> devices !!</span>
<span id="cb16-918"><a href="#cb16-918"></a><span class="ex">[2024-07-17</span> 07:35:32.130219]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:874</span><span class="pp">]</span> <span class="at">-</span> Setting up wandb from rank: 0</span>
<span id="cb16-919"><a href="#cb16-919"></a><span class="ex">[2024-07-17</span> 07:35:32.130638]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:875</span><span class="pp">]</span> <span class="at">-</span> Using: WB PROJECT: ezpz.test_dist</span>
<span id="cb16-920"><a href="#cb16-920"></a><span class="ex">wandb:</span> Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.</span>
<span id="cb16-921"><a href="#cb16-921"></a><span class="ex">wandb:</span> Currently logged in as: foremans <span class="er">(</span><span class="ex">aurora_gpt</span><span class="kw">)</span><span class="bu">.</span> Use <span class="kw">`</span>wandb login <span class="at">--relogin</span><span class="kw">`</span> <span class="ex">to</span> force relogin</span>
<span id="cb16-922"><a href="#cb16-922"></a><span class="ex">wandb:</span> Tracking run with wandb version 0.17.4</span>
<span id="cb16-923"><a href="#cb16-923"></a><span class="ex">wandb:</span> Run data is saved locally in /home/foremans/tmp/polaris-talk/2024-07-17-073327/wandb/run-20240717_073532-p49rzxtv</span>
<span id="cb16-924"><a href="#cb16-924"></a><span class="ex">wandb:</span> Run <span class="kw">`</span>wandb offline<span class="kw">`</span> <span class="ex">to</span> turn off syncing.</span>
<span id="cb16-925"><a href="#cb16-925"></a><span class="ex">wandb:</span> Syncing run vibrant-river-284</span>
<span id="cb16-926"><a href="#cb16-926"></a><span class="ex">wandb:</span> ⭐️ View project at https://wandb.ai/aurora_gpt/ezpz.test_dist</span>
<span id="cb16-927"><a href="#cb16-927"></a><span class="ex">wandb:</span> 🚀 View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span>
<span id="cb16-928"><a href="#cb16-928"></a><span class="ex">[2024-07-17</span> 07:35:33.171085]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:905</span><span class="pp">]</span> <span class="at">-</span> W<span class="kw">&amp;</span><span class="ex">B</span> RUN: <span class="pp">[</span><span class="ss">vibrant</span><span class="pp">-</span><span class="ss">river</span><span class="pp">-</span><span class="ss">284</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span><span class="kw">)</span></span>
<span id="cb16-929"><a href="#cb16-929"></a><span class="ex">[2024-07-17</span> 07:35:33.182307]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:312</span><span class="pp">]</span> <span class="at">-</span> Updating wandb.run: vibrant-river-284 config with <span class="st">"DIST_INFO"</span></span>
<span id="cb16-930"><a href="#cb16-930"></a><span class="ex">[2024-07-17</span> 07:35:33.186499]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:938</span><span class="pp">]</span> <span class="at">-</span> Running on machine=<span class="st">'Polaris'</span></span>
<span id="cb16-931"><a href="#cb16-931"></a><span class="ex">[2024-07-17</span> 07:35:33.187790]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb16-932"><a href="#cb16-932"></a><span class="ex">[timers_import]:</span></span>
<span id="cb16-933"><a href="#cb16-933"></a>  <span class="ex">•</span> os=1.082196831703186e-06</span>
<span id="cb16-934"><a href="#cb16-934"></a>  <span class="ex">•</span> logging=4.507601261138916e-07</span>
<span id="cb16-935"><a href="#cb16-935"></a>  <span class="ex">•</span> typing=2.9457733035087585e-06</span>
<span id="cb16-936"><a href="#cb16-936"></a>  <span class="ex">•</span> pathlib=1.3122335076332092e-06</span>
<span id="cb16-937"><a href="#cb16-937"></a>  <span class="ex">•</span> ezpz=6.109476089477539e-07</span>
<span id="cb16-938"><a href="#cb16-938"></a>  <span class="ex">•</span> torch=2.9457733035087585e-06</span>
<span id="cb16-939"><a href="#cb16-939"></a>  <span class="ex">•</span> torch_ddp=2.314336597919464e-06</span>
<span id="cb16-940"><a href="#cb16-940"></a>  <span class="ex">•</span> wandb=1.842435449361801e-05</span>
<span id="cb16-941"><a href="#cb16-941"></a>  <span class="ex">•</span> total=3.0086375772953033e-05</span>
<span id="cb16-942"><a href="#cb16-942"></a></span>
<span id="cb16-943"><a href="#cb16-943"></a><span class="ex">[2024-07-17</span> 07:35:33.188979]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb16-944"><a href="#cb16-944"></a></span>
<span id="cb16-945"><a href="#cb16-945"></a><span class="ex">[CONFIG]:</span></span>
<span id="cb16-946"><a href="#cb16-946"></a>  <span class="ex">•</span> warmup=0</span>
<span id="cb16-947"><a href="#cb16-947"></a>  <span class="ex">•</span> log_freq=1</span>
<span id="cb16-948"><a href="#cb16-948"></a>  <span class="ex">•</span> batch_size=64</span>
<span id="cb16-949"><a href="#cb16-949"></a>  <span class="ex">•</span> input_size=128</span>
<span id="cb16-950"><a href="#cb16-950"></a>  <span class="ex">•</span> output_size=128</span>
<span id="cb16-951"><a href="#cb16-951"></a>  <span class="ex">•</span> dtype=torch.float32</span>
<span id="cb16-952"><a href="#cb16-952"></a>  <span class="ex">•</span> device=cuda</span>
<span id="cb16-953"><a href="#cb16-953"></a>  <span class="ex">•</span> world_size=4</span>
<span id="cb16-954"><a href="#cb16-954"></a>  <span class="ex">•</span> train_iters=100</span>
<span id="cb16-955"><a href="#cb16-955"></a></span>
<span id="cb16-956"><a href="#cb16-956"></a><span class="ex">[2024-07-17</span> 07:35:34.761945]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:183</span><span class="pp">]</span> <span class="at">-</span> model=Network<span class="er">(</span></span>
<span id="cb16-957"><a href="#cb16-957"></a>  <span class="kw">(</span><span class="ex">layers</span><span class="kw">)</span><span class="bu">:</span> Sequential<span class="er">(</span></span>
<span id="cb16-958"><a href="#cb16-958"></a>    <span class="kw">(</span><span class="ex">0</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>128, <span class="va">out_features</span><span class="op">=</span>1024, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb16-959"><a href="#cb16-959"></a>    <span class="kw">(</span><span class="ex">1</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>1024, <span class="va">out_features</span><span class="op">=</span>512, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb16-960"><a href="#cb16-960"></a>    <span class="kw">(</span><span class="ex">2</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>512, <span class="va">out_features</span><span class="op">=</span>256, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb16-961"><a href="#cb16-961"></a>    <span class="kw">(</span><span class="ex">3</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>256, <span class="va">out_features</span><span class="op">=</span>128, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb16-962"><a href="#cb16-962"></a>    <span class="kw">(</span><span class="ex">4</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>128, <span class="va">out_features</span><span class="op">=</span>128, <span class="va">bias</span><span class="op">=</span>True<span class="kw">)</span></span>
<span id="cb16-963"><a href="#cb16-963"></a>  <span class="kw">)</span></span>
<span id="cb16-964"><a href="#cb16-964"></a><span class="kw">)</span></span>
<span id="cb16-965"><a href="#cb16-965"></a><span class="ex">[2024-07-17</span> 07:35:36.943300]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=1, loss=2152.41, sps=1.697e+04, dt=0.00377066, dtf=0.001003, dtb=0.002768</span>
<span id="cb16-966"><a href="#cb16-966"></a><span class="ex">[2024-07-17</span> 07:35:36.948048]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=2, loss=1577.24, sps=3.611e+04, dt=0.00177221, dtf=0.0005256, dtb=0.001247</span>
<span id="cb16-967"><a href="#cb16-967"></a><span class="ex">[2024-07-17</span> 07:35:36.952085]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=3, loss=1201.25, sps=3.59e+04, dt=0.00178271, dtf=0.0004875, dtb=0.001295</span>
<span id="cb16-968"><a href="#cb16-968"></a><span class="ex">[2024-07-17</span> 07:35:36.956071]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=4, loss=1034.03, sps=3.704e+04, dt=0.0017279, dtf=0.0005082, dtb=0.00122</span>
<span id="cb16-969"><a href="#cb16-969"></a><span class="ex">[2024-07-17</span> 07:35:36.959944]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=5, loss=875.796, sps=3.825e+04, dt=0.00167313, dtf=0.0005121, dtb=0.001161</span>
<span id="cb16-970"><a href="#cb16-970"></a><span class="ex">[2024-07-17</span> 07:35:36.963806]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=6, loss=817.544, sps=3.804e+04, dt=0.00168248, dtf=0.0004651, dtb=0.001217</span>
<span id="cb16-971"><a href="#cb16-971"></a><span class="ex">[2024-07-17</span> 07:35:36.967806]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=7, loss=734.838, sps=3.536e+04, dt=0.0018099, dtf=0.0004969, dtb=0.001313</span>
<span id="cb16-972"><a href="#cb16-972"></a><span class="ex">[2024-07-17</span> 07:35:36.971741]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=8, loss=741.583, sps=3.682e+04, dt=0.00173809, dtf=0.0004537, dtb=0.001284</span>
<span id="cb16-973"><a href="#cb16-973"></a><span class="ex">[2024-07-17</span> 07:35:36.975672]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=9, loss=738.157, sps=3.717e+04, dt=0.0017217, dtf=0.0004635, dtb=0.001258</span>
<span id="cb16-974"><a href="#cb16-974"></a><span class="ex">[2024-07-17</span> 07:35:36.979537]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=10, loss=727.255, sps=3.857e+04, dt=0.00165911, dtf=0.0004897, dtb=0.001169</span>
<span id="cb16-975"><a href="#cb16-975"></a><span class="ex">[2024-07-17</span> 07:35:36.983367]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=11, loss=715.534, sps=3.979e+04, dt=0.00160845, dtf=0.0004246, dtb=0.001184</span>
<span id="cb16-976"><a href="#cb16-976"></a><span class="ex">[2024-07-17</span> 07:35:36.987262]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=12, loss=693.96, sps=3.791e+04, dt=0.00168827, dtf=0.0004543, dtb=0.001234</span>
<span id="cb16-977"><a href="#cb16-977"></a><span class="ex">[2024-07-17</span> 07:35:36.991156]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=13, loss=693.518, sps=3.815e+04, dt=0.00167748, dtf=0.0004182, dtb=0.001259</span>
<span id="cb16-978"><a href="#cb16-978"></a><span class="ex">[2024-07-17</span> 07:35:36.994942]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=14, loss=675.289, sps=4.003e+04, dt=0.00159879, dtf=0.0004048, dtb=0.001194</span>
<span id="cb16-979"><a href="#cb16-979"></a><span class="ex">[2024-07-17</span> 07:35:36.999681]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=15, loss=677.706, sps=4.062e+04, dt=0.0015755, dtf=0.0004248, dtb=0.001151</span>
<span id="cb16-980"><a href="#cb16-980"></a><span class="ex">[2024-07-17</span> 07:35:37.003599]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=16, loss=671.639, sps=3.754e+04, dt=0.00170499, dtf=0.000416, dtb=0.001289</span>
<span id="cb16-981"><a href="#cb16-981"></a><span class="ex">[2024-07-17</span> 07:35:37.007565]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=17, loss=652.219, sps=3.704e+04, dt=0.00172777, dtf=0.0004208, dtb=0.001307</span>
<span id="cb16-982"><a href="#cb16-982"></a><span class="ex">[2024-07-17</span> 07:35:37.011753]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=18, loss=633.308, sps=3.191e+04, dt=0.00200554, dtf=0.0004193, dtb=0.001586</span>
<span id="cb16-983"><a href="#cb16-983"></a><span class="ex">[2024-07-17</span> 07:35:37.015595]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=19, loss=635.459, sps=3.845e+04, dt=0.0016645, dtf=0.0004236, dtb=0.001241</span>
<span id="cb16-984"><a href="#cb16-984"></a><span class="ex">[2024-07-17</span> 07:35:37.019356]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=20, loss=626.979, sps=4.033e+04, dt=0.00158685, dtf=0.0004225, dtb=0.001164</span>
<span id="cb16-985"><a href="#cb16-985"></a><span class="ex">[2024-07-17</span> 07:35:37.023081]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=21, loss=612.352, sps=4.105e+04, dt=0.00155914, dtf=0.0004169, dtb=0.001142</span>
<span id="cb16-986"><a href="#cb16-986"></a><span class="ex">[2024-07-17</span> 07:35:37.026861]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=22, loss=609.89, sps=4.004e+04, dt=0.00159827, dtf=0.0004155, dtb=0.001183</span>
<span id="cb16-987"><a href="#cb16-987"></a><span class="ex">[2024-07-17</span> 07:35:37.030555]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=23, loss=602.673, sps=4.258e+04, dt=0.00150295, dtf=0.0004166, dtb=0.001086</span>
<span id="cb16-988"><a href="#cb16-988"></a><span class="ex">[2024-07-17</span> 07:35:37.034382]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=24, loss=613.106, sps=3.918e+04, dt=0.00163367, dtf=0.0004164, dtb=0.001217</span>
<span id="cb16-989"><a href="#cb16-989"></a><span class="ex">[2024-07-17</span> 07:35:37.038129]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=25, loss=644.755, sps=4.173e+04, dt=0.00153368, dtf=0.0004175, dtb=0.001116</span>
<span id="cb16-990"><a href="#cb16-990"></a><span class="ex">[2024-07-17</span> 07:35:37.041943]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=26, loss=789.106, sps=4.049e+04, dt=0.00158053, dtf=0.0004397, dtb=0.001141</span>
<span id="cb16-991"><a href="#cb16-991"></a><span class="ex">[2024-07-17</span> 07:35:37.045705]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=27, loss=691.36, sps=4.166e+04, dt=0.00153641, dtf=0.0004157, dtb=0.001121</span>
<span id="cb16-992"><a href="#cb16-992"></a><span class="ex">[2024-07-17</span> 07:35:37.049496]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=28, loss=657.228, sps=4.018e+04, dt=0.00159288, dtf=0.0004209, dtb=0.001172</span>
<span id="cb16-993"><a href="#cb16-993"></a><span class="ex">[2024-07-17</span> 07:35:37.053229]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=29, loss=633.212, sps=4.19e+04, dt=0.0015274, dtf=0.0004288, dtb=0.001099</span>
<span id="cb16-994"><a href="#cb16-994"></a><span class="ex">[2024-07-17</span> 07:35:37.057013]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=30, loss=640.29, sps=4.012e+04, dt=0.00159538, dtf=0.0004144, dtb=0.001181</span>
<span id="cb16-995"><a href="#cb16-995"></a><span class="ex">[2024-07-17</span> 07:35:37.060722]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=31, loss=604.287, sps=4.21e+04, dt=0.00152018, dtf=0.000398, dtb=0.001122</span>
<span id="cb16-996"><a href="#cb16-996"></a><span class="ex">[2024-07-17</span> 07:35:37.064489]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=32, loss=640.15, sps=4.079e+04, dt=0.00156912, dtf=0.0004007, dtb=0.001168</span>
<span id="cb16-997"><a href="#cb16-997"></a><span class="ex">[2024-07-17</span> 07:35:37.068206]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=33, loss=585.789, sps=4.238e+04, dt=0.00151007, dtf=0.0004199, dtb=0.00109</span>
<span id="cb16-998"><a href="#cb16-998"></a><span class="ex">[2024-07-17</span> 07:35:37.071974]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=34, loss=591.99, sps=4.053e+04, dt=0.00157917, dtf=0.000434, dtb=0.001145</span>
<span id="cb16-999"><a href="#cb16-999"></a><span class="ex">[2024-07-17</span> 07:35:37.075702]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=35, loss=618.223, sps=4.168e+04, dt=0.00153538, dtf=0.0004152, dtb=0.00112</span>
<span id="cb16-1000"><a href="#cb16-1000"></a><span class="ex">[2024-07-17</span> 07:35:37.079496]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=36, loss=572.365, sps=3.998e+04, dt=0.0016008, dtf=0.0004108, dtb=0.00119</span>
<span id="cb16-1001"><a href="#cb16-1001"></a><span class="ex">[2024-07-17</span> 07:35:37.083250]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=37, loss=573.749, sps=4.276e+04, dt=0.00149675, dtf=0.0004123, dtb=0.001084</span>
<span id="cb16-1002"><a href="#cb16-1002"></a><span class="ex">[2024-07-17</span> 07:35:37.086969]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=38, loss=580.662, sps=4.136e+04, dt=0.00154751, dtf=0.0004129, dtb=0.001135</span>
<span id="cb16-1003"><a href="#cb16-1003"></a><span class="ex">[2024-07-17</span> 07:35:37.090636]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=39, loss=568.836, sps=4.311e+04, dt=0.0014847, dtf=0.000409, dtb=0.001076</span>
<span id="cb16-1004"><a href="#cb16-1004"></a><span class="ex">[2024-07-17</span> 07:35:37.094396]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=40, loss=551.294, sps=4.145e+04, dt=0.00154388, dtf=0.0004118, dtb=0.001132</span>
<span id="cb16-1005"><a href="#cb16-1005"></a><span class="ex">[2024-07-17</span> 07:35:37.098103]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=41, loss=573.647, sps=4.352e+04, dt=0.00147048, dtf=0.0003977, dtb=0.001073</span>
<span id="cb16-1006"><a href="#cb16-1006"></a><span class="ex">[2024-07-17</span> 07:35:37.101867]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=42, loss=545.584, sps=4.257e+04, dt=0.00150354, dtf=0.000433, dtb=0.001071</span>
<span id="cb16-1007"><a href="#cb16-1007"></a><span class="ex">[2024-07-17</span> 07:35:37.105639]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=43, loss=544.877, sps=4.322e+04, dt=0.00148085, dtf=0.0004117, dtb=0.001069</span>
<span id="cb16-1008"><a href="#cb16-1008"></a><span class="ex">[2024-07-17</span> 07:35:37.109471]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=44, loss=559.886, sps=4.028e+04, dt=0.00158879, dtf=0.0004254, dtb=0.001163</span>
<span id="cb16-1009"><a href="#cb16-1009"></a><span class="ex">[2024-07-17</span> 07:35:37.113186]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=45, loss=534.895, sps=4.311e+04, dt=0.00148444, dtf=0.0004153, dtb=0.001069</span>
<span id="cb16-1010"><a href="#cb16-1010"></a><span class="ex">[2024-07-17</span> 07:35:37.116972]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=46, loss=536.457, sps=4.099e+04, dt=0.00156151, dtf=0.0004113, dtb=0.00115</span>
<span id="cb16-1011"><a href="#cb16-1011"></a><span class="ex">[2024-07-17</span> 07:35:37.120710]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=47, loss=548.508, sps=4.183e+04, dt=0.00152993, dtf=0.0004151, dtb=0.001115</span>
<span id="cb16-1012"><a href="#cb16-1012"></a><span class="ex">[2024-07-17</span> 07:35:37.124552]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=48, loss=532.186, sps=4.051e+04, dt=0.0015798, dtf=0.0004379, dtb=0.001142</span>
<span id="cb16-1013"><a href="#cb16-1013"></a><span class="ex">[2024-07-17</span> 07:35:37.128266]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=49, loss=519.254, sps=4.272e+04, dt=0.0014981, dtf=0.0004164, dtb=0.001082</span>
<span id="cb16-1014"><a href="#cb16-1014"></a><span class="ex">[2024-07-17</span> 07:35:37.131975]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=50, loss=535.535, sps=4.16e+04, dt=0.00153862, dtf=0.0004304, dtb=0.001108</span>
<span id="cb16-1015"><a href="#cb16-1015"></a><span class="ex">[2024-07-17</span> 07:35:37.135717]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=51, loss=520.722, sps=4.136e+04, dt=0.00154757, dtf=0.0004158, dtb=0.001132</span>
<span id="cb16-1016"><a href="#cb16-1016"></a><span class="ex">[2024-07-17</span> 07:35:37.139451]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=52, loss=513.063, sps=4.147e+04, dt=0.00154317, dtf=0.0004138, dtb=0.001129</span>
<span id="cb16-1017"><a href="#cb16-1017"></a><span class="ex">[2024-07-17</span> 07:35:37.143231]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=53, loss=514.546, sps=4.038e+04, dt=0.0015848, dtf=0.0004149, dtb=0.00117</span>
<span id="cb16-1018"><a href="#cb16-1018"></a><span class="ex">[2024-07-17</span> 07:35:37.146971]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=54, loss=506.488, sps=4.137e+04, dt=0.00154701, dtf=0.0004132, dtb=0.001134</span>
<span id="cb16-1019"><a href="#cb16-1019"></a><span class="ex">[2024-07-17</span> 07:35:37.150659]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=55, loss=503.01, sps=4.319e+04, dt=0.0014817, dtf=0.000415, dtb=0.001067</span>
<span id="cb16-1020"><a href="#cb16-1020"></a><span class="ex">[2024-07-17</span> 07:35:37.154441]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=56, loss=506.116, sps=4.06e+04, dt=0.00157637, dtf=0.0004211, dtb=0.001155</span>
<span id="cb16-1021"><a href="#cb16-1021"></a><span class="ex">[2024-07-17</span> 07:35:37.158180]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=57, loss=485.523, sps=4.287e+04, dt=0.00149301, dtf=0.000414, dtb=0.001079</span>
<span id="cb16-1022"><a href="#cb16-1022"></a><span class="ex">[2024-07-17</span> 07:35:37.161931]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=58, loss=489.076, sps=4.185e+04, dt=0.00152915, dtf=0.0004162, dtb=0.001113</span>
<span id="cb16-1023"><a href="#cb16-1023"></a><span class="ex">[2024-07-17</span> 07:35:37.165759]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=59, loss=484.844, sps=4.134e+04, dt=0.00154802, dtf=0.0004119, dtb=0.001136</span>
<span id="cb16-1024"><a href="#cb16-1024"></a><span class="ex">[2024-07-17</span> 07:35:37.169483]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=60, loss=496.104, sps=4.209e+04, dt=0.00152069, dtf=0.0003993, dtb=0.001121</span>
<span id="cb16-1025"><a href="#cb16-1025"></a><span class="ex">[2024-07-17</span> 07:35:37.173190]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=61, loss=467.599, sps=4.221e+04, dt=0.00151621, dtf=0.0004142, dtb=0.001102</span>
<span id="cb16-1026"><a href="#cb16-1026"></a><span class="ex">[2024-07-17</span> 07:35:37.176950]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=62, loss=480.055, sps=4.187e+04, dt=0.00152868, dtf=0.0004138, dtb=0.001115</span>
<span id="cb16-1027"><a href="#cb16-1027"></a><span class="ex">[2024-07-17</span> 07:35:37.181194]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=63, loss=483.146, sps=3.656e+04, dt=0.00175062, dtf=0.0006253, dtb=0.001125</span>
<span id="cb16-1028"><a href="#cb16-1028"></a><span class="ex">[2024-07-17</span> 07:35:37.185018]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=64, loss=479.273, sps=4.099e+04, dt=0.00156151, dtf=0.0004447, dtb=0.001117</span>
<span id="cb16-1029"><a href="#cb16-1029"></a><span class="ex">[2024-07-17</span> 07:35:37.188752]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=65, loss=464.753, sps=4.189e+04, dt=0.00152781, dtf=0.0004161, dtb=0.001112</span>
<span id="cb16-1030"><a href="#cb16-1030"></a><span class="ex">[2024-07-17</span> 07:35:37.192464]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=66, loss=462.583, sps=4.188e+04, dt=0.00152824, dtf=0.0004138, dtb=0.001114</span>
<span id="cb16-1031"><a href="#cb16-1031"></a><span class="ex">[2024-07-17</span> 07:35:37.196126]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=67, loss=461.665, sps=4.272e+04, dt=0.00149801, dtf=0.0004293, dtb=0.001069</span>
<span id="cb16-1032"><a href="#cb16-1032"></a><span class="ex">[2024-07-17</span> 07:35:37.199838]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=68, loss=465.25, sps=4.118e+04, dt=0.00155412, dtf=0.0004298, dtb=0.001124</span>
<span id="cb16-1033"><a href="#cb16-1033"></a><span class="ex">[2024-07-17</span> 07:35:37.203602]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=69, loss=460.897, sps=4.01e+04, dt=0.00159593, dtf=0.0004131, dtb=0.001183</span>
<span id="cb16-1034"><a href="#cb16-1034"></a><span class="ex">[2024-07-17</span> 07:35:37.207372]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=70, loss=456.136, sps=4.106e+04, dt=0.00155887, dtf=0.00041, dtb=0.001149</span>
<span id="cb16-1035"><a href="#cb16-1035"></a><span class="ex">[2024-07-17</span> 07:35:37.211089]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=71, loss=447.565, sps=4.158e+04, dt=0.00153923, dtf=0.0004113, dtb=0.001128</span>
<span id="cb16-1036"><a href="#cb16-1036"></a><span class="ex">[2024-07-17</span> 07:35:37.214861]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=72, loss=444.733, sps=4.05e+04, dt=0.00158026, dtf=0.0004127, dtb=0.001168</span>
<span id="cb16-1037"><a href="#cb16-1037"></a><span class="ex">[2024-07-17</span> 07:35:37.218601]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=73, loss=459.152, sps=4.123e+04, dt=0.00155234, dtf=0.0004201, dtb=0.001132</span>
<span id="cb16-1038"><a href="#cb16-1038"></a><span class="ex">[2024-07-17</span> 07:35:37.222334]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=74, loss=444.6, sps=4.226e+04, dt=0.00151444, dtf=0.0004371, dtb=0.001077</span>
<span id="cb16-1039"><a href="#cb16-1039"></a><span class="ex">[2024-07-17</span> 07:35:37.226042]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=75, loss=439.884, sps=4.29e+04, dt=0.001492, dtf=0.0004154, dtb=0.001077</span>
<span id="cb16-1040"><a href="#cb16-1040"></a><span class="ex">[2024-07-17</span> 07:35:37.229838]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=76, loss=438.578, sps=4.086e+04, dt=0.00156632, dtf=0.0004418, dtb=0.001125</span>
<span id="cb16-1041"><a href="#cb16-1041"></a><span class="ex">[2024-07-17</span> 07:35:37.233560]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=77, loss=431.993, sps=4.327e+04, dt=0.00147909, dtf=0.0004096, dtb=0.00107</span>
<span id="cb16-1042"><a href="#cb16-1042"></a><span class="ex">[2024-07-17</span> 07:35:37.237367]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=78, loss=422.338, sps=4.057e+04, dt=0.00157754, dtf=0.0004468, dtb=0.001131</span>
<span id="cb16-1043"><a href="#cb16-1043"></a><span class="ex">[2024-07-17</span> 07:35:37.241117]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=79, loss=427.973, sps=4.288e+04, dt=0.00149254, dtf=0.000415, dtb=0.001077</span>
<span id="cb16-1044"><a href="#cb16-1044"></a><span class="ex">[2024-07-17</span> 07:35:37.244895]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=80, loss=418.703, sps=4.06e+04, dt=0.00157617, dtf=0.0004137, dtb=0.001162</span>
<span id="cb16-1045"><a href="#cb16-1045"></a><span class="ex">[2024-07-17</span> 07:35:37.248740]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=81, loss=427.645, sps=4.031e+04, dt=0.00158766, dtf=0.000415, dtb=0.001173</span>
<span id="cb16-1046"><a href="#cb16-1046"></a><span class="ex">[2024-07-17</span> 07:35:37.252447]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=82, loss=417.629, sps=4.227e+04, dt=0.00151406, dtf=0.0004149, dtb=0.001099</span>
<span id="cb16-1047"><a href="#cb16-1047"></a><span class="ex">[2024-07-17</span> 07:35:37.256190]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=83, loss=411.667, sps=4.189e+04, dt=0.00152778, dtf=0.0004357, dtb=0.001092</span>
<span id="cb16-1048"><a href="#cb16-1048"></a><span class="ex">[2024-07-17</span> 07:35:37.259935]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=84, loss=409.366, sps=4.144e+04, dt=0.0015445, dtf=0.0004575, dtb=0.001087</span>
<span id="cb16-1049"><a href="#cb16-1049"></a><span class="ex">[2024-07-17</span> 07:35:37.263677]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=85, loss=409.511, sps=4.232e+04, dt=0.00151228, dtf=0.0004035, dtb=0.001109</span>
<span id="cb16-1050"><a href="#cb16-1050"></a><span class="ex">[2024-07-17</span> 07:35:37.267463]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=86, loss=409.593, sps=4.101e+04, dt=0.00156049, dtf=0.0004028, dtb=0.001158</span>
<span id="cb16-1051"><a href="#cb16-1051"></a><span class="ex">[2024-07-17</span> 07:35:37.271174]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=87, loss=408.794, sps=4.3e+04, dt=0.00148828, dtf=0.0004006, dtb=0.001088</span>
<span id="cb16-1052"><a href="#cb16-1052"></a><span class="ex">[2024-07-17</span> 07:35:37.274926]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=88, loss=403.151, sps=4.091e+04, dt=0.00156441, dtf=0.000415, dtb=0.001149</span>
<span id="cb16-1053"><a href="#cb16-1053"></a><span class="ex">[2024-07-17</span> 07:35:37.278633]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=89, loss=402.182, sps=4.26e+04, dt=0.00150243, dtf=0.0004147, dtb=0.001088</span>
<span id="cb16-1054"><a href="#cb16-1054"></a><span class="ex">[2024-07-17</span> 07:35:37.282372]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=90, loss=387.829, sps=4.216e+04, dt=0.00151793, dtf=0.0004411, dtb=0.001077</span>
<span id="cb16-1055"><a href="#cb16-1055"></a><span class="ex">[2024-07-17</span> 07:35:37.286102]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=91, loss=393.108, sps=4.308e+04, dt=0.00148558, dtf=0.0004167, dtb=0.001069</span>
<span id="cb16-1056"><a href="#cb16-1056"></a><span class="ex">[2024-07-17</span> 07:35:37.289904]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=92, loss=389.039, sps=4.103e+04, dt=0.00155996, dtf=0.0004359, dtb=0.001124</span>
<span id="cb16-1057"><a href="#cb16-1057"></a><span class="ex">[2024-07-17</span> 07:35:37.293618]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=93, loss=383.54, sps=4.322e+04, dt=0.00148092, dtf=0.0004147, dtb=0.001066</span>
<span id="cb16-1058"><a href="#cb16-1058"></a><span class="ex">[2024-07-17</span> 07:35:37.297401]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=94, loss=384.459, sps=4.1e+04, dt=0.00156106, dtf=0.0004164, dtb=0.001145</span>
<span id="cb16-1059"><a href="#cb16-1059"></a><span class="ex">[2024-07-17</span> 07:35:37.301172]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=95, loss=376.397, sps=4.191e+04, dt=0.0015272, dtf=0.0004129, dtb=0.001114</span>
<span id="cb16-1060"><a href="#cb16-1060"></a><span class="ex">[2024-07-17</span> 07:35:37.304924]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=96, loss=389.544, sps=4.091e+04, dt=0.00156433, dtf=0.0004139, dtb=0.00115</span>
<span id="cb16-1061"><a href="#cb16-1061"></a><span class="ex">[2024-07-17</span> 07:35:37.308641]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=97, loss=365.041, sps=4.343e+04, dt=0.00147362, dtf=0.0004165, dtb=0.001057</span>
<span id="cb16-1062"><a href="#cb16-1062"></a><span class="ex">[2024-07-17</span> 07:35:37.312398]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=98, loss=358.427, sps=4.134e+04, dt=0.00154796, dtf=0.0004143, dtb=0.001134</span>
<span id="cb16-1063"><a href="#cb16-1063"></a><span class="ex">[2024-07-17</span> 07:35:37.561881]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:274</span><span class="pp">]</span> <span class="at">-</span> iter=99, loss=375.596, sps=258.9, dt=0.247161, dtf=0.1969, dtb=0.05026</span>
<span id="cb16-1064"><a href="#cb16-1064"></a></span>
<span id="cb16-1065"><a href="#cb16-1065"></a>                            <span class="ex">train/dt</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1066"><a href="#cb16-1066"></a>     <span class="ex">┌─────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1067"><a href="#cb16-1067"></a><span class="ex">0.247┤</span>                                                                        ▝│</span>
<span id="cb16-1068"><a href="#cb16-1068"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1069"><a href="#cb16-1069"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1070"><a href="#cb16-1070"></a><span class="ex">0.206┤</span>                                                                         │</span>
<span id="cb16-1071"><a href="#cb16-1071"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1072"><a href="#cb16-1072"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1073"><a href="#cb16-1073"></a><span class="ex">0.165┤</span>                                                                         │</span>
<span id="cb16-1074"><a href="#cb16-1074"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1075"><a href="#cb16-1075"></a><span class="ex">0.124┤</span>                                                                         │</span>
<span id="cb16-1076"><a href="#cb16-1076"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1077"><a href="#cb16-1077"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1078"><a href="#cb16-1078"></a><span class="ex">0.083┤</span>                                                                         │</span>
<span id="cb16-1079"><a href="#cb16-1079"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1080"><a href="#cb16-1080"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1081"><a href="#cb16-1081"></a><span class="ex">0.042┤</span>                                                                         │</span>
<span id="cb16-1082"><a href="#cb16-1082"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1083"><a href="#cb16-1083"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1084"><a href="#cb16-1084"></a><span class="ex">0.001┤▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb16-1085"><a href="#cb16-1085"></a>     <span class="ex">└┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb16-1086"><a href="#cb16-1086"></a>     <span class="ex">1.0</span>              25.5              50.0              74.5             99.0</span>
<span id="cb16-1087"><a href="#cb16-1087"></a><span class="ex">train/dt</span>                                iter</span>
<span id="cb16-1088"><a href="#cb16-1088"></a><span class="ex">[2024-07-17</span> 07:35:37.589287]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dt.txt</span>
<span id="cb16-1089"><a href="#cb16-1089"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dt.txt</span>
<span id="cb16-1090"><a href="#cb16-1090"></a>                            <span class="ex">train/dtf</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1091"><a href="#cb16-1091"></a>     <span class="ex">┌─────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1092"><a href="#cb16-1092"></a><span class="ex">0.197┤</span>                                                                        ▝│</span>
<span id="cb16-1093"><a href="#cb16-1093"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1094"><a href="#cb16-1094"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1095"><a href="#cb16-1095"></a><span class="ex">0.164┤</span>                                                                         │</span>
<span id="cb16-1096"><a href="#cb16-1096"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1097"><a href="#cb16-1097"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1098"><a href="#cb16-1098"></a><span class="ex">0.131┤</span>                                                                         │</span>
<span id="cb16-1099"><a href="#cb16-1099"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1100"><a href="#cb16-1100"></a><span class="ex">0.099┤</span>                                                                         │</span>
<span id="cb16-1101"><a href="#cb16-1101"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1102"><a href="#cb16-1102"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1103"><a href="#cb16-1103"></a><span class="ex">0.066┤</span>                                                                         │</span>
<span id="cb16-1104"><a href="#cb16-1104"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1105"><a href="#cb16-1105"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1106"><a href="#cb16-1106"></a><span class="ex">0.033┤</span>                                                                         │</span>
<span id="cb16-1107"><a href="#cb16-1107"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1108"><a href="#cb16-1108"></a>     <span class="ex">│</span>                                                                         │</span>
<span id="cb16-1109"><a href="#cb16-1109"></a><span class="ex">0.000┤▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb16-1110"><a href="#cb16-1110"></a>     <span class="ex">└┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb16-1111"><a href="#cb16-1111"></a>     <span class="ex">1.0</span>              25.5              50.0              74.5             99.0</span>
<span id="cb16-1112"><a href="#cb16-1112"></a><span class="ex">train/dtf</span>                               iter</span>
<span id="cb16-1113"><a href="#cb16-1113"></a><span class="ex">[2024-07-17</span> 07:35:37.603242]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtf.txt</span>
<span id="cb16-1114"><a href="#cb16-1114"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtf.txt</span>
<span id="cb16-1115"><a href="#cb16-1115"></a>                             <span class="ex">train/dtb</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1116"><a href="#cb16-1116"></a>      <span class="ex">┌────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1117"><a href="#cb16-1117"></a><span class="ex">0.0503┤</span>                                                                       ▝│</span>
<span id="cb16-1118"><a href="#cb16-1118"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1119"><a href="#cb16-1119"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1120"><a href="#cb16-1120"></a><span class="ex">0.0421┤</span>                                                                        │</span>
<span id="cb16-1121"><a href="#cb16-1121"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1122"><a href="#cb16-1122"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1123"><a href="#cb16-1123"></a><span class="ex">0.0339┤</span>                                                                        │</span>
<span id="cb16-1124"><a href="#cb16-1124"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1125"><a href="#cb16-1125"></a><span class="ex">0.0257┤</span>                                                                        │</span>
<span id="cb16-1126"><a href="#cb16-1126"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1127"><a href="#cb16-1127"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1128"><a href="#cb16-1128"></a><span class="ex">0.0175┤</span>                                                                        │</span>
<span id="cb16-1129"><a href="#cb16-1129"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1130"><a href="#cb16-1130"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1131"><a href="#cb16-1131"></a><span class="ex">0.0093┤</span>                                                                        │</span>
<span id="cb16-1132"><a href="#cb16-1132"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1133"><a href="#cb16-1133"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1134"><a href="#cb16-1134"></a><span class="ex">0.0011┤▚▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▖▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▄▗▖▄▗▖▄▗▖▖│</span></span>
<span id="cb16-1135"><a href="#cb16-1135"></a>      <span class="ex">└┬─────────────────┬─────────────────┬────────────────┬─────────────────┬┘</span></span>
<span id="cb16-1136"><a href="#cb16-1136"></a>      <span class="ex">1.0</span>              25.5              50.0             74.5             99.0</span>
<span id="cb16-1137"><a href="#cb16-1137"></a><span class="ex">train/dtb</span>                                iter</span>
<span id="cb16-1138"><a href="#cb16-1138"></a><span class="ex">[2024-07-17</span> 07:35:37.615896]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtb.txt</span>
<span id="cb16-1139"><a href="#cb16-1139"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/dtb.txt</span>
<span id="cb16-1140"><a href="#cb16-1140"></a>                            <span class="ex">train/loss</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1141"><a href="#cb16-1141"></a>      <span class="ex">┌────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1142"><a href="#cb16-1142"></a><span class="ex">2152.4┤▘</span>                                                                       │</span>
<span id="cb16-1143"><a href="#cb16-1143"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1144"><a href="#cb16-1144"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1145"><a href="#cb16-1145"></a><span class="ex">1853.4┤</span>                                                                        │</span>
<span id="cb16-1146"><a href="#cb16-1146"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1147"><a href="#cb16-1147"></a>      <span class="ex">│▗</span>                                                                       │</span>
<span id="cb16-1148"><a href="#cb16-1148"></a><span class="ex">1554.4┤</span>                                                                        │</span>
<span id="cb16-1149"><a href="#cb16-1149"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1150"><a href="#cb16-1150"></a><span class="ex">1255.4┤</span>                                                                        │</span>
<span id="cb16-1151"><a href="#cb16-1151"></a>      <span class="ex">│</span> ▗                                                                      │</span>
<span id="cb16-1152"><a href="#cb16-1152"></a>      <span class="ex">│</span>                                                                        │</span>
<span id="cb16-1153"><a href="#cb16-1153"></a> <span class="ex">956.4┤</span>  ▘                                                                     │</span>
<span id="cb16-1154"><a href="#cb16-1154"></a>      <span class="ex">│</span>   ▖                                                                    │</span>
<span id="cb16-1155"><a href="#cb16-1155"></a>      <span class="ex">│</span>   ▝              ▖                                                     │</span>
<span id="cb16-1156"><a href="#cb16-1156"></a> <span class="ex">657.4┤</span>    ▝▘▀▝▘▚▖▄     ▗ ▄                                                    │</span>
<span id="cb16-1157"><a href="#cb16-1157"></a>      <span class="ex">│</span>            ▝▘▀▝▘▘  ▝▘▀▗▘▚▗▄▗▖▄▗ ▗                                      │</span>
<span id="cb16-1158"><a href="#cb16-1158"></a>      <span class="ex">│</span>                                ▘▘▝▘▀▘▀▝▘▞▗▘▄▖▄▗▖▄▗▖▄▗▄                 │</span>
<span id="cb16-1159"><a href="#cb16-1159"></a> <span class="ex">358.4┤</span>                                                       ▝▘▀▝▘▀▝▀▝▘▀▝▖▚▝▖▄│</span>
<span id="cb16-1160"><a href="#cb16-1160"></a>      <span class="ex">└┬─────────────────┬─────────────────┬────────────────┬─────────────────┬┘</span></span>
<span id="cb16-1161"><a href="#cb16-1161"></a>      <span class="ex">1.0</span>              25.5              50.0             74.5             99.0</span>
<span id="cb16-1162"><a href="#cb16-1162"></a><span class="ex">train/loss</span>                               iter</span>
<span id="cb16-1163"><a href="#cb16-1163"></a><span class="ex">[2024-07-17</span> 07:35:37.655339]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/loss.txt</span>
<span id="cb16-1164"><a href="#cb16-1164"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/loss.txt</span>
<span id="cb16-1165"><a href="#cb16-1165"></a>                           <span class="ex">train/iter</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1166"><a href="#cb16-1166"></a>    <span class="ex">┌──────────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1167"><a href="#cb16-1167"></a><span class="ex">99.0┤</span>                                                                      ▗▗▖▀│</span>
<span id="cb16-1168"><a href="#cb16-1168"></a>    <span class="ex">│</span>                                                                   ▄▝▘▘   │</span>
<span id="cb16-1169"><a href="#cb16-1169"></a>    <span class="ex">│</span>                                                              ▗▖▞▝▘       │</span>
<span id="cb16-1170"><a href="#cb16-1170"></a><span class="ex">82.7┤</span>                                                          ▄▗▘▀            │</span>
<span id="cb16-1171"><a href="#cb16-1171"></a>    <span class="ex">│</span>                                                      ▖▄▝▘                │</span>
<span id="cb16-1172"><a href="#cb16-1172"></a>    <span class="ex">│</span>                                                 ▗▗▖▀▝                    │</span>
<span id="cb16-1173"><a href="#cb16-1173"></a><span class="ex">66.3┤</span>                                              ▄▝▘▘                        │</span>
<span id="cb16-1174"><a href="#cb16-1174"></a>    <span class="ex">│</span>                                         ▗▖▞▝▘                            │</span>
<span id="cb16-1175"><a href="#cb16-1175"></a><span class="ex">50.0┤</span>                                     ▄▗▘▀                                 │</span>
<span id="cb16-1176"><a href="#cb16-1176"></a>    <span class="ex">│</span>                                 ▖▄▝▘                                     │</span>
<span id="cb16-1177"><a href="#cb16-1177"></a>    <span class="ex">│</span>                            ▗▗▖▀▝                                         │</span>
<span id="cb16-1178"><a href="#cb16-1178"></a><span class="ex">33.7┤</span>                         ▄▝▘▘                                             │</span>
<span id="cb16-1179"><a href="#cb16-1179"></a>    <span class="ex">│</span>                    ▗▖▞▝▘                                                 │</span>
<span id="cb16-1180"><a href="#cb16-1180"></a>    <span class="ex">│</span>                ▄▗▘▀                                                      │</span>
<span id="cb16-1181"><a href="#cb16-1181"></a><span class="ex">17.3┤</span>            ▖▄▝▘                                                          │</span>
<span id="cb16-1182"><a href="#cb16-1182"></a>    <span class="ex">│</span>       ▗▗▖▀▝                                                              │</span>
<span id="cb16-1183"><a href="#cb16-1183"></a>    <span class="ex">│</span>    ▄▝▘▘                                                                  │</span>
<span id="cb16-1184"><a href="#cb16-1184"></a> <span class="ex">1.0┤▖▞▝▘</span>                                                                      │</span>
<span id="cb16-1185"><a href="#cb16-1185"></a>    <span class="ex">└┬─────────────────┬──────────────────┬─────────────────┬─────────────────┬┘</span></span>
<span id="cb16-1186"><a href="#cb16-1186"></a>    <span class="ex">1.0</span>              25.5               50.0              74.5             99.0</span>
<span id="cb16-1187"><a href="#cb16-1187"></a><span class="ex">train/iter</span>                              iter</span>
<span id="cb16-1188"><a href="#cb16-1188"></a><span class="ex">[2024-07-17</span> 07:35:37.669214]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/iter.txt</span>
<span id="cb16-1189"><a href="#cb16-1189"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/iter.txt</span>
<span id="cb16-1190"><a href="#cb16-1190"></a>                             <span class="ex">train/sps</span> <span class="pp">[</span><span class="ss">2024</span><span class="pp">-</span><span class="ss">07</span><span class="pp">-</span><span class="ss">17</span><span class="pp">-</span><span class="ss">073537</span><span class="pp">]</span></span>
<span id="cb16-1191"><a href="#cb16-1191"></a>       <span class="ex">┌───────────────────────────────────────────────────────────────────────┐</span></span>
<span id="cb16-1192"><a href="#cb16-1192"></a><span class="ex">43523.3┤</span>                ▖▗  ▖▗ ▖▗ ▖▝ ▚▘▝ ▖▗    ▘▗▖▗▖▖ ▖▄    ▗▖▝ ▖ ▗▖▗ ▘▗▞ ▘▗ ▘ │</span>
<span id="cb16-1193"><a href="#cb16-1193"></a>       <span class="ex">│</span>       ▖ ▗▘  ▗▝▖  ▀▗ ▖▝▝ ▖▝ ▘  ▖▝ ▘▝▀▗▘▝ ▝   ▝  ▘▞▝▘▘ ▘▝ ▚ ▝ ▘▝  ▝ ▘▝ ▘│</span>
<span id="cb16-1194"><a href="#cb16-1194"></a>       <span class="ex">│</span>  ▖▀ ▖▞ ▞  ▄ ▘  ▝                                                      │</span>
<span id="cb16-1195"><a href="#cb16-1195"></a><span class="ex">36312.5┤▝▝</span>  ▗                                       ▝                          │</span>
<span id="cb16-1196"><a href="#cb16-1196"></a>       <span class="ex">│</span>            ▖                                                          │</span>
<span id="cb16-1197"><a href="#cb16-1197"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1198"><a href="#cb16-1198"></a><span class="ex">29101.8┤</span>                                                                       │</span>
<span id="cb16-1199"><a href="#cb16-1199"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1200"><a href="#cb16-1200"></a><span class="ex">21891.1┤</span>                                                                       │</span>
<span id="cb16-1201"><a href="#cb16-1201"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1202"><a href="#cb16-1202"></a>       <span class="ex">│▖</span>                                                                      │</span>
<span id="cb16-1203"><a href="#cb16-1203"></a><span class="ex">14680.4┤</span>                                                                       │</span>
<span id="cb16-1204"><a href="#cb16-1204"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1205"><a href="#cb16-1205"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1206"><a href="#cb16-1206"></a> <span class="ex">7469.7┤</span>                                                                       │</span>
<span id="cb16-1207"><a href="#cb16-1207"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1208"><a href="#cb16-1208"></a>       <span class="ex">│</span>                                                                       │</span>
<span id="cb16-1209"><a href="#cb16-1209"></a>  <span class="ex">258.9┤</span>                                                                      ▗│</span>
<span id="cb16-1210"><a href="#cb16-1210"></a>       <span class="ex">└┬─────────────────┬────────────────┬─────────────────┬────────────────┬┘</span></span>
<span id="cb16-1211"><a href="#cb16-1211"></a>       <span class="ex">1.0</span>              25.5             50.0              74.5            99.0</span>
<span id="cb16-1212"><a href="#cb16-1212"></a><span class="ex">train/sps</span>                                iter</span>
<span id="cb16-1213"><a href="#cb16-1213"></a><span class="ex">[2024-07-17</span> 07:35:37.681268]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">plot:156</span><span class="pp">]</span> <span class="at">-</span> Appending plot to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/sps.txt</span>
<span id="cb16-1214"><a href="#cb16-1214"></a><span class="ex">text</span> saved in /home/foremans/tmp/polaris-talk/2024-07-17-073327/test-dist-plots/train/sps.txt</span>
<span id="cb16-1215"><a href="#cb16-1215"></a><span class="kw">```</span></span>
<span id="cb16-1216"><a href="#cb16-1216"></a></span>
<span id="cb16-1217"><a href="#cb16-1217"></a><span class="ex">:::</span></span>
<span id="cb16-1218"><a href="#cb16-1218"></a></span>
<span id="cb16-1219"><a href="#cb16-1219"></a><span class="co"># PyInstrument Profile {background-color="white"}</span></span>
<span id="cb16-1220"><a href="#cb16-1220"></a></span>
<span id="cb16-1221"><a href="#cb16-1221"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-1222"><a href="#cb16-1222"></a></span>
<span id="cb16-1223"><a href="#cb16-1223"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-1224"><a href="#cb16-1224"></a><span class="ex">Recorded:</span> 07:35:34  Samples:  2227</span>
<span id="cb16-1225"><a href="#cb16-1225"></a><span class="ex">Duration:</span> 2.948     CPU time: 5.441</span>
<span id="cb16-1226"><a href="#cb16-1226"></a><span class="ex">PyInstrument:</span> v4.6.2</span>
<span id="cb16-1227"><a href="#cb16-1227"></a><span class="ex">Program:</span> /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz/src/ezpz/test_dist.py</span>
<span id="cb16-1228"><a href="#cb16-1228"></a><span class="ex">2.948</span> <span class="op">&lt;</span>module<span class="op">&gt;</span>  ezpz/test_dist.py:1</span>
<span id="cb16-1229"><a href="#cb16-1229"></a><span class="ex">└─</span> 2.946 main  ezpz/test_dist.py:217</span>
<span id="cb16-1230"><a href="#cb16-1230"></a>   <span class="ex">├─</span> 2.043 build_model_and_optimizer  ezpz/test_dist.py:171</span>
<span id="cb16-1231"><a href="#cb16-1231"></a>   <span class="ex">│</span>  └─ 2.011 Adam.__init__  torch/optim/adam.py:15</span>
<span id="cb16-1232"><a href="#cb16-1232"></a>   <span class="ex">│</span>        [129 frames hidden]  torch, wandb, transformers, jax, func...</span>
<span id="cb16-1233"><a href="#cb16-1233"></a>   <span class="ex">├─</span> 0.326 _forward_step  ezpz/test_dist.py:231</span>
<span id="cb16-1234"><a href="#cb16-1234"></a>   <span class="ex">│</span>  ├─ 0.279 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528</span>
<span id="cb16-1235"><a href="#cb16-1235"></a>   <span class="ex">│</span>  │     [13 frames hidden]  torch, wandb, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb16-1236"><a href="#cb16-1236"></a>   <span class="ex">│</span>  │        0.273 Network._call_impl  torch/nn/modules/module.py:1534</span>
<span id="cb16-1237"><a href="#cb16-1237"></a>   <span class="ex">│</span>  │        └─ 0.076 Network.forward  ezpz/test_dist.py:164</span>
<span id="cb16-1238"><a href="#cb16-1238"></a>   <span class="ex">│</span>  │           └─ 0.076 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528</span>
<span id="cb16-1239"><a href="#cb16-1239"></a>   <span class="ex">│</span>  │                 [7 frames hidden]  torch, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb16-1240"><a href="#cb16-1240"></a>   <span class="ex">│</span>  └─ 0.046 calc_loss  ezpz/test_dist.py:168</span>
<span id="cb16-1241"><a href="#cb16-1241"></a>   <span class="ex">├─</span> 0.254 _backward_step  ezpz/test_dist.py:236</span>
<span id="cb16-1242"><a href="#cb16-1242"></a>   <span class="ex">│</span>  ├─ 0.177 Tensor.backward  torch/_tensor.py:466</span>
<span id="cb16-1243"><a href="#cb16-1243"></a>   <span class="ex">│</span>  │     [4 frames hidden]  torch, <span class="op">&lt;</span>built-in<span class="op">&gt;</span></span>
<span id="cb16-1244"><a href="#cb16-1244"></a>   <span class="ex">│</span>  └─ 0.077 wrapper  torch/optim/optimizer.py:374</span>
<span id="cb16-1245"><a href="#cb16-1245"></a>   <span class="ex">│</span>        [5 frames hidden]  torch</span>
<span id="cb16-1246"><a href="#cb16-1246"></a>   <span class="ex">├─</span> 0.119 tplot_dict  ezpz/plot.py:136</span>
<span id="cb16-1247"><a href="#cb16-1247"></a>   <span class="ex">│</span>  └─ 0.069 show  plotext/_core.py:292</span>
<span id="cb16-1248"><a href="#cb16-1248"></a>   <span class="ex">│</span>        [5 frames hidden]  plotext</span>
<span id="cb16-1249"><a href="#cb16-1249"></a>   <span class="ex">├─</span> 0.102 Logger.info  logging/__init__.py:1479</span>
<span id="cb16-1250"><a href="#cb16-1250"></a>   <span class="ex">│</span>     [6 frames hidden]  logging, rich</span>
<span id="cb16-1251"><a href="#cb16-1251"></a>   <span class="ex">│</span>        0.102 RichHandler.emit  rich/logging.py:126</span>
<span id="cb16-1252"><a href="#cb16-1252"></a>   <span class="ex">│</span>        └─ 0.100 Console.print  ezpz/log/console.py:79</span>
<span id="cb16-1253"><a href="#cb16-1253"></a>   <span class="ex">│</span>           └─ 0.100 Console.print  rich/console.py:1624</span>
<span id="cb16-1254"><a href="#cb16-1254"></a>   <span class="ex">│</span>                 [5 frames hidden]  rich</span>
<span id="cb16-1255"><a href="#cb16-1255"></a>   <span class="ex">└─</span> 0.099 Run.wrapper  wandb/sdk/wandb_run.py:418</span>
<span id="cb16-1256"><a href="#cb16-1256"></a>         <span class="ex">[13</span> frames hidden]  wandb, json</span>
<span id="cb16-1257"><a href="#cb16-1257"></a><span class="ex">[2024-07-17</span> 07:35:37.876629]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:115</span><span class="pp">]</span> <span class="at">-</span> Saving pyinstrument profile output to: /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles</span>
<span id="cb16-1258"><a href="#cb16-1258"></a><span class="ex">[2024-07-17</span> 07:35:37.877255]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:123</span><span class="pp">]</span> <span class="at">-</span> PyInstrument profile saved <span class="er">(</span><span class="fu">as</span> html<span class="kw">)</span> <span class="ex">to:</span>  /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-17-073537.html</span>
<span id="cb16-1259"><a href="#cb16-1259"></a><span class="ex">[2024-07-17</span> 07:35:37.877936]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:131</span><span class="pp">]</span> <span class="at">-</span> PyInstrument profile saved <span class="er">(</span><span class="fu">as</span> text<span class="kw">)</span> <span class="ex">to:</span>  /home/foremans/tmp/polaris-talk/2024-07-17-073327/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-17-073537.txt</span>
<span id="cb16-1260"><a href="#cb16-1260"></a><span class="ex">[2024-07-17</span> 07:35:38.391628]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">profile:143</span><span class="pp">]</span> <span class="at">-</span> Finished with pyinstrument profiler. Took: 2.94768s</span>
<span id="cb16-1261"><a href="#cb16-1261"></a><span class="ex">[2024-07-17</span> 07:35:38.392519]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">test_dist:318</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0</span><span class="pp">]</span> runtime=8.075730s</span>
<span id="cb16-1262"><a href="#cb16-1262"></a><span class="ex">wandb:</span> 🚀 View run vibrant-river-284 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/p49rzxtv</span>
<span id="cb16-1263"><a href="#cb16-1263"></a><span class="ex">wandb:</span> Find logs at: wandb/run-20240717_073532-p49rzxtv/logs</span>
<span id="cb16-1264"><a href="#cb16-1264"></a><span class="ex">Application</span> cff755ee resources: utime=25s stime=23s maxrss=1434396KB inblock=32 oublock=4320 minflt=670179 majflt=864 nvcsw=195893 nivcsw=1331214</span>
<span id="cb16-1265"><a href="#cb16-1265"></a><span class="kw">```</span></span>
<span id="cb16-1266"><a href="#cb16-1266"></a></span>
<span id="cb16-1267"><a href="#cb16-1267"></a><span class="ex">:::</span></span>
<span id="cb16-1268"><a href="#cb16-1268"></a></span>
<span id="cb16-1269"><a href="#cb16-1269"></a><span class="co"># Example: [`ezpz` 🍋](https://github.com/saforem2/ezpz) {.centeredslide .smaller height="100%" style="max-height: 100%;" slide-background="#FFFFFF"}</span></span>
<span id="cb16-1270"><a href="#cb16-1270"></a></span>
<span id="cb16-1271"><a href="#cb16-1271"></a><span class="ex">:::</span> {.flex-container}</span>
<span id="cb16-1272"><a href="#cb16-1272"></a></span>
<span id="cb16-1273"><a href="#cb16-1273"></a><span class="ex">:::</span> {#fig-ezpz-asciinema}</span>
<span id="cb16-1274"><a href="#cb16-1274"></a></span>
<span id="cb16-1275"><a href="#cb16-1275"></a><span class="op">&lt;</span>script <span class="va">src</span><span class="op">=</span><span class="st">"https://asciinema.org/a/668460.js"</span> <span class="va">id</span><span class="op">=</span><span class="st">"asciicast-668460"</span> <span class="va">async</span><span class="op">=</span><span class="st">"true"</span> <span class="va">style</span><span class="op">=</span><span class="st">"max-height: 90%!important;"</span><span class="op">&gt;&lt;</span>/script<span class="op">&gt;</span></span>
<span id="cb16-1276"><a href="#cb16-1276"></a></span>
<span id="cb16-1277"><a href="#cb16-1277"></a><span class="ex">Example:</span> using [🍋 <span class="kw">`</span><span class="ex">ezpz.test_dist</span><span class="kw">`</span>]<span class="er">(</span><span class="ex">https://github.com/saforem2/ezpz/blob/main/src/ezpz/test_dist.py</span><span class="kw">)</span> <span class="ex">to</span> train a small model using DDP</span>
<span id="cb16-1278"><a href="#cb16-1278"></a><span class="ex">:::</span></span>
<span id="cb16-1279"><a href="#cb16-1279"></a></span>
<span id="cb16-1280"><a href="#cb16-1280"></a><span class="ex">:::</span> aside</span>
<span id="cb16-1281"><a href="#cb16-1281"></a><span class="ex">Link</span> to <span class="pp">[</span><span class="ss">video</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://asciinema.org/a/668460</span><span class="kw">)</span></span>
<span id="cb16-1282"><a href="#cb16-1282"></a><span class="ex">:::</span></span>
<span id="cb16-1283"><a href="#cb16-1283"></a></span>
<span id="cb16-1284"><a href="#cb16-1284"></a><span class="ex">:::</span></span>
<span id="cb16-1285"><a href="#cb16-1285"></a></span>
<span id="cb16-1286"><a href="#cb16-1286"></a><span class="co"># Example: [`wordplay` 🎮💬 ](https://github.com/saforem2/wordplay) {background-color="white"}</span></span>
<span id="cb16-1287"><a href="#cb16-1287"></a></span>
<span id="cb16-1288"><a href="#cb16-1288"></a><span class="co"># Prepare Data {background-color="white"}</span></span>
<span id="cb16-1289"><a href="#cb16-1289"></a></span>
<span id="cb16-1290"><a href="#cb16-1290"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-1291"><a href="#cb16-1291"></a></span>
<span id="cb16-1292"><a href="#cb16-1292"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-1293"><a href="#cb16-1293"></a><span class="co">#[⭐][07:41:20 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327][⏱ 29s]</span></span>
<span id="cb16-1294"><a href="#cb16-1294"></a><span class="ex">$</span> python3 wordplay/data/shakespeare_char/prepare.py</span>
<span id="cb16-1295"><a href="#cb16-1295"></a><span class="ex">Using</span> HF_DATASETS_CACHE=/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/.cache/huggingface</span>
<span id="cb16-1296"><a href="#cb16-1296"></a><span class="ex">length</span> of dataset in characters: 1,115,394</span>
<span id="cb16-1297"><a href="#cb16-1297"></a><span class="ex">all</span> the unique characters:</span>
<span id="cb16-1298"><a href="#cb16-1298"></a> <span class="ex">!$</span><span class="kw">&amp;</span><span class="ex">\',-.3:</span><span class="kw">;</span><span class="ex">?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz</span></span>
<span id="cb16-1299"><a href="#cb16-1299"></a><span class="ex">vocab</span> size: 65</span>
<span id="cb16-1300"><a href="#cb16-1300"></a><span class="ex">train</span> has 1,003,854 tokens</span>
<span id="cb16-1301"><a href="#cb16-1301"></a><span class="ex">val</span> has 111,540 tokens</span>
<span id="cb16-1302"><a href="#cb16-1302"></a><span class="kw">```</span></span>
<span id="cb16-1303"><a href="#cb16-1303"></a></span>
<span id="cb16-1304"><a href="#cb16-1304"></a><span class="ex">:::</span></span>
<span id="cb16-1305"><a href="#cb16-1305"></a></span>
<span id="cb16-1306"><a href="#cb16-1306"></a><span class="co"># Launch Training (DDP) {background-color="white"}</span></span>
<span id="cb16-1307"><a href="#cb16-1307"></a></span>
<span id="cb16-1308"><a href="#cb16-1308"></a><span class="ex">:::</span> {style=<span class="st">"font-size: 0.8em; line-height: 1.0em;"</span>}</span>
<span id="cb16-1309"><a href="#cb16-1309"></a></span>
<span id="cb16-1310"><a href="#cb16-1310"></a><span class="kw">```</span><span class="fu">bash</span></span>
<span id="cb16-1311"><a href="#cb16-1311"></a><span class="co">#(👻 2024-04-29)</span></span>
<span id="cb16-1312"><a href="#cb16-1312"></a><span class="co">#[⭐][07:42:02 AM][foremans@x3101c0s13b0n0][~/tmp/polaris-talk/2024-07-17-073327]</span></span>
<span id="cb16-1313"><a href="#cb16-1313"></a><span class="ex">$</span> launch python3 <span class="at">-m</span> wordplay train.backend=DDP train.eval_interval=100 data=shakespeare train.dtype=bf16 model.batch_size=64 model.block_size=1024 train.max_iters=1000 train.log_interval=10 train.compile=false <span class="kw">|</span> <span class="fu">tee</span> wordplay-gpt2-DDP.log</span>
<span id="cb16-1314"><a href="#cb16-1314"></a><span class="ex">[2024-07-17</span> 07:42:11.746540]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:156</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'INFO'</span> on <span class="st">'RANK == 0'</span></span>
<span id="cb16-1315"><a href="#cb16-1315"></a><span class="ex">[2024-07-17</span> 07:42:11.748763]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:157</span><span class="pp">]</span> <span class="at">-</span> Setting logging level to <span class="st">'CRITICAL'</span> on all others <span class="st">'RANK != 0'</span></span>
<span id="cb16-1316"><a href="#cb16-1316"></a><span class="ex">[2024-07-17</span> 07:42:11.749453]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">__init__:160</span><span class="pp">]</span> <span class="at">-</span> To disable this behavior, and log from ALL ranks <span class="er">(</span><span class="ex">not</span> recommended<span class="kw">)</span><span class="ex">,</span> set: <span class="st">'export LOG_FROM_ALL_RANKS=1'</span>  in your environment, and re-run.</span>
<span id="cb16-1317"><a href="#cb16-1317"></a><span class="ex">[2024-07-17</span> 07:42:11.772718]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:81</span><span class="pp">]</span> <span class="at">-</span> Setting HF_DATASETS_CACHE to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/.cache/huggingface/datasets</span>
<span id="cb16-1318"><a href="#cb16-1318"></a><span class="ex">[2024-07-17</span> 07:42:15.341532]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=2/3</span><span class="pp">][</span><span class="ss">local_rank=2/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-1319"><a href="#cb16-1319"></a><span class="ex">[2024-07-17</span> 07:42:15.342381]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=1/3</span><span class="pp">][</span><span class="ss">local_rank=1/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-1320"><a href="#cb16-1320"></a><span class="ex">[2024-07-17</span> 07:42:15.342430]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=3/3</span><span class="pp">][</span><span class="ss">local_rank=3/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-1321"><a href="#cb16-1321"></a><span class="ex">[2024-07-17</span> 07:42:15.348657]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:95</span><span class="pp">]</span> <span class="at">-</span></span>
<span id="cb16-1322"><a href="#cb16-1322"></a></span>
<span id="cb16-1323"><a href="#cb16-1323"></a><span class="ex">[dist_info]:</span></span>
<span id="cb16-1324"><a href="#cb16-1324"></a>  <span class="ex">•</span> DEVICE=cuda</span>
<span id="cb16-1325"><a href="#cb16-1325"></a>  <span class="ex">•</span> DEVICE_ID=cuda:0</span>
<span id="cb16-1326"><a href="#cb16-1326"></a>  <span class="ex">•</span> DISTRIBUTED_BACKEND=nccl</span>
<span id="cb16-1327"><a href="#cb16-1327"></a>  <span class="ex">•</span> GPUS_PER_NODE=4</span>
<span id="cb16-1328"><a href="#cb16-1328"></a>  <span class="ex">•</span> HOSTS=<span class="pp">[</span><span class="st">'x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov'</span><span class="pp">]</span></span>
<span id="cb16-1329"><a href="#cb16-1329"></a>  <span class="ex">•</span> HOSTFILE=/var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-1330"><a href="#cb16-1330"></a>  <span class="ex">•</span> HOSTNAME=x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov</span>
<span id="cb16-1331"><a href="#cb16-1331"></a>  <span class="ex">•</span> LOCAL_RANK=0</span>
<span id="cb16-1332"><a href="#cb16-1332"></a>  <span class="ex">•</span> MACHINE=Polaris</span>
<span id="cb16-1333"><a href="#cb16-1333"></a>  <span class="ex">•</span> NUM_NODES=1</span>
<span id="cb16-1334"><a href="#cb16-1334"></a>  <span class="ex">•</span> NGPUS=4</span>
<span id="cb16-1335"><a href="#cb16-1335"></a>  <span class="ex">•</span> NGPUS_AVAILABLE=4</span>
<span id="cb16-1336"><a href="#cb16-1336"></a>  <span class="ex">•</span> NODE_ID=0</span>
<span id="cb16-1337"><a href="#cb16-1337"></a>  <span class="ex">•</span> RANK=0</span>
<span id="cb16-1338"><a href="#cb16-1338"></a>  <span class="ex">•</span> SCHEDULER=PBS</span>
<span id="cb16-1339"><a href="#cb16-1339"></a>  <span class="ex">•</span> WORLD_SIZE_TOTAL=4</span>
<span id="cb16-1340"><a href="#cb16-1340"></a>  <span class="ex">•</span> WORLD_SIZE_IN_USE=4</span>
<span id="cb16-1341"><a href="#cb16-1341"></a>  <span class="ex">•</span> LAUNCH_CMD=mpiexec <span class="at">--verbose</span> <span class="at">--envall</span> <span class="at">-n</span> 4 <span class="at">-ppn</span> 4 <span class="at">--hostfile</span> /var/spool/pbs/aux/2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov <span class="at">--cpu-bind</span> depth <span class="at">-d</span> 16</span>
<span id="cb16-1342"><a href="#cb16-1342"></a></span>
<span id="cb16-1343"><a href="#cb16-1343"></a></span>
<span id="cb16-1344"><a href="#cb16-1344"></a><span class="ex">[2024-07-17</span> 07:42:15.351446]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:725</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">0/4</span><span class="pp">]</span> Using device=<span class="st">'cuda'</span> with backend=<span class="st">'DDP'</span> + <span class="st">'nccl'</span> for distributed training.</span>
<span id="cb16-1345"><a href="#cb16-1345"></a><span class="ex">[2024-07-17</span> 07:42:15.356169]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:358</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="ss">device=</span><span class="st">'cuda'</span><span class="pp">][</span><span class="ss">rank=0/3</span><span class="pp">][</span><span class="ss">local_rank=0/3</span><span class="pp">][</span><span class="ss">node=0/0</span><span class="pp">]</span></span>
<span id="cb16-1346"><a href="#cb16-1346"></a><span class="ex">[2024-07-17</span> 07:42:15.356692]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">dist:364</span><span class="pp">]</span> <span class="at">-</span> Using [4 / 4] available <span class="st">"cuda"</span> devices !!</span>
<span id="cb16-1347"><a href="#cb16-1347"></a><span class="ex">[2024-07-17</span> 07:42:15.359571]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:317</span><span class="pp">]</span> <span class="at">-</span> Loading val from /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/val.bin</span>
<span id="cb16-1348"><a href="#cb16-1348"></a><span class="ex">[2024-07-17</span> 07:42:15.360138]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:317</span><span class="pp">]</span> <span class="at">-</span> Loading train from /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/train.bin</span>
<span id="cb16-1349"><a href="#cb16-1349"></a><span class="ex">[2024-07-17</span> 07:42:15.361154]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:442</span><span class="pp">]</span> <span class="at">-</span> Tokens per iteration: 262,144</span>
<span id="cb16-1350"><a href="#cb16-1350"></a><span class="ex">[2024-07-17</span> 07:42:15.361574]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:465</span><span class="pp">]</span> <span class="at">-</span> Using self.ptdtype=torch.float16 on self.device_type=<span class="st">'cuda'</span></span>
<span id="cb16-1351"><a href="#cb16-1351"></a><span class="ex">[2024-07-17</span> 07:42:15.362002]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:471</span><span class="pp">]</span> <span class="at">-</span> Initializing a new model from scratch</span>
<span id="cb16-1352"><a href="#cb16-1352"></a><span class="ex">[2024-07-17</span> 07:42:15.362529]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:874</span><span class="pp">]</span> <span class="at">-</span> Setting up wandb from rank: 0</span>
<span id="cb16-1353"><a href="#cb16-1353"></a><span class="ex">[2024-07-17</span> 07:42:15.362896]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:875</span><span class="pp">]</span> <span class="at">-</span> Using: WB PROJECT: WordPlay</span>
<span id="cb16-1354"><a href="#cb16-1354"></a><span class="ex">[2024-07-17</span> 07:42:16.451786]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:905</span><span class="pp">]</span> <span class="at">-</span> W<span class="kw">&amp;</span><span class="ex">B</span> RUN: <span class="pp">[</span><span class="ss">still</span><span class="pp">-</span><span class="ss">frog</span><span class="pp">-</span><span class="ss">17</span><span class="pp">]</span><span class="er">(</span><span class="ex">https://wandb.ai/aurora_gpt/WordPlay/runs/6by9vpcj</span><span class="kw">)</span></span>
<span id="cb16-1355"><a href="#cb16-1355"></a><span class="ex">[2024-07-17</span> 07:42:16.464106]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:312</span><span class="pp">]</span> <span class="at">-</span> Updating wandb.run: still-frog-17 config with <span class="st">"DIST_INFO"</span></span>
<span id="cb16-1356"><a href="#cb16-1356"></a><span class="ex">[2024-07-17</span> 07:42:16.469424]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">dist:938</span><span class="pp">]</span> <span class="at">-</span> Running on machine=<span class="st">'Polaris'</span></span>
<span id="cb16-1357"><a href="#cb16-1357"></a><span class="ex">[2024-07-17</span> 07:42:16.471151]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">__main__:89</span><span class="pp">]</span> <span class="at">-</span> {</span>
<span id="cb16-1358"><a href="#cb16-1358"></a>    <span class="st">"train"</span><span class="ex">:</span> {</span>
<span id="cb16-1359"><a href="#cb16-1359"></a>        <span class="st">"framework"</span><span class="ex">:</span> <span class="st">"pytorch"</span>,</span>
<span id="cb16-1360"><a href="#cb16-1360"></a>        <span class="st">"backend"</span><span class="ex">:</span> <span class="st">"DDP"</span>,</span>
<span id="cb16-1361"><a href="#cb16-1361"></a>        <span class="st">"device"</span><span class="ex">:</span> null,</span>
<span id="cb16-1362"><a href="#cb16-1362"></a>        <span class="st">"seed"</span><span class="ex">:</span> null,</span>
<span id="cb16-1363"><a href="#cb16-1363"></a>        <span class="st">"port"</span><span class="ex">:</span> null,</span>
<span id="cb16-1364"><a href="#cb16-1364"></a>        <span class="st">"ds_config_path"</span><span class="ex">:</span> null,</span>
<span id="cb16-1365"><a href="#cb16-1365"></a>        <span class="st">"precision"</span><span class="ex">:</span> null,</span>
<span id="cb16-1366"><a href="#cb16-1366"></a>        <span class="st">"ngpus"</span><span class="ex">:</span> null,</span>
<span id="cb16-1367"><a href="#cb16-1367"></a>        <span class="st">"use_wandb"</span><span class="ex">:</span> true,</span>
<span id="cb16-1368"><a href="#cb16-1368"></a>        <span class="st">"eval_interval"</span><span class="ex">:</span> 100,</span>
<span id="cb16-1369"><a href="#cb16-1369"></a>        <span class="st">"log_interval"</span><span class="ex">:</span> 10,</span>
<span id="cb16-1370"><a href="#cb16-1370"></a>        <span class="st">"eval_iters"</span><span class="ex">:</span> 200,</span>
<span id="cb16-1371"><a href="#cb16-1371"></a>        <span class="st">"eval_only"</span><span class="ex">:</span> false,</span>
<span id="cb16-1372"><a href="#cb16-1372"></a>        <span class="st">"always_save_checkpoint"</span><span class="ex">:</span> false,</span>
<span id="cb16-1373"><a href="#cb16-1373"></a>        <span class="st">"init_from"</span><span class="ex">:</span> <span class="st">"scratch"</span>,</span>
<span id="cb16-1374"><a href="#cb16-1374"></a>        <span class="st">"wandb_project"</span><span class="ex">:</span> <span class="st">"WordPlay"</span>,</span>
<span id="cb16-1375"><a href="#cb16-1375"></a>        <span class="st">"max_iters"</span><span class="ex">:</span> 1000,</span>
<span id="cb16-1376"><a href="#cb16-1376"></a>        <span class="st">"warmup_iters"</span><span class="ex">:</span> 100,</span>
<span id="cb16-1377"><a href="#cb16-1377"></a>        <span class="st">"dtype"</span><span class="ex">:</span> <span class="st">"bf16"</span>,</span>
<span id="cb16-1378"><a href="#cb16-1378"></a>        <span class="st">"compile"</span><span class="ex">:</span> false</span>
<span id="cb16-1379"><a href="#cb16-1379"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-1380"><a href="#cb16-1380"></a>    <span class="st">"model"</span><span class="ex">:</span> {</span>
<span id="cb16-1381"><a href="#cb16-1381"></a>        <span class="st">"n_layer"</span><span class="ex">:</span> 12,</span>
<span id="cb16-1382"><a href="#cb16-1382"></a>        <span class="st">"n_head"</span><span class="ex">:</span> 12,</span>
<span id="cb16-1383"><a href="#cb16-1383"></a>        <span class="st">"n_embd"</span><span class="ex">:</span> 768,</span>
<span id="cb16-1384"><a href="#cb16-1384"></a>        <span class="st">"batch_size"</span><span class="ex">:</span> 64,</span>
<span id="cb16-1385"><a href="#cb16-1385"></a>        <span class="st">"block_size"</span><span class="ex">:</span> 1024,</span>
<span id="cb16-1386"><a href="#cb16-1386"></a>        <span class="st">"activation"</span><span class="ex">:</span> <span class="st">"gelu"</span>,</span>
<span id="cb16-1387"><a href="#cb16-1387"></a>        <span class="st">"dropout"</span><span class="ex">:</span> 0.0,</span>
<span id="cb16-1388"><a href="#cb16-1388"></a>        <span class="st">"bias"</span><span class="ex">:</span> false,</span>
<span id="cb16-1389"><a href="#cb16-1389"></a>        <span class="st">"vocab_size"</span><span class="ex">:</span> 65</span>
<span id="cb16-1390"><a href="#cb16-1390"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-1391"><a href="#cb16-1391"></a>    <span class="st">"data"</span><span class="ex">:</span> {</span>
<span id="cb16-1392"><a href="#cb16-1392"></a>        <span class="st">"dataset"</span><span class="ex">:</span> <span class="st">"shakespeare_char"</span>,</span>
<span id="cb16-1393"><a href="#cb16-1393"></a>        <span class="st">"out_dir"</span><span class="ex">:</span> <span class="st">"out-shakespeare-char"</span>,</span>
<span id="cb16-1394"><a href="#cb16-1394"></a>        <span class="st">"root_path"</span><span class="ex">:</span> null</span>
<span id="cb16-1395"><a href="#cb16-1395"></a>    <span class="er">}</span><span class="ex">,</span></span>
<span id="cb16-1396"><a href="#cb16-1396"></a>    <span class="st">"optimizer"</span><span class="ex">:</span> {</span>
<span id="cb16-1397"><a href="#cb16-1397"></a>        <span class="st">"gas"</span><span class="ex">:</span> 1,</span>
<span id="cb16-1398"><a href="#cb16-1398"></a>        <span class="st">"name"</span><span class="ex">:</span> <span class="st">"AdamW"</span>,</span>
<span id="cb16-1399"><a href="#cb16-1399"></a>        <span class="st">"learning_rate"</span><span class="ex">:</span> 0.0006,</span>
<span id="cb16-1400"><a href="#cb16-1400"></a>        <span class="st">"weight_decay"</span><span class="ex">:</span> 0.1,</span>
<span id="cb16-1401"><a href="#cb16-1401"></a>        <span class="st">"beta1"</span><span class="ex">:</span> 0.9,</span>
<span id="cb16-1402"><a href="#cb16-1402"></a>        <span class="st">"beta2"</span><span class="ex">:</span> 0.95,</span>
<span id="cb16-1403"><a href="#cb16-1403"></a>        <span class="st">"grad_clip"</span><span class="ex">:</span> 1.0,</span>
<span id="cb16-1404"><a href="#cb16-1404"></a>        <span class="st">"decay_lr"</span><span class="ex">:</span> true,</span>
<span id="cb16-1405"><a href="#cb16-1405"></a>        <span class="st">"lr_decay_iters"</span><span class="ex">:</span> 600000,</span>
<span id="cb16-1406"><a href="#cb16-1406"></a>        <span class="st">"min_lr"</span><span class="ex">:</span> 6e-05</span>
<span id="cb16-1407"><a href="#cb16-1407"></a>    <span class="er">}</span></span>
<span id="cb16-1408"><a href="#cb16-1408"></a><span class="er">}</span></span>
<span id="cb16-1409"><a href="#cb16-1409"></a><span class="ex">[2024-07-17</span> 07:42:16.474305]<span class="pp">[</span><span class="ss">WARNING</span><span class="pp">][</span><span class="ss">__main__:90</span><span class="pp">]</span> <span class="at">-</span> Output dir: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb16-1410"><a href="#cb16-1410"></a><span class="ex">[2024-07-17</span> 07:42:16.474922]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:246</span><span class="pp">]</span> <span class="at">-</span> Initializing a new model from scratch</span>
<span id="cb16-1411"><a href="#cb16-1411"></a><span class="ex">[2024-07-17</span> 07:42:17.258904]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:255</span><span class="pp">]</span> <span class="at">-</span> number of parameters: 85.00M</span>
<span id="cb16-1412"><a href="#cb16-1412"></a><span class="ex">[2024-07-17</span> 07:42:17.290004]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:264</span><span class="pp">]</span> <span class="at">-</span> Model size: num_params=85003776</span>
<span id="cb16-1413"><a href="#cb16-1413"></a><span class="ex">[2024-07-17</span> 07:42:17.292626]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:445</span><span class="pp">]</span> <span class="at">-</span> num decayed parameter tensors: 50, with 85,771,008 parameters</span>
<span id="cb16-1414"><a href="#cb16-1414"></a><span class="ex">[2024-07-17</span> 07:42:17.293296]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:449</span><span class="pp">]</span> <span class="at">-</span> num non-decayed parameter tensors: 25, with 19,200 parameters</span>
<span id="cb16-1415"><a href="#cb16-1415"></a><span class="ex">[2024-07-17</span> 07:42:17.515324]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:1'"</span></span>
<span id="cb16-1416"><a href="#cb16-1416"></a><span class="ex">[2024-07-17</span> 07:42:17.515340]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:2'"</span></span>
<span id="cb16-1417"><a href="#cb16-1417"></a><span class="ex">[2024-07-17</span> 07:42:17.515465]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:3'"</span></span>
<span id="cb16-1418"><a href="#cb16-1418"></a><span class="ex">[2024-07-17</span> 07:42:18.431814]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">model:465</span><span class="pp">]</span> <span class="at">-</span> using fused AdamW: True</span>
<span id="cb16-1419"><a href="#cb16-1419"></a><span class="ex">[2024-07-17</span> 07:42:18.432620]<span class="pp">[</span><span class="ss">CRITICAL</span><span class="pp">][</span><span class="ss">trainer:316</span><span class="pp">]</span> <span class="at">-</span> <span class="st">"devid='cuda:0'"</span></span>
<span id="cb16-1420"><a href="#cb16-1420"></a><span class="ex">[2024-07-17</span> 07:42:19.951020]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:356</span><span class="pp">]</span> <span class="at">-</span> • self.model=GPT<span class="er">(</span></span>
<span id="cb16-1421"><a href="#cb16-1421"></a>  <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb16-1422"><a href="#cb16-1422"></a>    <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb16-1423"><a href="#cb16-1423"></a>    <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">1024,</span> 768<span class="kw">)</span></span>
<span id="cb16-1424"><a href="#cb16-1424"></a>    <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1425"><a href="#cb16-1425"></a>    <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb16-1426"><a href="#cb16-1426"></a>      <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb16-1427"><a href="#cb16-1427"></a>        <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1428"><a href="#cb16-1428"></a>        <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb16-1429"><a href="#cb16-1429"></a>          <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1430"><a href="#cb16-1430"></a>          <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1431"><a href="#cb16-1431"></a>          <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1432"><a href="#cb16-1432"></a>          <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1433"><a href="#cb16-1433"></a>        <span class="kw">)</span></span>
<span id="cb16-1434"><a href="#cb16-1434"></a>        <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1435"><a href="#cb16-1435"></a>        <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb16-1436"><a href="#cb16-1436"></a>          <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1437"><a href="#cb16-1437"></a>          <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb16-1438"><a href="#cb16-1438"></a>          <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1439"><a href="#cb16-1439"></a>          <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1440"><a href="#cb16-1440"></a>        <span class="kw">)</span></span>
<span id="cb16-1441"><a href="#cb16-1441"></a>      <span class="kw">)</span></span>
<span id="cb16-1442"><a href="#cb16-1442"></a>    <span class="kw">)</span></span>
<span id="cb16-1443"><a href="#cb16-1443"></a>    <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1444"><a href="#cb16-1444"></a>  <span class="kw">)</span></span>
<span id="cb16-1445"><a href="#cb16-1445"></a>  <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1446"><a href="#cb16-1446"></a><span class="kw">)</span></span>
<span id="cb16-1447"><a href="#cb16-1447"></a><span class="ex">[2024-07-17</span> 07:42:19.955340]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:357</span><span class="pp">]</span> <span class="at">-</span> • self.grad_scaler=<span class="op">&lt;</span>torch.cuda.amp.grad_scaler.GradScaler object at 0x145a38f0f090<span class="op">&gt;</span></span>
<span id="cb16-1448"><a href="#cb16-1448"></a><span class="ex">[2024-07-17</span> 07:42:19.956897]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:358</span><span class="pp">]</span> <span class="at">-</span> • self.model_engine=DistributedDataParallel<span class="er">(</span></span>
<span id="cb16-1449"><a href="#cb16-1449"></a>  <span class="kw">(</span><span class="ex">module</span><span class="kw">)</span><span class="bu">:</span> GPT<span class="er">(</span></span>
<span id="cb16-1450"><a href="#cb16-1450"></a>    <span class="kw">(</span><span class="ex">transformer</span><span class="kw">)</span><span class="bu">:</span> ModuleDict<span class="er">(</span></span>
<span id="cb16-1451"><a href="#cb16-1451"></a>      <span class="kw">(</span><span class="ex">wte</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">65,</span> 768<span class="kw">)</span></span>
<span id="cb16-1452"><a href="#cb16-1452"></a>      <span class="kw">(</span><span class="ex">wpe</span><span class="kw">)</span><span class="bu">:</span> Embedding<span class="er">(</span><span class="ex">1024,</span> 768<span class="kw">)</span></span>
<span id="cb16-1453"><a href="#cb16-1453"></a>      <span class="kw">(</span><span class="ex">drop</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1454"><a href="#cb16-1454"></a>      <span class="kw">(</span><span class="ex">h</span><span class="kw">)</span><span class="bu">:</span> ModuleList<span class="er">(</span></span>
<span id="cb16-1455"><a href="#cb16-1455"></a>        <span class="kw">(</span><span class="ex">0-11</span><span class="kw">)</span><span class="bu">:</span> 12 x Block<span class="er">(</span></span>
<span id="cb16-1456"><a href="#cb16-1456"></a>          <span class="kw">(</span><span class="ex">ln_1</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1457"><a href="#cb16-1457"></a>          <span class="kw">(</span><span class="ex">attn</span><span class="kw">)</span><span class="bu">:</span> CausalSelfAttention<span class="er">(</span></span>
<span id="cb16-1458"><a href="#cb16-1458"></a>            <span class="kw">(</span><span class="ex">c_attn</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>2304, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1459"><a href="#cb16-1459"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1460"><a href="#cb16-1460"></a>            <span class="kw">(</span><span class="ex">attn_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1461"><a href="#cb16-1461"></a>            <span class="kw">(</span><span class="ex">resid_dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1462"><a href="#cb16-1462"></a>          <span class="kw">)</span></span>
<span id="cb16-1463"><a href="#cb16-1463"></a>          <span class="kw">(</span><span class="ex">ln_2</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1464"><a href="#cb16-1464"></a>          <span class="kw">(</span><span class="ex">mlp</span><span class="kw">)</span><span class="bu">:</span> MLP<span class="er">(</span></span>
<span id="cb16-1465"><a href="#cb16-1465"></a>            <span class="kw">(</span><span class="ex">c_fc</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>3072, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1466"><a href="#cb16-1466"></a>            <span class="kw">(</span><span class="ex">act_fn</span><span class="kw">)</span><span class="bu">:</span> GELU<span class="er">(</span><span class="va">approximate</span><span class="op">=</span><span class="st">'none'</span><span class="kw">)</span></span>
<span id="cb16-1467"><a href="#cb16-1467"></a>            <span class="kw">(</span><span class="ex">c_proj</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>3072, <span class="va">out_features</span><span class="op">=</span>768, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1468"><a href="#cb16-1468"></a>            <span class="kw">(</span><span class="ex">dropout</span><span class="kw">)</span><span class="bu">:</span> Dropout<span class="er">(</span><span class="va">p</span><span class="op">=</span>0.0, <span class="va">inplace</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1469"><a href="#cb16-1469"></a>          <span class="kw">)</span></span>
<span id="cb16-1470"><a href="#cb16-1470"></a>        <span class="kw">)</span></span>
<span id="cb16-1471"><a href="#cb16-1471"></a>      <span class="kw">)</span></span>
<span id="cb16-1472"><a href="#cb16-1472"></a>      <span class="kw">(</span><span class="ex">ln_f</span><span class="kw">)</span><span class="bu">:</span> LayerNorm<span class="er">(</span><span class="kw">)</span></span>
<span id="cb16-1473"><a href="#cb16-1473"></a>    <span class="kw">)</span></span>
<span id="cb16-1474"><a href="#cb16-1474"></a>    <span class="kw">(</span><span class="ex">lm_head</span><span class="kw">)</span><span class="bu">:</span> Linear<span class="er">(</span><span class="va">in_features</span><span class="op">=</span>768, <span class="va">out_features</span><span class="op">=</span>65, <span class="va">bias</span><span class="op">=</span>False<span class="kw">)</span></span>
<span id="cb16-1475"><a href="#cb16-1475"></a>  <span class="kw">)</span></span>
<span id="cb16-1476"><a href="#cb16-1476"></a><span class="kw">)</span></span>
<span id="cb16-1477"><a href="#cb16-1477"></a><span class="ex">[2024-07-17</span> 07:42:19.961066]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:359</span><span class="pp">]</span> <span class="at">-</span> • self.optimizer=AdamW <span class="er">(</span></span>
<span id="cb16-1478"><a href="#cb16-1478"></a><span class="ex">Parameter</span> Group 0</span>
<span id="cb16-1479"><a href="#cb16-1479"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb16-1480"><a href="#cb16-1480"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb16-1481"><a href="#cb16-1481"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb16-1482"><a href="#cb16-1482"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb16-1483"><a href="#cb16-1483"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb16-1484"><a href="#cb16-1484"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb16-1485"><a href="#cb16-1485"></a>    <span class="ex">fused:</span> True</span>
<span id="cb16-1486"><a href="#cb16-1486"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb16-1487"><a href="#cb16-1487"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb16-1488"><a href="#cb16-1488"></a>    <span class="ex">weight_decay:</span> 0.1</span>
<span id="cb16-1489"><a href="#cb16-1489"></a></span>
<span id="cb16-1490"><a href="#cb16-1490"></a><span class="ex">Parameter</span> Group 1</span>
<span id="cb16-1491"><a href="#cb16-1491"></a>    <span class="ex">amsgrad:</span> False</span>
<span id="cb16-1492"><a href="#cb16-1492"></a>    <span class="ex">betas:</span> <span class="er">(</span><span class="ex">0.9,</span> 0.95<span class="kw">)</span></span>
<span id="cb16-1493"><a href="#cb16-1493"></a>    <span class="ex">capturable:</span> False</span>
<span id="cb16-1494"><a href="#cb16-1494"></a>    <span class="ex">differentiable:</span> False</span>
<span id="cb16-1495"><a href="#cb16-1495"></a>    <span class="ex">eps:</span> 1e-08</span>
<span id="cb16-1496"><a href="#cb16-1496"></a>    <span class="ex">foreach:</span> None</span>
<span id="cb16-1497"><a href="#cb16-1497"></a>    <span class="ex">fused:</span> True</span>
<span id="cb16-1498"><a href="#cb16-1498"></a>    <span class="ex">lr:</span> 0.0006</span>
<span id="cb16-1499"><a href="#cb16-1499"></a>    <span class="ex">maximize:</span> False</span>
<span id="cb16-1500"><a href="#cb16-1500"></a>    <span class="ex">weight_decay:</span> 0.0</span>
<span id="cb16-1501"><a href="#cb16-1501"></a><span class="kw">)</span></span>
<span id="cb16-1502"><a href="#cb16-1502"></a><span class="ex">[2024-07-17</span> 07:42:19.988827]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:802</span><span class="pp">]</span> <span class="at">-</span> Startup time: 6.7125</span>
<span id="cb16-1503"><a href="#cb16-1503"></a>                <span class="ex">Training</span> Legend</span>
<span id="cb16-1504"><a href="#cb16-1504"></a><span class="ex">┏━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span></span>
<span id="cb16-1505"><a href="#cb16-1505"></a><span class="ex">┃</span>    abbr     ┃ desc                           ┃</span>
<span id="cb16-1506"><a href="#cb16-1506"></a><span class="ex">┡━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩</span></span>
<span id="cb16-1507"><a href="#cb16-1507"></a><span class="ex">│</span>    step     │ Current training iteration     │</span>
<span id="cb16-1508"><a href="#cb16-1508"></a><span class="ex">│</span>    loss     │ Loss value                     │</span>
<span id="cb16-1509"><a href="#cb16-1509"></a><span class="ex">│</span>     dt      │ Elapsed time per training step │</span>
<span id="cb16-1510"><a href="#cb16-1510"></a><span class="ex">│</span>     dtf     │ Elapsed time per forward step  │</span>
<span id="cb16-1511"><a href="#cb16-1511"></a><span class="ex">│</span>     dtb     │ Elapsed time per backward step │</span>
<span id="cb16-1512"><a href="#cb16-1512"></a><span class="ex">│</span>     sps     │ Samples per second             │</span>
<span id="cb16-1513"><a href="#cb16-1513"></a><span class="ex">│</span> sps_per_gpu │ Samples per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>   <span class="ex">│</span></span>
<span id="cb16-1514"><a href="#cb16-1514"></a><span class="ex">│</span>     tps     │ Tokens per second              │</span>
<span id="cb16-1515"><a href="#cb16-1515"></a><span class="ex">│</span> tps_per_gpu │ Tokens per second <span class="er">(</span><span class="ex">per</span> GPU<span class="kw">)</span>    <span class="ex">│</span></span>
<span id="cb16-1516"><a href="#cb16-1516"></a><span class="ex">│</span>     mfu     │ Model flops utilization        │</span>
<span id="cb16-1517"><a href="#cb16-1517"></a><span class="ex">│</span> train_loss  │ Training loss value            │</span>
<span id="cb16-1518"><a href="#cb16-1518"></a><span class="ex">│</span>  val_loss   │ Validation loss value          │</span>
<span id="cb16-1519"><a href="#cb16-1519"></a><span class="ex">└─────────────┴────────────────────────────────┘</span></span>
<span id="cb16-1520"><a href="#cb16-1520"></a><span class="ex">[2024-07-17</span> 07:42:21.451865]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-1521"><a href="#cb16-1521"></a><span class="ex">[2024-07-17</span> 07:42:21.452667]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-1522"><a href="#cb16-1522"></a><span class="ex">What</span> is an LLM<span class="pp">?</span>eelEl\'<span class="va">$nltPwBSWal</span>,<span class="kw">;</span><span class="ex">PWw</span> bbu<span class="dt">\'</span>HiyP<span class="dt">\'</span>FWwF <span class="kw">&amp;</span><span class="ex">AhW:ygrn</span> kk-<span class="dt">\'\'</span>KFlMwnlEfflkc,elpWaWtgml<span class="va">$Pgglhllw</span> lglhFllzczPAFHpeAAPPSltgkrWPPhlEMgcrN ggPWt-WPSSzHSkkrzzk.FFrtSSkgMll<span class="kw">&amp;</span><span class="ex">gFXr,hghaueaVPW-pHFF-gg,,,FF,,kbApgg</span> gg<span class="dt">\'</span>aWWzzkk<span class="dt">\'</span>a<span class="dt">\'</span>CggHl<span class="va">$bGeA</span>,FFk,,SF<span class="kw">;</span><span class="ex">UF,,aZ</span> <span class="kw">;</span><span class="ex">gglee$,k.US</span><span class="kw">&amp;</span><span class="ex">kg:S,,zVzzc</span></span>
<span id="cb16-1523"><a href="#cb16-1523"></a><span class="ex">[2024-07-17</span> 07:43:01.573073]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=10 loss=3.154310 dt=0.282833 dtf=0.005247 dtb=0.011417 sps=14.142633 sps_per_gpu=3.535658 tps=926851.609409 tps_per_gpu=231712.902352 mfu=46.288281 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1524"><a href="#cb16-1524"></a><span class="ex">[2024-07-17</span> 07:43:04.402750]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=20 loss=2.660851 dt=0.306263 dtf=0.005233 dtb=0.011419 sps=13.060678 sps_per_gpu=3.265170 tps=855944.613638 tps_per_gpu=213986.153409 mfu=45.934162 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1525"><a href="#cb16-1525"></a><span class="ex">[2024-07-17</span> 07:43:07.237507]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=30 loss=2.543283 dt=0.283021 dtf=0.005238 dtb=0.011245 sps=14.133211 sps_per_gpu=3.533303 tps=926234.088226 tps_per_gpu=231558.522057 mfu=45.966490 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1526"><a href="#cb16-1526"></a><span class="ex">[2024-07-17</span> 07:43:10.077248]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=40 loss=2.503963 dt=0.285001 dtf=0.005213 dtb=0.011471 sps=14.035061 sps_per_gpu=3.508765 tps=919801.749941 tps_per_gpu=229950.437485 mfu=45.963461 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1527"><a href="#cb16-1527"></a><span class="ex">[2024-07-17</span> 07:43:12.917039]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=50 loss=2.477469 dt=0.283532 dtf=0.005166 dtb=0.011294 sps=14.107763 sps_per_gpu=3.526941 tps=924566.380009 tps_per_gpu=231141.595002 mfu=45.984530 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1528"><a href="#cb16-1528"></a><span class="ex">[2024-07-17</span> 07:43:15.760749]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=60 loss=2.471083 dt=0.284630 dtf=0.005140 dtb=0.011224 sps=14.053326 sps_per_gpu=3.513332 tps=920998.786204 tps_per_gpu=230249.696551 mfu=45.985675 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1529"><a href="#cb16-1529"></a><span class="ex">[2024-07-17</span> 07:43:18.602785]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=70 loss=2.458894 dt=0.283926 dtf=0.005219 dtb=0.010383 sps=14.088155 sps_per_gpu=3.522039 tps=923281.352698 tps_per_gpu=230820.338174 mfu=45.998106 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1530"><a href="#cb16-1530"></a><span class="ex">[2024-07-17</span> 07:43:21.451433]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=80 loss=2.489088 dt=0.285537 dtf=0.005183 dtb=0.011373 sps=14.008683 sps_per_gpu=3.502171 tps=918073.060430 tps_per_gpu=229518.265108 mfu=45.983282 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1531"><a href="#cb16-1531"></a><span class="ex">[2024-07-17</span> 07:43:24.302241]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=90 loss=2.471990 dt=0.300767 dtf=0.005445 dtb=0.010290 sps=13.299337 sps_per_gpu=3.324834 tps=871585.359388 tps_per_gpu=217896.339847 mfu=45.737774 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1532"><a href="#cb16-1532"></a><span class="ex">[2024-07-17</span> 07:43:27.153275]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=100 loss=2.445556 dt=0.285869 dtf=0.005182 dtb=0.011251 sps=13.992403 sps_per_gpu=3.498101 tps=917006.151328 tps_per_gpu=229251.537832 mfu=45.743655 train_loss=4.125778 val_loss=4.128809</span>
<span id="cb16-1533"><a href="#cb16-1533"></a><span class="ex">[2024-07-17</span> 07:43:28.182553]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-1534"><a href="#cb16-1534"></a><span class="ex">[2024-07-17</span> 07:43:28.183179]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-1535"><a href="#cb16-1535"></a></span>
<span id="cb16-1536"><a href="#cb16-1536"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-1537"><a href="#cb16-1537"></a></span>
<span id="cb16-1538"><a href="#cb16-1538"></a><span class="ex">Goupay</span> my winghimithell bls ger t bon sinthard ht omind be,</span>
<span id="cb16-1539"><a href="#cb16-1539"></a><span class="ex">And</span> lereind h py balithand frd oforondof wimon me hageas thinero mand,</span>
<span id="cb16-1540"><a href="#cb16-1540"></a><span class="ex">Thacanes,</span></span>
<span id="cb16-1541"><a href="#cb16-1541"></a><span class="ex">An</span> frift ghik med d herthecke ntore thack couthen ale, t thit ang d m t h chy me fache ag, wit my hathan glat ng</span>
<span id="cb16-1542"><a href="#cb16-1542"></a><span class="ex">[2024-07-17</span> 07:44:06.025837]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:760</span><span class="pp">]</span> <span class="at">-</span> Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb16-1543"><a href="#cb16-1543"></a><span class="ex">[2024-07-17</span> 07:44:06.026607]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:761</span><span class="pp">]</span> <span class="at">-</span> Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span>
<span id="cb16-1544"><a href="#cb16-1544"></a><span class="ex">[2024-07-17</span> 07:44:07.682968]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:141</span><span class="pp">]</span> <span class="at">-</span> Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb16-1545"><a href="#cb16-1545"></a><span class="ex">[2024-07-17</span> 07:44:10.519506]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=110 loss=2.433923 dt=0.285038 dtf=0.005757 dtb=0.011762 sps=14.033209 sps_per_gpu=3.508302 tps=919680.367894 tps_per_gpu=229920.091974 mfu=45.762304 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1546"><a href="#cb16-1546"></a><span class="ex">[2024-07-17</span> 07:44:13.362148]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=120 loss=2.429014 dt=0.284445 dtf=0.005222 dtb=0.011486 sps=14.062460 sps_per_gpu=3.515615 tps=921597.361532 tps_per_gpu=230399.340383 mfu=45.788661 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1547"><a href="#cb16-1547"></a><span class="ex">[2024-07-17</span> 07:44:16.210694]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=130 loss=2.402059 dt=0.285559 dtf=0.005199 dtb=0.011765 sps=14.007633 sps_per_gpu=3.501908 tps=918004.211586 tps_per_gpu=229501.052897 mfu=45.794438 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1548"><a href="#cb16-1548"></a><span class="ex">[2024-07-17</span> 07:44:19.061546]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=140 loss=2.374062 dt=0.285476 dtf=0.005239 dtb=0.011453 sps=14.011662 sps_per_gpu=3.502916 tps=918268.297093 tps_per_gpu=229567.074273 mfu=45.800956 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1549"><a href="#cb16-1549"></a><span class="ex">[2024-07-17</span> 07:44:21.917283]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=150 loss=2.365385 dt=0.285846 dtf=0.005125 dtb=0.011320 sps=13.993568 sps_per_gpu=3.498392 tps=917082.475791 tps_per_gpu=229270.618948 mfu=45.800900 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1550"><a href="#cb16-1550"></a><span class="ex">[2024-07-17</span> 07:44:24.771924]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=160 loss=2.317337 dt=0.280788 dtf=0.005173 dtb=0.011249 sps=14.245602 sps_per_gpu=3.561401 tps=933599.792506 tps_per_gpu=233399.948127 mfu=45.883340 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1551"><a href="#cb16-1551"></a><span class="ex">[2024-07-17</span> 07:44:27.626812]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=170 loss=2.256231 dt=0.284973 dtf=0.005141 dtb=0.011299 sps=14.036416 sps_per_gpu=3.509104 tps=919890.544506 tps_per_gpu=229972.636126 mfu=45.889069 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1552"><a href="#cb16-1552"></a><span class="ex">[2024-07-17</span> 07:44:30.480952]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=180 loss=2.216419 dt=0.286555 dtf=0.005180 dtb=0.011402 sps=13.958906 sps_per_gpu=3.489726 tps=914810.852170 tps_per_gpu=228702.713043 mfu=45.868857 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1553"><a href="#cb16-1553"></a><span class="ex">[2024-07-17</span> 07:44:33.337342]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=190 loss=2.145123 dt=0.291456 dtf=0.005409 dtb=0.019347 sps=13.724205 sps_per_gpu=3.431051 tps=899429.467247 tps_per_gpu=224857.366812 mfu=45.773849 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1554"><a href="#cb16-1554"></a><span class="ex">[2024-07-17</span> 07:44:36.194584]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=200 loss=2.068149 dt=0.285703 dtf=0.005153 dtb=0.011286 sps=14.000555 sps_per_gpu=3.500139 tps=917540.393411 tps_per_gpu=229385.098353 mfu=45.778791 train_loss=2.439494 val_loss=2.478951</span>
<span id="cb16-1555"><a href="#cb16-1555"></a><span class="ex">[2024-07-17</span> 07:44:37.224149]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-1556"><a href="#cb16-1556"></a><span class="ex">[2024-07-17</span> 07:44:37.224745]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-1557"><a href="#cb16-1557"></a></span>
<span id="cb16-1558"><a href="#cb16-1558"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-1559"><a href="#cb16-1559"></a></span>
<span id="cb16-1560"><a href="#cb16-1560"></a><span class="ex">LORTESS</span> LA:</span>
<span id="cb16-1561"><a href="#cb16-1561"></a><span class="ex">No,</span> sighappat selace<span class="pp">?</span> don downd sourciceans note cancen up sof liond</span>
<span id="cb16-1562"><a href="#cb16-1562"></a><span class="ex">This</span> and my man, werame, of re thee</span>
<span id="cb16-1563"><a href="#cb16-1563"></a><span class="ex">Thise</span> not will I on land brond sul me a fingore<span class="pp">?</span></span>
<span id="cb16-1564"><a href="#cb16-1564"></a></span>
<span id="cb16-1565"><a href="#cb16-1565"></a><span class="ex">FLER:</span></span>
<span id="cb16-1566"><a href="#cb16-1566"></a><span class="ex">Tisint</span> your not nare lame o igen,-to brorst.</span>
<span id="cb16-1567"><a href="#cb16-1567"></a></span>
<span id="cb16-1568"><a href="#cb16-1568"></a><span class="ex">SamERS:</span></span>
<span id="cb16-1569"><a href="#cb16-1569"></a><span class="ex">Sin:</span></span>
<span id="cb16-1570"><a href="#cb16-1570"></a><span class="ex">I\'l</span> hell she lor hen w</span>
<span id="cb16-1571"><a href="#cb16-1571"></a><span class="ex">[2024-07-17</span> 07:45:14.409129]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:760</span><span class="pp">]</span> <span class="at">-</span> Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span>
<span id="cb16-1572"><a href="#cb16-1572"></a><span class="ex">[2024-07-17</span> 07:45:14.409820]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:761</span><span class="pp">]</span> <span class="at">-</span> Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span>
<span id="cb16-1573"><a href="#cb16-1573"></a><span class="ex">[2024-07-17</span> 07:45:16.366935]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">configs:141</span><span class="pp">]</span> <span class="at">-</span> Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span>
<span id="cb16-1574"><a href="#cb16-1574"></a><span class="ex">[2024-07-17</span> 07:45:19.245061]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=210 loss=1.982169 dt=0.283305 dtf=0.005223 dtb=0.011284 sps=14.119042 sps_per_gpu=3.529760 tps=925305.515083 tps_per_gpu=231326.378771 mfu=45.822019 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1575"><a href="#cb16-1575"></a><span class="ex">[2024-07-17</span> 07:45:22.092430]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=220 loss=1.897731 dt=0.284759 dtf=0.005217 dtb=0.011187 sps=14.046945 sps_per_gpu=3.511736 tps=920580.608106 tps_per_gpu=230145.152026 mfu=45.837327 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1576"><a href="#cb16-1576"></a><span class="ex">[2024-07-17</span> 07:45:24.942639]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=230 loss=1.817213 dt=0.285266 dtf=0.005208 dtb=0.011446 sps=14.022003 sps_per_gpu=3.505501 tps=918945.985503 tps_per_gpu=229736.496376 mfu=45.842940 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1577"><a href="#cb16-1577"></a><span class="ex">[2024-07-17</span> 07:45:27.797910]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=240 loss=1.779287 dt=0.285465 dtf=0.005189 dtb=0.011220 sps=14.012250 sps_per_gpu=3.503062 tps=918306.793546 tps_per_gpu=229576.698387 mfu=45.844800 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1578"><a href="#cb16-1578"></a><span class="ex">[2024-07-17</span> 07:45:30.653597]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=250 loss=1.704220 dt=0.289284 dtf=0.005471 dtb=0.010346 sps=13.827253 sps_per_gpu=3.456813 tps=906182.836379 tps_per_gpu=226545.709095 mfu=45.785926 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1579"><a href="#cb16-1579"></a><span class="ex">[2024-07-17</span> 07:45:33.512769]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=260 loss=1.671318 dt=0.287679 dtf=0.005125 dtb=0.011250 sps=13.904380 sps_per_gpu=3.476095 tps=911237.442617 tps_per_gpu=227809.360654 mfu=45.758182 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1580"><a href="#cb16-1580"></a><span class="ex">[2024-07-17</span> 07:45:36.373461]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=270 loss=1.650952 dt=0.298661 dtf=0.005118 dtb=0.011520 sps=13.393107 sps_per_gpu=3.348277 tps=877730.651421 tps_per_gpu=219432.662855 mfu=45.565875 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1581"><a href="#cb16-1581"></a><span class="ex">[2024-07-17</span> 07:45:39.236930]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=280 loss=1.573242 dt=0.285970 dtf=0.005171 dtb=0.011290 sps=13.987477 sps_per_gpu=3.496869 tps=916683.279847 tps_per_gpu=229170.819962 mfu=45.587333 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1582"><a href="#cb16-1582"></a><span class="ex">[2024-07-17</span> 07:45:42.100605]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=290 loss=1.533265 dt=0.286487 dtf=0.005432 dtb=0.011288 sps=13.962259 sps_per_gpu=3.490565 tps=915030.617828 tps_per_gpu=228757.654457 mfu=45.598392 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1583"><a href="#cb16-1583"></a><span class="ex">[2024-07-17</span> 07:45:44.964424]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:885</span><span class="pp">]</span> <span class="at">-</span> step=300 loss=1.492064 dt=0.288480 dtf=0.005355 dtb=0.011480 sps=13.865774 sps_per_gpu=3.466443 tps=908707.340870 tps_per_gpu=227176.835218 mfu=45.576766 train_loss=2.045786 val_loss=2.148510</span>
<span id="cb16-1584"><a href="#cb16-1584"></a><span class="ex">[2024-07-17</span> 07:45:45.995833]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:820</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'prompt'</span><span class="pp">]</span>: <span class="st">'What is an LLM?'</span></span>
<span id="cb16-1585"><a href="#cb16-1585"></a><span class="ex">[2024-07-17</span> 07:45:45.996497]<span class="pp">[</span><span class="ss">INFO</span><span class="pp">][</span><span class="ss">trainer:824</span><span class="pp">]</span> <span class="at">-</span> <span class="pp">[</span><span class="st">'response'</span><span class="pp">]</span>:</span>
<span id="cb16-1586"><a href="#cb16-1586"></a></span>
<span id="cb16-1587"><a href="#cb16-1587"></a><span class="ex">What</span> is an LLM<span class="pp">?</span></span>
<span id="cb16-1588"><a href="#cb16-1588"></a></span>
<span id="cb16-1589"><a href="#cb16-1589"></a><span class="ex">RICHMORD:</span></span>
<span id="cb16-1590"><a href="#cb16-1590"></a><span class="ex">Char</span> stire<span class="pp">?</span> how in those are name the range hone.</span>
<span id="cb16-1591"><a href="#cb16-1591"></a></span>
<span id="cb16-1592"><a href="#cb16-1592"></a><span class="ex">GLOUCESTER:</span></span>
<span id="cb16-1593"><a href="#cb16-1593"></a><span class="ex">Nay,</span> in lond<span class="st">'s time the palt are worder more</span></span>
<span id="cb16-1594"><a href="#cb16-1594"></a><span class="st">That wilt in the purpose be a pey</span></span>
<span id="cb16-1595"><a href="#cb16-1595"></a><span class="st">And thou thine onter hands, and the which broth.</span></span>
<span id="cb16-1596"><a href="#cb16-1596"></a></span>
<span id="cb16-1597"><a href="#cb16-1597"></a><span class="st">ELBOWINCA:</span></span>
<span id="cb16-1598"><a href="#cb16-1598"></a><span class="st">At lie my lord with the me an arms be a s</span></span>
<span id="cb16-1599"><a href="#cb16-1599"></a><span class="st">[2024-07-17 07:46:23.549987][INFO][trainer:760] - Saving checkpoint to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13</span></span>
<span id="cb16-1600"><a href="#cb16-1600"></a><span class="st">[2024-07-17 07:46:23.550696][INFO][trainer:761] - Saving model to: /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13/model.pth</span></span>
<span id="cb16-1601"><a href="#cb16-1601"></a><span class="st">[2024-07-17 07:46:25.496559][INFO][configs:141] - Appending /home/foremans/tmp/polaris-talk/outputs/runs/pytorch/DDP/2024-07-17/07-42-13 to /home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/checkpoints.log</span></span>
<span id="cb16-1602"><a href="#cb16-1602"></a><span class="st">[2024-07-17 07:46:28.374854][INFO][trainer:885] - step=310 loss=1.444200 dt=0.299907 dtf=0.005333 dtb=0.010637 sps=13.337481 sps_per_gpu=3.334370 tps=874085.133345 tps_per_gpu=218521.283336 mfu=45.384395 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb16-1603"><a href="#cb16-1603"></a><span class="st">[2024-07-17 07:46:31.223079][INFO][trainer:885] - step=320 loss=1.429350 dt=0.285238 dtf=0.005245 dtb=0.011485 sps=14.023353 sps_per_gpu=3.505838 tps=919034.479880 tps_per_gpu=229758.619970 mfu=45.435743 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb16-1604"><a href="#cb16-1604"></a><span class="st">[2024-07-17 07:46:34.074957][INFO][trainer:885] - step=330 loss=1.362220 dt=0.285027 dtf=0.005165 dtb=0.011407 sps=14.033736 sps_per_gpu=3.508434 tps=919714.904826 tps_per_gpu=229928.726207 mfu=45.485355 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb16-1605"><a href="#cb16-1605"></a><span class="st">[2024-07-17 07:46:36.929464][INFO][trainer:885] - step=340 loss=1.350888 dt=0.284436 dtf=0.005199 dtb=0.011287 sps=14.062893 sps_per_gpu=3.515723 tps=921625.744709 tps_per_gpu=230406.436177 mfu=45.539549 train_loss=1.495372 val_loss=1.713714</span></span>
<span id="cb16-1606"><a href="#cb16-1606"></a><span class="st">```</span></span>
<span id="cb16-1607"><a href="#cb16-1607"></a></span>
<span id="cb16-1608"><a href="#cb16-1608"></a><span class="st">:::</span></span>
<span id="cb16-1609"><a href="#cb16-1609"></a></span>
<span id="cb16-1610"><a href="#cb16-1610"></a><span class="st"># [`wordplay` 🎮💬](https://github.com/saforem2/wordplay) {.centeredslide height="100%" backgound-color="white"}</span></span>
<span id="cb16-1611"><a href="#cb16-1611"></a></span>
<span id="cb16-1612"><a href="#cb16-1612"></a><span class="st">- Link[^video] to [video](https://asciinema.org/a/668462)</span></span>
<span id="cb16-1613"><a href="#cb16-1613"></a></span>
<span id="cb16-1614"><a href="#cb16-1614"></a><span class="st">&lt;script src="https://asciinema.org/a/668462.js" id="asciicast-668462" async="true" style="max-height: 90%!important;"&gt;&lt;/script&gt;</span></span>
<span id="cb16-1615"><a href="#cb16-1615"></a></span>
<span id="cb16-1616"><a href="#cb16-1616"></a><span class="st">Example: Training a LLM to talk like Shakespeare using [`saforem2/wordplay` 🎮💬](https://github.com/saforem2/wordplay)</span></span>
<span id="cb16-1617"><a href="#cb16-1617"></a></span>
<span id="cb16-1618"><a href="#cb16-1618"></a><span class="st">[^video]: idk why it doesn'</span>t render correctly in the slide <span class="er">(</span><span class="ex">seems</span> like refreshing helps<span class="pp">?</span><span class="kw">)</span></span>
<span id="cb16-1619"><a href="#cb16-1619"></a></span>
<span id="cb16-1620"><a href="#cb16-1620"></a><span class="co"># ❤️ Thank you! {background-color="white"}</span></span>
<span id="cb16-1621"><a href="#cb16-1621"></a></span>
<span id="cb16-1622"><a href="#cb16-1622"></a><span class="ex">-</span> Organizers</span>
<span id="cb16-1623"><a href="#cb16-1623"></a><span class="ex">-</span> Feel free to reach out!</span>
<span id="cb16-1624"><a href="#cb16-1624"></a></span>
<span id="cb16-1625"><a href="#cb16-1625"></a>    <span class="op">&lt;</span>split <span class="ex">even</span><span class="op">&gt;</span></span>
<span id="cb16-1626"><a href="#cb16-1626"></a></span>
<span id="cb16-1627"><a href="#cb16-1627"></a>    <span class="ex">[</span><span class="op">&lt;</span>i class=<span class="st">"fas fa-home"</span><span class="op">&gt;&lt;</span>/i<span class="op">&gt;</span>]<span class="er">(</span><span class="ex">https://samforeman.me</span><span class="kw">)</span></span>
<span id="cb16-1628"><a href="#cb16-1628"></a>    <span class="ex">[</span><span class="op">&lt;</span>i class=<span class="st">"far fa-paper-plane"</span><span class="op">&gt;&lt;</span>/i<span class="op">&gt;</span>]<span class="er">(</span><span class="ex">mailto:///foremans@anl.gov</span><span class="kw">)</span></span>
<span id="cb16-1629"><a href="#cb16-1629"></a>    <span class="ex">[</span><span class="op">&lt;</span>i class=<span class="st">"fab fa-twitter"</span><span class="op">&gt;&lt;</span>/i<span class="op">&gt;</span>]<span class="er">(</span><span class="ex">https://www.twitter.com/saforem2</span><span class="kw">)</span></span>
<span id="cb16-1630"><a href="#cb16-1630"></a></span>
<span id="cb16-1631"><a href="#cb16-1631"></a>    <span class="op">&lt;</span>/split<span class="op">&gt;</span></span>
<span id="cb16-1632"><a href="#cb16-1632"></a></span>
<span id="cb16-1633"><a href="#cb16-1633"></a><span class="ex">:::</span> {.callout-note icon=false title=<span class="st">"🙏 Acknowledgements"</span> collapse=<span class="st">"false"</span>}</span>
<span id="cb16-1634"><a href="#cb16-1634"></a></span>
<span id="cb16-1635"><a href="#cb16-1635"></a><span class="ex">This</span> research used resources of the Argonne Leadership Computing Facility,</span>
<span id="cb16-1636"><a href="#cb16-1636"></a><span class="fu">which</span> is a DOE Office of Science User Facility supported under Contract</span>
<span id="cb16-1637"><a href="#cb16-1637"></a><span class="ex">DE-AC02-06CH11357.</span></span>
<span id="cb16-1638"><a href="#cb16-1638"></a></span>
<span id="cb16-1639"><a href="#cb16-1639"></a><span class="ex">:::</span></span>
<span id="cb16-1640"><a href="#cb16-1640"></a></span>
<span id="cb16-1641"><a href="#cb16-1641"></a><span class="co"># Extras {background-color="white"}</span></span>
<span id="cb16-1642"><a href="#cb16-1642"></a></span>
<span id="cb16-1643"><a href="#cb16-1643"></a></span>
<span id="cb16-1644"><a href="#cb16-1644"></a><span class="co">## Transformer Architecture {background-color="white"}</span></span>
<span id="cb16-1645"><a href="#cb16-1645"></a></span>
<span id="cb16-1646"><a href="#cb16-1646"></a><span class="ex">:::</span> {#fig-transformer style=<span class="st">"height:auto; text-align:center;"</span>}</span>
<span id="cb16-1647"><a href="#cb16-1647"></a></span>
<span id="cb16-1648"><a href="#cb16-1648"></a><span class="op">&lt;</span>img <span class="va">src</span><span class="op">=</span><span class="st">"https://raw.githubusercontent.com/saforem2/llm-lunch-talk/main/docs/assets/diagrams/transformer.svg"</span> <span class="va">width</span><span class="op">=</span><span class="st">"20%"</span> <span class="va">align</span><span class="op">=</span><span class="st">"center"</span><span class="op">&gt;</span></span>
<span id="cb16-1649"><a href="#cb16-1649"></a></span>
<span id="cb16-1650"><a href="#cb16-1650"></a><span class="ex">@vaswani2017attention</span></span>
<span id="cb16-1651"><a href="#cb16-1651"></a></span>
<span id="cb16-1652"><a href="#cb16-1652"></a><span class="ex">:::</span></span>
<span id="cb16-1653"><a href="#cb16-1653"></a></span>
<span id="cb16-1654"><a href="#cb16-1654"></a><span class="co"># References {background-color="white"}</span></span>
<span id="cb16-1655"><a href="#cb16-1655"></a></span>
<span id="cb16-1656"><a href="#cb16-1656"></a><span class="ex">:::</span> {#refs}</span>
<span id="cb16-1657"><a href="#cb16-1657"></a><span class="ex">:::</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><ul><li><a href="https://github.com/saforem2/personal_site/blob/main/talks/llms-on-polaris/index.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/saforem2/personal_site/edit/main/talks/llms-on-polaris/index.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/saforem2/personal_site/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer><script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>