{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "[Sam Foreman](https://samforeman.me)\n",
        "(\\[[ALCF](https://alcf.anl.gov/about/people/sam-foreman)\\](<https://alcf.anl.gov/about/people/sam-foreman>))\n",
        "\n",
        "# Introduction to Large Language Models\n",
        "\n",
        "Author: Archit Vasan , including materials on LLMs by Varuni Sastri and\n",
        "Carlo Graziani at Argonne, and discussion/editorial work by Taylor\n",
        "Childers, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
        "\n",
        "Inspiration from the blog posts “The Illustrated Transformer” and “The\n",
        "Illustrated GPT2” by Jay Alammar, highly recommended reading.\n",
        "\n",
        "This tutorial covers the some fundamental concepts necessary to to study\n",
        "of large language models (LLMs).\n",
        "\n",
        "## Brief overview\n",
        "\n",
        "-   Scientific applications for language models\n",
        "-   General overview of Transformers\n",
        "-   Tokenization\n",
        "-   Model Architecture\n",
        "-   Pipeline using HuggingFace\n",
        "-   Model loading\n",
        "\n",
        "## Sophia Setup\n",
        "\n",
        "1.  If you are using ALCF, first log in. From a terminal run the\n",
        "    following command:\n",
        "\n",
        "<!-- -->\n",
        "\n",
        "    ssh username@sophia.alcf.anl.gov\n",
        "\n",
        "1.  Although we already cloned the repo before, you’ll want the updated\n",
        "    version. To be reminded of the instructions for syncing your fork,\n",
        "    click\n",
        "    [here](https://github.com/argonne-lcf/ai-science-training-series/blob/main/00_introToAlcf/03_githubHomework.md).\n",
        "\n",
        "2.  Now that we have the updated notebooks, we can open them. If you are\n",
        "    using ALCF JupyterHub or Google Colab, you can be reminded of the\n",
        "    steps\n",
        "    [here](https://github.com/argonne-lcf/ai-science-training-series/blob/main/01_intro_AI_on_Supercomputer/01_linear_regression_sgd.ipynb).\n",
        "\n",
        "3.  Reminder: Change the notebook’s kernel to\n",
        "    `datascience/conda-2024-08-08` (you may need to change kernel each\n",
        "    time you open a notebook for the first time):\n",
        "\n",
        "    1.  select *Kernel* in the menu bar\n",
        "    2.  select *Change kernel…*\n",
        "    3.  select *datascience/conda-2024-08-08* from the drop-down menu\n",
        "\n",
        "## Google colab setup\n",
        "\n",
        "In case you have trouble accessing Sophia, all notebook material can be\n",
        "run in google colab.\n",
        "\n",
        "Just: 1. Go to this link:\n",
        "[Colab](https://colab.research.google.com/#scrollTo=Wf5KrEb6vrkR) 2.\n",
        "Click on `File/Open notebook` 3. Nagivate to the `GitHub` tab and find\n",
        "`argonne-lcf/ai-science-training-series` 4. Click on\n",
        "`04_intro_to_llms/IntroLLMs.ipynb`\n",
        "\n",
        "## **References:**\n",
        "\n",
        "I strongly recommend reading [“The Illustrated\n",
        "Transformer”](https://jalammar.github.io/illustrated-transformer/) by\n",
        "Jay AlammarAlammar also has a useful post dedicated more generally to\n",
        "Sequence-to-Sequence modeling [“Visualizing A Neural Machine Translation\n",
        "Model (Mechanics of Seq2seq Models With\n",
        "Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/),\n",
        "which illustrates the attention mechanism in the context of a more\n",
        "generic language translation model.\n",
        "\n",
        "## Homework solutions\n",
        "\n",
        "Solutions to homework problems are posted in IntroLLMHWSols.ipynb To see\n",
        "BertViz attention mechanisms, simply open the notebook in google colab."
      ],
      "id": "04690b65-1ee2-409d-bc94-0125e79574e5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}