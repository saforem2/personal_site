[
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "üìö Projects",
    "section": "",
    "text": "Tipüìä GitHub Stats\n\n\n\n\n\n\n \n\n\n \n\n\n\n\nEven More !!\n\n\n\nWakatime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipüìÇ saforem2/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {üìö {Projects}},\n  url = {https://samforeman.me/projects/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äúüìö Projects.‚Äù https://samforeman.me/projects/.",
    "crumbs": [
      "talks",
      "üìö Projects"
    ]
  },
  {
    "objectID": "posts/torchtune-patch-aurora/index.html#patch-to-get-torchtune-working-on-aurora",
    "href": "posts/torchtune-patch-aurora/index.html#patch-to-get-torchtune-working-on-aurora",
    "title": "üöë Torchtune Patch on Aurora",
    "section": "Patch to get torchtune working on Aurora",
    "text": "Patch to get torchtune working on Aurora\ndiff --git a/torchtune/training/_distributed.py b/torchtune/training/_distributed.py\nindex ff959c5f..c3966290 100644\n--- a/torchtune/training/_distributed.py\n+++ b/torchtune/training/_distributed.py\n@@ -14,7 +14,11 @@ import torch\n import torch.distributed as dist\n from torch import nn\n\n-from torch.distributed._composable.fsdp import CPUOffloadPolicy, fully_shard\n+try:\n+    from torch.distributed._composable.fsdp import fully_shard\n+except (ImportError, ModuleNotFoundError):\n+    from torch.distributed._composable.fsdp.fully_shard import fully_shard\n+\n from torch.distributed._tensor import distribute_tensor, DTensor\n from torch.distributed._tensor.placement_types import DTensorSpec, TensorMeta\n from torch.distributed.checkpoint.state_dict import (\n@@ -532,6 +536,11 @@ def shard_model(\n     \"\"\"\n     fsdp_kwargs = {\"reshard_after_forward\": reshard_after_forward}\n     if cpu_offload:\n+        try:\n+            from torch.distributed._composable.fsdp import CPUOffloadPolicy\n+        except (ImportError, ModuleNotFoundError):\n+            from torch.distributed._composable.fsdp._fsdp_api import MixedPrecisionPolicy, CPUOffloadPolicy\n+            # from torch.distributed._composable import CPUOffloadPolicy\n         fsdp_kwargs[\"offload_policy\"] = CPUOffloadPolicy()\n\n     # Shard the model with FSDP, iterating in reverse to start with",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üöë Torchtune Patch on Aurora"
    ]
  },
  {
    "objectID": "posts/svgbob/index.html",
    "href": "posts/svgbob/index.html",
    "title": "ü´• svgbob",
    "section": "",
    "text": "Playing with  ivanceras/svgbob as an alternative to Mermaid\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  Network\n  \n  Loss\n  \n  x0\n  \n  \n  Network\n  \n  Loss\n  \n  x1\n  \n  \n  Network\n  \n  Loss\n  \n  x2\n  \n  Data\n  GPU0\n  x0\n  \n  \n  GPU1\n  \n  x1\n  \n  \n  \n  GPU2\n  \n  x2\n  \n  \n  \n  \n  \n  \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  Network\n  \n  Loss\n  \n  Network\n  \n  Loss\n  \n  Network\n  \n  Loss\n  Data\n  GPU0\n  x0\n  \n  \n  \n  GPU1\n  \n  x1\n  \n  \n  \n  GPU2\n  \n  x2\n  \n  \n  \n  \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  \n  \n  \n  \n  \n  Filesystem\n  \n  Scheduler\n  \n  IO\n  \n  Network\n  \n  HAL\n  \n  \n  MMU\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  OS\n  API\n  \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  Network\n  \n  Loss\n  \n  x1\n  \n  x2\n  Data\n  GPU0\n  \n  x0\n  \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  Loss\n  \n  Network\n  \n  Loss\n  \n  Network\n  \n  Loss\n  Data\n  GPU0\n  x0\n  \n  Network\n  \n  \n  \n  \n  GPU1\n  \n  x1\n  \n  \n  \n  GPU2\n  \n  x2\n  \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  \n  \n  \n  \n  8\n  \n  9\n  \n  10\n  \n  11\n  \n  12\n  \n  \n  Latest\n  addition:\n  Styling\n  of\n  tagged\n  shapes\n  Advantages:\n  \n  \n  Plain\n  text\n  format\n  Ultimately\n  portable,\n  Degrades\n  gracefully\n  Even\n  when\n  not\n  using\n  a\n  graphical\n  renderer,\n  it\n  would\n  still\n  looks\n  as\n  text\n  based\n  diagrams.\n  Paste\n  the\n  text\n  in\n  your\n  source\n  code.\n  Easiest\n  to\n  use.\n  Anyone\n  knows\n  how\n  to\n  edit\n  text.\n  backward\n  compatible\n  and\n  future\n  proof.\n  \n  \n  good\n  \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n\n\n  \n  \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  MMU\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  Filesystem\n  \n  Scheduler\n  \n  IO\n  \n  Network\n  \n  HAL\n  \n  \n  MMU\n  \n  \n  \n  \n  \n  \n  \n  \n  8\n  \n  9\n  \n  10\n  \n  11\n  \n  12\n  Svgbob\n  is\n  a\n  diagramming\n  model\n  which\n  uses\n  a\n  set\n  of\n  typing\n  characters\n  to\n  approximate\n  the\n  intended\n  shape.\n  \n  \n  \n  \n  It\n  uses\n  a\n  which\n  are\n  combination\n  of\n  characters\n  readily\n  available\n  on\n  your\n  keyboards.\n  What\n  can\n  it\n  do?\n  \n  \n  Basic\n  shapes\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  .\n  .\n  .\n  .\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  Quick\n  logo\n  \n  \n  \n  \n  scribbles\n  \n  \n  \n  \n  \n  .::::.\n  \n  \n  Even\n  unicode\n  box\n  drawing\n  characters\n  are\n  supported\n  \n  \n  Circle,\n  quarter\n  arcs,\n  half\n  circles,\n  3\n  \n  4\n  quarter\n  arcs\n  \n  \n  Grids\n  {r}\n  {g}\n  \n  \n  Graphics\n  Diagram\n  \n  \n  \n  \n  \n  \n  \n  0\n  3\n  \n  \n  \n  \n  \n  \n  \n  1\n  2\n  \n  \n  \n  \n  4\n  7\n  \n  \n  \n  \n  \n  \n  5\n  6\n  P\n  \n  \n  v0\n  v3\n  \n  \n  \n  \n  \n  \n  X\n  \n  \n  \n  Eye\n  \n  +y\n  \n  \n  \n  \n  \n  ‚§¥\n  \n  +z\n  Reflection\n  +x\n  \n  \n  Refraction\n  \n  \n  \n  \n  \n  \n  v1\n  v2\n  \n  \n  CJK\n  characters\n  \n  \n  \n  \n  Sequence\n  Diagrams\n  \n  A\n  B\n  C\n  D\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  B\n  F\n  E\n  G\n  \n  \n  C\n  \n  \n  Bob\n  Alice\n  hello\n  \n  \n  Is\n  \n  \n  \n  \n  Alice\n  Bob\n  \n  \n  it\n  ok?\n  \n  \n  \n  \n  0\n  \n  \n  1\n  \n  \n  3\n  \n  \n  4\n  .\n  \n  \n  \n  .\n  \n  \n  \n  5\n  6\n  7\n  \n  \n  2\n  \n  \n  Plot\n  diagrams\n  \n  \n  \n  Uin\n  Udc\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  500ms\n  Inactive\n  Active\n  \n  Cpu.Qon\n  \n  \n  Railroad\n  diagrams\n  \n  elem\n  ;\n  n\n  \n  \n  \n  x\n  \n  \n  ,\n  \n  \n  x\n  ,\n  \n  \n  O\n  struct\n  \n  name\n  :\n  \n  \n  name\n  :\n  tpe\n  \n  body\n  O\n  \n  \n  ,\n  \n  \n  Statistical\n  charts\n  E\n  D\n  C\n  B\n  A\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  5\n  10\n  15\n  20\n  25\n  30\n  35\n  40\n  45\n  50\n  E\n  D\n  C\n  B\n  A\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  5\n  10\n  15\n  20\n  25\n  30\n  35\n  40\n  45\n  50\n  85.67\n  78.20\n  70.73\n  63.27\n  55.80\n  48.33\n  40.87\n  33.40\n  25.93\n  18.47\n  11.00\n  2011\n  2012\n  2013\n  2014\n  2015\n  2016\n  \n  \n  Flow\n  charts\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  OS\n  API\n  \n  \n  Block\n  diagrams\n  vncviewer\n  \n  [\n  \n  ]\n  \n  \n  \n  ,\n  \n  \n  \n  \n  \n  ,\n  gateway\n  vncserver\n  )\n  \n  \n  \n  \n  \n  .\n  \n  '\n  [\n  \n  ...\n  \n  \n  .\n  \n  internet\n  '\n  \n  .\n  \n  Valveless\n  Pulsejet\n  engine\n  \n  \n  \n  '\n  \n  .\n  GND\n  \n  \n  \n  \n  \n  \n  \n  power\n  \n  \n  switch\n  \n  \n  HHO\n  Generator\n  +\n  \n  Battery\n  \n  \n  thrust\n  \n  \n  \n  \n  fuel\n  intake\n  \n  ^\n  ^\n  \n  spark\n  plug\n  \n  Water\n  intake\n  Solar\n  panel\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  micro\n  henry\n  coil\n  w\n  \n  tuning\n  '\n  pico\n  farad\n  cap\n  \n  trimmable\n  \n  ground\n  plane\n  \n  foil\n  \n  symbolic\n  antenna\n  lug\n  PC\n  \n  \n  Board\n  \n  \n  Mindmaps\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  Worklaod\n  \n  \n  \n  \n  Alpha\n  Initial\n  \n  \n  Release\n  Planning\n  Patch\n  1\n  Initial\n  research\n  \n  \n  Patch\n  2\n  Beta\n  .\n  Release\n  .\n  Push\n  backs\n  Setbacks\n  Reception\n  Team\n  Career\n  change\n  PTO\n  Bug\n  \n  \n  It\n  can\n  do\n  complex\n  stuff\n  such\n  as\n  circuit\n  diagrams\n  +10\n  \n  15V\n  0,047R\n  \n  \n  \n  \n  \n  \n  \n  \n  +\n  \n  \n  \n  \n  \n  \n  \n  \n  .\n  \n  \n  \n  \n  470\n  \n  +\n  \n  \n  uF\n  \n  6\n  7\n  8\n  \n  \n  \n  1\n  GND\n  \n  `\n  \n  \n  220R\n  \n  \n  BYV29\n  \n  12V6\n  \n  \n  \n  \n  \n  \n  \n  OUT\n  \n  +\n  2\n  \n  C\n  \n  \n  \n  \n  \n  \n  GND\n  C\n  \n  3\n  1nF\n  C\n  \n  \n  \n  \n  \n  +\n  GND\n  GND\n  5\n  4\n  \n  \n  \n  \n  2k\n  1k0\n  GND\n  2k2\n  LED\n  1k\n  BC\n  547\n  IRF9Z34\n  MC34063\n  6000\n  micro\n  Farad,\n  40V\n  Capacitor\n  30uH\n  470\n  uF\n  5k6\n  +\n  3k3\n  in\n  Serie\n  \n  \n  Latest\n  addition:\n  Styling\n  of\n  tagged\n  shapes\n  Advantages:\n  \n  \n  Plain\n  text\n  format\n  Ultimately\n  portable,\n  Degrades\n  gracefully\n  Even\n  when\n  not\n  using\n  a\n  graphical\n  renderer,\n  it\n  would\n  still\n  looks\n  as\n  text\n  based\n  diagrams.\n  Paste\n  the\n  text\n  in\n  your\n  source\n  code.\n  Easiest\n  to\n  use.\n  Anyone\n  knows\n  how\n  to\n  edit\n  text.\n  backward\n  compatible\n  and\n  future\n  proof.\n  \n  \n  good\n  \n  \n  .--------------.\n  | Don't draw me|\n  |              |\n  '--------------'\n  Udc_OK\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    Êñá\n    ‰ª∂\n    Á≥ª\n    Áªü\n  \n  \n    Ë∞É\n    Â∫¶\n    Âô®\n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    ‚†∂\n    ‚†∂\n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    ...¬∞\n    ]\n  \n  \n    ‚†∂\n    ‚†∂\n    ‚†∂\n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2024,\n  author = {Foreman, Sam},\n  title = {Svgbob},\n  date = {2024-11-15},\n  url = {https://samforeman.me/posts/svgbob},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2024. ‚ÄúSvgbob.‚Äù November 15, 2024. https://samforeman.me/posts/svgbob.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü´• svgbob"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html",
    "href": "posts/jupyter/test/index.html",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "",
    "text": "Sam Foreman  2023-12-14\nThis notebook will (attempt) to walk through the steps needed to successfully instantiate and run an experiment.\nFor this example, we wish to train the L2HMC sampler for the 2D U(1) lattice gauge model with Wilson action:\nS_{\\beta}(n) = \\beta \\sum_{n}\\sum_{\\mu&lt;\\nu}\\mathrm{Re}\\left[1 - U_{\\mu\\nu}(n) \\right]\nThis consists of the following steps:",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html#imports-setup",
    "href": "posts/jupyter/test/index.html#imports-setup",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "Imports / Setup",
    "text": "Imports / Setup\n! nvidia-smi | tail --lines -7\n\n\n\n\noutput\n\n\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    1   N/A  N/A   4027423      C   ...PU/2023-04-26/bin/python3     2915MiB |\n|    2   N/A  N/A   4054944      C   ...PU/2023-04-26/bin/python3     5793MiB |\n|    3   N/A  N/A   3989894      C   ...PU/2023-04-26/bin/python3     6021MiB |\n|    4   N/A  N/A   3981679      C   ...PU/2023-04-26/bin/python3     3951MiB |\n+-----------------------------------------------------------------------------+\n\n\n\n\nimport os\ndevices = os.environ.get('CUDA_VISIBLE_DEVICES', None)\nprint(devices)\n!getconf _NPROCESSORS_ONLN  # get number of availble CPUs\n\n\n\n\noutput\n\n\nNone\n256\n\n\n\n\nos.environ['TORCH_CPP_LOG_LEVEL'] = 'ERROR'\nos.environ['AUTOGRAPH_VERBOSITY'] = '10'\n!echo $CUDA_VISIBLE_DEVICES\nimport lovely_tensors as lt\nlt.monkey_patch()\nlt.set_config(color=False)\n# automatically detect and reload local changes to modules\n%load_ext autoreload\n%autoreload 2\n\n# automatically detect and reload local changes to modules\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg', 'retina')\n\n\n\n\noutput\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\nimport os\nimport warnings\n\nos.environ['COLORTERM'] = 'truecolor'\nwarnings.filterwarnings('ignore')\n# --------------------------------------\n# BE SURE TO GRAB A FRESH GPU !\nos.environ['CUDA_VISIBLE_DEVICES'] = '5'\n!echo $CUDA_VISIBLE_DEVICES\n# --------------------------------------\n\n\n\n\noutput\n\n\n5\n\n\n\n\nimport yaml\nimport logging\nfrom l2hmc.configs import CONF_DIR\n\nrlog_yaml = CONF_DIR.joinpath('hydra', 'job_logging', 'rich_jupyter.yaml')\nwith rlog_yaml.open('r') as stream:\n    logconf = dict(yaml.safe_load(stream))\n\nlogging.config.dictConfig(logconf)\nlog = logging.getLogger()\nlog.setLevel('INFO')\n\n\n\n\noutput\n\n\n--------------------------------------------------------------------------\nWARNING: There was an error initializing an OpenFabrics device.\n\n  Local host:   thetagpu23\n  Local device: mlx5_0\n--------------------------------------------------------------------------\nUsing device: cuda \n\n\n\n\nimport torch\nimport opinionated\n\nimport seaborn as sns\nimport numpy as np\nimport lovely_tensors as lt\nimport matplotlib.pyplot as plt\nimport l2hmc.group.su3.pytorch.group as g\n\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom ezpz import setup_torch\n#from l2hmc.utils.dist import setup_torch_distributed\n\nfrom l2hmc.common import grab_tensor, print_dict\nfrom l2hmc.configs import dict_to_list_of_overrides, get_experiment\nfrom l2hmc.experiment.pytorch.experiment import Experiment, evaluate  # noqa  # noqa\nfrom l2hmc.utils.plot_helpers import set_plot_style\nfrom l2hmc.utils.history import BaseHistory\nfrom l2hmc.utils.plot_helpers import (  # noqa\n    set_plot_style,\n    plot_scalar,\n    plot_chains,\n    plot_leapfrogs\n)\n\nos.environ['COLORTERM'] = 'truecolor'\nPORT = np.random.randint(5000, 6000)\n#SEED = np.random.randint(0, 2 ** 16)\nSEED = 4351\nlog.critical(f'{SEED=}')\nlog.info(f'{PORT=}')\nos.environ['MASTER_PORT'] = str(PORT)\n\n#_ = setup_torch_distributed(backend='DDP', )\n_ = setup_torch(backend='DDP', seed=SEED, port=PORT)\n\n_ = (\n    torch.set_default_device('cuda')\n    if torch.cuda.is_available() else None\n)\n#torch.set_default_dtype(torch.bfloat16)\n#_ = (\n#    torch.set_autocast_gpu_dtype(torch.bfloat16)\n#    if torch.cuda.is_available() else None\n#)\n\nset_plot_style()\nplt.style.use(opinionated.STYLES['opinionated_min'])\nsns.set_context('notebook', font_scale=1.25)\n\n\n\n\noutput\n\n\nFailed to download font: Source Sans Pro, skipping!\nFailed to download font: Titillium WebRoboto Condensed, skipping!\n\n\n2023-12-05 11:12:19.257964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n[2023-12-05 11:12:22,359] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect) \n[2023-12-05 11:12:27][CRITICAL][747729381.py:32] - SEED=4351 \n[2023-12-05 11:12:27][INFO][747729381.py:33] - PORT=5249 \n[2023-12-05 11:12:27][INFO][dist.py:185] - Using DDP for distributed training \n[2023-12-05 11:12:27][INFO][dist.py:162] - Caught MASTER_PORT:5249 from environment! \n[2023-12-05 11:12:27][INFO][distributed_c10d.py:442] - Added key: store_based_barrier_key:1 to store for rank: 0 \n[2023-12-05 11:12:27][INFO][distributed_c10d.py:476] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes. \n[2023-12-05 11:12:27][INFO][dist.py:240] - RANK: 0 / 0 \n\n\n\n\nimport l2hmc\nlog.info(f'{l2hmc.__file__=}')\n\n\n\n\noutput\n\n\n[2023-12-05 11:12:28][INFO][1221488284.py:2] - l2hmc.__file__='/lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/__init__.py'",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html#pytorch",
    "href": "posts/jupyter/test/index.html#pytorch",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "PyTorch",
    "text": "PyTorch\nimport time\nfrom l2hmc.utils.history import BaseHistory, summarize_dict\nimport l2hmc.utils.live_plots as plotter\n\nplt.rcParams['xaxis.labellocation'] = 'center'\nplt.rcParams['yaxis.labellocation'] = 'center'\n\nbeta = 4.0\nstate = ptExpU1.trainer.dynamics.random_state(beta)\nstate.x.device\n\n\n\n\noutput\n\n\ndevice(type='cuda', index=0)\n\n\n\n\n\nTraining\noutputs['pytorch']['train'] = ptExpU1.trainer.train(\n    nera=1,\n    nepoch=5000,\n    beta=4.0,\n    # beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n)\n\n\n\n\n\noutput\n\n\n[2023-12-05 11:14:13][INFO][trainer.py:108] - ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì  \n[2023-12-05 11:14:13][INFO][trainer.py:109] - ‚îÉ ERA: 0 / 1, BETA: 4.000 ‚îÉ \n[2023-12-05 11:14:13][INFO][trainer.py:110] - ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ \n[2023-12-05 11:14:14][INFO][trainer.py:471] - Thermalizing configs @ 4.00 took 1.7203 s \n[2023-12-05 11:14:15][INFO][trainer.py:1623] - era=0 epoch=0 tstep=1 dt=0.311 beta=4.000 loss=81.851 dQsin=0.006 dQint=0.002 energy=411.822 logprob=411.697 logdet=0.125 sldf=0.120 sldb=-0.107 sld=0.125 xeps=0.050 veps=0.050 acc=0.026 sumlogdet=0.003 acc_mask=0.026 plaqs=0.854 intQ=0.053 sinQ=0.037 lr=0.001 \n[2023-12-05 11:14:15][INFO][distributed.py:1140] - Reducer buckets have been rebuilt in this iteration. \n[2023-12-05 11:15:18][INFO][trainer.py:1623] - era=0 epoch=200 tstep=201 dt=0.291 beta=4.000 loss=10.499 dQsin=0.076 dQint=0.011 energy=396.810 logprob=396.496 logdet=0.314 sldf=0.195 sldb=-0.154 sld=0.314 xeps=0.021 veps=0.022 acc=0.598 sumlogdet=-0.006 acc_mask=0.601 plaqs=0.863 intQ=0.056 sinQ=0.060 lr=0.001 \n[2023-12-05 11:16:19][INFO][trainer.py:1623] - era=0 epoch=400 tstep=401 dt=0.289 beta=4.000 loss=7.030 dQsin=0.099 dQint=0.014 energy=396.425 logprob=395.868 logdet=0.557 sldf=0.347 sldb=-0.310 sld=0.557 xeps=0.029 veps=0.030 acc=0.630 sumlogdet=-0.002 acc_mask=0.631 plaqs=0.864 intQ=0.047 sinQ=0.036 lr=0.001 \n[2023-12-05 11:17:22][INFO][trainer.py:1623] - era=0 epoch=600 tstep=601 dt=0.291 beta=4.000 loss=2.930 dQsin=0.130 dQint=0.023 energy=397.770 logprob=396.874 logdet=0.896 sldf=0.553 sldb=-0.487 sld=0.896 xeps=0.039 veps=0.040 acc=0.664 sumlogdet=-0.003 acc_mask=0.676 plaqs=0.864 intQ=0.035 sinQ=0.023 lr=0.001 \n[2023-12-05 11:18:25][INFO][trainer.py:1623] - era=0 epoch=800 tstep=801 dt=0.291 beta=4.000 loss=0.603 dQsin=0.154 dQint=0.029 energy=399.160 logprob=397.946 logdet=1.214 sldf=0.750 sldb=-0.663 sld=1.214 xeps=0.047 veps=0.050 acc=0.757 sumlogdet=-0.000 acc_mask=0.746 plaqs=0.863 intQ=0.030 sinQ=0.015 lr=0.001 \n[2023-12-05 11:19:29][INFO][trainer.py:1623] - era=0 epoch=1000 tstep=1001 dt=0.300 beta=4.000 loss=-0.085 dQsin=0.168 dQint=0.025 energy=398.964 logprob=397.578 logdet=1.386 sldf=0.858 sldb=-0.783 sld=1.386 xeps=0.052 veps=0.055 acc=0.814 sumlogdet=0.000 acc_mask=0.808 plaqs=0.864 intQ=0.010 sinQ=0.003 lr=0.001 \n[2023-12-05 11:20:34][INFO][trainer.py:1623] - era=0 epoch=1200 tstep=1201 dt=0.313 beta=4.000 loss=-1.749 dQsin=0.181 dQint=0.045 energy=399.484 logprob=397.867 logdet=1.617 sldf=1.003 sldb=-0.942 sld=1.617 xeps=0.062 veps=0.065 acc=0.814 sumlogdet=0.003 acc_mask=0.794 plaqs=0.863 intQ=-0.012 sinQ=-0.007 lr=0.001 \n[2023-12-05 11:21:38][INFO][trainer.py:1623] - era=0 epoch=1400 tstep=1401 dt=0.297 beta=4.000 loss=-2.117 dQsin=0.192 dQint=0.042 energy=399.738 logprob=397.874 logdet=1.864 sldf=1.158 sldb=-1.104 sld=1.864 xeps=0.072 veps=0.076 acc=0.832 sumlogdet=0.007 acc_mask=0.831 plaqs=0.864 intQ=-0.052 sinQ=-0.047 lr=0.001 \n[2023-12-05 11:22:41][INFO][trainer.py:1623] - era=0 epoch=1600 tstep=1601 dt=0.297 beta=4.000 loss=-3.168 dQsin=0.205 dQint=0.063 energy=401.640 logprob=399.423 logdet=2.218 sldf=1.373 sldb=-1.267 sld=2.218 xeps=0.085 veps=0.089 acc=0.813 sumlogdet=-0.000 acc_mask=0.815 plaqs=0.863 intQ=0.031 sinQ=0.022 lr=0.001 \n[2023-12-05 11:23:44][INFO][trainer.py:1623] - era=0 epoch=1800 tstep=1801 dt=0.297 beta=4.000 loss=-4.396 dQsin=0.212 dQint=0.054 energy=400.607 logprob=398.216 logdet=2.391 sldf=1.477 sldb=-1.335 sld=2.391 xeps=0.091 veps=0.095 acc=0.820 sumlogdet=-0.003 acc_mask=0.822 plaqs=0.863 intQ=0.005 sinQ=0.000 lr=0.001 \n[2023-12-05 11:24:49][INFO][trainer.py:1623] - era=0 epoch=2000 tstep=2001 dt=0.319 beta=4.000 loss=-4.874 dQsin=0.220 dQint=0.060 energy=400.020 logprob=397.462 logdet=2.557 sldf=1.575 sldb=-1.388 sld=2.557 xeps=0.097 veps=0.100 acc=0.825 sumlogdet=0.002 acc_mask=0.832 plaqs=0.863 intQ=-0.021 sinQ=-0.021 lr=0.001 \n[2023-12-05 11:25:53][INFO][trainer.py:1623] - era=0 epoch=2200 tstep=2201 dt=0.297 beta=4.000 loss=-5.154 dQsin=0.222 dQint=0.066 energy=400.023 logprob=397.279 logdet=2.743 sldf=1.685 sldb=-1.462 sld=2.743 xeps=0.105 veps=0.108 acc=0.840 sumlogdet=0.011 acc_mask=0.847 plaqs=0.863 intQ=0.014 sinQ=0.017 lr=0.001 \n[2023-12-05 11:26:56][INFO][trainer.py:1623] - era=0 epoch=2400 tstep=2401 dt=0.298 beta=4.000 loss=-7.020 dQsin=0.231 dQint=0.070 energy=400.368 logprob=397.445 logdet=2.922 sldf=1.793 sldb=-1.533 sld=2.922 xeps=0.114 veps=0.116 acc=0.858 sumlogdet=0.005 acc_mask=0.848 plaqs=0.863 intQ=0.062 sinQ=0.059 lr=0.001 \n[2023-12-05 11:28:00][INFO][trainer.py:1623] - era=0 epoch=2600 tstep=2601 dt=0.297 beta=4.000 loss=-7.241 dQsin=0.240 dQint=0.091 energy=401.233 logprob=398.224 logdet=3.009 sldf=1.847 sldb=-1.578 sld=3.009 xeps=0.120 veps=0.120 acc=0.865 sumlogdet=0.002 acc_mask=0.856 plaqs=0.863 intQ=0.047 sinQ=0.042 lr=0.001 \n[2023-12-05 11:29:03][INFO][trainer.py:1623] - era=0 epoch=2800 tstep=2801 dt=0.304 beta=4.000 loss=-6.760 dQsin=0.237 dQint=0.086 energy=399.980 logprob=396.791 logdet=3.189 sldf=1.955 sldb=-1.653 sld=3.189 xeps=0.127 veps=0.128 acc=0.870 sumlogdet=0.000 acc_mask=0.870 plaqs=0.863 intQ=0.014 sinQ=0.007 lr=0.001 \n[2023-12-05 11:30:08][INFO][trainer.py:1623] - era=0 epoch=3000 tstep=3001 dt=0.302 beta=4.000 loss=-7.325 dQsin=0.243 dQint=0.083 energy=401.154 logprob=397.836 logdet=3.319 sldf=2.032 sldb=-1.711 sld=3.319 xeps=0.131 veps=0.133 acc=0.878 sumlogdet=0.010 acc_mask=0.876 plaqs=0.863 intQ=-0.017 sinQ=-0.011 lr=0.001 \n[2023-12-05 11:31:12][INFO][trainer.py:1623] - era=0 epoch=3200 tstep=3201 dt=0.302 beta=4.000 loss=-7.431 dQsin=0.242 dQint=0.082 energy=400.859 logprob=397.497 logdet=3.362 sldf=2.059 sldb=-1.728 sld=3.362 xeps=0.134 veps=0.135 acc=0.885 sumlogdet=0.006 acc_mask=0.883 plaqs=0.863 intQ=0.012 sinQ=0.006 lr=0.001 \n[2023-12-05 11:32:16][INFO][trainer.py:1623] - era=0 epoch=3400 tstep=3401 dt=0.302 beta=4.000 loss=-6.296 dQsin=0.229 dQint=0.084 energy=400.674 logprob=397.367 logdet=3.307 sldf=2.026 sldb=-1.714 sld=3.307 xeps=0.132 veps=0.132 acc=0.885 sumlogdet=0.006 acc_mask=0.881 plaqs=0.863 intQ=0.045 sinQ=0.041 lr=0.001 \n[2023-12-05 11:33:20][INFO][trainer.py:1623] - era=0 epoch=3600 tstep=3601 dt=0.302 beta=4.000 loss=-7.885 dQsin=0.252 dQint=0.092 energy=399.823 logprob=396.495 logdet=3.328 sldf=2.039 sldb=-1.725 sld=3.328 xeps=0.132 veps=0.133 acc=0.900 sumlogdet=0.008 acc_mask=0.903 plaqs=0.864 intQ=-0.002 sinQ=0.000 lr=0.001 \n[2023-12-05 11:34:25][INFO][trainer.py:1623] - era=0 epoch=3800 tstep=3801 dt=0.303 beta=4.000 loss=-8.489 dQsin=0.257 dQint=0.091 energy=400.076 logprob=396.664 logdet=3.412 sldf=2.091 sldb=-1.762 sld=3.412 xeps=0.135 veps=0.137 acc=0.897 sumlogdet=-0.005 acc_mask=0.913 plaqs=0.863 intQ=-0.035 sinQ=-0.029 lr=0.001 \n[2023-12-05 11:35:30][INFO][trainer.py:1623] - era=0 epoch=4000 tstep=4001 dt=0.306 beta=4.000 loss=-7.836 dQsin=0.245 dQint=0.085 energy=400.851 logprob=397.384 logdet=3.468 sldf=2.125 sldb=-1.793 sld=3.468 xeps=0.137 veps=0.139 acc=0.891 sumlogdet=0.002 acc_mask=0.893 plaqs=0.863 intQ=0.022 sinQ=0.013 lr=0.001 \n[2023-12-05 11:36:34][INFO][trainer.py:1623] - era=0 epoch=4200 tstep=4201 dt=0.305 beta=4.000 loss=-7.812 dQsin=0.252 dQint=0.084 energy=400.178 logprob=396.688 logdet=3.490 sldf=2.137 sldb=-1.801 sld=3.490 xeps=0.137 veps=0.139 acc=0.904 sumlogdet=0.015 acc_mask=0.906 plaqs=0.864 intQ=-0.042 sinQ=-0.032 lr=0.001 \n[2023-12-05 11:37:38][INFO][trainer.py:1623] - era=0 epoch=4400 tstep=4401 dt=0.302 beta=4.000 loss=-7.997 dQsin=0.251 dQint=0.088 energy=400.410 logprob=396.859 logdet=3.550 sldf=2.175 sldb=-1.834 sld=3.550 xeps=0.140 veps=0.142 acc=0.898 sumlogdet=0.012 acc_mask=0.911 plaqs=0.863 intQ=-0.001 sinQ=-0.003 lr=0.001 \n[2023-12-05 11:38:42][INFO][trainer.py:1623] - era=0 epoch=4600 tstep=4601 dt=0.306 beta=4.000 loss=-8.629 dQsin=0.252 dQint=0.088 energy=400.759 logprob=397.157 logdet=3.601 sldf=2.208 sldb=-1.865 sld=3.601 xeps=0.142 veps=0.144 acc=0.896 sumlogdet=-0.003 acc_mask=0.902 plaqs=0.863 intQ=0.017 sinQ=0.013 lr=0.001 \n[2023-12-05 11:39:46][INFO][trainer.py:1623] - era=0 epoch=4800 tstep=4801 dt=0.304 beta=4.000 loss=-8.538 dQsin=0.256 dQint=0.095 energy=400.788 logprob=397.108 logdet=3.680 sldf=2.257 sldb=-1.907 sld=3.680 xeps=0.146 veps=0.148 acc=0.891 sumlogdet=-0.012 acc_mask=0.892 plaqs=0.863 intQ=0.018 sinQ=0.016 lr=0.001 \n\n\n\n\n\n# dset_train = ptExpU1.trainer.histories['train'].plot_all(num_chains=128)\ndset_train_pt = ptExpU1.save_dataset(job_type='train', nchains=32)\n\n\n\n\noutput\n\n\n[2023-12-05 11:41:01][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 11:41:03][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 11:41:05][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 11:41:07][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg \n[2023-12-05 11:41:09][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg \n[2023-12-05 11:41:11][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg \n[2023-12-05 11:41:41][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/data/train_data.h5 \n[2023-12-05 11:41:42][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 11:41:42][INFO][experiment.py:379] - Creating summaries for WandB, Aim \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference\n\nEvaluation\noutputs['pytorch']['eval'] = ptExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\ndset_eval_pt = ptExpU1.save_dataset(job_type='eval', nchains=32)\n# dset_eval_pt = ptExpU1.trainer.histories['eval'].plot_all()\n\n\n\n\noutput\n\n\n[2023-12-05 11:42:03][WARNING][trainer.py:467] - x.shape (original): torch.Size([2048, 2, 16, 16]) \n[2023-12-05 11:42:03][WARNING][trainer.py:467] - x[:nchains].shape: torch.Size([128, 2, 16, 16]) \n[2023-12-05 11:42:03][INFO][trainer.py:1077] - eps=None\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7efbf40b16f0&gt;\nnprint=500\neval_steps=2000\nnleapfrog=None \n\n[2023-12-05 11:42:06][INFO][trainer.py:1207] - estep=0 dt=0.140 beta=4.000 loss=-9.137 dQsin=0.269 dQint=0.148 energy=407.745 logprob=404.067 logdet=3.678 sldf=2.253 sldb=-1.896 sld=3.678 xeps=0.145 veps=0.147 acc=0.913 sumlogdet=0.004 acc_mask=0.930 plaqs=0.854 intQ=0.156 sinQ=0.151 \n[2023-12-05 11:43:38][INFO][trainer.py:1207] - estep=500 dt=0.119 beta=4.000 loss=-7.346 dQsin=0.264 dQint=0.125 energy=403.427 logprob=399.747 logdet=3.680 sldf=2.255 sldb=-1.906 sld=3.680 xeps=0.145 veps=0.147 acc=0.909 sumlogdet=0.005 acc_mask=0.883 plaqs=0.864 intQ=-0.305 sinQ=-0.216 \n[2023-12-05 11:45:11][INFO][trainer.py:1207] - estep=1000 dt=0.119 beta=4.000 loss=-8.075 dQsin=0.287 dQint=0.133 energy=402.009 logprob=398.331 logdet=3.678 sldf=2.253 sldb=-1.898 sld=3.678 xeps=0.145 veps=0.147 acc=0.897 sumlogdet=0.005 acc_mask=0.945 plaqs=0.863 intQ=-0.023 sinQ=-0.042 \n[2023-12-05 11:46:44][INFO][trainer.py:1207] - estep=1500 dt=0.119 beta=4.000 loss=-11.254 dQsin=0.261 dQint=0.109 energy=401.410 logprob=397.734 logdet=3.676 sldf=2.254 sldb=-1.918 sld=3.676 xeps=0.145 veps=0.147 acc=0.896 sumlogdet=0.004 acc_mask=0.875 plaqs=0.862 intQ=0.078 sinQ=0.071 \n[2023-12-05 11:48:21][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 11:48:23][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 11:48:25][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 11:48:27][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg \n[2023-12-05 11:48:28][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg \n[2023-12-05 11:48:30][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg \n[2023-12-05 11:48:45][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/data/eval_data.h5 \n[2023-12-05 11:48:45][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 11:48:45][INFO][experiment.py:379] - Creating summaries for WandB, Aim \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHMC\noutputs['pytorch']['hmc'] = ptExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\ndset_hmc_pt = ptExpU1.save_dataset(job_type='hmc', nchains=32)\n# dset_hmc_pt = ptExpU1.trainer.histories['hmc'].plot_all()\n\n\n\n\noutput\n\n\n[2023-12-05 11:49:07][WARNING][trainer.py:467] - Step size `eps` not specified for HMC! Using default: 0.2500 for generic HMC \n[2023-12-05 11:49:07][WARNING][trainer.py:467] - x.shape (original): torch.Size([2048, 2, 16, 16]) \n[2023-12-05 11:49:07][WARNING][trainer.py:467] - x[:nchains].shape: torch.Size([128, 2, 16, 16]) \n[2023-12-05 11:49:07][INFO][trainer.py:1077] - eps=0.25\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7efbf4167580&gt;\nnprint=500\neval_steps=2000\nnleapfrog=8 \n\n[2023-12-05 11:49:09][INFO][trainer.py:1207] - hstep=0 dt=0.018 beta=4.000 loss=46.645 dQsin=0.039 dQint=0.031 energy=412.712 logprob=412.712 logdet=0.000 acc=0.114 sumlogdet=0.000 acc_mask=0.125 plaqs=0.853 intQ=-0.117 sinQ=-0.126 \n[2023-12-05 11:49:50][INFO][trainer.py:1207] - hstep=500 dt=0.018 beta=4.000 loss=51.958 dQsin=0.014 dQint=0.000 energy=401.030 logprob=401.030 logdet=0.000 acc=0.054 sumlogdet=0.000 acc_mask=0.055 plaqs=0.863 intQ=-0.016 sinQ=-0.038 \n[2023-12-05 11:50:31][INFO][trainer.py:1207] - hstep=1000 dt=0.017 beta=4.000 loss=58.470 dQsin=0.017 dQint=0.016 energy=403.846 logprob=403.846 logdet=0.000 acc=0.055 sumlogdet=0.000 acc_mask=0.055 plaqs=0.862 intQ=-0.078 sinQ=-0.089 \n[2023-12-05 11:51:13][INFO][trainer.py:1207] - hstep=1500 dt=0.017 beta=4.000 loss=54.941 dQsin=0.014 dQint=0.000 energy=400.502 logprob=400.502 logdet=0.000 acc=0.056 sumlogdet=0.000 acc_mask=0.047 plaqs=0.865 intQ=-0.117 sinQ=-0.096 \n[2023-12-05 11:51:58][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 11:52:00][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 11:52:02][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 11:52:14][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111355/pytorch/data/hmc_data.h5 \n[2023-12-05 11:52:14][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 11:52:14][INFO][experiment.py:379] - Creating summaries for WandB, Aim",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html#tensorflow",
    "href": "posts/jupyter/test/index.html#tensorflow",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "TensorFlow",
    "text": "TensorFlow\n\nTrain\noutputs['tensorflow']['train'] = tfExpU1.trainer.train(\n    nera=1,\n    nepoch=5000,\n    beta=4.0,\n    # beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n)\n# dset_train_tf = tfExpU1.trainer.histories['train'].plot_all()\n_ = tfExpU1.save_dataset(job_type='train', nchains=32)\n\n\n\n\n\noutput\n\n\n[2023-12-05 11:52:30][INFO][trainer.py:198] - Looking for checkpoints in: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-4/xsplit-True/sepnets-True/merge-True/net-16-16-16-16_dp-0.2_bn-True/tensorflow \n[2023-12-05 11:52:30][INFO][trainer.py:198] - No checkpoints found to load from. Continuing \n[2023-12-05 11:52:31][INFO][trainer.py:1259] - ERA: 0 / 1, BETA: 4.000 \n[2023-12-05 11:53:11][INFO][trainer.py:198] - Thermalizing configs @ 4.00 took 40.3690 s \nTraining:   0%|          | 0/5000 [00:00&lt;?, ?it/s]\n[2023-12-05 11:53:21][WARNING][deprecation.py:350] - From /lus/grand/projects/datascience/foremans/locations/thetaGPU/miniconda3/envs/2023-04-26/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\nInstructions for updating:\nLambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089 \n[2023-12-05 11:53:55][WARNING][trainer.py:194] - Resetting optimizer state! \n[2023-12-05 11:53:55][WARNING][trainer.py:194] - Chains are stuck! Re-drawing x ! \n[2023-12-05 11:53:56][INFO][trainer.py:1085] - era=0 epoch=0 tstep=1.000 dt=44.185 beta=4.000 loss=99.113 dQsin=0.000 dQint=0.000 energy=1288.705 logprob=1288.768 logdet=-0.063 sldf=-0.013 sldb=-0.029 sld=-0.063 xeps=0.051 veps=0.049 acc=0.000 sumlogdet=0.000 acc_mask=0.000 plaqs=0.000 intQ=0.046 sinQ=0.038 lr=0.001 \n[2023-12-05 11:54:23][INFO][trainer.py:1085] - era=0 epoch=200 tstep=201.000 dt=0.103 beta=4.000 loss=2.764 dQsin=0.126 dQint=0.027 energy=397.227 logprob=397.120 logdet=0.107 sldf=0.070 sldb=-0.071 sld=0.107 xeps=0.051 veps=0.047 acc=0.610 sumlogdet=-0.015 acc_mask=0.610 plaqs=0.863 intQ=-0.045 sinQ=-0.039 lr=0.001 \n[2023-12-05 11:54:51][INFO][trainer.py:1085] - era=0 epoch=400 tstep=401.000 dt=0.105 beta=4.000 loss=0.957 dQsin=0.151 dQint=0.028 energy=395.704 logprob=395.575 logdet=0.130 sldf=0.082 sldb=-0.076 sld=0.130 xeps=0.050 veps=0.047 acc=0.741 sumlogdet=-0.002 acc_mask=0.737 plaqs=0.864 intQ=-0.063 sinQ=-0.049 lr=0.001 \n[2023-12-05 11:55:18][INFO][trainer.py:1085] - era=0 epoch=600 tstep=601.000 dt=0.094 beta=4.000 loss=0.614 dQsin=0.168 dQint=0.034 energy=396.128 logprob=395.997 logdet=0.132 sldf=0.081 sldb=-0.070 sld=0.132 xeps=0.051 veps=0.048 acc=0.816 sumlogdet=-0.004 acc_mask=0.826 plaqs=0.864 intQ=0.005 sinQ=0.009 lr=0.001 \n[2023-12-05 11:55:45][INFO][trainer.py:1085] - era=0 epoch=800 tstep=801.000 dt=0.103 beta=4.000 loss=-0.637 dQsin=0.175 dQint=0.034 energy=395.974 logprob=395.842 logdet=0.132 sldf=0.080 sldb=-0.064 sld=0.132 xeps=0.053 veps=0.050 acc=0.866 sumlogdet=0.001 acc_mask=0.853 plaqs=0.863 intQ=0.012 sinQ=0.013 lr=0.001 \n[2023-12-05 11:56:11][INFO][trainer.py:1085] - era=0 epoch=1000 tstep=1001.000 dt=0.095 beta=4.000 loss=-0.714 dQsin=0.185 dQint=0.038 energy=395.177 logprob=395.041 logdet=0.135 sldf=0.083 sldb=-0.067 sld=0.135 xeps=0.055 veps=0.051 acc=0.883 sumlogdet=-0.002 acc_mask=0.886 plaqs=0.864 intQ=0.028 sinQ=0.020 lr=0.001 \n[2023-12-05 11:56:37][INFO][trainer.py:1085] - era=0 epoch=1200 tstep=1201.000 dt=0.097 beta=4.000 loss=-2.043 dQsin=0.197 dQint=0.047 energy=396.446 logprob=396.308 logdet=0.138 sldf=0.084 sldb=-0.067 sld=0.138 xeps=0.057 veps=0.054 acc=0.893 sumlogdet=0.001 acc_mask=0.904 plaqs=0.863 intQ=0.029 sinQ=0.022 lr=0.001 \n[2023-12-05 11:57:04][INFO][trainer.py:1085] - era=0 epoch=1400 tstep=1401.000 dt=0.095 beta=4.000 loss=-1.262 dQsin=0.193 dQint=0.044 energy=397.347 logprob=397.203 logdet=0.144 sldf=0.088 sldb=-0.071 sld=0.144 xeps=0.061 veps=0.057 acc=0.909 sumlogdet=-0.000 acc_mask=0.898 plaqs=0.863 intQ=-0.008 sinQ=0.003 lr=0.001 \n[2023-12-05 11:57:30][INFO][trainer.py:1085] - era=0 epoch=1600 tstep=1601.000 dt=0.096 beta=4.000 loss=-2.389 dQsin=0.203 dQint=0.050 energy=396.358 logprob=396.205 logdet=0.153 sldf=0.094 sldb=-0.079 sld=0.153 xeps=0.065 veps=0.060 acc=0.915 sumlogdet=0.001 acc_mask=0.922 plaqs=0.863 intQ=0.010 sinQ=0.001 lr=0.001 \n[2023-12-05 11:57:55][INFO][trainer.py:1085] - era=0 epoch=1800 tstep=1801.000 dt=0.093 beta=4.000 loss=-3.667 dQsin=0.215 dQint=0.056 energy=396.103 logprob=395.927 logdet=0.175 sldf=0.108 sldb=-0.093 sld=0.175 xeps=0.071 veps=0.066 acc=0.923 sumlogdet=0.001 acc_mask=0.926 plaqs=0.864 intQ=0.023 sinQ=0.025 lr=0.001 \n[2023-12-05 11:58:19][INFO][trainer.py:1085] - era=0 epoch=2000 tstep=2001.000 dt=0.086 beta=4.000 loss=-3.192 dQsin=0.211 dQint=0.050 energy=395.770 logprob=395.575 logdet=0.195 sldf=0.120 sldb=-0.108 sld=0.195 xeps=0.077 veps=0.071 acc=0.932 sumlogdet=-0.001 acc_mask=0.925 plaqs=0.864 intQ=0.042 sinQ=0.034 lr=0.001 \n[2023-12-05 11:58:44][INFO][trainer.py:1085] - era=0 epoch=2200 tstep=2201.000 dt=0.088 beta=4.000 loss=-3.860 dQsin=0.222 dQint=0.052 energy=395.970 logprob=395.744 logdet=0.226 sldf=0.139 sldb=-0.120 sld=0.226 xeps=0.083 veps=0.076 acc=0.932 sumlogdet=0.000 acc_mask=0.942 plaqs=0.864 intQ=-0.017 sinQ=-0.018 lr=0.001 \n[2023-12-05 11:59:08][INFO][trainer.py:1085] - era=0 epoch=2400 tstep=2401.000 dt=0.089 beta=4.000 loss=-5.338 dQsin=0.234 dQint=0.063 energy=396.330 logprob=396.058 logdet=0.271 sldf=0.165 sldb=-0.130 sld=0.271 xeps=0.092 veps=0.084 acc=0.927 sumlogdet=0.000 acc_mask=0.935 plaqs=0.863 intQ=-0.083 sinQ=-0.069 lr=0.001 \n[2023-12-05 11:59:33][INFO][trainer.py:1085] - era=0 epoch=2600 tstep=2601.000 dt=0.089 beta=4.000 loss=-6.596 dQsin=0.238 dQint=0.067 energy=396.078 logprob=395.751 logdet=0.327 sldf=0.197 sldb=-0.137 sld=0.327 xeps=0.100 veps=0.091 acc=0.919 sumlogdet=-0.000 acc_mask=0.911 plaqs=0.863 intQ=-0.020 sinQ=-0.018 lr=0.001 \n[2023-12-05 11:59:58][INFO][trainer.py:1085] - era=0 epoch=2800 tstep=2801.000 dt=0.087 beta=4.000 loss=-6.121 dQsin=0.239 dQint=0.071 energy=396.373 logprob=396.000 logdet=0.373 sldf=0.222 sldb=-0.138 sld=0.373 xeps=0.108 veps=0.097 acc=0.912 sumlogdet=-0.000 acc_mask=0.908 plaqs=0.863 intQ=-0.003 sinQ=-0.007 lr=0.001 \n[2023-12-05 12:00:24][INFO][trainer.py:1085] - era=0 epoch=3000 tstep=3001.000 dt=0.092 beta=4.000 loss=-7.409 dQsin=0.247 dQint=0.078 energy=396.537 logprob=396.127 logdet=0.411 sldf=0.244 sldb=-0.141 sld=0.411 xeps=0.113 veps=0.101 acc=0.914 sumlogdet=-0.000 acc_mask=0.915 plaqs=0.863 intQ=-0.025 sinQ=-0.023 lr=0.001 \n[2023-12-05 12:00:50][INFO][trainer.py:1085] - era=0 epoch=3200 tstep=3201.000 dt=0.094 beta=4.000 loss=-7.105 dQsin=0.242 dQint=0.063 energy=396.792 logprob=396.322 logdet=0.469 sldf=0.277 sldb=-0.145 sld=0.469 xeps=0.121 veps=0.107 acc=0.918 sumlogdet=0.001 acc_mask=0.917 plaqs=0.863 intQ=0.019 sinQ=0.016 lr=0.001 \n[2023-12-05 12:01:15][INFO][trainer.py:1085] - era=0 epoch=3400 tstep=3401.000 dt=0.090 beta=4.000 loss=-7.398 dQsin=0.244 dQint=0.082 energy=396.890 logprob=396.384 logdet=0.506 sldf=0.298 sldb=-0.151 sld=0.506 xeps=0.126 veps=0.111 acc=0.912 sumlogdet=-0.000 acc_mask=0.901 plaqs=0.863 intQ=0.006 sinQ=0.006 lr=0.001 \n[2023-12-05 12:01:41][INFO][trainer.py:1085] - era=0 epoch=3600 tstep=3601.000 dt=0.092 beta=4.000 loss=-7.570 dQsin=0.248 dQint=0.073 energy=396.491 logprob=395.964 logdet=0.528 sldf=0.312 sldb=-0.167 sld=0.528 xeps=0.129 veps=0.114 acc=0.910 sumlogdet=-0.000 acc_mask=0.914 plaqs=0.864 intQ=0.028 sinQ=0.021 lr=0.001 \n[2023-12-05 12:02:07][INFO][trainer.py:1085] - era=0 epoch=3800 tstep=3801.000 dt=0.102 beta=4.000 loss=-7.497 dQsin=0.245 dQint=0.095 energy=396.474 logprob=395.923 logdet=0.551 sldf=0.326 sldb=-0.180 sld=0.551 xeps=0.132 veps=0.116 acc=0.913 sumlogdet=-0.000 acc_mask=0.901 plaqs=0.863 intQ=0.016 sinQ=0.017 lr=0.001 \n[2023-12-05 12:02:33][INFO][trainer.py:1085] - era=0 epoch=4000 tstep=4001.000 dt=0.092 beta=4.000 loss=-8.825 dQsin=0.254 dQint=0.087 energy=397.397 logprob=396.827 logdet=0.570 sldf=0.338 sldb=-0.194 sld=0.570 xeps=0.136 veps=0.119 acc=0.908 sumlogdet=-0.000 acc_mask=0.902 plaqs=0.863 intQ=0.003 sinQ=-0.000 lr=0.001 \n[2023-12-05 12:02:57][INFO][trainer.py:1085] - era=0 epoch=4200 tstep=4201.000 dt=0.094 beta=4.000 loss=-7.265 dQsin=0.244 dQint=0.074 energy=396.583 logprob=395.992 logdet=0.591 sldf=0.351 sldb=-0.207 sld=0.591 xeps=0.139 veps=0.121 acc=0.910 sumlogdet=-0.001 acc_mask=0.902 plaqs=0.864 intQ=0.042 sinQ=0.031 lr=0.001 \n[2023-12-05 12:03:22][INFO][trainer.py:1085] - era=0 epoch=4400 tstep=4401.000 dt=0.092 beta=4.000 loss=-7.974 dQsin=0.256 dQint=0.096 energy=397.000 logprob=396.407 logdet=0.593 sldf=0.353 sldb=-0.214 sld=0.593 xeps=0.140 veps=0.122 acc=0.919 sumlogdet=0.000 acc_mask=0.928 plaqs=0.863 intQ=-0.015 sinQ=-0.010 lr=0.001 \n[2023-12-05 12:03:47][INFO][trainer.py:1085] - era=0 epoch=4600 tstep=4601.000 dt=0.092 beta=4.000 loss=-8.677 dQsin=0.258 dQint=0.094 energy=396.710 logprob=396.109 logdet=0.601 sldf=0.359 sldb=-0.223 sld=0.601 xeps=0.142 veps=0.122 acc=0.903 sumlogdet=-0.000 acc_mask=0.897 plaqs=0.864 intQ=0.012 sinQ=0.007 lr=0.001 \n[2023-12-05 12:04:12][INFO][trainer.py:1085] - era=0 epoch=4800 tstep=4801.000 dt=0.094 beta=4.000 loss=-8.739 dQsin=0.258 dQint=0.087 energy=396.618 logprob=396.036 logdet=0.583 sldf=0.348 sldb=-0.218 sld=0.583 xeps=0.140 veps=0.121 acc=0.921 sumlogdet=-0.000 acc_mask=0.914 plaqs=0.864 intQ=-0.034 sinQ=-0.027 lr=0.001 \n[2023-12-05 12:04:37][INFO][trainer.py:1296] - Saving took: 4.76837e-06s \n[2023-12-05 12:04:37][INFO][trainer.py:1297] - Checkpoint saved to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-4/xsplit-True/sepnets-True/merge-True/net-16-16-16-16_dp-0.2_bn-True/tensorflow \n[2023-12-05 12:04:37][INFO][trainer.py:1298] - Era 0 took: 725.949s \n[2023-12-05 12:04:38][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 12:04:40][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 12:04:42][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 12:04:44][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg \n[2023-12-05 12:04:46][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg \n[2023-12-05 12:04:48][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg \n[2023-12-05 12:05:19][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/data/train_data.h5 \n[2023-12-05 12:05:20][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 12:05:20][INFO][experiment.py:379] - Creating summaries for WandB, Aim \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInference\n\nEvaluate\noutputs['tensorflow']['eval'] = tfExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n# dset_eval_tf = tfExpU1.trainer.histories['eval'].plot_all()\n_ = tfExpU1.save_dataset(job_type='eval', nchains=32)\n\n\n\n\noutput\n\n\n[2023-12-05 12:05:41][WARNING][trainer.py:194] - x.shape (original): (2048, 2, 16, 16) \n[2023-12-05 12:05:41][WARNING][trainer.py:194] - x[:nchains].shape: (128, 2, 16, 16) \n[2023-12-05 12:05:41][INFO][trainer.py:198] - eps = None\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7efa683ea0e0&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = None \n\n  0%|          | 0/2000 [00:00&lt;?, ?it/s]\n[2023-12-05 12:06:28][INFO][trainer.py:198] - estep=0 dt=4.940 beta=4.000 loss=-7.502 dQsin=0.238 dQint=0.117 energy=396.232 logprob=395.648 logdet=0.584 sldf=0.349 sldb=-0.222 sld=0.584 xeps=0.141 veps=0.121 acc=0.928 sumlogdet=0.001 acc_mask=0.914 plaqs=0.863 intQ=0.023 sinQ=0.036 \n[2023-12-05 12:07:17][INFO][trainer.py:198] - estep=500 dt=0.024 beta=4.000 loss=-3.405 dQsin=0.239 dQint=0.047 energy=395.434 logprob=394.850 logdet=0.584 sldf=0.349 sldb=-0.223 sld=0.584 xeps=0.141 veps=0.121 acc=0.934 sumlogdet=0.000 acc_mask=0.969 plaqs=0.865 intQ=0.008 sinQ=0.001 \n[2023-12-05 12:08:01][INFO][trainer.py:198] - estep=1000 dt=0.024 beta=4.000 loss=-5.784 dQsin=0.227 dQint=0.102 energy=393.733 logprob=393.149 logdet=0.584 sldf=0.349 sldb=-0.222 sld=0.584 xeps=0.141 veps=0.121 acc=0.913 sumlogdet=0.000 acc_mask=0.953 plaqs=0.863 intQ=0.188 sinQ=0.178 \n[2023-12-05 12:08:44][INFO][trainer.py:198] - estep=1500 dt=0.024 beta=4.000 loss=-7.127 dQsin=0.226 dQint=0.063 energy=396.790 logprob=396.205 logdet=0.584 sldf=0.349 sldb=-0.223 sld=0.584 xeps=0.141 veps=0.121 acc=0.902 sumlogdet=-0.000 acc_mask=0.898 plaqs=0.864 intQ=-0.172 sinQ=-0.126 \n[2023-12-05 12:09:32][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 12:09:34][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 12:09:36][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 12:09:38][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg \n[2023-12-05 12:09:40][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg \n[2023-12-05 12:09:42][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg \n[2023-12-05 12:09:57][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/data/eval_data.h5 \n[2023-12-05 12:09:57][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 12:09:57][INFO][experiment.py:379] - Creating summaries for WandB, Aim \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHMC\noutputs['tensorflow']['hmc'] = tfExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = tfExpU1.save_dataset(job_type='hmc', nchains=32)\n\n\n\n\noutput\n\noutput:\n\n[2023-12-05 12:10:19][WARNING][trainer.py:194] - Step size `eps` not specified for HMC! Using default: 0.2500 for generic HMC \n[2023-12-05 12:10:19][WARNING][trainer.py:194] - x.shape (original): (2048, 2, 16, 16) \n[2023-12-05 12:10:19][WARNING][trainer.py:194] - x[:nchains].shape: (128, 2, 16, 16) \n[2023-12-05 12:10:19][INFO][trainer.py:198] - eps = 0.25\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7ef93c654940&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = 8 \n\n  0%|          | 0/2000 [00:00&lt;?, ?it/s]\n[2023-12-05 12:11:01][INFO][trainer.py:198] - hstep=0 dt=0.089 beta=4.000 loss=59.310 dQsin=0.049 dQint=0.039 energy=403.394 logprob=403.394 logdet=0.000 acc=0.059 sumlogdet=0.000 acc_mask=0.078 plaqs=0.863 intQ=-0.109 sinQ=-0.093 \n[2023-12-05 12:12:14][INFO][trainer.py:198] - hstep=500 dt=0.083 beta=4.000 loss=55.566 dQsin=0.021 dQint=0.016 energy=400.521 logprob=400.521 logdet=0.000 acc=0.061 sumlogdet=0.000 acc_mask=0.047 plaqs=0.864 intQ=0.148 sinQ=0.112 \n[2023-12-05 12:13:28][INFO][trainer.py:198] - hstep=1000 dt=0.084 beta=4.000 loss=63.178 dQsin=0.019 dQint=0.016 energy=401.798 logprob=401.798 logdet=0.000 acc=0.039 sumlogdet=0.000 acc_mask=0.039 plaqs=0.865 intQ=-0.016 sinQ=-0.016 \n[2023-12-05 12:14:43][INFO][trainer.py:198] - hstep=1500 dt=0.084 beta=4.000 loss=61.681 dQsin=0.018 dQint=0.008 energy=398.577 logprob=398.577 logdet=0.000 acc=0.058 sumlogdet=0.000 acc_mask=0.062 plaqs=0.865 intQ=-0.148 sinQ=-0.140 \n[2023-12-05 12:16:02][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg \n[2023-12-05 12:16:03][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg \n[2023-12-05 12:16:05][INFO][plot_helpers.py:1046] - Saving figure to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg \n[2023-12-05 12:16:17][INFO][common.py:275] - Saving dataset to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-12-05-111405/tensorflow/data/hmc_data.h5 \n[2023-12-05 12:16:17][INFO][experiment.py:378] - Done saving and analyzing data. \n[2023-12-05 12:16:17][INFO][experiment.py:379] - Creating summaries for WandB, Aim",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html#tensorflow-results",
    "href": "posts/jupyter/test/index.html#tensorflow-results",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "TensorFlow Results",
    "text": "TensorFlow Results\nsns.set_context('notebook')\nndraws = len(dsets['tf']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['tf']['eval']['dQint'][:, -90:]\ndqh = dsets['tf']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\n#figsize = (2.5 * fsize[0], fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}');\n_ = ax[1].set_title(f'HMC, total: {htot.values}');\n_ = fig.suptitle(fr'TensorFlow Improvement: {100*(etot / htot):3.0f}%')\n\ndqe_tot = dqe.astype(int).sum().T.values.sum()\ndqh_tot = dqh.astype(int).sum().T.values.sum()\ndqeh_ratio = dqe_tot / dqh_tot\n\nlog.info(f\"TensorFlow, EVAL\\n {dqe.astype(int).sum('chain').T=}\")\nlog.info(f\"Eval: {dqe.astype(int).sum().T.values.sum()=}\")\nlog.info(f\"TensorFlow, HMC\\n {dqh.astype(int).sum('chain').T=}\")\nlog.info(f\"HMC: {dqh.astype(int).sum().T.values.sum()=}\")\nlog.critical(f\"dQ_eval / dQ_hmc: {dqeh_ratio:.4f}\")\n\n\n\n\noutput\n\n\n[2023-12-05 12:33:43][INFO][3549449091.py:25] - TensorFlow, EVAL\n dqe.astype(int).sum('chain').T=&lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([ 4,  2,  7,  5, 10,  6,  9,  6,  4,  5,  7,  6,  3,  5,  2,  7,  9,\n        7,  2,  5,  8,  8, 10,  6,  5,  9,  5, 10,  7,  6,  7,  8,  3,  7,\n        9,  4,  8,  8,  4,  5,  3,  4,  5, 10,  9,  4,  9,  8,  4,  9,  5,\n        5,  6,  9,  4,  7,  5,  5,  7,  7,  6,  3,  8,  8, 11,  4, 10,  7,\n        7,  7,  5,  9,  7,  7,  7,  9,  5,  8,  6,  5,  7,  6,  6,  6, 10,\n        6,  8,  7,  7,  4])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199 \n[2023-12-05 12:33:43][INFO][3549449091.py:26] - Eval: dqe.astype(int).sum().T.values.sum()=579 \n[2023-12-05 12:33:43][INFO][3549449091.py:27] - TensorFlow, HMC\n dqh.astype(int).sum('chain').T=&lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([0, 1, 0, 1, 0, 0, 2, 0, 3, 0, 1, 2, 0, 2, 1, 3, 1, 0, 2, 2, 0, 0,\n       0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 0, 1, 0,\n       2, 1, 1, 1, 2, 3, 3, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 3, 1, 0, 5, 0,\n       0, 1, 0, 0, 0, 1, 1, 2, 1, 3, 1, 1, 0, 2, 0, 1, 0, 0, 1, 3, 0, 0,\n       0, 1])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199 \n[2023-12-05 12:33:43][INFO][3549449091.py:28] - HMC: dqh.astype(int).sum().T.values.sum()=80 \n[2023-12-05 12:33:43][CRITICAL][3549449091.py:29] - dQ_eval / dQ_hmc: 7.2375 \n\n\n\n\n\n\nPyTorch Results\nsns.set_context('notebook', font_scale=1.25)\n\nndraws = len(dsets['pt']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['pt']['eval']['dQint'][:, -90:]\ndqh = dsets['pt']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\nfigsize = (2.5 * fsize[0], 0.8 * fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}');\n_ = ax[1].set_title(f'HMC, total: {htot.values}');\n#_ = fig.suptitle(fr'PyTorch Improvement: {100*(etot / htot):3.0f}%')\n\n\n\n\noutput\n\n\n\n\n\n\n\ndqe_tot = dqe.astype(int).sum().T.values.sum()\ndqh_tot = dqh.astype(int).sum().T.values.sum()\ndqeh_ratio = dqe_tot / dqh_tot\n\nlog.info(f\"PyTorch, EVAL\\n {dqe.astype(int).sum('chain').T=}\")\nlog.info(f\"Eval: {dqe.astype(int).sum().T.values.sum()=}\")\nlog.info(f\"TensorFlow, HMC\\n {dqh.astype(int).sum('chain').T=}\")\nlog.info(f\"HMC: {dqh.astype(int).sum().T.values.sum()=}\")\nlog.critical(f\"dQ_eval / dQ_hmc: {dqeh_ratio:.4f}\")\n\n\n\n\noutput\n\n\n[2023-12-05 12:35:35][INFO][2202273834.py:5] - PyTorch, EVAL\n dqe.astype(int).sum('chain').T=&lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([ 8,  6,  8,  8,  5,  6,  5, 10, 13,  8,  2,  4,  7,  9,  6,  6,  8,\n        8,  8, 10,  5,  9,  6,  6, 12,  3,  6,  7,  5,  8,  8, 12,  7,  4,\n        8,  7,  3,  6,  4,  5,  7,  6,  6, 10,  7,  4,  4, 11,  7,  7,  7,\n        4,  6,  7,  6,  6, 10,  9,  5,  6,  6,  5, 13,  2,  9,  9, 14,  7,\n        3,  5,  7,  6,  9,  9,  3,  9,  4,  2,  6,  9,  5,  3, 10,  7,  8,\n        8,  7,  6,  6,  7])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199 \n[2023-12-05 12:35:35][INFO][2202273834.py:6] - Eval: dqe.astype(int).sum().T.values.sum()=615 \n[2023-12-05 12:35:35][INFO][2202273834.py:7] - TensorFlow, HMC\n dqh.astype(int).sum('chain').T=&lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([2, 3, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 2, 1, 3, 0, 0, 5, 3, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 3, 4, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1, 2, 4, 0, 1, 2, 1,\n       1, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1,\n       0, 0])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199 \n[2023-12-05 12:35:35][INFO][2202273834.py:8] - HMC: dqh.astype(int).sum().T.values.sum()=73 \n[2023-12-05 12:35:35][CRITICAL][2202273834.py:9] - dQ_eval / dQ_hmc: 8.4247",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/test/index.html#comparisons-1",
    "href": "posts/jupyter/test/index.html#comparisons-1",
    "title": "üèÅ l2hmc Example: 2D U(1)",
    "section": "Comparisons",
    "text": "Comparisons\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import set_plot_style, COLORS\n\nimport seaborn as sns\nset_plot_style()\nplt.rcParams['axes.linewidth'] = 2.0\nsns.set_context('notebook', font_scale=1.25)\nfigsize = plt.rcParamsDefault['figure.figsize']\nplt.rcParams['figure.dpi'] = plt.rcParamsDefault['figure.dpi']\n\nfor idx in range(4):\n    fig, (ax, ax1) = plt.subplots(\n        ncols=2,\n        #nrows=4,\n        figsize=(3. * figsize[0], figsize[1]),\n    )\n    _ = ax.plot(\n        dsets['pt']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[100:],\n        color=COLORS['red'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n    );\n\n    _ = ax.plot(\n        dsets['pt']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[100:],\n        ls='-',\n        label='HMC',\n        color='#666666',\n        zorder=5,\n        lw=2.0,\n    );\n\n    _ = ax1.plot(\n        dsets['tf']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[-100:],\n        color=COLORS['blue'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n\n    );\n    _ = ax1.plot(\n        dsets['tf']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[-100:],\n        color='#666666',\n        ls='-',\n        label='HMC',\n        zorder=5,\n        lw=2.0,\n    );\n    _ = ax.set_title('PyTorch')\n    _ = ax1.set_title('TensorFlow')\n    #_ = ax1.set_ylim(ax.get_ylim())\n    _ = ax.grid(True, alpha=0.2)\n    _ = ax1.grid(True, alpha=0.2)\n    _ = ax.set_xlabel('MD Step')\n    _ = ax1.set_xlabel('MD Step')\n    _ = ax.set_ylabel('dQint'\n                     )\n    _ = ax.legend(loc='best', ncol=2, labelcolor='#939393')\n    _ = ax1.legend(loc='best', ncol=2, labelcolor='#939393')\n\n\n\n\noutput",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "üèÅ `l2hmc` Example: 2D $U(1)$"
    ]
  },
  {
    "objectID": "posts/jupyter/index.html",
    "href": "posts/jupyter/index.html",
    "title": "üìó Jupyter",
    "section": "",
    "text": "CitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {üìó {Jupyter}},\n  url = {https://samforeman.me/posts/jupyter/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äúüìó Jupyter.‚Äù https://samforeman.me/posts/jupyter/."
  },
  {
    "objectID": "posts/ezpz-v1/index.html#ezpz-v1",
    "href": "posts/ezpz-v1/index.html#ezpz-v1",
    "title": "üìù ezpz-v1",
    "section": "üçã ezpz v1",
    "text": "üçã ezpz v1\nSam Foreman\n2024-05-14\n\nüëÄ Overview\nezpz üçã\nLaunch, train and communicate across all your accelerators, ezpz.\nFull support for your favorite framework + backend combo ‚ù§Ô∏è.\nezpz simplifies the process of:\n\nSetting up + launching distributed training:\n\nimport ezpz as ez\n\nRANK = ez.setup_torch(backend=backend) for backend \\in {DDP, deepspeed, horovod}\nRANK = ez.get_rank()\nLOCAL_RANK = ez.get_local_rank()\nWORLD_SIZE = ez.get_world_size()\n\n (see ezpz/dist.py for more details). \n\nWriting device agnostic code:\n\nezpz.get_torch_device() &gt; &gt; - Full support for any {device + framework + backend}: &gt; - device: {GPU, XPU, MPS, CPU} &gt; - framework: {torch, deepspeed, horovod, tensorflow} &gt; - backend: {DDP, deepspeed, horovod}",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìù ezpz-v1"
    ]
  },
  {
    "objectID": "posts/ezpz-v1/index.html#test_dist.py",
    "href": "posts/ezpz-v1/index.html#test_dist.py",
    "title": "üìù ezpz-v1",
    "section": "test_dist.py",
    "text": "test_dist.py\nimport os\nimport logging\nimport time\nfrom typing import Optional\nimport torch\nimport ezpz as ez\n\n# backend can be any of DDP, deespepeed, horovod\nRANK = ez.setup_torch(\n  backend=(\n      backend := os.environ.get('BACKEND', 'DDP')\n  ),\n  port=(\n      port := os.environ.get(\"MASTER_PORT\", \"29500\")\n  )\n)\n# RANK = DIST_INIT['rank']\n# WORLD_SIZE = DIST_INIT['world_size']\n# LOCAL_RANK = DIST_INIT['local_rank']\n# if DEVICE == \"cuda\" and torch.cuda.is_available():\n#     torch.cuda.set_device(LOCAL_RANK)\nDEVICE = ez.get_torch_device()\nWORLD_SIZE = ez.get_world_size()\nLOCAL_RANK = ez.get_local_rank()\nDEVICE_ID = f\"{DEVICE}:{LOCAL_RANK}\"\n\n\n# log only from RANK == 0\nlogger = logging.getLogger(__name__)\nlogger.setLevel(\"INFO\") if RANK == 0 else logger.setLevel(\"CRITICAL\")\n\nBATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", 64))  # 64\nINPUT_SIZE = int(os.environ.get(\"INPUT_SIZE\", 128))  # 128\nOUTPUT_SIZE = int(os.environ.get(\"OUTPUT_SIZE\", 128))  # 128\nDTYPE = os.environ.get(\"DTYPE\", torch.get_default_dtype())\nTRAIN_ITERS = int(os.environ.get(\"TRAIN_ITERS\", 50))\n\n# logger.info(f\"{DIST_INIT=}\")\n\n\nclass Network(torch.nn.Module):\n  def __init__(\n          self,\n          input_dim: int = 128,\n          output_dim: int = 128,\n          sizes: Optional[list[int]] = None,\n  ):\n      super(Network, self).__init__()\n      if sizes is None:\n          self.layers = torch.nn.Linear(input_dim, output_dim)\n      elif len(sizes) &gt; 0:\n          layers = [torch.nn.Linear(input_dim, sizes[0])]\n          for idx, size in enumerate(sizes[1:]):\n              layers.append(\n                  torch.nn.Linear(sizes[idx], size)\n              )\n          layers.append(torch.nn.Linear(sizes[-1], output_dim))\n          self.layers = torch.nn.Sequential(*layers)\n\n  def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n      return self.layers(x)\n\n\ndef calc_loss(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n  return (y - x).pow(2).sum()\n\n\ndef plot_losses(losses: dict) -&gt; None:\n  import plotext as pltx\n  # y = list(losses.values())\n  pltx.theme('clear')\n  pltx.scatter(list(losses.values()))\n  pltx.show()\n  pltx.save_fig(\"test_dist_losses.txt\")\n  pltx.ylabel(\"loss\")\n  pltx.xlabel(\"iteration\")\n\n\ndef main():\n  model = Network(\n      input_dim=INPUT_SIZE,\n      output_dim=OUTPUT_SIZE,\n      sizes=[1024, 512, 256, 128]\n  )\n  model.to(DEVICE)\n  model.to(DEVICE_ID)\n  logger.info(f'{model=}')\n  optimizer = torch.optim.Adam(model.parameters())\n  if backend.lower() == 'ddp':\n      if WORLD_SIZE &gt; 1:\n          from torch.nn.parallel import DistributedDataParallel as DDP\n          model = DDP(\n              model,\n              device_ids=[]\n          )\n  elif backend.lower() in ('ds', 'deepspeed'):\n      import deepspeed\n      # config = ez.load_ds_config().update(\n      #     {\"train_micro_batch_size_per_gpu\": BATCH_SIZE}\n      # )\n      import argparse\n      parser = argparse.ArgumentParser(\n          description='My training script.'\n      )\n      parser.add_argument(\n          '--local_rank',\n          required=False,\n          type=int,\n          default=-1,\n          # default=ez.get_local_rank()),\n          help='local rank passed from distributed launcher',\n      )\n      # Include DeepSpeed configuration arguments\n      parser = deepspeed.add_config_arguments(parser)\n      cmd_args = parser.parse_args()\n      logger.info(f'{cmd_args=}')\n      model, optimizer, *_ = deepspeed.initialize(\n          args=cmd_args,\n          model=model,\n          optimizer=optimizer,\n      )\n\n  losses = {}\n  for iter in range(TRAIN_ITERS):\n      t0 = time.perf_counter()\n      x = torch.rand((BATCH_SIZE, INPUT_SIZE), dtype=DTYPE).to(DEVICE)\n      y = model(x)\n      loss = calc_loss(x, y)\n      losses[iter] = loss\n      dtf = ((t1 := time.perf_counter()) - t0)\n      if backend == 'deepspeed':\n          model.backward(loss)\n          model.step(loss)\n      else:\n          loss.backward()\n          optimizer.step()\n      optimizer.zero_grad()\n      dtb = time.perf_counter() - t1\n      logger.info(\n          ', '.join([\n              f'{iter=}',\n              f'loss={loss.item():.5f}',\n              f'dt={dtf+dtb:.3f}',\n              f'{dtf=:.3f}',\n              f'{dtb=:.3f}'\n          ])\n      )\n  if RANK == 0:\n      plot_losses(losses)\n\n\nif __name__ == '__main__':\n  main()",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìù ezpz-v1"
    ]
  },
  {
    "objectID": "posts/ezpz-v1/index.html#ezpz",
    "href": "posts/ezpz-v1/index.html#ezpz",
    "title": "üìù ezpz-v1",
    "section": "ezpz",
    "text": "ezpz\n \nSimplifies the process of setting up distributed training for:\n\npytorch + {DDP, deepspeed, horovod}\ntensorflow + horovod\n\n\nSetup\n\nInstall:\ngit clone https://github.com/saforem2/ezpz\npython3 -m pip install -e ezpz\nDetermine available resources:\n[ \"$(hostname)==theta*\" ] && HOSTFILE=\"${COBALT_NODEFILE}\"  # ThetaGPU @ ALCF\n[ \"$(hostname)==x3*\" ] && HOSTFILE=\"${PBS_NODEFILE}\"        # Polaris @ ALCF\n[ \"$(hostname)==nid*\" ] && HOSTFILE=\"${SLURM_NODELIST}\"     # Perlmutter @ NERSC\nNHOSTS=$(wc -l &lt; \"${HOSTFILE}\")\nNGPU_PER_HOST=$(nvidia-smi -L | wc -l)\nNGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\";\necho $NHOSTS $NGPU_PER_HOST $NGPUS\n2 4 8\nExample python script:\n\"\"\"\nezpz/test.py\n\"\"\"\nfrom ezpz import setup_torch, setup_tensorflow\n\n\ndef test(\n        framework: str = 'pytorch',\n        backend: str = 'deepspeed',\n        port: int | str = '5432'\n):\n    if framework == 'pytorch':\n        _ = setup_torch(\n            backend=backend,\n            port=port,\n        )\n    elif framework == 'tensorflow':\n        _ = setup_tensorflow()\n    else:\n        raise ValueError  \n\nif __name__ == '__main__':\n    import sys\n    try:\n        framework = sys.argv[1]\n    except IndexError:\n        framework = 'pytorch'\n    try:\n        backend = sys.argv[2]\n    except IndexError:\n        backend = 'deepspeed'\n    try:\n        port = sys.argv[3]\n    except IndexError:\n        port = '5432'\n    test(framework=framework, backend=backend, port=port)\n\n\n\nTests\nYou can test a {framework, backend} combination by:\nmpiexec --verbose --envall -n \"${NGPUS}\" --ppn \"${NGPU_PER_HOST}\" python3 test.py framework backend\nfor framework \\in {pytorch, tensorflow} and backend \\in {horovod, deepspeed, DDP}1\n\n‚úÖ PyTorch + DDP:\nmpiexec --verbose --envall -n \"${NGPUS}\" --ppn \"${NGPU_PER_HOST}\" python3 test.py pytorch DDP\n‚úÖ PyTorch + DeepSpeed:\nmpiexec --verbose --envall -n \"${NGPUS}\" --ppn \"${NGPU_PER_HOST}\" python3 test.py pytorch deepspeed\n‚úÖ PyTorch + Horovod:\nmpiexec --verbose --envall -n \"${NGPUS}\" --ppn \"${NGPU_PER_HOST}\" python3 test.py pytorch horovod\n‚úÖ TensorFlow + Horovod:\nmpiexec --verbose --envall -n \"${NGPUS}\" --ppn \"${NGPU_PER_HOST}\" python3 test.py tensorflow\n\n\n\nHelper Utilities\n\nsrc/ezpz/bin/savejobenv: Shell script to save relevant job related environment variables to a file which can be sourced from new login instances.\nsrc/ezpz/bin/getjobenv: Shell script that, when sourced, will populate the current environment with the necessary job-related variables.\n\n\nLaunch a job, clone (or navigate into) ezpz, and run src/ezpz/bin/savejobenv:\n(thetalogin5) $ qsub-gpu -A datascience -n 4 -q full-node --attrs=\"filesystems=home,grand,eagle,theta-fs0:ssds=required\" -t 12:00 -I\n(thetagpu13) $ git clone https://github.com/saforem2/ezpz\n(thetagpu13) $ cd ezpz/src/ezpz\n(thetagpu13) $ ./bin/savejobenv\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ [DIST INFO]:\n‚îÇ   ‚Ä¢ Writing Job info to /home/foremans/.cobaltenv\n‚îÇ       ‚Ä¢ NHOSTS: 4\n‚îÇ       ‚Ä¢ NGPU_PER_HOST: 8\n‚îÇ       ‚Ä¢ NGPUS = (NHOSTS * NGPU_PER_HOST) = 32\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Saving COBALT env to /home/foremans/.cobaltenv from thetagpu13\n‚îÇ Writing COBALT vars to /home/foremans/.cobaltenv                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Copying COBALT_NODEFILE to clipboard...\n‚îÇ COBALT_NODEFILE: /var/tmp/cobalt.10154591\n‚îÇ [Hosts]:\n‚îÇ   thetagpu13 thetagpu12 thetagpu19 thetagpu18\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Run 'source getjobenv' in a NEW SHELL to automatically set env vars   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nnow, in a NEW SHELL\n(localhost) $ ssh foremans@theta\n(thetalogin5) $ ssh thetagpu18\n(thetagpu18) $ module load conda/2023-01-11; cond activate base\n(thetagpu18) $ cd ezpz\n(thetagpu18) $ mkdir -p venvs/thetaGPU/2023-01-11\n(thetagpu18) $ python3 -m venv venvs/thetaGPU/2023-01-11 --system-site-packages\n(thetagpu18) $ source venvs/thetaGPU/2023-01-11/bin/activate\n(thetagpu18) $ python3 -m pip install -e .\n(thetagpu18) $ cd ezpz/src/ezpz\n(thetagpu18) $ source bin/getjobenv\nRUNNING_JOB_FILE: /var/tmp/cobalt-running-job\nJOBID: 10154591\nLoading job env from: /home/foremans/.cobaltenv\nDefining alias mpilaunch: mpilaunch: aliased to mpirun -n 32 -N 8 --hostfile /var/tmp/cobalt.10154591 -x PATH -x LD_LIBRARY_PATH\nHOSTFILE: /var/tmp/cobalt.10154591\nNHOSTS: 4\nNGPU_PER_HOST: 8\nNGPUS (NHOSTS x NGPU_PER_HOST): 32\nHOSTS: thetagpu13 thetagpu12 thetagpu19 thetagpu18\n(thetagpu18) $ mpilaunch python3 -m ezpz pytorch DDP\nUsing DDP for distributed training\nRANK: 0 / 31\nRANK: 25 / 31\nRANK: 24 / 31\nRANK: 15 / 31\nRANK: 26 / 31\nRANK: 31 / 31\nRANK: 2 / 31\nRANK: 12 / 31\nRANK: 1 / 31\nRANK: 28 / 31\nRANK: 3 / 31\nRANK: 14 / 31\nRANK: 4 / 31\nRANK: 10 / 31\nRANK: 27 / 31\nRANK: 5 / 31\nRANK: 30 / 31\nRANK: 29 / 31\nRANK: 9 / 31\nRANK: 7 / 31\nRANK: 6 / 31\nRANK: 13 / 31\nRANK: 8 / 31\nRANK: 11 / 31\nRANK: 18 / 31\nRANK: 16 / 31\nRANK: 21 / 31\nRANK: 20 / 31\nRANK: 22 / 31\nRANK: 19 / 31\nRANK: 17 / 31\nRANK: 23 / 31\nwhile this example looked at ThetaGPU, the exact same process will work on any of {ThetaGPU, Polaris, Perlmutter}.\n2ez",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìù ezpz-v1"
    ]
  },
  {
    "objectID": "posts/ezpz-v1/index.html#complete-example",
    "href": "posts/ezpz-v1/index.html#complete-example",
    "title": "üìù ezpz-v1",
    "section": "Complete Example",
    "text": "Complete Example\n\nGist\n\n\n\n\n\n\nTip saforem2/ezpz.md\n\n\n\n\n\n\n\n\n\n\n\nüì¶ Clone Repo(s)\n\nargonne-lcf/Megatron-DeepSpeed:\n$ git clone https://github.com/argonne-lcf/Megatron-DeepSpeed\nCloning into 'Megatron-DeepSpeed'...\nremote: Enumerating objects: 15538, done.\nremote: Counting objects: 100% (21/21), done.\nremote: Compressing objects: 100% (11/11), done.\nremote: Total 15538 (delta 10), reused 18 (delta 10), pack-reused 15517\nReceiving objects: 100% (15538/15538), 6.25 MiB | 32.32 MiB/s, done.\nResolving deltas: 100% (11482/11482), done.\nUpdating files: 100% (596/596), done.\nsaforem2/ezpz:\n$ cd Megatron-DeepSpeed\n$ git clone https://github.com/saforem2/ezpz deps/ezpz\nCloning into 'deps/ezpz'...\nremote: Enumerating objects: 2161, done.\nremote: Counting objects: 100% (390/390), done.\nremote: Compressing objects: 100% (181/181), done.\nremote: Total 2161 (delta 214), reused 285 (delta 151), pack-reused 1771\nReceiving objects: 100% (2161/2161), 4.28 MiB | 25.35 MiB/s, done.\nResolving deltas: 100% (1134/1134), done.\n\n\n\nüõú Setup Job\n\nSource ezpz/bin/utils.sh:\n$ PBS_O_WORKDIR=$(pwd) source deps/ezpz/src/ezpz/bin/utils.sh\nUsing WORKING_DIR: /eagle/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed\nezpz_setup_alcf:\n$ ezpz_setup_alcf\n[ezpz/bin/utils.sh]\n\n[2024-07-23-221417]\n    ‚Ä¢ USER=foremans\n    ‚Ä¢ MACHINE=polaris\n    ‚Ä¢ HOST=x3006c0s25b1n0\n\n[ezpz_get_pbs_env]: Caught 0 arguments\n    ‚Ä¢ hostfile: /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n    ‚Ä¢ jobenv_file: /home/foremans/.pbsenv\n\n[ezpz_setup_host]\n    ‚Ä¢ Using hostfile: /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n    ‚Ä¢ Found in environment:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n        ‚Ä¢ Writing PBS vars to: /home/foremans/.pbsenv\n\n[ezpz_save_pbs_env]\n    ‚Ä¢ Setting:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n        ‚Ä¢ JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n    ‚Ä¢ [host:0] - x3006c0s25b1n0.hsn.cm.polaris.alcf.anl.gov\n\n[DIST INFO]\n    ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n    ‚Ä¢ NHOSTS=1\n    ‚Ä¢ NGPU_PER_HOST=4\n    ‚Ä¢ NGPUS=4\n    ‚Ä¢ DIST_LAUNCH=mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n[LAUNCH]:\n    ‚Ä¢ To launch across all available GPUs, use: launch\n      launch = mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n\n\nüêç Setup Python\n\nezpz_setup_python:\n$ ezpz_setup_python\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\nLmod is automatically replacing \"nvhpc/23.9\" with \"gcc-native/12.3\".\nLmod is automatically replacing \"PrgEnv-nvhpc/8.5.0\" with \"PrgEnv-gnu/8.5.0\".\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.28\nFound conda at: /soft/applications/conda/2024-04-29/mconda3\nNo VIRTUAL_ENV found in environment!\n    - Trying to setup from /soft/applications/conda/2024-04-29/mconda3\n    - Using VENV_DIR=/eagle/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/venvs/2024-04-29\n    - Creating a new virtual env on top of 2024-04-29 in /eagle/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/venvs/2024-04-29\n[python] Using /eagle/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/venvs/2024-04-29/bin/python3\n\n$ which python3\n/eagle/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/venvs/2024-04-29/bin/python3\n\n$ python3 -m pip install -e deps/ezpz --require-virtualenv\nLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nObtaining file:///lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/deps/ezpz\n  Installing build dependencies ... done\n  Checking if build backend supports build_editable ... done\n  Getting requirements to build editable ... done\n  Installing backend dependencies ... done\n  Preparing editable metadata (pyproject.toml) ... done\n\n\n\nüìù Test Setup\n\nezpz/test_dist.py\n$ launch python3 -m ezpz.test_dist\n\n\nOutput\n\n[2024-07-23 22:21:37.972869][INFO][__init__:156] - Setting logging level to 'INFO' on 'RANK == 0'\n[2024-07-23 22:21:37.975224][INFO][__init__:157] - Setting logging level to 'CRITICAL' on all others 'RANK != 0'\n[2024-07-23 22:21:37.975718][INFO][__init__:160] - To disable this behavior, and log from ALL ranks (not recommended), set: 'export LOG_FROM_ALL_RANKS=1'  in your environment, and re-run.\n[2024-07-23 22:21:39.790899][INFO][dist:358] - [device='cuda'][rank=1/3][local_rank=1/3][node=0/0]\n[2024-07-23 22:21:39.790850][INFO][dist:358] - [device='cuda'][rank=2/3][local_rank=2/3][node=0/0]\n[2024-07-23 22:21:39.791749][INFO][dist:358] - [device='cuda'][rank=3/3][local_rank=3/3][node=0/0]\n[2024-07-23 22:21:39.797666][INFO][dist:95] -\n\n[dist_info]:\n  ‚Ä¢ DEVICE=cuda\n  ‚Ä¢ DEVICE_ID=cuda:0\n  ‚Ä¢ DISTRIBUTED_BACKEND=nccl\n  ‚Ä¢ GPUS_PER_NODE=4\n  ‚Ä¢ HOSTS=['x3006c0s25b1n0.hsn.cm.polaris.alcf.anl.gov']\n  ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ HOSTNAME=x3006c0s25b1n0.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ LOCAL_RANK=0\n  ‚Ä¢ MACHINE=Polaris\n  ‚Ä¢ NUM_NODES=1\n  ‚Ä¢ NGPUS=4\n  ‚Ä¢ NGPUS_AVAILABLE=4\n  ‚Ä¢ NODE_ID=0\n  ‚Ä¢ RANK=0\n  ‚Ä¢ SCHEDULER=PBS\n  ‚Ä¢ WORLD_SIZE_TOTAL=4\n  ‚Ä¢ WORLD_SIZE_IN_USE=4\n  ‚Ä¢ LAUNCH_CMD=mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2036165.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n\n[2024-07-23 22:21:39.800519][INFO][dist:725] - [0/4] Using device='cuda' with backend='DDP' + 'nccl' for distributed training.\n[2024-07-23 22:21:39.805001][INFO][dist:358] - [device='cuda'][rank=0/3][local_rank=0/3][node=0/0]\n[2024-07-23 22:21:39.805513][WARNING][dist:364] - Using [4 / 4] available \"cuda\" devices !!\n[2024-07-23 22:21:39.806121][INFO][dist:95] -\n\n[timers_import]:\n  ‚Ä¢ os=1.062639057636261e-06\n  ‚Ä¢ logging=4.0046870708465576e-07\n  ‚Ä¢ typing=2.7157366275787354e-06\n  ‚Ä¢ pathlib=1.2516975402832031e-06\n  ‚Ä¢ ezpz=6.30505383014679e-07\n  ‚Ä¢ torch=2.555549144744873e-06\n  ‚Ä¢ torch_ddp=2.4745240807533264e-06\n  ‚Ä¢ wandb=6.44102692604065e-05\n  ‚Ä¢ total=7.550138980150223e-05\n\n\n[2024-07-23 22:21:39.807221][INFO][dist:95] -\n\n[CONFIG]:\n  ‚Ä¢ warmup=0\n  ‚Ä¢ log_freq=1\n  ‚Ä¢ batch_size=64\n  ‚Ä¢ input_size=128\n  ‚Ä¢ output_size=128\n  ‚Ä¢ dtype=torch.float32\n  ‚Ä¢ device=cuda\n  ‚Ä¢ world_size=4\n  ‚Ä¢ train_iters=100\n\n[2024-07-23 22:21:41.373173][INFO][test_dist:183] - model=Network(\n  (layers): Sequential(\n    (0): Linear(in_features=128, out_features=1024, bias=True)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=256, bias=True)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n)\n[2024-07-23 22:21:43.625040][INFO][test_dist:274] - iter=1, loss=2039.91, sps=2.252e+04, dt=0.00284196, dtf=0.0009801, dtb=0.001862\n[2024-07-23 22:21:43.628643][INFO][test_dist:274] - iter=2, loss=1424.54, sps=3.272e+04, dt=0.00195628, dtf=0.0005183, dtb=0.001438\n[2024-07-23 22:21:43.631833][INFO][test_dist:274] - iter=3, loss=1159.38, sps=3.331e+04, dt=0.00192147, dtf=0.0006139, dtb=0.001308\n[2024-07-23 22:21:43.634991][INFO][test_dist:274] - iter=4, loss=935.58, sps=3.343e+04, dt=0.00191451, dtf=0.0006113, dtb=0.001303\n[2024-07-23 22:21:43.638092][INFO][test_dist:274] - iter=5, loss=851.468, sps=3.483e+04, dt=0.00183759, dtf=0.0005938, dtb=0.001244\n[2024-07-23 22:21:43.641232][INFO][test_dist:274] - iter=6, loss=785.109, sps=3.409e+04, dt=0.00187757, dtf=0.0005972, dtb=0.00128\n[2024-07-23 22:21:43.644367][INFO][test_dist:274] - iter=7, loss=772.966, sps=3.417e+04, dt=0.00187292, dtf=0.0005868, dtb=0.001286\n[2024-07-23 22:21:43.647507][INFO][test_dist:274] - iter=8, loss=727.854, sps=3.411e+04, dt=0.00187638, dtf=0.0005814, dtb=0.001295\n[2024-07-23 22:21:43.650561][INFO][test_dist:274] - iter=9, loss=725.773, sps=3.546e+04, dt=0.00180485, dtf=0.0005975, dtb=0.001207\n[2024-07-23 22:21:43.653520][INFO][test_dist:274] - iter=10, loss=720.374, sps=3.785e+04, dt=0.00169078, dtf=0.0006108, dtb=0.00108\n[2024-07-23 22:21:43.656564][INFO][test_dist:274] - iter=11, loss=717.926, sps=3.602e+04, dt=0.00177678, dtf=0.0005694, dtb=0.001207\n[2024-07-23 22:21:43.659555][INFO][test_dist:274] - iter=12, loss=692.535, sps=3.682e+04, dt=0.00173814, dtf=0.0005557, dtb=0.001182\n[2024-07-23 22:21:43.662596][INFO][test_dist:274] - iter=13, loss=679.509, sps=3.67e+04, dt=0.00174377, dtf=0.0005531, dtb=0.001191\n[2024-07-23 22:21:43.665598][INFO][test_dist:274] - iter=14, loss=674.778, sps=3.727e+04, dt=0.00171741, dtf=0.0005496, dtb=0.001168\n[2024-07-23 22:21:43.668593][INFO][test_dist:274] - iter=15, loss=673.873, sps=3.666e+04, dt=0.00174556, dtf=0.0005708, dtb=0.001175\n[2024-07-23 22:21:43.671589][INFO][test_dist:274] - iter=16, loss=667.283, sps=3.694e+04, dt=0.00173238, dtf=0.0005453, dtb=0.001187\n[2024-07-23 22:21:43.674599][INFO][test_dist:274] - iter=17, loss=660.292, sps=3.646e+04, dt=0.00175558, dtf=0.0005538, dtb=0.001202\n[2024-07-23 22:21:43.677592][INFO][test_dist:274] - iter=18, loss=660.664, sps=3.696e+04, dt=0.00173169, dtf=0.0005441, dtb=0.001188\n[2024-07-23 22:21:43.680559][INFO][test_dist:274] - iter=19, loss=676.161, sps=3.709e+04, dt=0.00172556, dtf=0.0005668, dtb=0.001159\n[2024-07-23 22:21:43.683539][INFO][test_dist:274] - iter=20, loss=665.099, sps=3.702e+04, dt=0.0017287, dtf=0.0005281, dtb=0.001201\n[2024-07-23 22:21:43.686527][INFO][test_dist:274] - iter=21, loss=626.671, sps=3.7e+04, dt=0.00172989, dtf=0.0005279, dtb=0.001202\n[2024-07-23 22:21:43.689518][INFO][test_dist:274] - iter=22, loss=632.127, sps=3.702e+04, dt=0.00172883, dtf=0.0005085, dtb=0.00122\n[2024-07-23 22:21:43.692469][INFO][test_dist:274] - iter=23, loss=657.324, sps=3.755e+04, dt=0.00170436, dtf=0.0005164, dtb=0.001188\n[2024-07-23 22:21:43.695563][INFO][test_dist:274] - iter=24, loss=617.646, sps=3.558e+04, dt=0.00179856, dtf=0.0005767, dtb=0.001222\n[2024-07-23 22:21:43.698537][INFO][test_dist:274] - iter=25, loss=618.284, sps=3.705e+04, dt=0.00172744, dtf=0.0005522, dtb=0.001175\n[2024-07-23 22:21:43.701410][INFO][test_dist:274] - iter=26, loss=615.418, sps=3.961e+04, dt=0.00161577, dtf=0.0005298, dtb=0.001086\n[2024-07-23 22:21:43.704427][INFO][test_dist:274] - iter=27, loss=599.058, sps=3.648e+04, dt=0.00175461, dtf=0.0005156, dtb=0.001239\n[2024-07-23 22:21:43.707374][INFO][test_dist:274] - iter=28, loss=621.717, sps=3.778e+04, dt=0.00169387, dtf=0.0004899, dtb=0.001204\n[2024-07-23 22:21:43.710390][INFO][test_dist:274] - iter=29, loss=597.588, sps=3.623e+04, dt=0.00176654, dtf=0.0005663, dtb=0.0012\n[2024-07-23 22:21:43.713386][INFO][test_dist:274] - iter=30, loss=598.102, sps=3.71e+04, dt=0.00172484, dtf=0.0005497, dtb=0.001175\n[2024-07-23 22:21:43.716530][INFO][test_dist:274] - iter=31, loss=586.188, sps=3.357e+04, dt=0.00190664, dtf=0.0005618, dtb=0.001345\n[2024-07-23 22:21:43.719525][INFO][test_dist:274] - iter=32, loss=591.646, sps=3.672e+04, dt=0.00174293, dtf=0.000561, dtb=0.001182\n[2024-07-23 22:21:43.722513][INFO][test_dist:274] - iter=33, loss=574.161, sps=3.668e+04, dt=0.00174487, dtf=0.0005502, dtb=0.001195\n[2024-07-23 22:21:43.725524][INFO][test_dist:274] - iter=34, loss=586.41, sps=3.707e+04, dt=0.00172628, dtf=0.0005552, dtb=0.001171\n[2024-07-23 22:21:43.728594][INFO][test_dist:274] - iter=35, loss=574.43, sps=3.605e+04, dt=0.00177526, dtf=0.000576, dtb=0.001199\n[2024-07-23 22:21:43.731615][INFO][test_dist:274] - iter=36, loss=552.77, sps=3.642e+04, dt=0.00175741, dtf=0.0005588, dtb=0.001199\n[2024-07-23 22:21:43.734574][INFO][test_dist:274] - iter=37, loss=567.612, sps=3.748e+04, dt=0.00170768, dtf=0.0005318, dtb=0.001176\n[2024-07-23 22:21:43.737564][INFO][test_dist:274] - iter=38, loss=561.004, sps=3.706e+04, dt=0.00172686, dtf=0.0005489, dtb=0.001178\n[2024-07-23 22:21:43.740578][INFO][test_dist:274] - iter=39, loss=555.718, sps=3.645e+04, dt=0.00175567, dtf=0.0005662, dtb=0.001189\n[2024-07-23 22:21:43.743565][INFO][test_dist:274] - iter=40, loss=543.661, sps=3.708e+04, dt=0.00172613, dtf=0.0005363, dtb=0.00119\n[2024-07-23 22:21:43.746561][INFO][test_dist:274] - iter=41, loss=537.186, sps=3.691e+04, dt=0.00173373, dtf=0.0005346, dtb=0.001199\n[2024-07-23 22:21:43.749446][INFO][test_dist:274] - iter=42, loss=545.877, sps=3.998e+04, dt=0.00160083, dtf=0.000533, dtb=0.001068\n[2024-07-23 22:21:43.752446][INFO][test_dist:274] - iter=43, loss=546.533, sps=3.681e+04, dt=0.00173875, dtf=0.0005124, dtb=0.001226\n[2024-07-23 22:21:43.755384][INFO][test_dist:274] - iter=44, loss=545.989, sps=3.796e+04, dt=0.001686, dtf=0.0005054, dtb=0.001181\n[2024-07-23 22:21:43.758389][INFO][test_dist:274] - iter=45, loss=531.344, sps=3.667e+04, dt=0.00174516, dtf=0.0005569, dtb=0.001188\n[2024-07-23 22:21:43.761470][INFO][test_dist:274] - iter=46, loss=515.415, sps=3.69e+04, dt=0.00173432, dtf=0.000551, dtb=0.001183\n[2024-07-23 22:21:43.764494][INFO][test_dist:274] - iter=47, loss=523.498, sps=3.634e+04, dt=0.00176121, dtf=0.0005524, dtb=0.001209\n[2024-07-23 22:21:43.767522][INFO][test_dist:274] - iter=48, loss=515.942, sps=3.625e+04, dt=0.00176562, dtf=0.0005655, dtb=0.0012\n[2024-07-23 22:21:43.770555][INFO][test_dist:274] - iter=49, loss=527.433, sps=3.62e+04, dt=0.00176783, dtf=0.0005579, dtb=0.00121\n[2024-07-23 22:21:43.773467][INFO][test_dist:274] - iter=50, loss=520.038, sps=3.938e+04, dt=0.00162521, dtf=0.0005579, dtb=0.001067\n[2024-07-23 22:21:43.776470][INFO][test_dist:274] - iter=51, loss=507.743, sps=3.68e+04, dt=0.00173934, dtf=0.0005378, dtb=0.001202\n[2024-07-23 22:21:43.779466][INFO][test_dist:274] - iter=52, loss=505.372, sps=3.694e+04, dt=0.00173268, dtf=0.0005321, dtb=0.001201\n[2024-07-23 22:21:43.782434][INFO][test_dist:274] - iter=53, loss=505.824, sps=3.736e+04, dt=0.00171324, dtf=0.0005403, dtb=0.001173\n[2024-07-23 22:21:43.785426][INFO][test_dist:274] - iter=54, loss=498.697, sps=3.751e+04, dt=0.00170619, dtf=0.0005259, dtb=0.00118\n[2024-07-23 22:21:43.788396][INFO][test_dist:274] - iter=55, loss=492.434, sps=3.719e+04, dt=0.00172085, dtf=0.0005036, dtb=0.001217\n[2024-07-23 22:21:43.791354][INFO][test_dist:274] - iter=56, loss=486.032, sps=3.754e+04, dt=0.00170497, dtf=0.0005077, dtb=0.001197\n[2024-07-23 22:21:43.794333][INFO][test_dist:274] - iter=57, loss=487.687, sps=3.803e+04, dt=0.00168299, dtf=0.0005009, dtb=0.001182\n[2024-07-23 22:21:43.797238][INFO][test_dist:274] - iter=58, loss=481.011, sps=3.929e+04, dt=0.00162898, dtf=0.0005554, dtb=0.001074\n[2024-07-23 22:21:43.800237][INFO][test_dist:274] - iter=59, loss=478.058, sps=3.692e+04, dt=0.00173365, dtf=0.0005374, dtb=0.001196\n[2024-07-23 22:21:43.803250][INFO][test_dist:274] - iter=60, loss=476.983, sps=3.666e+04, dt=0.00174587, dtf=0.0005318, dtb=0.001214\n[2024-07-23 22:21:43.806222][INFO][test_dist:274] - iter=61, loss=468.415, sps=3.716e+04, dt=0.00172234, dtf=0.0005256, dtb=0.001197\n[2024-07-23 22:21:43.809230][INFO][test_dist:274] - iter=62, loss=461.661, sps=3.727e+04, dt=0.00171737, dtf=0.0005219, dtb=0.001195\n[2024-07-23 22:21:43.812204][INFO][test_dist:274] - iter=63, loss=465.746, sps=3.688e+04, dt=0.00173519, dtf=0.0005067, dtb=0.001228\n[2024-07-23 22:21:43.815192][INFO][test_dist:274] - iter=64, loss=470.95, sps=3.724e+04, dt=0.00171855, dtf=0.0004994, dtb=0.001219\n[2024-07-23 22:21:43.818155][INFO][test_dist:274] - iter=65, loss=463.301, sps=3.774e+04, dt=0.00169586, dtf=0.0005053, dtb=0.001191\n[2024-07-23 22:21:43.821161][INFO][test_dist:274] - iter=66, loss=450.195, sps=3.68e+04, dt=0.00173904, dtf=0.0005626, dtb=0.001176\n[2024-07-23 22:21:43.824143][INFO][test_dist:274] - iter=67, loss=449.097, sps=3.662e+04, dt=0.00174746, dtf=0.0005578, dtb=0.00119\n[2024-07-23 22:21:43.827103][INFO][test_dist:274] - iter=68, loss=447.465, sps=3.778e+04, dt=0.00169412, dtf=0.0005488, dtb=0.001145\n[2024-07-23 22:21:43.830071][INFO][test_dist:274] - iter=69, loss=444.676, sps=3.835e+04, dt=0.00166873, dtf=0.0005467, dtb=0.001122\n[2024-07-23 22:21:43.833030][INFO][test_dist:274] - iter=70, loss=429.532, sps=3.83e+04, dt=0.00167122, dtf=0.0005362, dtb=0.001135\n[2024-07-23 22:21:43.836024][INFO][test_dist:274] - iter=71, loss=437.085, sps=3.711e+04, dt=0.00172438, dtf=0.0005086, dtb=0.001216\n[2024-07-23 22:21:43.839009][INFO][test_dist:274] - iter=72, loss=436.272, sps=3.71e+04, dt=0.00172525, dtf=0.0005177, dtb=0.001208\n[2024-07-23 22:21:43.841920][INFO][test_dist:274] - iter=73, loss=430.464, sps=3.893e+04, dt=0.00164403, dtf=0.0004874, dtb=0.001157\n[2024-07-23 22:21:43.844806][INFO][test_dist:274] - iter=74, loss=426.483, sps=3.904e+04, dt=0.0016393, dtf=0.000449, dtb=0.00119\n[2024-07-23 22:21:43.847771][INFO][test_dist:274] - iter=75, loss=413.371, sps=3.75e+04, dt=0.0017066, dtf=0.0005185, dtb=0.001188\n[2024-07-23 22:21:43.850712][INFO][test_dist:274] - iter=76, loss=421.381, sps=3.77e+04, dt=0.00169769, dtf=0.000506, dtb=0.001192\n[2024-07-23 22:21:43.853587][INFO][test_dist:274] - iter=77, loss=415.112, sps=3.988e+04, dt=0.0016047, dtf=0.000537, dtb=0.001068\n[2024-07-23 22:21:43.856557][INFO][test_dist:274] - iter=78, loss=413.084, sps=3.729e+04, dt=0.0017161, dtf=0.0005459, dtb=0.00117\n[2024-07-23 22:21:43.859518][INFO][test_dist:274] - iter=79, loss=412.671, sps=3.761e+04, dt=0.00170149, dtf=0.0005066, dtb=0.001195\n[2024-07-23 22:21:43.862469][INFO][test_dist:274] - iter=80, loss=408.688, sps=3.776e+04, dt=0.00169481, dtf=0.0005446, dtb=0.00115\n[2024-07-23 22:21:43.865521][INFO][test_dist:274] - iter=81, loss=400.914, sps=3.674e+04, dt=0.00174196, dtf=0.0005528, dtb=0.001189\n[2024-07-23 22:21:43.868536][INFO][test_dist:274] - iter=82, loss=389.823, sps=3.655e+04, dt=0.00175112, dtf=0.000574, dtb=0.001177\n[2024-07-23 22:21:43.871531][INFO][test_dist:274] - iter=83, loss=399.073, sps=3.686e+04, dt=0.00173618, dtf=0.0005504, dtb=0.001186\n[2024-07-23 22:21:43.874511][INFO][test_dist:274] - iter=84, loss=385.773, sps=3.725e+04, dt=0.00171814, dtf=0.0005499, dtb=0.001168\n[2024-07-23 22:21:43.877492][INFO][test_dist:274] - iter=85, loss=400.61, sps=3.739e+04, dt=0.00171182, dtf=0.000546, dtb=0.001166\n[2024-07-23 22:21:43.880505][INFO][test_dist:274] - iter=86, loss=389.813, sps=3.673e+04, dt=0.00174226, dtf=0.0005734, dtb=0.001169\n[2024-07-23 22:21:43.883515][INFO][test_dist:274] - iter=87, loss=385.995, sps=3.694e+04, dt=0.00173256, dtf=0.0005296, dtb=0.001203\n[2024-07-23 22:21:43.886470][INFO][test_dist:274] - iter=88, loss=379.115, sps=3.774e+04, dt=0.00169591, dtf=0.0005467, dtb=0.001149\n[2024-07-23 22:21:43.889422][INFO][test_dist:274] - iter=89, loss=378.738, sps=3.798e+04, dt=0.00168494, dtf=0.0005276, dtb=0.001157\n[2024-07-23 22:21:43.892414][INFO][test_dist:274] - iter=90, loss=365.054, sps=3.675e+04, dt=0.00174164, dtf=0.000513, dtb=0.001229\n[2024-07-23 22:21:43.895367][INFO][test_dist:274] - iter=91, loss=380.372, sps=3.772e+04, dt=0.00169654, dtf=0.000495, dtb=0.001201\n[2024-07-23 22:21:43.898322][INFO][test_dist:274] - iter=92, loss=377.233, sps=3.852e+04, dt=0.00166155, dtf=0.000539, dtb=0.001123\n[2024-07-23 22:21:43.901288][INFO][test_dist:274] - iter=93, loss=366.226, sps=3.788e+04, dt=0.00168959, dtf=0.0005446, dtb=0.001145\n[2024-07-23 22:21:43.904284][INFO][test_dist:274] - iter=94, loss=366.221, sps=3.69e+04, dt=0.00173462, dtf=0.0005535, dtb=0.001181\n[2024-07-23 22:21:43.907289][INFO][test_dist:274] - iter=95, loss=366.673, sps=3.662e+04, dt=0.00174759, dtf=0.0005328, dtb=0.001215\n[2024-07-23 22:21:43.910260][INFO][test_dist:274] - iter=96, loss=362.985, sps=3.716e+04, dt=0.00172234, dtf=0.0005436, dtb=0.001179\n[2024-07-23 22:21:43.913277][INFO][test_dist:274] - iter=97, loss=349.768, sps=3.668e+04, dt=0.00174469, dtf=0.000529, dtb=0.001216\n[2024-07-23 22:21:43.916293][INFO][test_dist:274] - iter=98, loss=363.521, sps=3.675e+04, dt=0.0017416, dtf=0.0005412, dtb=0.0012\n[2024-07-23 22:21:43.919280][INFO][test_dist:274] - iter=99, loss=345.533, sps=3.717e+04, dt=0.00172205, dtf=0.0005134, dtb=0.001209\n                             train/dt [2024-07-23-222143]\n       ‚îÇ\n0.00284‚î§‚ñò\n       ‚îÇ\n       ‚îÇ\n0.00264‚î§\n       ‚îÇ\n       ‚îÇ\n0.00243‚î§\n       ‚îÇ\n0.00222‚î§\n       ‚îÇ\n       ‚îÇ\n0.00201‚î§\n       ‚îÇ‚ñó\n       ‚îÇ ‚ñù‚ñò‚ñó‚ñó‚ññ               ‚ñù\n0.00181‚î§   ‚ñò  ‚ññ         ‚ñó\n       ‚îÇ       ‚ñò‚ñÑ ‚ññ‚ñÑ‚ññ‚ñÑ‚ñó‚ññ ‚ñó‚ñó ‚ñò ‚ñó‚ñÑ‚ñù‚ññ‚ñó‚ñó‚ññ‚ññ‚ññ‚ñó‚ñó‚ñò‚ñÄ ‚ñÑ    ‚ñó‚ñó ‚ñó  ‚ñÑ   ‚ññ     ‚ñó‚ñó‚ññ ‚ññ‚ññ ‚ññ  ‚ñÑ ‚ññ‚ññ\n       ‚îÇ      ‚ñù  ‚ñù      ‚ñò  ‚ñù ‚ñò    ‚ñò    ‚ññ     ‚ñù‚ñò‚ñÄ‚ñó  ‚ñò‚ñò‚ñù‚ñò ‚ñò‚ñÑ‚ñù  ‚ñò‚ñò‚ñù‚ñò‚ñò ‚ñù‚ñù ‚ñù‚ñó‚ñù‚ñó‚ñò ‚ñù ‚ñù\n0.00160‚î§                  ‚ññ          ‚ñó     ‚ñù     ‚ñò          ‚ñÄ ‚ñó\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ\n       1.0              25.5             50.0              74.5            99.0\ntrain/dt                                 iter\n[2024-07-23 22:21:43.943086][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dt.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dt.txt\n                             train/dtf [2024-07-23-222143]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00098‚î§‚ñò                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00089‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00080‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00071‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00063‚î§                                                                       ‚îÇ\n       ‚îÇ ‚ñù‚ñò‚ñÑ  ‚ñû                                                                ‚îÇ\n       ‚îÇ    ‚ñù‚ñò ‚ññ  ‚ññ  ‚ññ  ‚ñó   ‚ññ   ‚ñó  ‚ñó      ‚ññ                       ‚ñó  ‚ññ         ‚îÇ\n0.00054‚î§        ‚ñÄ‚ñù ‚ñû‚ññ    ‚ñù   ‚ñÄ‚ñù‚ñÄ ‚ñò‚ñù ‚ññ‚ñÑ ‚ñù‚ñù‚ñò‚ñù‚ñù‚ññ‚ñó   ‚ñö     ‚ñÄ‚ñò‚ñÑ    ‚ñó‚ñó ‚ñû ‚ñÄ‚ñó ‚ñó  ‚ñó‚ññ‚ñö‚ñó ‚ññ‚îÇ\n       ‚îÇ‚ñù            ‚ñù‚ñù‚ññ‚ññ ‚ñö       ‚ñò   ‚ññ‚ññ    ‚ñù ‚ñò‚ñÑ  ‚ñù‚ñò‚ñö ‚ññ   ‚ñó‚ñò ‚ñò‚ññ ‚ññ     ‚ñò‚ñù‚ññ    ‚ñò‚ñó‚îÇ\n       ‚îÇ                   ‚ñù                    ‚ñù    ‚ñù      ‚ñò           ‚ñù      ‚îÇ\n0.00045‚î§                                                    ‚ñó                  ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/dtf                                iter\n[2024-07-23 22:21:43.952631][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dtf.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dtf.txt\n                             train/dtb [2024-07-23-222143]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00186‚î§‚ñò                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00173‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00160‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00146‚î§                                                                       ‚îÇ\n       ‚îÇ‚ñó                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00133‚î§                     ‚ñó                                                 ‚îÇ\n       ‚îÇ ‚ñù‚ññ ‚ñó‚ññ                                                                 ‚îÇ\n       ‚îÇ   ‚ñû              ‚ñó                                                    ‚îÇ\n0.00120‚î§      ‚ññ‚ññ   ‚ñó ‚ñó‚ñó‚ñò‚ñù  ‚ñó‚ññ  ‚ññ‚ñó‚ññ   ‚ññ‚ñò  ‚ññ‚ñÑ ‚ñÑ  ‚ñö ‚ñó‚ñó‚ññ‚ñû‚ñù    ‚ñù‚ññ    ‚ññ     ‚ññ ‚ñö  ‚ñó ‚ñò‚ñÑ‚îÇ\n       ‚îÇ        ‚ñÄ‚ñó‚ñò‚ñò‚ñò‚ññ  ‚ñò‚ñù   ‚ñò‚ñù‚ñù  ‚ñÄ‚ñù‚ñò  ‚ñÄ‚ñù    ‚ñù‚ñò ‚ñù     ‚ñò‚ñÄ    ‚ñû‚ñò‚ñò‚ñù ‚ñû‚ñù‚ñö‚ñó‚ññ‚ñó‚ñó   ‚ñò‚ñù  ‚îÇ\n       ‚îÇ                                                ‚ñò‚ñû               ‚ñó‚ñò    ‚îÇ\n0.00107‚î§      ‚ñù           ‚ñò          ‚ñó     ‚ñó     ‚ññ            ‚ñó                ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/dtb                                iter\n[2024-07-23 22:21:43.962230][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dtb.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/dtb.txt\n                            train/loss [2024-07-23-222143]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n 2039.9‚î§‚ñò                                                                       ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n 1757.5‚î§                                                                        ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n 1475.1‚î§‚ñó                                                                       ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n 1192.7‚î§                                                                        ‚îÇ\n       ‚îÇ ‚ñù                                                                      ‚îÇ\n       ‚îÇ                                                                        ‚îÇ\n  910.3‚î§  ‚ññ                                                                     ‚îÇ\n       ‚îÇ   ‚ññ                                                                    ‚îÇ\n       ‚îÇ   ‚ñù‚ñù‚ññ‚ñÑ‚ñó                                                                ‚îÇ\n  627.9‚î§        ‚ñò‚ñÄ‚ñò‚ñÄ‚ñù‚ñò‚ñö‚ñó‚ññ‚ñÑ‚ññ‚ñó                                                    ‚îÇ\n       ‚îÇ                   ‚ñò‚ñù‚ñò‚ñÄ‚ñù‚ñò‚ñö‚ñù‚ñÑ‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ññ                                   ‚îÇ\n       ‚îÇ                                    ‚ñù‚ñò‚ñÄ‚ñù‚ñò‚ñÄ‚ñù‚ñò‚ñö‚ññ‚ñö‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚ñó‚ñó                 ‚îÇ\n  345.5‚î§                                                      ‚ñò‚ñù‚ñò‚ñÄ‚ñù‚ñò‚ñÄ‚ñù‚ñÄ‚ñù‚ñò‚ñû‚ñù‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5              50.0             74.5             99.0\ntrain/loss                               iter\n[2024-07-23 22:21:44.011096][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/loss.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/loss.txt\n                           train/iter [2024-07-23-222144]\n     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n 99.0‚î§                                                                      ‚ñó‚ñó‚ññ‚ñÄ‚îÇ\n     ‚îÇ                                                                   ‚ñÑ‚ñù‚ñò‚ñò   ‚îÇ\n     ‚îÇ                                                              ‚ñó‚ññ‚ñû‚ñù‚ñò       ‚îÇ\n 82.7‚î§                                                          ‚ñÑ‚ñó‚ñò‚ñÄ            ‚îÇ\n     ‚îÇ                                                      ‚ññ‚ñÑ‚ñù‚ñò                ‚îÇ\n     ‚îÇ                                                 ‚ñó‚ñó‚ññ‚ñÄ‚ñù                    ‚îÇ\n 66.3‚î§                                              ‚ñÑ‚ñù‚ñò‚ñò                        ‚îÇ\n     ‚îÇ                                         ‚ñó‚ññ‚ñû‚ñù‚ñò                            ‚îÇ\n 50.0‚î§                                     ‚ñÑ‚ñó‚ñò‚ñÄ                                 ‚îÇ\n     ‚îÇ                                 ‚ññ‚ñÑ‚ñù‚ñò                                     ‚îÇ\n     ‚îÇ                            ‚ñó‚ñó‚ññ‚ñÄ‚ñù                                         ‚îÇ\n 33.7‚î§                         ‚ñÑ‚ñù‚ñò‚ñò                                             ‚îÇ\n     ‚îÇ                    ‚ñó‚ññ‚ñû‚ñù‚ñò                                                 ‚îÇ\n     ‚îÇ                ‚ñÑ‚ñó‚ñò‚ñÄ                                                      ‚îÇ\n 17.3‚î§            ‚ññ‚ñÑ‚ñù‚ñò                                                          ‚îÇ\n     ‚îÇ       ‚ñó‚ñó‚ññ‚ñÄ‚ñù                                                              ‚îÇ\n     ‚îÇ    ‚ñÑ‚ñù‚ñò‚ñò                                                                  ‚îÇ\n  1.0‚î§‚ññ‚ñû‚ñù‚ñò                                                                      ‚îÇ\n     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n     1.0              25.5               50.0              74.5             99.0\ntrain/iter                              iter\n[2024-07-23 22:21:44.021040][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/iter.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/iter.txt\n                            train/sps [2024-07-23-222144]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n39979.2‚î§                  ‚ññ          ‚ñù     ‚ñó     ‚ññ            ‚ñù                ‚îÇ\n       ‚îÇ                                                 ‚ñÑ  ‚ñÄ            ‚ñó     ‚îÇ\n       ‚îÇ      ‚ñù  ‚ñó      ‚ññ  ‚ñù      ‚ññ    ‚ñò     ‚ñó‚ññ‚ñó‚ñù   ‚ññ‚ñó‚ñò ‚ñò    ‚ññ‚ññ‚ñó‚ññ‚ñò ‚ñó‚ñó ‚ñù‚ñù‚ñó ‚ñò    ‚îÇ\n37069.3‚î§        ‚ñö ‚ññ‚ñö‚ñò‚ñÄ‚ñù‚ñò ‚ñù‚ñó  ‚ñò‚ñó‚ñû ‚ññ‚ñù‚ñó‚ñò‚ñò‚ñò‚ñó‚ñù‚ññ‚ññ ‚ñÄ  ‚ñò ‚ñù‚ñó‚ñò‚ñù  ‚ñö  ‚ñù‚ñò     ‚ñù‚ñó‚ñò ‚ññ‚ñò ‚ñò  ‚ñö‚ñù‚ññ‚ñÄ‚îÇ\n       ‚îÇ      ‚ññ‚ñò        ‚ñó   ‚ñò   ‚ñù         ‚ñù                                    ‚îÇ\n       ‚îÇ   ‚ñò                                                                   ‚îÇ\n34159.4‚î§ ‚ñó‚ññ‚ñù‚ñù‚ñò               ‚ñó                                                 ‚îÇ\n       ‚îÇ‚ñó                                                                      ‚îÇ\n31249.4‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n28339.5‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n25429.6‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n22519.7‚î§‚ññ                                                                      ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/sps                                iter\n[2024-07-23 22:21:44.030585][INFO][plot:156] - Appending plot to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/sps.txt\ntext saved in /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/test-dist-plots/train/sps.txt\n\n\nPyInstrument Profile:\n\nRecorded: 22:21:41  Samples:  2223\nDuration: 2.668     CPU time: 2.406\nv4.6.2\n\nProgram: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/deps/ezpz/src/ezpz/test_dist.py\n\n2.668 &lt;module&gt;  ezpz/test_dist.py:1\n‚îî‚îÄ 2.667 main  ezpz/test_dist.py:217\n  ‚îú‚îÄ 2.106 build_model_and_optimizer  ezpz/test_dist.py:171\n  ‚îÇ  ‚îî‚îÄ 2.092 Adam.__init__  torch/optim/adam.py:15\n  ‚îÇ        [147 frames hidden]  torch, transformers, jax, huggingface...\n  ‚îú‚îÄ 0.183 _forward_step  ezpz/test_dist.py:231\n  ‚îÇ  ‚îú‚îÄ 0.137 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528\n  ‚îÇ  ‚îÇ     [6 frames hidden]  torch\n  ‚îÇ  ‚îÇ        0.123 Network._call_impl  torch/nn/modules/module.py:1534\n  ‚îÇ  ‚îÇ        ‚îî‚îÄ 0.123 Network.forward  ezpz/test_dist.py:164\n  ‚îÇ  ‚îÇ           ‚îî‚îÄ 0.123 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528\n  ‚îÇ  ‚îÇ                 [7 frames hidden]  torch, &lt;built-in&gt;\n  ‚îÇ  ‚îî‚îÄ 0.046 calc_loss  ezpz/test_dist.py:168\n  ‚îú‚îÄ 0.164 _backward_step  ezpz/test_dist.py:236\n  ‚îÇ  ‚îú‚îÄ 0.103 wrapper  torch/optim/optimizer.py:374\n  ‚îÇ  ‚îÇ     [5 frames hidden]  torch\n  ‚îÇ  ‚îî‚îÄ 0.060 Tensor.backward  torch/_tensor.py:466\n  ‚îÇ        [4 frames hidden]  torch, &lt;built-in&gt;\n  ‚îú‚îÄ 0.113 tplot_dict  ezpz/plot.py:136\n  ‚îÇ  ‚îî‚îÄ 0.082 show  plotext/_core.py:292\n  ‚îÇ        [5 frames hidden]  plotext\n  ‚îî‚îÄ 0.099 Logger.info  logging/__init__.py:1479\n        [6 frames hidden]  logging, rich\n            0.099 RichHandler.emit  rich/logging.py:126\n            ‚îî‚îÄ 0.099 Console.print  ezpz/log/console.py:79\n              ‚îî‚îÄ 0.099 Console.print  rich/console.py:1624\n                    [5 frames hidden]  rich\n\n\n[2024-07-23 22:21:44.231519][INFO][profile:115] - Saving pyinstrument profile output to: /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/ezpz_pyinstrument_profiles\n[2024-07-23 22:21:44.232054][INFO][profile:123] - PyInstrument profile saved (as html) to:  /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-23-222144.html\n[2024-07-23 22:21:44.232619][INFO][profile:131] - PyInstrument profile saved (as text) to:  /lus/eagle/projects/argonne_tpc/foremans/projects/argonne-lcf/tmp/2024-07-23-221253/Megatron-DeepSpeed/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-23-222144.txt\n[2024-07-23 22:21:44.761876][INFO][profile:143] - Finished with pyinstrument profiler. Took: 2.66778s\n[2024-07-23 22:21:44.762534][INFO][test_dist:318] - [0] runtime=6.785542s\nezpz-test-dist.log lines 216-359/359 (END)\n\n\n\n\n\n\nDeprecated:\n\n\nDownload and source ezpz/bin/utils.sh:\nezpz_utils() {\n    fp=$(mktemp)\n    curl -Ls https://raw.githubusercontent.com/saforem2/ezpz/main/src/ezpz/bin/utils.sh &gt; $fp\n    source $fp\n}\nezpz_utils\nUse ezpz_setup_python to:\n\nSetup base conda environment\nCreate2 a virtual environment on top of the base conda environment3\n\n#[üåå][12:45:49 PM][foremans@x3006c0s13b0n0][~/tmp/foremans/2024-07-15-124441]\n$ PBS_O_WORKDIR=$(pwd) ezpz_utils && ezpz_setup_python && ezpz_setup_alcf \n\nUsing WORKING_DIR: /home/foremans/tmp/foremans/2024-07-15-124441\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\n\nLmod is automatically replacing \"nvhpc/23.9\" with \"gcc-native/12.3\".\n\n\nLmod is automatically replacing \"PrgEnv-nvhpc/8.5.0\" with \"PrgEnv-gnu/8.5.0\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n1) cray-mpich/8.1.28\n\nFound conda at: /soft/applications/conda/2024-04-29/mconda3\nNo VIRTUAL_ENV found in environment!\n  - Trying to setup from /soft/applications/conda/2024-04-29/mconda3\n  - Using VENV_DIR=/home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n\n  - Creating a new virtual env on top of 2024-04-29 in /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n[python] Using /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/bin/python3\n\n[ezpz/bin/utils.sh]\n\n[2024-07-15-124600]\n  ‚Ä¢ USER=foremans\n  ‚Ä¢ MACHINE=polaris\n  ‚Ä¢ HOST=x3006c0s13b0n0\n\n[ezpz_setup_host]\n  ‚Ä¢ Using hostfile: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ Found in environment:\n      ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n      ‚Ä¢ Writing PBS vars to: /home/foremans/.pbsenv\n\n[ezpz_save_pbs_env]\n  ‚Ä¢ Setting:\n      ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n      ‚Ä¢ JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n  ‚Ä¢ [host:0] - x3006c0s13b0n0.hsn.cm.polaris.alcf.anl.gov\n\n[DIST INFO]\n  ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ NHOSTS=1\n  ‚Ä¢ NGPU_PER_HOST=4\n  ‚Ä¢ NGPUS=4\n  ‚Ä¢ DIST_LAUNCH=mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n[LAUNCH]:\n  ‚Ä¢ To launch across all available GPUs, use: launch\n    launch = mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n\nInstall ezpz into the virtual environment from 2.\npython3 -m pip install -e \"git+https://github.com/saforem2/ezpz#egg=ezpz\" --require-virtualenv\n\n\noutput\n\nLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nObtaining ezpz from git+https://github.com/saforem2/ezpz#egg=ezpz\nCloning https://github.com/saforem2/ezpz to ./venvs/2024-04-29/src/ezpz\nRunning command git clone --filter=blob:none --quiet https://github.com/saforem2/ezpz /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/src/ezpz\nResolved https://github.com/saforem2/ezpz to commit d8fabca03038db55a1dc490f801581e980f93a25\nInstalling build dependencies ... done\nChecking if build backend supports build_editable ... done\nGetting requirements to build editable ... done\nInstalling backend dependencies ... done\nPreparing editable metadata (pyproject.toml) ... done\nRequirement already satisfied: ambivalent in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (0.0.1)\nRequirement already satisfied: hydra-colorlog in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.2.0)\nRequirement already satisfied: hydra-core in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.3.2)\nRequirement already satisfied: ipython in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (8.24.0)\nRequirement already satisfied: jax in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.4.26)\nRequirement already satisfied: jaxlib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.4.26+cuda12.cudnn89)\nRequirement already satisfied: jaxtyping in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.2.28)\nRequirement already satisfied: joblib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.4.0)\nRequirement already satisfied: ml-dtypes in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.3.2)\nRequirement already satisfied: mpi4py in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (3.1.6)\nRequirement already satisfied: omegaconf in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.3.0)\nRequirement already satisfied: plotext in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (5.2.8)\nCollecting pyinstrument (from ezpz)\nDownloading pyinstrument-4.6.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: rich in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (13.7.1)\nRequirement already satisfied: seaborn in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.13.2)\nRequirement already satisfied: sentencepiece in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (0.2.0)\nRequirement already satisfied: sh in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (2.0.6)\nRequirement already satisfied: tensorboard in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.16.2)\nRequirement already satisfied: torch in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.3.0)\nRequirement already satisfied: tqdm in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (4.65.0)\nRequirement already satisfied: wandb in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.16.6)\nRequirement already satisfied: xarray in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2024.3.0)\nRequirement already satisfied: colormaps in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (0.4.1)\nRequirement already satisfied: matplotlib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (3.8.4)\nRequirement already satisfied: requests in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (2.31.0)\nRequirement already satisfied: colorlog in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-colorlog-&gt;ezpz) (6.8.2)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-core-&gt;ezpz) (4.9.3)\nRequirement already satisfied: packaging in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-core-&gt;ezpz) (24.0)\nRequirement already satisfied: PyYAML&gt;=5.1.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from omegaconf-&gt;ezpz) (6.0.1)\nRequirement already satisfied: decorator in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.1.7)\nRequirement already satisfied: prompt-toolkit&lt;3.1.0,&gt;=3.0.41 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (3.0.43)\nRequirement already satisfied: pygments&gt;=2.4.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (2.17.2)\nRequirement already satisfied: stack-data in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.6.3)\nRequirement already satisfied: traitlets&gt;=5.13.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (5.14.3)\nRequirement already satisfied: typing-extensions&gt;=4.6 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (4.11.0)\nRequirement already satisfied: pexpect&gt;4.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (4.9.0)\nRequirement already satisfied: numpy&gt;=1.22 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (1.26.4)\nRequirement already satisfied: opt-einsum in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (3.3.0)\nRequirement already satisfied: scipy&gt;=1.9 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (1.13.0)\nRequirement already satisfied: typeguard==2.13.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jaxtyping-&gt;ezpz) (2.13.3)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from rich-&gt;ezpz) (3.0.0)\nRequirement already satisfied: pandas&gt;=1.2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from seaborn-&gt;ezpz) (2.2.2)\nRequirement already satisfied: absl-py&gt;=0.4 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (2.1.0)\nRequirement already satisfied: grpcio&gt;=1.48.2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (1.62.2)\nRequirement already satisfied: markdown&gt;=2.6.8 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.6)\nRequirement already satisfied: protobuf!=4.24.0,&gt;=3.19.6 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.20.3)\nRequirement already satisfied: setuptools&gt;=41.0.0 in ./venvs/2024-04-29/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (65.5.0)\nRequirement already satisfied: six&gt;1.9 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (1.16.0)\nRequirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (0.7.2)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.0.2)\nRequirement already satisfied: filelock in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.13.1)\nRequirement already satisfied: sympy in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (1.12)\nRequirement already satisfied: networkx in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.3)\nRequirement already satisfied: jinja2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.0.3)\nRequirement already satisfied: fsspec in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (2024.3.1)\nRequirement already satisfied: Click!=8.0.0,&gt;=7.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,&gt;=1.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (3.1.43)\nRequirement already satisfied: psutil&gt;=5.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (5.9.8)\nRequirement already satisfied: sentry-sdk&gt;=1.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (2.0.1)\nRequirement already satisfied: docker-pycreds&gt;=0.4.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (0.4.0)\nRequirement already satisfied: setproctitle in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (1.3.3)\nRequirement already satisfied: appdirs&gt;=1.4.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (1.4.4)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb-&gt;ezpz) (4.0.11)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;ezpz) (0.8.4)\nRequirement already satisfied: mdurl~=0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;ezpz) (0.1.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (1.2.1)\nRequirement already satisfied: cycler&gt;=0.10 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (1.4.5)\nRequirement already satisfied: pillow&gt;=8 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (10.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (3.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;ezpz) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;ezpz) (2024.1)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;ezpz) (0.7.0)\nRequirement already satisfied: wcwidth in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from prompt-toolkit&lt;3.1.0,&gt;=3.0.41-&gt;ipython-&gt;ezpz) (0.2.13)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2.1.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2024.2.2)\nRequirement already satisfied: MarkupSafe&gt;=2.1.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;ezpz) (2.1.3)\nRequirement already satisfied: executing&gt;=1.2.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (2.0.1)\nRequirement already satisfied: asttokens&gt;=2.1.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (2.4.1)\nRequirement already satisfied: pure-eval in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (0.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from sympy-&gt;torch-&gt;ezpz) (1.3.0)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb-&gt;ezpz) (5.0.1)\nDownloading pyinstrument-4.6.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 104.9/104.9 kB 3.1 MB/s eta 0:00:00\nBuilding wheels for collected packages: ezpz\nBuilding editable for ezpz (pyproject.toml) ... done\nCreated wheel for ezpz: filename=ezpz-0.1-py3-none-any.whl size=10104 sha256=f73fbc552c6192f2d1575c08528267c1c70bd4ed2eebab011c692b4cf66fd9cb\nStored in directory: /tmp/pip-ephem-wheel-cache-6xb0tqk8/wheels/b3/57/90/f3324177d75cbc607a034b5b8e66d5b3d35dcf087967430718\nSuccessfully built ezpz\nInstalling collected packages: pyinstrument, ezpz\nAttempting uninstall: ezpz\n  Found existing installation: ezpz 0.1\n  Not uninstalling ezpz at /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages, outside environment /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n  Cant uninstall 'ezpz'. No files were found to uninstall.\nSuccessfully installed ezpz pyinstrument-4.6.2\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.1.2\n[notice] To update, run: pip install --upgrade pip\n9.63s user 1.44s system 60% cpu 18.301s total\n\n\n#[üåå][12:44:34 PM][foremans@x3006c0s13b0n0][~/tmp]\n$ dname=$USER/$(tstamp) ; mkdir -p $dname && cd $dname\n\n\n#[üåå][12:44:45 PM][foremans@x3006c0s13b0n0][~/tmp/foremans/2024-07-15-124441]\n; ezpz_utils() { fp=$(mktemp) && curl -Ls https://raw.githubusercontent.com/saforem2/ezpz/main/src/ezpz/bin/utils.sh &gt; $fp && source $fp || exit }\n\n\n#[üåå][12:44:47 PM][foremans@x3006c0s13b0n0][~/tmp/foremans/2024-07-15-124441]\n$ PBS_O_WORKDIR=$(pwd) ezpz_utils\nUsing WORKING_DIR: /home/foremans/tmp/foremans/2024-07-15-124441\n\n\n#[üåå][12:45:49 PM][foremans@x3006c0s13b0n0][~/tmp/foremans/2024-07-15-124441]\n$ PBS_O_WORKDIR=$(pwd) ezpz_utils && ezpz_setup_python && ezpz_setup_alcf \n\nUsing WORKING_DIR: /home/foremans/tmp/foremans/2024-07-15-124441\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\n\nLmod is automatically replacing \"nvhpc/23.9\" with \"gcc-native/12.3\".\n\n\nLmod is automatically replacing \"PrgEnv-nvhpc/8.5.0\" with \"PrgEnv-gnu/8.5.0\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.28\n\nFound conda at: /soft/applications/conda/2024-04-29/mconda3\nNo VIRTUAL_ENV found in environment!\n    - Trying to setup from /soft/applications/conda/2024-04-29/mconda3\n    - Using VENV_DIR=/home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n\n    - Creating a new virtual env on top of 2024-04-29 in /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n[python] Using /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/bin/python3\n\n[ezpz/bin/utils.sh]\n\n[2024-07-15-124600]\n    ‚Ä¢ USER=foremans\n    ‚Ä¢ MACHINE=polaris\n    ‚Ä¢ HOST=x3006c0s13b0n0\n\n[ezpz_setup_host]\n    ‚Ä¢ Using hostfile: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n    ‚Ä¢ Found in environment:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n        ‚Ä¢ Writing PBS vars to: /home/foremans/.pbsenv\n\n[ezpz_save_pbs_env]\n    ‚Ä¢ Setting:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n        ‚Ä¢ JOBENV_FILE: /home/foremans/.pbsenv\n\nalias LAUNCH='mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16'\n[HOSTS]\n    ‚Ä¢ [host:0] - x3006c0s13b0n0.hsn.cm.polaris.alcf.anl.gov\n\n[DIST INFO]\n    ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n    ‚Ä¢ NHOSTS=1\n    ‚Ä¢ NGPU_PER_HOST=4\n    ‚Ä¢ NGPUS=4\n    ‚Ä¢ DIST_LAUNCH=mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n[LAUNCH]:\n    ‚Ä¢ To launch across all available GPUs, use: launch\n      launch = mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\nLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nObtaining ezpz from git+https://github.com/saforem2/ezpz#egg=ezpz\n  Cloning https://github.com/saforem2/ezpz to ./venvs/2024-04-29/src/ezpz\n  Running command git clone --filter=blob:none --quiet https://github.com/saforem2/ezpz /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/src/ezpz\n  Resolved https://github.com/saforem2/ezpz to commit d8fabca03038db55a1dc490f801581e980f93a25\n  Installing build dependencies ... done\n  Checking if build backend supports build_editable ... done\n  Getting requirements to build editable ... done\n  Installing backend dependencies ... done\n  Preparing editable metadata (pyproject.toml) ... done\nRequirement already satisfied: ambivalent in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (0.0.1)\nRequirement already satisfied: hydra-colorlog in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.2.0)\nRequirement already satisfied: hydra-core in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.3.2)\nRequirement already satisfied: ipython in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (8.24.0)\nRequirement already satisfied: jax in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.4.26)\nRequirement already satisfied: jaxlib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.4.26+cuda12.cudnn89)\nRequirement already satisfied: jaxtyping in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.2.28)\nRequirement already satisfied: joblib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (1.4.0)\nRequirement already satisfied: ml-dtypes in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.3.2)\nRequirement already satisfied: mpi4py in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (3.1.6)\nRequirement already satisfied: omegaconf in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.3.0)\nRequirement already satisfied: plotext in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (5.2.8)\nCollecting pyinstrument (from ezpz)\n  Downloading pyinstrument-4.6.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: rich in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (13.7.1)\nRequirement already satisfied: seaborn in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.13.2)\nRequirement already satisfied: sentencepiece in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (0.2.0)\nRequirement already satisfied: sh in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ezpz) (2.0.6)\nRequirement already satisfied: tensorboard in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.16.2)\nRequirement already satisfied: torch in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2.3.0)\nRequirement already satisfied: tqdm in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (4.65.0)\nRequirement already satisfied: wandb in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (0.16.6)\nRequirement already satisfied: xarray in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ezpz) (2024.3.0)\nRequirement already satisfied: colormaps in /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (0.4.1)\nRequirement already satisfied: matplotlib in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (3.8.4)\nRequirement already satisfied: requests in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ambivalent-&gt;ezpz) (2.31.0)\nRequirement already satisfied: colorlog in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-colorlog-&gt;ezpz) (6.8.2)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-core-&gt;ezpz) (4.9.3)\nRequirement already satisfied: packaging in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from hydra-core-&gt;ezpz) (24.0)\nRequirement already satisfied: PyYAML&gt;=5.1.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from omegaconf-&gt;ezpz) (6.0.1)\nRequirement already satisfied: decorator in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.1.7)\nRequirement already satisfied: prompt-toolkit&lt;3.1.0,&gt;=3.0.41 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (3.0.43)\nRequirement already satisfied: pygments&gt;=2.4.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (2.17.2)\nRequirement already satisfied: stack-data in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (0.6.3)\nRequirement already satisfied: traitlets&gt;=5.13.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (5.14.3)\nRequirement already satisfied: typing-extensions&gt;=4.6 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (4.11.0)\nRequirement already satisfied: pexpect&gt;4.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from ipython-&gt;ezpz) (4.9.0)\nRequirement already satisfied: numpy&gt;=1.22 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (1.26.4)\nRequirement already satisfied: opt-einsum in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (3.3.0)\nRequirement already satisfied: scipy&gt;=1.9 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jax-&gt;ezpz) (1.13.0)\nRequirement already satisfied: typeguard==2.13.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jaxtyping-&gt;ezpz) (2.13.3)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from rich-&gt;ezpz) (3.0.0)\nRequirement already satisfied: pandas&gt;=1.2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from seaborn-&gt;ezpz) (2.2.2)\nRequirement already satisfied: absl-py&gt;=0.4 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (2.1.0)\nRequirement already satisfied: grpcio&gt;=1.48.2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (1.62.2)\nRequirement already satisfied: markdown&gt;=2.6.8 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.6)\nRequirement already satisfied: protobuf!=4.24.0,&gt;=3.19.6 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.20.3)\nRequirement already satisfied: setuptools&gt;=41.0.0 in ./venvs/2024-04-29/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (65.5.0)\nRequirement already satisfied: six&gt;1.9 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (1.16.0)\nRequirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (0.7.2)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from tensorboard-&gt;ezpz) (3.0.2)\nRequirement already satisfied: filelock in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.13.1)\nRequirement already satisfied: sympy in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (1.12)\nRequirement already satisfied: networkx in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.3)\nRequirement already satisfied: jinja2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (3.0.3)\nRequirement already satisfied: fsspec in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from torch-&gt;ezpz) (2024.3.1)\nRequirement already satisfied: Click!=8.0.0,&gt;=7.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,&gt;=1.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (3.1.43)\nRequirement already satisfied: psutil&gt;=5.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (5.9.8)\nRequirement already satisfied: sentry-sdk&gt;=1.0.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (2.0.1)\nRequirement already satisfied: docker-pycreds&gt;=0.4.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (0.4.0)\nRequirement already satisfied: setproctitle in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (1.3.3)\nRequirement already satisfied: appdirs&gt;=1.4.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from wandb-&gt;ezpz) (1.4.4)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb-&gt;ezpz) (4.0.11)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;ezpz) (0.8.4)\nRequirement already satisfied: mdurl~=0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;ezpz) (0.1.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (1.2.1)\nRequirement already satisfied: cycler&gt;=0.10 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (1.4.5)\nRequirement already satisfied: pillow&gt;=8 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (10.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (3.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from matplotlib-&gt;ambivalent-&gt;ezpz) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;ezpz) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;ezpz) (2024.1)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;ezpz) (0.7.0)\nRequirement already satisfied: wcwidth in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from prompt-toolkit&lt;3.1.0,&gt;=3.0.41-&gt;ipython-&gt;ezpz) (0.2.13)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2.1.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from requests-&gt;ambivalent-&gt;ezpz) (2024.2.2)\nRequirement already satisfied: MarkupSafe&gt;=2.1.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard-&gt;ezpz) (2.1.3)\nRequirement already satisfied: executing&gt;=1.2.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (2.0.1)\nRequirement already satisfied: asttokens&gt;=2.1.0 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (2.4.1)\nRequirement already satisfied: pure-eval in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from stack-data-&gt;ipython-&gt;ezpz) (0.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from sympy-&gt;torch-&gt;ezpz) (1.3.0)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb-&gt;ezpz) (5.0.1)\nDownloading pyinstrument-4.6.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (104 kB)\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 104.9/104.9 kB 3.1 MB/s eta 0:00:00\nBuilding wheels for collected packages: ezpz\n  Building editable for ezpz (pyproject.toml) ... done\n  Created wheel for ezpz: filename=ezpz-0.1-py3-none-any.whl size=10104 sha256=f73fbc552c6192f2d1575c08528267c1c70bd4ed2eebab011c692b4cf66fd9cb\n  Stored in directory: /tmp/pip-ephem-wheel-cache-6xb0tqk8/wheels/b3/57/90/f3324177d75cbc607a034b5b8e66d5b3d35dcf087967430718\nSuccessfully built ezpz\nInstalling collected packages: pyinstrument, ezpz\n  Attempting uninstall: ezpz\n    Found existing installation: ezpz 0.1\n    Not uninstalling ezpz at /home/foremans/.local/polaris/conda/2024-04-29/lib/python3.11/site-packages, outside environment /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29\n    Cant uninstall 'ezpz'. No files were found to uninstall.\nSuccessfully installed ezpz pyinstrument-4.6.2\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.1.2\n[notice] To update, run: pip install --upgrade pip\n9.63s user 1.44s system 60% cpu 18.301s total\nConnected to tcp://x3006c0s13b0n0.hsn.cm.polaris.alcf.anl.gov:7919\nFound executable /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/bin/python3\nLaunching application 5ccc89be-4289-49f5-8b4e-64104021b3c5\n[2024-07-15 12:46:24.601903][INFO][__init__:156] - Setting logging level to 'INFO' on 'RANK == 0'\n[2024-07-15 12:46:24.604160][INFO][__init__:157] - Setting logging level to 'CRITICAL' on all others 'RANK != 0'\n[2024-07-15 12:46:24.604624][INFO][__init__:160] - To disable this behavior, and log from ALL ranks (not recommended), set: 'export LOG_FROM_ALL_RANKS=1'  in your environment, and re-run.\nwandb: WARNING require() unsupported requirement: core\nwandb: ERROR Supported wandb.require() features can be found at: https://wandb.me/library-require\nwandb: WARNING require() unsupported requirement: core\nwandb: ERROR Supported wandb.require() features can be found at: https://wandb.me/library-require\nwandb: WARNING require() unsupported requirement: core\nwandb: ERROR Supported wandb.require() features can be found at: https://wandb.me/library-require\nwandb: WARNING require() unsupported requirement: core\nwandb: ERROR Supported wandb.require() features can be found at: https://wandb.me/library-require\n[2024-07-15 12:46:26.437667][INFO][dist:358] - [device='cuda'][rank=1/3][local_rank=1/3][node=0/0]\n[2024-07-15 12:46:26.437716][INFO][dist:358] - [device='cuda'][rank=3/3][local_rank=3/3][node=0/0]\n[2024-07-15 12:46:26.438619][INFO][dist:358] - [device='cuda'][rank=2/3][local_rank=2/3][node=0/0]\n[2024-07-15 12:46:26.444402][INFO][dist:95] -\n\n[dist_info]:\n  ‚Ä¢ DEVICE=cuda\n  ‚Ä¢ DEVICE_ID=cuda:0\n  ‚Ä¢ DISTRIBUTED_BACKEND=nccl\n  ‚Ä¢ GPUS_PER_NODE=4\n  ‚Ä¢ HOSTS=['x3006c0s13b0n0.hsn.cm.polaris.alcf.anl.gov']\n  ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ HOSTNAME=x3006c0s13b0n0.hsn.cm.polaris.alcf.anl.gov\n  ‚Ä¢ LOCAL_RANK=0\n  ‚Ä¢ MACHINE=Polaris\n  ‚Ä¢ NUM_NODES=1\n  ‚Ä¢ NGPUS=4\n  ‚Ä¢ NGPUS_AVAILABLE=4\n  ‚Ä¢ NODE_ID=0\n  ‚Ä¢ RANK=0\n  ‚Ä¢ SCHEDULER=PBS\n  ‚Ä¢ WORLD_SIZE_TOTAL=4\n  ‚Ä¢ WORLD_SIZE_IN_USE=4\n  ‚Ä¢ LAUNCH_CMD=mpiexec --verbose --envall -n 4 -ppn 4 --hostfile /var/spool/pbs/aux/2021158.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\n\n\n[2024-07-15 12:46:26.447254][INFO][dist:725] - [0/4] Using device='cuda' with backend='DDP' + 'nccl' for distributed training.\n[2024-07-15 12:46:26.451604][INFO][dist:358] - [device='cuda'][rank=0/3][local_rank=0/3][node=0/0]\n[2024-07-15 12:46:26.452120][WARNING][dist:364] - Using [4 / 4] available \"cuda\" devices !!\n[2024-07-15 12:46:26.452676][INFO][dist:95] -\n\n[timers_import]:\n  ‚Ä¢ os=1.1026859283447266e-06\n  ‚Ä¢ logging=4.507601261138916e-07\n  ‚Ä¢ typing=2.9457733035087585e-06\n  ‚Ä¢ pathlib=1.2619420886039734e-06\n  ‚Ä¢ ezpz=6.109476089477539e-07\n  ‚Ä¢ torch=3.5976991057395935e-06\n  ‚Ä¢ torch_ddp=2.3636966943740845e-06\n  ‚Ä¢ wandb=6.36400654911995e-05\n  ‚Ä¢ total=7.597357034683228e-05\n\n\n[2024-07-15 12:46:26.453718][INFO][dist:95] -\n\n[CONFIG]:\n  ‚Ä¢ warmup=0\n  ‚Ä¢ log_freq=1\n  ‚Ä¢ batch_size=64\n  ‚Ä¢ input_size=128\n  ‚Ä¢ output_size=128\n  ‚Ä¢ dtype=torch.float32\n  ‚Ä¢ device=cuda\n  ‚Ä¢ world_size=4\n  ‚Ä¢ train_iters=100\n\n\n[2024-07-15 12:46:28.048558][INFO][test_dist:183] - model=Network(\n  (layers): Sequential(\n    (0): Linear(in_features=128, out_features=1024, bias=True)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=256, bias=True)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n)\n[2024-07-15 12:46:30.303706][INFO][test_dist:274] - iter=1, loss=1977.36, sps=1.829e+04, dt=0.00349948, dtf=0.00097, dtb=0.00253\n[2024-07-15 12:46:30.307445][INFO][test_dist:274] - iter=2, loss=1521.61, sps=3.179e+04, dt=0.00201315, dtf=0.0005266, dtb=0.001487\n[2024-07-15 12:46:30.310480][INFO][test_dist:274] - iter=3, loss=1101.45, sps=3.636e+04, dt=0.00176022, dtf=0.0005615, dtb=0.001199\n[2024-07-15 12:46:30.313460][INFO][test_dist:274] - iter=4, loss=907.963, sps=3.725e+04, dt=0.00171805, dtf=0.0005335, dtb=0.001185\n[2024-07-15 12:46:30.316456][INFO][test_dist:274] - iter=5, loss=842.827, sps=3.698e+04, dt=0.0017307, dtf=0.0005462, dtb=0.001184\n[2024-07-15 12:46:30.319577][INFO][test_dist:274] - iter=6, loss=781.918, sps=3.443e+04, dt=0.00185873, dtf=0.0006062, dtb=0.001253\n[2024-07-15 12:46:30.322847][INFO][test_dist:274] - iter=7, loss=778.317, sps=3.253e+04, dt=0.00196762, dtf=0.0005706, dtb=0.001397\n[2024-07-15 12:46:30.325813][INFO][test_dist:274] - iter=8, loss=746.629, sps=3.746e+04, dt=0.00170848, dtf=0.0005085, dtb=0.0012\n[2024-07-15 12:46:30.328695][INFO][test_dist:274] - iter=9, loss=736.385, sps=3.913e+04, dt=0.00163572, dtf=0.0004885, dtb=0.001147\n[2024-07-15 12:46:30.331672][INFO][test_dist:274] - iter=10, loss=733.067, sps=3.713e+04, dt=0.00172381, dtf=0.0004742, dtb=0.00125\n[2024-07-15 12:46:30.334841][INFO][test_dist:274] - iter=11, loss=729.301, sps=3.342e+04, dt=0.00191528, dtf=0.0003869, dtb=0.001528\n[2024-07-15 12:46:30.338105][INFO][test_dist:274] - iter=12, loss=701.243, sps=3.198e+04, dt=0.00200144, dtf=0.0004697, dtb=0.001532\n[2024-07-15 12:46:30.340953][INFO][test_dist:274] - iter=13, loss=681.563, sps=4.088e+04, dt=0.00156543, dtf=0.0004341, dtb=0.001131\n[2024-07-15 12:46:30.343843][INFO][test_dist:274] - iter=14, loss=685.259, sps=4.053e+04, dt=0.00157891, dtf=0.0004456, dtb=0.001133\n[2024-07-15 12:46:30.346744][INFO][test_dist:274] - iter=15, loss=678.99, sps=3.935e+04, dt=0.00162651, dtf=0.0004026, dtb=0.001224\n[2024-07-15 12:46:30.349674][INFO][test_dist:274] - iter=16, loss=672.654, sps=3.801e+04, dt=0.00168398, dtf=0.0004565, dtb=0.001227\n[2024-07-15 12:46:30.352400][INFO][test_dist:274] - iter=17, loss=660.552, sps=4.319e+04, dt=0.00148184, dtf=0.0003963, dtb=0.001085\n[2024-07-15 12:46:30.355521][INFO][test_dist:274] - iter=18, loss=640.175, sps=3.408e+04, dt=0.00187814, dtf=0.0005312, dtb=0.001347\n[2024-07-15 12:46:30.358530][INFO][test_dist:274] - iter=19, loss=645.41, sps=3.65e+04, dt=0.00175325, dtf=0.0004639, dtb=0.001289\n[2024-07-15 12:46:30.361515][INFO][test_dist:274] - iter=20, loss=649.203, sps=3.675e+04, dt=0.00174155, dtf=0.0004799, dtb=0.001262\n[2024-07-15 12:46:30.364256][INFO][test_dist:274] - iter=21, loss=633.891, sps=4.277e+04, dt=0.00149629, dtf=0.000416, dtb=0.00108\n[2024-07-15 12:46:30.367135][INFO][test_dist:274] - iter=22, loss=623.202, sps=3.892e+04, dt=0.00164444, dtf=0.0004509, dtb=0.001194\n[2024-07-15 12:46:30.370090][INFO][test_dist:274] - iter=23, loss=623.178, sps=3.771e+04, dt=0.00169695, dtf=0.0004252, dtb=0.001272\n[2024-07-15 12:46:30.373119][INFO][test_dist:274] - iter=24, loss=626.489, sps=3.69e+04, dt=0.00173444, dtf=0.0004551, dtb=0.001279\n[2024-07-15 12:46:30.375951][INFO][test_dist:274] - iter=25, loss=636.674, sps=4.089e+04, dt=0.0015651, dtf=0.0004223, dtb=0.001143\n[2024-07-15 12:46:30.378913][INFO][test_dist:274] - iter=26, loss=639.64, sps=3.758e+04, dt=0.00170305, dtf=0.0004532, dtb=0.00125\n[2024-07-15 12:46:30.381808][INFO][test_dist:274] - iter=27, loss=605.015, sps=3.874e+04, dt=0.00165192, dtf=0.0004257, dtb=0.001226\n[2024-07-15 12:46:30.384573][INFO][test_dist:274] - iter=28, loss=603.894, sps=4.244e+04, dt=0.00150807, dtf=0.0004296, dtb=0.001078\n[2024-07-15 12:46:30.387388][INFO][test_dist:274] - iter=29, loss=619.885, sps=4.03e+04, dt=0.00158808, dtf=0.0004196, dtb=0.001168\n[2024-07-15 12:46:30.390148][INFO][test_dist:274] - iter=30, loss=589.771, sps=4.21e+04, dt=0.0015203, dtf=0.0004438, dtb=0.001076\n[2024-07-15 12:46:30.392838][INFO][test_dist:274] - iter=31, loss=595.523, sps=4.381e+04, dt=0.001461, dtf=0.0004153, dtb=0.001046\n[2024-07-15 12:46:30.395622][INFO][test_dist:274] - iter=32, loss=605.537, sps=4.104e+04, dt=0.00155956, dtf=0.0004367, dtb=0.001123\n[2024-07-15 12:46:30.398489][INFO][test_dist:274] - iter=33, loss=586.025, sps=3.913e+04, dt=0.00163565, dtf=0.0003743, dtb=0.001261\n[2024-07-15 12:46:30.401355][INFO][test_dist:274] - iter=34, loss=577.14, sps=3.877e+04, dt=0.0016506, dtf=0.0004581, dtb=0.001192\n[2024-07-15 12:46:30.404092][INFO][test_dist:274] - iter=35, loss=568.886, sps=4.383e+04, dt=0.00146019, dtf=0.0003966, dtb=0.001064\n[2024-07-15 12:46:30.406843][INFO][test_dist:274] - iter=36, loss=567.26, sps=4.228e+04, dt=0.00151377, dtf=0.0004537, dtb=0.00106\n[2024-07-15 12:46:30.409591][INFO][test_dist:274] - iter=37, loss=574.633, sps=4.226e+04, dt=0.00151457, dtf=0.0003845, dtb=0.00113\n[2024-07-15 12:46:30.412347][INFO][test_dist:274] - iter=38, loss=557.928, sps=4.212e+04, dt=0.00151945, dtf=0.000457, dtb=0.001062\n[2024-07-15 12:46:30.415130][INFO][test_dist:274] - iter=39, loss=558.186, sps=4.135e+04, dt=0.00154767, dtf=0.0003975, dtb=0.00115\n[2024-07-15 12:46:30.417880][INFO][test_dist:274] - iter=40, loss=553.377, sps=4.233e+04, dt=0.00151185, dtf=0.0004556, dtb=0.001056\n[2024-07-15 12:46:30.420583][INFO][test_dist:274] - iter=41, loss=542.918, sps=4.394e+04, dt=0.00145645, dtf=0.0003928, dtb=0.001064\n[2024-07-15 12:46:30.423489][INFO][test_dist:274] - iter=42, loss=547.64, sps=3.827e+04, dt=0.00167242, dtf=0.0004762, dtb=0.001196\n[2024-07-15 12:46:30.426243][INFO][test_dist:274] - iter=43, loss=546.106, sps=4.22e+04, dt=0.00151648, dtf=0.0004665, dtb=0.00105\n[2024-07-15 12:46:30.428998][INFO][test_dist:274] - iter=44, loss=535.946, sps=4.209e+04, dt=0.0015204, dtf=0.0004679, dtb=0.001053\n[2024-07-15 12:46:30.431749][INFO][test_dist:274] - iter=45, loss=534.731, sps=4.324e+04, dt=0.00148002, dtf=0.0003821, dtb=0.001098\n[2024-07-15 12:46:30.434709][INFO][test_dist:274] - iter=46, loss=520.207, sps=3.74e+04, dt=0.00171109, dtf=0.0004486, dtb=0.001263\n[2024-07-15 12:46:30.437524][INFO][test_dist:274] - iter=47, loss=527.301, sps=4.191e+04, dt=0.00152713, dtf=0.0004943, dtb=0.001033\n[2024-07-15 12:46:30.440277][INFO][test_dist:274] - iter=48, loss=516.108, sps=4.279e+04, dt=0.00149561, dtf=0.0004418, dtb=0.001054\n[2024-07-15 12:46:30.443029][INFO][test_dist:274] - iter=49, loss=516.086, sps=4.231e+04, dt=0.00151262, dtf=0.0003899, dtb=0.001123\n[2024-07-15 12:46:30.445895][INFO][test_dist:274] - iter=50, loss=508.945, sps=3.922e+04, dt=0.00163198, dtf=0.0004333, dtb=0.001199\n[2024-07-15 12:46:30.448667][INFO][test_dist:274] - iter=51, loss=513.235, sps=4.163e+04, dt=0.00153721, dtf=0.0004863, dtb=0.001051\n[2024-07-15 12:46:30.451581][INFO][test_dist:274] - iter=52, loss=511.549, sps=3.822e+04, dt=0.00167444, dtf=0.0004698, dtb=0.001205\n[2024-07-15 12:46:30.454412][INFO][test_dist:274] - iter=53, loss=510.211, sps=4.042e+04, dt=0.00158328, dtf=0.0004193, dtb=0.001164\n[2024-07-15 12:46:30.457220][INFO][test_dist:274] - iter=54, loss=492.431, sps=4.151e+04, dt=0.00154189, dtf=0.0004324, dtb=0.001109\n[2024-07-15 12:46:30.460039][INFO][test_dist:274] - iter=55, loss=499.074, sps=4.121e+04, dt=0.00155284, dtf=0.0005013, dtb=0.001052\n[2024-07-15 12:46:30.462836][INFO][test_dist:274] - iter=56, loss=490.718, sps=4.108e+04, dt=0.0015581, dtf=0.0004388, dtb=0.001119\n[2024-07-15 12:46:30.465621][INFO][test_dist:274] - iter=57, loss=493.223, sps=4.157e+04, dt=0.00153946, dtf=0.0003867, dtb=0.001153\n[2024-07-15 12:46:30.468390][INFO][test_dist:274] - iter=58, loss=486.601, sps=4.256e+04, dt=0.00150368, dtf=0.0004462, dtb=0.001057\n[2024-07-15 12:46:30.471148][INFO][test_dist:274] - iter=59, loss=473.609, sps=4.326e+04, dt=0.00147947, dtf=0.0004221, dtb=0.001057\n[2024-07-15 12:46:30.473847][INFO][test_dist:274] - iter=60, loss=478.577, sps=4.378e+04, dt=0.00146188, dtf=0.0004284, dtb=0.001033\n[2024-07-15 12:46:30.476547][INFO][test_dist:274] - iter=61, loss=475.991, sps=4.387e+04, dt=0.00145878, dtf=0.0003923, dtb=0.001066\n[2024-07-15 12:46:30.479447][INFO][test_dist:274] - iter=62, loss=471.526, sps=3.859e+04, dt=0.00165854, dtf=0.0004523, dtb=0.001206\n[2024-07-15 12:46:30.482180][INFO][test_dist:274] - iter=63, loss=460.986, sps=4.277e+04, dt=0.00149626, dtf=0.0003914, dtb=0.001105\n[2024-07-15 12:46:30.484857][INFO][test_dist:274] - iter=64, loss=464.409, sps=4.404e+04, dt=0.00145311, dtf=0.0004247, dtb=0.001028\n[2024-07-15 12:46:30.487652][INFO][test_dist:274] - iter=65, loss=458.023, sps=4.104e+04, dt=0.00155961, dtf=0.0003934, dtb=0.001166\n[2024-07-15 12:46:30.490474][INFO][test_dist:274] - iter=66, loss=456.718, sps=4.013e+04, dt=0.00159499, dtf=0.000416, dtb=0.001179\n[2024-07-15 12:46:30.493187][INFO][test_dist:274] - iter=67, loss=451.993, sps=4.296e+04, dt=0.00148977, dtf=0.000395, dtb=0.001095\n[2024-07-15 12:46:30.495894][INFO][test_dist:274] - iter=68, loss=454.66, sps=4.4e+04, dt=0.0014545, dtf=0.000425, dtb=0.001029\n[2024-07-15 12:46:30.498664][INFO][test_dist:274] - iter=69, loss=451.727, sps=4.17e+04, dt=0.00153459, dtf=0.0003837, dtb=0.001151\n[2024-07-15 12:46:30.501502][INFO][test_dist:274] - iter=70, loss=440.922, sps=4.015e+04, dt=0.00159391, dtf=0.0004272, dtb=0.001167\n[2024-07-15 12:46:30.504271][INFO][test_dist:274] - iter=71, loss=442.788, sps=4.322e+04, dt=0.00148083, dtf=0.0004178, dtb=0.001063\n[2024-07-15 12:46:30.507000][INFO][test_dist:274] - iter=72, loss=439.069, sps=4.307e+04, dt=0.00148594, dtf=0.0004285, dtb=0.001057\n[2024-07-15 12:46:30.509755][INFO][test_dist:274] - iter=73, loss=430.236, sps=4.211e+04, dt=0.00151976, dtf=0.0003829, dtb=0.001137\n[2024-07-15 12:46:30.512494][INFO][test_dist:274] - iter=74, loss=428.951, sps=4.318e+04, dt=0.00148219, dtf=0.0004357, dtb=0.001046\n[2024-07-15 12:46:30.515244][INFO][test_dist:274] - iter=75, loss=430.417, sps=4.253e+04, dt=0.00150487, dtf=0.0004357, dtb=0.001069\n[2024-07-15 12:46:30.517921][INFO][test_dist:274] - iter=76, loss=416.647, sps=4.401e+04, dt=0.00145412, dtf=0.0004374, dtb=0.001017\n[2024-07-15 12:46:30.520610][INFO][test_dist:274] - iter=77, loss=422.518, sps=4.468e+04, dt=0.0014323, dtf=0.0003941, dtb=0.001038\n[2024-07-15 12:46:30.523343][INFO][test_dist:274] - iter=78, loss=412.028, sps=4.272e+04, dt=0.00149821, dtf=0.0004521, dtb=0.001046\n[2024-07-15 12:46:30.526016][INFO][test_dist:274] - iter=79, loss=406.225, sps=4.473e+04, dt=0.00143094, dtf=0.0003893, dtb=0.001042\n[2024-07-15 12:46:30.528730][INFO][test_dist:274] - iter=80, loss=402.887, sps=4.382e+04, dt=0.00146036, dtf=0.0004402, dtb=0.00102\n[2024-07-15 12:46:30.531536][INFO][test_dist:274] - iter=81, loss=397.311, sps=4.069e+04, dt=0.0015729, dtf=0.000404, dtb=0.001169\n[2024-07-15 12:46:30.534242][INFO][test_dist:274] - iter=82, loss=411.916, sps=4.39e+04, dt=0.00145795, dtf=0.0004351, dtb=0.001023\n[2024-07-15 12:46:30.537005][INFO][test_dist:274] - iter=83, loss=402.795, sps=4.366e+04, dt=0.00146599, dtf=0.0004252, dtb=0.001041\n[2024-07-15 12:46:30.539805][INFO][test_dist:274] - iter=84, loss=391.05, sps=4.1e+04, dt=0.00156095, dtf=0.0004323, dtb=0.001129\n[2024-07-15 12:46:30.542590][INFO][test_dist:274] - iter=85, loss=383.782, sps=4.118e+04, dt=0.00155416, dtf=0.000388, dtb=0.001166\n[2024-07-15 12:46:30.545290][INFO][test_dist:274] - iter=86, loss=399.543, sps=4.396e+04, dt=0.00145595, dtf=0.0004339, dtb=0.001022\n[2024-07-15 12:46:30.547992][INFO][test_dist:274] - iter=87, loss=379.003, sps=4.456e+04, dt=0.00143613, dtf=0.0004131, dtb=0.001023\n[2024-07-15 12:46:30.550837][INFO][test_dist:274] - iter=88, loss=372.048, sps=3.998e+04, dt=0.00160092, dtf=0.0004375, dtb=0.001163\n[2024-07-15 12:46:30.553641][INFO][test_dist:274] - iter=89, loss=376.187, sps=4.137e+04, dt=0.0015471, dtf=0.0004142, dtb=0.001133\n[2024-07-15 12:46:30.556354][INFO][test_dist:274] - iter=90, loss=372.281, sps=4.408e+04, dt=0.00145186, dtf=0.0004239, dtb=0.001028\n[2024-07-15 12:46:30.559101][INFO][test_dist:274] - iter=91, loss=370.701, sps=4.252e+04, dt=0.00150523, dtf=0.0004545, dtb=0.001051\n[2024-07-15 12:46:30.561884][INFO][test_dist:274] - iter=92, loss=356.074, sps=4.191e+04, dt=0.00152712, dtf=0.0004291, dtb=0.001098\n[2024-07-15 12:46:30.564556][INFO][test_dist:274] - iter=93, loss=360.663, sps=4.468e+04, dt=0.00143241, dtf=0.0003938, dtb=0.001039\n[2024-07-15 12:46:30.567287][INFO][test_dist:274] - iter=94, loss=374.599, sps=4.296e+04, dt=0.0014897, dtf=0.0004539, dtb=0.001036\n[2024-07-15 12:46:30.570088][INFO][test_dist:274] - iter=95, loss=364.476, sps=4.253e+04, dt=0.00150469, dtf=0.0004189, dtb=0.001086\n[2024-07-15 12:46:30.572767][INFO][test_dist:274] - iter=96, loss=358.992, sps=4.415e+04, dt=0.00144967, dtf=0.0004295, dtb=0.00102\n[2024-07-15 12:46:30.575567][INFO][test_dist:274] - iter=97, loss=354.959, sps=4.092e+04, dt=0.0015641, dtf=0.0004054, dtb=0.001159\n[2024-07-15 12:46:30.578287][INFO][test_dist:274] - iter=98, loss=345.644, sps=4.374e+04, dt=0.00146311, dtf=0.0004197, dtb=0.001043\n[2024-07-15 12:46:30.580996][INFO][test_dist:274] - iter=99, loss=348.209, sps=4.391e+04, dt=0.00145758, dtf=0.0004263, dtb=0.001031\n                             train/dt [2024-07-15-124630]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00350‚î§‚ñò                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00315‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00281‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00247‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00212‚î§                                                                       ‚îÇ\n       ‚îÇ‚ñó       ‚ññ                                                              ‚îÇ\n       ‚îÇ    ‚ñù  ‚ññ    ‚ññ                                                          ‚îÇ\n0.00178‚î§ ‚ñó ‚ñù                                                                   ‚îÇ\n       ‚îÇ  ‚ñò‚ñò ‚ñò‚ñù    ‚ññ ‚ñÄ ‚ññ‚ñÄ ‚ñö    ‚ñó     ‚ñó  ‚ñù   ‚ñó       ‚ññ                          ‚îÇ\n       ‚îÇ      ‚ñò ‚ñó‚ñù‚ñò      ‚ñó  ‚ñò‚ññ‚ñó‚ñò   ‚ñó   ‚ññ ‚ññ ‚ñù‚ññ‚ñù‚ññ‚ñÑ‚ñó     ‚ññ‚ñò ‚ñû  ‚ññ    ‚ñó ‚ñó‚ñó ‚ñù‚ñó ‚ñó   ‚ññ ‚îÇ\n0.00143‚î§           ‚ñù  ‚ñù    ‚ñù ‚ñù  ‚ñó‚ñò‚ñÄ ‚ñò‚ññ‚ñò‚ñù  ‚ñÄ      ‚ñÄ‚ñù‚ññ‚ñù‚ñó ‚ñù‚ññ ‚ñù‚ñò‚ñù‚ñò‚ñÑ‚ñù‚ññ‚ññ‚ñó‚ñò ‚ññ‚ññ ‚ñû ‚ññ‚ñÄ‚ñó ‚ñö‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/dt                                 iter\n[2024-07-15 12:46:30.627053][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dt.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dt.txt\n                             train/dtf [2024-07-15-124630]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00097‚î§‚ñò                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00087‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00077‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00067‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ   ‚ñó                                                                   ‚îÇ\n0.00057‚î§    ‚ñó                                                                  ‚îÇ\n       ‚îÇ ‚ñù ‚ññ                                                                   ‚îÇ\n       ‚îÇ‚ñù ‚ñò  ‚ññ      ‚ñò                                                          ‚îÇ\n0.00047‚î§      ‚ñö ‚ññ    ‚ñó               ‚ñó ‚ññ ‚ñò  ‚ñö  ‚ñò                               ‚îÇ\n       ‚îÇ        ‚ñó‚ñó ‚ñò ‚ñò ‚ñò‚ñù ‚ñò  ‚ññ‚ñó‚ñù ‚ñò‚ñù ‚ñò ‚ñò ‚ñó ‚ññ    ‚ñó ‚ññ  ‚ñò       ‚ñó‚ññ‚ññ‚ñù ‚ññ‚ñó  ‚ññ‚ñó ‚ñù  ‚ñò   ‚îÇ\n       ‚îÇ          ‚ññ   ‚ñó ‚ñò‚ñù‚ñù‚ñù‚ñò‚ñó             ‚ñù ‚ñù‚ñò  ‚ñù‚ñù  ‚ñù ‚ññ‚ñò‚ñù‚ñù‚ñò     ‚ñó ‚ñÄ  ‚ññ‚ñó‚ñò‚ñù ‚ñù‚ñù‚ññ‚ñÄ‚îÇ\n0.00037‚î§       ‚ñò   ‚ñù           ‚ññ‚ñù ‚ñò‚ñù ‚ñò ‚ñó  ‚ñù     ‚ñù  ‚ñò‚ñù ‚ñò‚ñù ‚ñò  ‚ñò ‚ñù ‚ñò   ‚ñù     ‚ñò    ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/dtf                                iter\n[2024-07-15 12:46:30.638406][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dtf.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dtf.txt\n                             train/dtb [2024-07-15-124630]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00253‚î§‚ñò                                                                      ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00228‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00203‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00177‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n0.00152‚î§       ‚ññ‚ññ                                                              ‚îÇ\n       ‚îÇ‚ñù                                                                      ‚îÇ\n       ‚îÇ    ‚ñù       ‚ññ                                                          ‚îÇ\n0.00127‚î§             ‚ñÑ  ‚ñÑ      ‚ññ        ‚ñó                                      ‚îÇ\n       ‚îÇ ‚ñó‚ññ‚ñû ‚ññ‚ñù   ‚ñò‚ñò   ‚ññ  ‚ñÄ ‚ññ  ‚ñó     ‚ñó     ‚ñó‚ñó       ‚ññ  ‚ññ         ‚ñó             ‚îÇ\n       ‚îÇ      ‚ñò ‚ñù‚ñù ‚ñó     ‚ñù    ‚ñó   ‚ñò‚ñù   ‚ñó  ‚ñó  ‚ñù‚ññ‚ñó‚ñù   ‚ñó ‚ñò‚ñó ‚ñÄ  ‚ñò      ‚ñù‚ñù ‚ñù‚ñù ‚ñó ‚ñó ‚ñò ‚îÇ\n0.00102‚î§              ‚ñù    ‚ñù ‚ñÄ  ‚ñù‚ñò‚ñù ‚ñò‚ñò‚ñò‚ñò ‚ññ‚ñò ‚ñò  ‚ñò ‚ñÄ‚ñó‚ñò ‚ñó  ‚ññ ‚ñù‚ñò‚ñù‚ñò‚ñÑ‚ñù‚ñò‚ññ‚ñó‚ñò ‚ññ‚ññ ‚ñû ‚ñò‚ññ‚ñó ‚ñö‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/dtb                                iter\n[2024-07-15 12:46:30.648950][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dtb.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/dtb.txt\n                            train/loss [2024-07-15-124630]\n      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n1977.4‚î§‚ñò                                                                       ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n1705.4‚î§                                                                        ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n      ‚îÇ‚ñù                                                                       ‚îÇ\n1433.5‚î§                                                                        ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n1161.5‚î§ ‚ñó                                                                      ‚îÇ\n      ‚îÇ                                                                        ‚îÇ\n 889.5‚î§  ‚ññ                                                                     ‚îÇ\n      ‚îÇ   ‚ñò                                                                    ‚îÇ\n      ‚îÇ   ‚ñù‚ñù‚ñò‚ñÑ‚ñó‚ññ                                                               ‚îÇ\n 617.6‚î§         ‚ñÄ‚ñò‚ñÄ‚ñó‚ññ‚ñö‚ñó‚ññ‚ñÑ‚ññ‚ñÑ‚ñó ‚ñó                                                 ‚îÇ\n      ‚îÇ                     ‚ñò‚ñò‚ñù‚ñò‚ñÄ‚ñù‚ñÄ‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚ññ‚ññ                                 ‚îÇ\n      ‚îÇ                                      ‚ñù‚ñù‚ñò‚ñÄ‚ñù‚ñò‚ñÄ‚ññ‚ñö‚ñó‚ññ‚ñÑ‚ñó‚ññ‚ñÑ‚ñó‚ñÑ‚ñó                ‚îÇ\n 345.6‚î§                                                        ‚ñò‚ñÄ‚ñù‚ñò‚ñÄ‚ñù‚ñÄ‚ñù‚ñò‚ñÄ‚ñó‚ññ‚ñö‚ñó‚ññ‚ñÑ‚îÇ\n      ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n      1.0              25.5              50.0             74.5             99.0\ntrain/loss                               iter\n[2024-07-15 12:46:30.702717][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/loss.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/loss.txt\n                           train/iter [2024-07-15-124630]\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n99.0‚î§                                                                      ‚ñó‚ñó‚ññ‚ñÄ‚îÇ\n    ‚îÇ                                                                   ‚ñÑ‚ñù‚ñò‚ñò   ‚îÇ\n    ‚îÇ                                                              ‚ñó‚ññ‚ñû‚ñù‚ñò       ‚îÇ\n82.7‚î§                                                          ‚ñÑ‚ñó‚ñò‚ñÄ            ‚îÇ\n    ‚îÇ                                                      ‚ññ‚ñÑ‚ñù‚ñò                ‚îÇ\n    ‚îÇ                                                 ‚ñó‚ñó‚ññ‚ñÄ‚ñù                    ‚îÇ\n66.3‚î§                                              ‚ñÑ‚ñù‚ñò‚ñò                        ‚îÇ\n    ‚îÇ                                         ‚ñó‚ññ‚ñû‚ñù‚ñò                            ‚îÇ\n50.0‚î§                                     ‚ñÑ‚ñó‚ñò‚ñÄ                                 ‚îÇ\n    ‚îÇ                                 ‚ññ‚ñÑ‚ñù‚ñò                                     ‚îÇ\n    ‚îÇ                            ‚ñó‚ñó‚ññ‚ñÄ‚ñù                                         ‚îÇ\n33.7‚î§                         ‚ñÑ‚ñù‚ñò‚ñò                                             ‚îÇ\n    ‚îÇ                    ‚ñó‚ññ‚ñû‚ñù‚ñò                                                 ‚îÇ\n    ‚îÇ                ‚ñÑ‚ñó‚ñò‚ñÄ                                                      ‚îÇ\n17.3‚î§            ‚ññ‚ñÑ‚ñù‚ñò                                                          ‚îÇ\n    ‚îÇ       ‚ñó‚ñó‚ññ‚ñÄ‚ñù                                                              ‚îÇ\n    ‚îÇ    ‚ñÑ‚ñù‚ñò‚ñò                                                                  ‚îÇ\n 1.0‚î§‚ññ‚ñû‚ñù‚ñò                                                                      ‚îÇ\n    ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n    1.0              25.5               50.0              74.5             99.0\ntrain/iter                              iter\n[2024-07-15 12:46:30.714042][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/iter.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/iter.txt\n                             train/sps [2024-07-15-124630]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n44725.9‚î§                     ‚ñó  ‚ñó    ‚ññ            ‚ñó‚ññ ‚ñó  ‚ññ     ‚ñû ‚ñò‚ññ‚ñó‚ññ ‚ññ‚ñò ‚ññ ‚ñò ‚ñó ‚ñÑ‚îÇ\n       ‚îÇ           ‚ñù  ‚ñó    ‚ñó ‚ññ   ‚ññ‚ñÑ ‚ññ ‚ññ‚ñû  ‚ñÑ      ‚ñû  ‚ñó  ‚ñù  ‚ñù‚ñò‚ñû‚ññ ‚ñó        ‚ñó  ‚ñö   ‚îÇ\n       ‚îÇ        ‚ñó        ‚ñó    ‚ñó    ‚ñù     ‚ñò  ‚ñò ‚ñò‚ñÑ‚ñù     ‚ññ  ‚ñò       ‚ñó ‚ñó‚ñó  ‚ñù ‚ñù   ‚ññ ‚îÇ\n40319.7‚î§      ‚ññ  ‚ñù‚ññ         ‚ñò  ‚ññ           ‚ñó ‚ñù         ‚ñò ‚ñù            ‚ñù        ‚îÇ\n       ‚îÇ           ‚ññ   ‚ñò‚ññ ‚ñû    ‚ñù     ‚ñó      ‚ñó       ‚ñò                          ‚îÇ\n       ‚îÇ ‚ñó‚ñò‚ñò ‚ñò‚ñù      ‚ñÑ  ‚ñù               ‚ñù                                      ‚îÇ\n35913.4‚î§                                                                       ‚îÇ\n       ‚îÇ   ‚ñù   ‚ññ    ‚ñò                                                          ‚îÇ\n31507.2‚î§‚ñó   ‚ñù   ‚ññ                                                              ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n27100.9‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n22694.7‚î§                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n       ‚îÇ                                                                       ‚îÇ\n18288.4‚î§‚ññ                                                                      ‚îÇ\n       ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò\n       1.0              25.5             50.0              74.5            99.0\ntrain/sps                                iter\n[2024-07-15 12:46:30.724919][INFO][plot:156] - Appending plot to: /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/sps.txt\ntext saved in /home/foremans/tmp/foremans/2024-07-15-124441/test-dist-plots/train/sps.txt\n\n  _     ._   __/__   _ _  _  _ _/_   Recorded: 12:46:28  Samples:  2182\n /_//_/// /_\\ / //_// / //_'/ //     Duration: 2.688     CPU time: 2.356\n/   _/                      v4.6.2\n\nProgram: /home/foremans/tmp/foremans/2024-07-15-124441/venvs/2024-04-29/src/ezpz/src/ezpz/test_dist.py\n\n2.688 &lt;module&gt;  ezpz/test_dist.py:1\n‚îî‚îÄ 2.687 main  ezpz/test_dist.py:217\n   ‚îú‚îÄ 2.104 build_model_and_optimizer  ezpz/test_dist.py:171\n   ‚îÇ  ‚îî‚îÄ 2.089 Adam.__init__  torch/optim/adam.py:15\n   ‚îÇ        [142 frames hidden]  torch, transformers, jax, huggingface...\n   ‚îú‚îÄ 0.199 _backward_step  ezpz/test_dist.py:236\n   ‚îÇ  ‚îú‚îÄ 0.104 Tensor.backward  torch/_tensor.py:466\n   ‚îÇ  ‚îÇ     [4 frames hidden]  torch, &lt;built-in&gt;\n   ‚îÇ  ‚îî‚îÄ 0.094 wrapper  torch/optim/optimizer.py:374\n   ‚îÇ        [6 frames hidden]  torch, &lt;built-in&gt;\n   ‚îú‚îÄ 0.145 tplot_dict  ezpz/plot.py:136\n   ‚îÇ  ‚îú‚îÄ 0.085 show  plotext/_core.py:292\n   ‚îÇ  ‚îÇ     [5 frames hidden]  plotext\n   ‚îÇ  ‚îî‚îÄ 0.031 &lt;module&gt;  plotext/__init__.py:1\n   ‚îú‚îÄ 0.136 _forward_step  ezpz/test_dist.py:231\n   ‚îÇ  ‚îú‚îÄ 0.084 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528\n   ‚îÇ  ‚îÇ     [6 frames hidden]  torch\n   ‚îÇ  ‚îÇ        0.071 Network._call_impl  torch/nn/modules/module.py:1534\n   ‚îÇ  ‚îÇ        ‚îî‚îÄ 0.071 Network.forward  ezpz/test_dist.py:164\n   ‚îÇ  ‚îÇ           ‚îî‚îÄ 0.071 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528\n   ‚îÇ  ‚îÇ                 [7 frames hidden]  torch, &lt;built-in&gt;\n   ‚îÇ  ‚îî‚îÄ 0.052 calc_loss  ezpz/test_dist.py:168\n   ‚îî‚îÄ 0.100 Logger.info  logging/__init__.py:1479\n         [6 frames hidden]  logging, rich\n            0.100 RichHandler.emit  rich/logging.py:126\n            ‚îî‚îÄ 0.098 Console.print  ezpz/log/console.py:79\n               ‚îî‚îÄ 0.098 Console.print  rich/console.py:1624\n                     [4 frames hidden]  rich\n\n\n[2024-07-15 12:46:30.921061][INFO][profile:115] - Saving pyinstrument profile output to: /home/foremans/tmp/foremans/2024-07-15-124441/ezpz_pyinstrument_profiles\n[2024-07-15 12:46:30.921555][INFO][profile:123] - PyInstrument profile saved (as html) to:  /home/foremans/tmp/foremans/2024-07-15-124441/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-15-124630.html\n[2024-07-15 12:46:30.922034][INFO][profile:131] - PyInstrument profile saved (as text) to:  /home/foremans/tmp/foremans/2024-07-15-124441/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-07-15-124630.txt\n[2024-07-15 12:46:31.432464][INFO][profile:143] - Finished with pyinstrument profiler. Took: 2.68764s\n[2024-07-15 12:46:31.433122][INFO][test_dist:318] - [0] runtime=6.820802s\nApplication 5ccc89be resources: utime=21s stime=21s maxrss=1383056KB inblock=8080 oublock=3456 minflt=659443 majflt=896 nvcsw=192077 nivcsw=672014",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìù ezpz-v1"
    ]
  },
  {
    "objectID": "posts/ezpz-v1/index.html#footnotes",
    "href": "posts/ezpz-v1/index.html#footnotes",
    "title": "üìù ezpz-v1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ndeepspeed, DDP only support pytorch‚Ü©Ô∏é\nIf necessary, otherwise activate if already exists‚Ü©Ô∏é\nNote that the virtual environment will be created at ./venvs/${CONDA_NAME}, where ${CONDA_NAME} will match the prefix of the active conda environment‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìù ezpz-v1"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#quarto-reveal.js",
    "href": "posts/dope-slides/index.html#quarto-reveal.js",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Quarto ü§ù Reveal.js",
    "text": "Quarto ü§ù Reveal.js\nSo, after making a promise some time ago on twitter 1, and having many questions following my talk on Parallel Training Techniques last week, I‚Äôm finally getting around to writing this up.\nThe slides are written using Quarto, a flavor of Markdown, and uses the built-in Quarto + Reveal.js functionality.\nFor this post, I‚Äôll focus on the slides I presented at last years Lattice 2023, shown below:\n\n\n\n\n\n\nTipü™ß MLMC: Machine Learning Monte Carlo @ Lattice 2023 [07/2023]\n\n\n\n\n\n\n&lt;p&gt;\nYour browser does not support iframes.\n&lt;/p&gt;\n\n\n\n\n\n\n\n\n\n\nTipüèÉ‚Äç‚ôÇÔ∏è Follow Along‚Ä¶\n\n\n\n\n\nOnce you‚Äôve Installed Quarto, you can build these slides yourself by:\n\ngit clone  saforem2/lattice23\ncd lattice23 && quarto preview\n\nThis will create a docs/ directory with the following structure:\nüìÇ docs/\n‚îú‚îÄ‚îÄ üìÇ assets/\n‚îú‚îÄ‚îÄ üìÇ css/\n‚îú‚îÄ‚îÄ üìÑ index.html\n‚îú‚îÄ‚îÄ üìÑ lattice23.md\n‚îú‚îÄ‚îÄ üìÑ search.json\n‚îî‚îÄ‚îÄ üìÇ site_libs/\nOnce you‚Äôve created this, and the docs/index.html file looks how you want, you can add the docs/ directory to your GitHub repo:\n$ git add docs\n$ git commit -m 'Create site'\n$ git push\nOnce you‚Äôve enabled the GitHub page, the site will be automatically built and updated alongside the repo.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#getting-started",
    "href": "posts/dope-slides/index.html#getting-started",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Getting Started",
    "text": "Getting Started\nWhenever I give a talk, my workflow is typically:\n\nCreate new GitHub repo for it\nHunt down the GitHub repo from my last talk and2:\n$ cp -r old_talk/{_quarto.yml,index.qmd,references.bib,css/*} new_talk/\n\nHonestly, other than that, 90% of the work is done automatically by Quarto. The remaining 10% consists of figuring out why my css is broken (see CSS).\nThe best place to start for learning to make slides with Quarto and Reveal.js is the official documentation:\n\nQuarto / Presentations / Revealjs:\n\nReveal Basics\nPresenting Slides\nAdvanced Reveal\nReveal Themes\n\n\n\nThe slides are written in markdown Quarto (.qmd)3, a pandoc-compliant based markup language.\nFor a single slide deck, the content will be placed in index.qmd and our directory structure will look something like:\n\nüìÇ lattice23/\n‚îú‚îÄ‚îÄ üìÇ assets/            # for images, etc.\n‚îÇ   ‚îî‚îÄ‚îÄ üñºÔ∏è thumbnail.png  # can be used as social preview image\n‚îú‚îÄ‚îÄ üìÇ css/\n‚îÇ   ‚îú‚îÄ‚îÄ üìÑ callouts.css\n‚îÇ   ‚îú‚îÄ‚îÄ üìÑ dark.scss\n‚îÇ   ‚îî‚îÄ‚îÄ üìÑ default.css\n‚îú‚îÄ‚îÄ üõ†Ô∏è _quarto.yml        # Configuration goes here\n‚îú‚îÄ‚îÄ üìÑ index.qmd          # Quarto document containing slides content\n‚îî‚îÄ‚îÄ üìú references.bib     # BibTex references\n\nEquations are rendered using $ delimiters for inline math and $$ for display math4.\nWe can use Divs and Spans from Pandoc.\n\n&lt;span&gt;‚Äôs: are created by wrapping text in square brackets, and will be treated as a &lt;span&gt; with attributes if it is followed immediately by attributes, e.g.:\n\nExample: [This is *some text*]{.class key=\"val\"}\nidk what I‚Äôm doing really, so I mostly find myself doing things like [blue text]{style=\"color:#1E88E5;\"} which produces blue text.\n\n&lt;div&gt;‚Äôs: are created by wrapping text with a line consisting of at least three colons :::.\n\nExample:\n::: {#special .sidebar}\nHere is a paragraph.\n\nAnd another.\n:::\nWe can use either attributes in curly braces or a single unbraced word, which will be treated as a class name.\n\n\n\n\nüéÅ Install Extensions\nFind the full list of available extensions at Quarto Extensions\nTo install various icon sets used in the example slides, we can install the following extensions:\n$ quarto install extension mcanouil/quarto-iconify      # https://icones.js.org/ [&lt;-- Contains rest of icon sets ??]\n$ quarto install extension shafayetShafee/bsicons       # bootstrap icons\n$ quarto install extension schochastics/academicicons   # OrcID, Google Scholar, ...\n$ quarto install extension quarto-ext/fontawesome       # Font Awesome icons\nnote that these aren‚Äôt necessary for functionality, but provide additional icons that I like to use ü§∑üèª‚Äç‚ôÇÔ∏è",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#metadata",
    "href": "posts/dope-slides/index.html#metadata",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Metadata",
    "text": "Metadata\nThe first section of our index.qmd contains the YAML metadata for the Quarto document.\nExplicitly, we see this consists of:\n\n\nExpand for yaml\n\n---\nformat:\n  revealjs:\n    title-block-style: none\n    slide-number: c\n    title-slide-style: default\n    chalkboard:\n      buttons: false\n    auto-animate: true\n    reference-location: section\n    touch: true\n    pause: false\n    footnotes-hover: true\n    citations-hover: true\n    preview-links: true\n    controls-tutorial: true\n    controls: false\n    logo: \"https://raw.githubusercontent.com/saforem2/anl-job-talk/main/docs/assets/anl.svg\"\n    history: false\n    theme: [dark, css/dark.scss]\n    css: [css/default.css, css/callouts.css]\n    self-contained: false\n    embed-resources: false\n    self-contained-math: false\n    center: true\n    highlight-style: \"atom-one\"\n    default-image-extension: svg\n    code-line-numbers: true\n    code-overflow: scroll\n    html-math-method: katex\n    fig-align: center\n    mermaid:\n      theme: dark\n  gfm:\n    output-file: \"lattice23.md\"\n---\n\nThe complete list of Reveal.js options are listed, with descriptions at: Quarto ‚Äì Revealjs Options",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#title-slide",
    "href": "posts/dope-slides/index.html#title-slide",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Title Slide",
    "text": "Title Slide\n\nStarting with the title slide5:\n\n\n\n\n\n\nFigure¬†1: Title Slide\n\n\n\n\nThe full slide contents are included below:\n\n\nExpand for quarto\n\n# {.title-slide .centeredslide background-iframe=\"https://saforem2.github.io/grid-worms-animation/\" loading=\"lazy\"}\n\n::: {style=\"background-color: rgba(22,22,22,0.75); border-radius: 10px; text-align:center; padding: 0px; padding-left: 1.5em; padding-right: 1.5em; max-width: min-content; min-width: max-content; margin-left: auto; margin-right: auto; padding-top: 0.2em; padding-bottom: 0.2em; line-height: 1.5em!important;\"}\n\n[MLMC: Machine Learning Monte Carlo]{.style=\"color:#939393; font-size:1.5em; font-weight:bold;}  \n[for Lattice Gauge Theory]{style=\"color:#777777; font-size:1.2em; font-weight: bold;\"}\n[&lt;br&gt;&nbsp;]{style=\"padding-bottom: 0.5rem;\"}  \n[](https://samforeman.me) Sam Foreman  \n[Xiao-Yong Jin, James C. Osborn]{.dim-text style=\"font-size:0.8em;\"}  \n[[[ `saforem2/`](https://github.com/saforem2/)]{style=\"border-bottom: 0.5px solid #00ccff;\"}`{`[[`lattice23`](https://github.com/saforem2/lattice23)]{style=\"border-bottom: 0.5px solid #00ccff;\"}, [[`l2hmc-qcd`](https://github.com/saforem2/l2hmc-qcd)]{style=\"border-bottom: 0.5px solid #00ccff;\"}`}`]{style=\"font-size:0.8em;\"}\n\n:::\n\n::: footer\n[2023-07-31 @ [Lattice 2023](https://indico.fnal.gov/event/57249/contributions/271305/)]{.dim-text style=\"text-align:left;'}\n:::\n\nFor the background, I made a simple animation  saforem2/grid-worms-animation that is hosted on GitHub pages as a simple html website\nThis static GitHub page is then used as an IFrame Background natively in Quarto with Reveal.js\nThis is as simple as:\n# {.title-slide .centeredslide background-iframe=\"https://saforem2.github.io/grid-worms-animation/\" loading=\"lazy\"}",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#single-column-slides",
    "href": "posts/dope-slides/index.html#single-column-slides",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Single-Column Slides",
    "text": "Single-Column Slides\nOther than the title slide, the remainder of the slides are all relatively straightforward to construct.\nFor single-column slides, constructing the content is as simple as writing it in Markdown:\n\nCodeSlide\n\n\n# Overview\n\n1. [Background: `{MCMC,HMC}`](#markov-chain-monte-carlo-mcmc)\n    - [Leapfrog Integrator](#leapfrog-integrator-hmc)\n    - [Issues with HMC](#sec-issues-with-hmc)\n    - [Can we do better?](#sec-can-we-do-better)\n\n2. [L2HMC: Generalizing MD](#sec-l2hmc)\n    - [4D $SU(3)$ Model](#sec-su3)\n    - [Results](#sec-results)\n3. [References](#sec-references)\n4. [Extras](#sec-extras)\n\n\n\n\n\n\n\n\n\nFigure¬†2: Overview Slide",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#centered-slides",
    "href": "posts/dope-slides/index.html#centered-slides",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Centered Slides",
    "text": "Centered Slides\nWe can center all the text on a slide by adding the {.centeredslide} class to the slide header, e.g.\n\nindex.qmdstyle.scss\n\n\n---\nformat:\n  revealjs:\n    theme: [style.scss]\n---\n\n# Title {.centeredslide}\n\n\n.centeredslide {\n  text-align: center;\n}",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#multi-column-slides",
    "href": "posts/dope-slides/index.html#multi-column-slides",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Multi-Column Slides",
    "text": "Multi-Column Slides\nSide-by-side content (either text or images)\n\n\n\n\n\n\n\n\n\nFigure¬†3: Markov Chain Monte Carlo\n\n\n\n\n\nThis slide is horizontally centered6 and the content consists of two rows split as follows:\n\n\n\n\n\n\nA\nB\n\n\nC\nC\n\n\n\n\n\nTable¬†1: Slide layout. First row split into two columns, second row spans full width.\n\n\n\n\nIn panel A, we have a ::: {.callout-note} block followed by a single list element containing a LaTeX equation.\nIn panel B we have a standard markdown image\n![](./assets/mcmc.png)\nIn panel C we have normal text + math with LaTeX7 syntax.\n\n\n\n\n\nNote that we additionally have a ::: footer element included at the bottom of the slide.\nThe code used to generate the slide above is included below:\n\n\nExpand forquarto\n\n# Markov Chain Monte Carlo (MCMC) {.centeredslide}\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.callout-note title=\"Goal\" style=\"text-align:left;!important\"}\nGenerate **independent** samples $\\{x_{i}\\}$, such that[^notation]\n$$\\{x_{i}\\} \\sim p(x) \\propto e^{-S(x)}$$\nwhere $S(x)$ is the _action_ (or potential energy)\n:::\n\n- Want to calculate observables $\\mathcal{O}$:  \n  $\\left\\langle \\mathcal{O}\\right\\rangle \\propto \\int \\left[\\mathcal{D}x\\right]\\hspace{4pt} {\\mathcal{O}(x)\\, p(x)}$\n\n:::\n\n::: {.column width=\"49%\"}\n![](https://raw.githubusercontent.com/saforem2/deep-fridays/main/assets/normal_distribution.dark.svg)\n:::\n\n::::\n\nIf these were [independent]{.style=\"color:#00CCFF;\"}, we could approximate:\n$\\left\\langle\\mathcal{O}\\right\\rangle \\simeq \\frac{1}{N}\\sum^{N}_{n=1}\\mathcal{O}(x_{n})$\n$$\\sigma_{\\mathcal{O}}^{2} = \\frac{1}{N}\\mathrm{Var}{\\left[\\mathcal{O} (x) \\right]}\\Longrightarrow\n\\sigma_{\\mathcal{O}} \\propto \\frac{1}{\\sqrt{N}}$$\n\n[^notation]: Here, $\\sim$ means \"is distributed according to\"\n\n::: footer\n[ `saforem2/lattice23`](https://saforem2.github.io/lattice23)\n:::",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#css",
    "href": "posts/dope-slides/index.html#css",
    "title": "üíÖ How to Make Dope Slides",
    "section": "üíÖ CSS",
    "text": "üíÖ CSS\nMy web developer friend laughs at me, but when something is broken / doesn‚Äôt look right / I want it to look different, I:\n\nPull up Chrome Tools ( ‚åò + ‚å• + I )\nInspect element of interest ( ‚åò + ‚áß + C )\nMake changes to the CSS\nSave the new rule to my .scss file ü§∑üèª‚Äç‚ôÇÔ∏è\n\nI‚Äôm guessing this might be obvious to some people, but it took me a while to figure out how things worked so maybe its helpful for others.\n\n\nExpand for css\n\n\n\n\n\n\n\nFigure¬†4: Example of selecting an element and making a change to the CSS.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#github-page",
    "href": "posts/dope-slides/index.html#github-page",
    "title": "üíÖ How to Make Dope Slides",
    "section": "üìÉ GitHub Page",
    "text": "üìÉ GitHub Page\nTo enable your GitHub page, you can do the following:\n\n\n\n\n\n\nFigure¬†5: Instructions for building a GitHub page using the docs/ directory off the main branch.\n\n\n\nIn this case, the repo is:\n saforem2/lattice23\nand the site is published at\nhttps://saforem2.github.io/lattice23",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#references",
    "href": "posts/dope-slides/index.html#references",
    "title": "üíÖ How to Make Dope Slides",
    "section": "üìì References",
    "text": "üìì References\n\nReveal Themes\nUsing Pandoc fenced divs\nSlidecraft 101: Colors and Fonts\nBeautiful Reports and Presentations with Quarto\n Quarto Clean Theme\n\n\n\n\n\n\n\nTip‚ù§Ô∏è‚Äçü©π Status\n\n\n\n\n\n\n\nLast Updated: 05/04/2025 @ 11:15:40",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/dope-slides/index.html#footnotes",
    "href": "posts/dope-slides/index.html#footnotes",
    "title": "üíÖ How to Make Dope Slides",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAnd countless other people IRL‚Ü©Ô∏é\nOne thing I‚Äôve been meaning to do, is clean up all my css/* files and move them all to a single repository, but I‚Äôll save that for another day.‚Ü©Ô∏é\nAn open-source scientific and technical publishing system‚Ü©Ô∏é\nEquations‚Ü©Ô∏é\nQuarto comes with lightbox support, so you can click on images to display them full screen.‚Ü©Ô∏é\nBy adding the {.centeredslide} class to the slide header‚Ü©Ô∏é\nText surrounded by $ will be rendered with LaTeX‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üíÖ How to Make Dope Slides"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#l2hmc-qcd",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#l2hmc-qcd",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "l2hmc-qcd",
    "text": "l2hmc-qcd\nThis notebook contains a minimal working example for the 4D SU(3) model\nUses torch.complex128 by default",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#setup",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#setup",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "Setup",
    "text": "Setup\nimport lovely_tensors as lt\nlt.monkey_patch()\nlt.set_config(color=False)\n%load_ext autoreload\n%autoreload 2\n# automatically detect and reload local changes to modules\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nimport lovely_tensors as lt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport yaml\n\nimport l2hmc.group.su3.pytorch.group as g\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.common import grab_tensor, print_dict\nfrom l2hmc.configs import dict_to_list_of_overrides, get_experiment\nfrom l2hmc.experiment.pytorch.experiment import Experiment, evaluate  # noqa  # noqa\nfrom l2hmc.utils.dist import setup_torch\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nos.environ['COLORTERM'] = 'truecolor;'\nos.environ['MASTER_PORT'] = '5433'\n# os.environ['MPLBACKEND'] = 'module://matplotlib-backend-kitty'\n# plt.switch_backend('module://matplotlib-backend-kitty')\nconsole = get_console()\n\n_ = setup_torch(precision='float64', backend='DDP', seed=4351)\n\nset_plot_style()\n\nfrom l2hmc.utils.plot_helpers import (  # noqa\n    set_plot_style,\n    plot_scalar,\n    plot_chains,\n    plot_leapfrogs\n)\n\ndef savefig(fig: plt.Figure, fname: str, outdir: os.PathLike):\n    pngfile = Path(outdir).joinpath(f\"pngs/{fname}.png\")\n    svgfile = Path(outdir).joinpath(f\"svgs/{fname}.svg\")\n    pngfile.parent.mkdir(exist_ok=True, parents=True)\n    svgfile.parent.mkdir(exist_ok=True, parents=True)\n    fig.savefig(svgfile, transparent=True, bbox_inches='tight')\n    fig.savefig(pngfile, transparent=True, bbox_inches='tight', dpi=300)\n\ndef plot_metrics(metrics: dict, title: Optional[str] = None, **kwargs):\n    outdir = Path(f\"./plots-4dSU3/{title}\")\n    outdir.mkdir(exist_ok=True, parents=True)\n    for key, val in metrics.items():\n        fig, ax = plot_metric(val, name=key, **kwargs)\n        if title is not None:\n            ax.set_title(title)\n        console.log(f\"Saving {key} to {outdir}\")\n        savefig(fig, f\"{key}\", outdir=outdir)\n        plt.show()\n\ndef plot_metric(\n        metric: torch.Tensor,\n        name: Optional[str] = None,\n        **kwargs,\n):\n    assert len(metric) &gt; 0\n    if isinstance(metric[0], (int, float, bool, np.floating)):\n        y = np.stack(metric)\n        return plot_scalar(y, ylabel=name, **kwargs)\n    element_shape = metric[0].shape\n    if len(element_shape) == 2:\n        y = grab_tensor(torch.stack(metric))\n        return plot_leapfrogs(y, ylabel=name)\n    if len(element_shape) == 1:\n        y = grab_tensor(torch.stack(metric))\n        return plot_chains(y, ylabel=name, **kwargs)\n    if len(element_shape) == 0:\n        y = grab_tensor(torch.stack(metric))\n        return plot_scalar(y, ylabel=name, **kwargs)\n    raise ValueError\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n[07/10/23 07:55:42][INFO][dist.py:226] - Caught MASTER_PORT:5433 from environment!\n[07/10/23 07:55:42][WARNING][dist.py:332] - Setting default dtype: float64\n[07/10/23 07:55:42][INFO][dist.py:338] - Global Rank: 0 / 0",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#load-config-build-experiment",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#load-config-build-experiment",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "Load config + build Experiment",
    "text": "Load config + build Experiment\nfrom rich import print\nset_plot_style()\n\nfrom l2hmc.configs import CONF_DIR\nsu3conf = Path(f\"{CONF_DIR}/su3-min.yaml\")\nwith su3conf.open('r') as stream:\n    conf = dict(yaml.safe_load(stream))\nconsole.log(conf)\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n[07:55:42] {                                                                                                       \n               'annealing_schedule': {'beta_final': 6.0, 'beta_init': 6.0},                                        \n               'backend': 'DDP',                                                                                   \n               'conv': 'none',                                                                                     \n               'dynamics': {                                                                                       \n                   'eps': 0.001,                                                                                   \n                   'eps_fixed': False,                                                                             \n                   'group': 'SU3',                                                                                 \n                   'latvolume': [4, 4, 4, 8],                                                                      \n                   'nchains': 4,                                                                                   \n                   'nleapfrog': 4,                                                                                 \n                   'use_separate_networks': False,                                                                 \n                   'use_split_xnets': False,                                                                       \n                   'verbose': True                                                                                 \n               },                                                                                                  \n               'framework': 'pytorch',                                                                             \n               'init_aim': False,                                                                                  \n               'init_wandb': False,                                                                                \n               'learning_rate': {'clip_norm': 1.0, 'lr_init': 1e-05},                                              \n               'loss': {'charge_weight': 0.0, 'plaq_weight': 0.0, 'rmse_weight': 1.0, 'use_mixed_loss': False},    \n               'net_weights': {'v': {'q': 1.0, 's': 1.0, 't': 1.0}, 'x': {'q': 0.0, 's': 0.0, 't': 0.0}},          \n               'network': {'activation_fn': 'tanh', 'dropout_prob': 0.0, 'units': [1], 'use_batch_norm': False},   \n               'restore': False,                                                                                   \n               'save': False,                                                                                      \n               'steps': {'log': 1, 'nepoch': 10, 'nera': 1, 'print': 1, 'test': 50},                               \n               'use_tb': False,                                                                                    \n               'use_wandb': False                                                                                  \n           }                                                                                                       \n\n\n\n\n\noverrides = dict_to_list_of_overrides(conf)\nptExpSU3 = get_experiment(overrides=[*overrides], build_networks=True)\nstate = ptExpSU3.trainer.dynamics.random_state(6.0)\nconsole.log(f\"checkSU(state.x): {g.checkSU(state.x)}\")\nassert isinstance(state.x, torch.Tensor)\nassert isinstance(state.beta, torch.Tensor)\nassert isinstance(ptExpSU3, Experiment)\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n\u001b[38;2;105;105;105m[07/10/23 07:55:42]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mdist.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m226\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - Caught MASTER_PORT:\u001b[38;2;32;148;243m5433\u001b[0m from environment!\n\u001b[38;2;105;105;105m[07/10/23 07:55:42]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mdist.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m226\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - Caught MASTER_PORT:\u001b[38;2;32;148;243m5433\u001b[0m from environment!\n\u001b[38;2;105;105;105m[07/10/23 07:55:42]\u001b[0m\u001b[33m[WARNING]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mtrainer.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m436\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - Using `torch.optim.Adam` optimizer\n\u001b[38;2;105;105;105m[07/10/23 07:55:42]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mtrainer.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m284\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - num_params in model: \u001b[38;2;32;148;243m401420\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:55:42]\u001b[0m\u001b[33m[WARNING]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mtrainer.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m250\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - logging with freq \u001b[38;2;32;148;243m1\u001b[0m for wandb.watch\n           checkSU(state.x): (tensor[4] f64 x‚àà[2.174e-07, 3.981e-07] Œº=3.044e-07 œÉ=7.432e-08 grad SqrtBackward0    \n           [2.174e-07, 3.981e-07, 3.107e-07, 2.914e-07], tensor[4] f64 x‚àà[4.942e-06, 1.187e-05] Œº=8.282e-06        \n           œÉ=2.848e-06 grad SqrtBackward0 [4.942e-06, 1.187e-05, 8.531e-06, 7.784e-06])                            \n\n\n\n\n\nstate.x.real.plt()\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n\n\n\nsvg\n\n\n\n\n\n\nstate.x.imag.plt()\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#hmc",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#hmc",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "HMC",
    "text": "HMC\nxhmc, history_hmc = evaluate(\n    nsteps=50,\n    exp=ptExpSU3,\n    beta=state.beta,\n    x=state.x,\n    eps=0.1,\n    nleapfrog=1,\n    job_type='hmc',\n    nlog=2,\n    nprint=5,\n    grab=True\n)\nxhmc = ptExpSU3.trainer.dynamics.unflatten(xhmc)\nconsole.log(f\"checkSU(x_hmc): {g.checkSU(xhmc)}\")\nplot_metrics(history_hmc, title='HMC', marker='.')\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m115\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - Running \u001b[38;2;32;148;243m50\u001b[0m steps of hmc at \u001b[38;2;125;134;151mbeta\u001b[0m=\u001b[38;2;32;148;243m6\u001b[0m\u001b[38;2;32;148;243m.0000\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m0\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m1\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m2\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m3\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m4\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m5\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1455.17436446\u001b[0m \u001b[38;2;32;148;243m-1652.1514185\u001b[0m  \u001b[38;2;32;148;243m-1517.90987068\u001b[0m \u001b[38;2;32;148;243m-1455.94178323\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1459.25165577\u001b[0m \u001b[38;2;32;148;243m-1657.51842424\u001b[0m \u001b[38;2;32;148;243m-1524.14091372\u001b[0m \u001b[38;2;32;148;243m-1460.98822723\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1455.17436446\u001b[0m \u001b[38;2;32;148;243m-1652.1514185\u001b[0m  \u001b[38;2;32;148;243m-1517.90987068\u001b[0m \u001b[38;2;32;148;243m-1455.94178323\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1459.25165577\u001b[0m \u001b[38;2;32;148;243m-1657.51842424\u001b[0m \u001b[38;2;32;148;243m-1524.14091372\u001b[0m \u001b[38;2;32;148;243m-1460.98822723\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.07198033\u001b[0m \u001b[38;2;32;148;243m0.07955383\u001b[0m \u001b[38;2;32;148;243m0.07632937\u001b[0m \u001b[38;2;32;148;243m0.079714\u001b[0m  \u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4.59449208e-03\u001b[0m  \u001b[38;2;32;148;243m6.97601890e-05\u001b[0m \u001b[38;2;32;148;243m-1.36834282e-03\u001b[0m  \u001b[38;2;32;148;243m2.93498261e-03\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13406958\u001b[0m  \u001b[38;2;32;148;243m0.00203564\u001b[0m \u001b[38;2;32;148;243m-0.03992893\u001b[0m  \u001b[38;2;32;148;243m0.08564426\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01024449\u001b[0m \u001b[38;2;32;148;243m0.02805506\u001b[0m \u001b[38;2;32;148;243m0.01725271\u001b[0m \u001b[38;2;32;148;243m0.01645253\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00035107\u001b[0m \u001b[38;2;32;148;243m0.00096143\u001b[0m \u001b[38;2;32;148;243m0.00059124\u001b[0m \u001b[38;2;32;148;243m0.00056382\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008833834588589714\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m6\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m7\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m8\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m9\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m10\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2774.80624156\u001b[0m \u001b[38;2;32;148;243m-2851.59293222\u001b[0m \u001b[38;2;32;148;243m-2661.49055236\u001b[0m \u001b[38;2;32;148;243m-2425.15656787\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2779.73017905\u001b[0m \u001b[38;2;32;148;243m-2856.7767309\u001b[0m  \u001b[38;2;32;148;243m-2666.12510868\u001b[0m \u001b[38;2;32;148;243m-2429.23105695\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2774.80624156\u001b[0m \u001b[38;2;32;148;243m-2851.59293222\u001b[0m \u001b[38;2;32;148;243m-2661.49055236\u001b[0m \u001b[38;2;32;148;243m-2425.15656787\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2779.73017905\u001b[0m \u001b[38;2;32;148;243m-2856.7767309\u001b[0m  \u001b[38;2;32;148;243m-2666.12510868\u001b[0m \u001b[38;2;32;148;243m-2429.23105695\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.13573134\u001b[0m \u001b[38;2;32;148;243m0.14720937\u001b[0m \u001b[38;2;32;148;243m0.14114639\u001b[0m \u001b[38;2;32;148;243m0.14401027\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00396796\u001b[0m \u001b[38;2;32;148;243m-0.00146382\u001b[0m  \u001b[38;2;32;148;243m0.0040015\u001b[0m   \u001b[38;2;32;148;243m0.00239218\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11578697\u001b[0m \u001b[38;2;32;148;243m-0.04271513\u001b[0m  \u001b[38;2;32;148;243m0.11676574\u001b[0m  \u001b[38;2;32;148;243m0.06980506\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01591121\u001b[0m \u001b[38;2;32;148;243m0.07023641\u001b[0m \u001b[38;2;32;148;243m0.03053575\u001b[0m \u001b[38;2;32;148;243m0.01694004\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00054527\u001b[0m \u001b[38;2;32;148;243m0.00240696\u001b[0m \u001b[38;2;32;148;243m0.00104644\u001b[0m \u001b[38;2;32;148;243m0.00058053\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008887014270663943\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m11\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m12\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m13\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m14\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m15\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3589.39696557\u001b[0m \u001b[38;2;32;148;243m-3672.75566478\u001b[0m \u001b[38;2;32;148;243m-3699.9655895\u001b[0m  \u001b[38;2;32;148;243m-3758.19489614\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3591.62366753\u001b[0m \u001b[38;2;32;148;243m-3676.34262087\u001b[0m \u001b[38;2;32;148;243m-3704.28601825\u001b[0m \u001b[38;2;32;148;243m-3763.08583919\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3589.39696557\u001b[0m \u001b[38;2;32;148;243m-3672.75566478\u001b[0m \u001b[38;2;32;148;243m-3699.9655895\u001b[0m  \u001b[38;2;32;148;243m-3758.19489614\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3591.62366753\u001b[0m \u001b[38;2;32;148;243m-3676.34262087\u001b[0m \u001b[38;2;32;148;243m-3704.28601825\u001b[0m \u001b[38;2;32;148;243m-3763.08583919\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19442852\u001b[0m \u001b[38;2;32;148;243m0.20120752\u001b[0m \u001b[38;2;32;148;243m0.19236084\u001b[0m \u001b[38;2;32;148;243m0.19703231\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00550476\u001b[0m \u001b[38;2;32;148;243m-0.00195778\u001b[0m  \u001b[38;2;32;148;243m0.00094388\u001b[0m  \u001b[38;2;32;148;243m0.00348485\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16063176\u001b[0m \u001b[38;2;32;148;243m-0.05712905\u001b[0m  \u001b[38;2;32;148;243m0.027543\u001b[0m    \u001b[38;2;32;148;243m0.10168963\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00838519\u001b[0m \u001b[38;2;32;148;243m0.00298843\u001b[0m \u001b[38;2;32;148;243m0.01475424\u001b[0m \u001b[38;2;32;148;243m0.05713639\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00028736\u001b[0m \u001b[38;2;32;148;243m0.00010241\u001b[0m \u001b[38;2;32;148;243m0.00050562\u001b[0m \u001b[38;2;32;148;243m0.00195803\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.00887361562615175\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m16\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m17\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m18\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m19\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m20\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4151.54650574\u001b[0m \u001b[38;2;32;148;243m-4494.28752887\u001b[0m \u001b[38;2;32;148;243m-4160.10384616\u001b[0m \u001b[38;2;32;148;243m-4408.71292573\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4156.03583628\u001b[0m \u001b[38;2;32;148;243m-4496.77600268\u001b[0m \u001b[38;2;32;148;243m-4162.17053388\u001b[0m \u001b[38;2;32;148;243m-4412.58171459\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4151.54650574\u001b[0m \u001b[38;2;32;148;243m-4494.28752887\u001b[0m \u001b[38;2;32;148;243m-4160.10384616\u001b[0m \u001b[38;2;32;148;243m-4408.71292573\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4156.03583628\u001b[0m \u001b[38;2;32;148;243m-4496.77600268\u001b[0m \u001b[38;2;32;148;243m-4162.17053388\u001b[0m \u001b[38;2;32;148;243m-4412.58171459\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22897834\u001b[0m \u001b[38;2;32;148;243m0.23997054\u001b[0m \u001b[38;2;32;148;243m0.22982328\u001b[0m \u001b[38;2;32;148;243m0.23599929\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00693299\u001b[0m \u001b[38;2;32;148;243m-0.00347184\u001b[0m \u001b[38;2;32;148;243m-0.00120909\u001b[0m  \u001b[38;2;32;148;243m0.00308169\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20230825\u001b[0m \u001b[38;2;32;148;243m-0.10131016\u001b[0m \u001b[38;2;32;148;243m-0.03528176\u001b[0m  \u001b[38;2;32;148;243m0.08992527\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.04257003\u001b[0m \u001b[38;2;32;148;243m0.05104837\u001b[0m \u001b[38;2;32;148;243m0.00619903\u001b[0m \u001b[38;2;32;148;243m0.00752605\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00145885\u001b[0m \u001b[38;2;32;148;243m0.0017494\u001b[0m  \u001b[38;2;32;148;243m0.00021244\u001b[0m \u001b[38;2;32;148;243m0.00025791\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008967695306967319\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m21\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m22\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m23\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m24\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m25\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4814.63799281\u001b[0m \u001b[38;2;32;148;243m-4919.94688869\u001b[0m \u001b[38;2;32;148;243m-4788.79616489\u001b[0m \u001b[38;2;32;148;243m-5002.9215054\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4817.09579284\u001b[0m \u001b[38;2;32;148;243m-4921.24269566\u001b[0m \u001b[38;2;32;148;243m-4790.50072208\u001b[0m \u001b[38;2;32;148;243m-5005.14858853\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4814.63799281\u001b[0m \u001b[38;2;32;148;243m-4919.94688869\u001b[0m \u001b[38;2;32;148;243m-4788.79616489\u001b[0m \u001b[38;2;32;148;243m-5002.9215054\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4817.09579284\u001b[0m \u001b[38;2;32;148;243m-4921.24269566\u001b[0m \u001b[38;2;32;148;243m-4790.50072208\u001b[0m \u001b[38;2;32;148;243m-5005.14858853\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.26288089\u001b[0m \u001b[38;2;32;148;243m0.27682883\u001b[0m \u001b[38;2;32;148;243m0.26268439\u001b[0m \u001b[38;2;32;148;243m0.26544038\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00063547\u001b[0m \u001b[38;2;32;148;243m-0.00425824\u001b[0m \u001b[38;2;32;148;243m-0.00254524\u001b[0m  \u001b[38;2;32;148;243m0.00551469\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01854337\u001b[0m \u001b[38;2;32;148;243m-0.12425771\u001b[0m \u001b[38;2;32;148;243m-0.07427149\u001b[0m  \u001b[38;2;32;148;243m0.16092137\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00165815\u001b[0m \u001b[38;2;32;148;243m0.03643215\u001b[0m \u001b[38;2;32;148;243m0.00549913\u001b[0m \u001b[38;2;32;148;243m0.03666496\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m5.68238145e-05\u001b[0m \u001b[38;2;32;148;243m1.24851003e-03\u001b[0m \u001b[38;2;32;148;243m1.88452222e-04\u001b[0m \u001b[38;2;32;148;243m1.25648827e-03\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008991637304362567\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m26\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m27\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m28\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m29\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m30\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5291.93327564\u001b[0m \u001b[38;2;32;148;243m-5277.74230381\u001b[0m \u001b[38;2;32;148;243m-5250.76164114\u001b[0m \u001b[38;2;32;148;243m-5396.46879447\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5292.63668436\u001b[0m \u001b[38;2;32;148;243m-5278.24552901\u001b[0m \u001b[38;2;32;148;243m-5252.56634155\u001b[0m \u001b[38;2;32;148;243m-5396.60232376\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5291.93327564\u001b[0m \u001b[38;2;32;148;243m-5277.74230381\u001b[0m \u001b[38;2;32;148;243m-5250.76164114\u001b[0m \u001b[38;2;32;148;243m-5396.46879447\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5292.63668436\u001b[0m \u001b[38;2;32;148;243m-5278.24552901\u001b[0m \u001b[38;2;32;148;243m-5252.56634155\u001b[0m \u001b[38;2;32;148;243m-5396.60232376\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.2875013\u001b[0m  \u001b[38;2;32;148;243m0.29490873\u001b[0m \u001b[38;2;32;148;243m0.28911575\u001b[0m \u001b[38;2;32;148;243m0.29292899\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00214532\u001b[0m \u001b[38;2;32;148;243m-0.00195831\u001b[0m  \u001b[38;2;32;148;243m0.00125583\u001b[0m  \u001b[38;2;32;148;243m0.00433508\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06260166\u001b[0m \u001b[38;2;32;148;243m-0.05714455\u001b[0m  \u001b[38;2;32;148;243m0.03664583\u001b[0m  \u001b[38;2;32;148;243m0.1264999\u001b[0m \u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00996321\u001b[0m \u001b[38;2;32;148;243m0.01477696\u001b[0m \u001b[38;2;32;148;243m0.00678131\u001b[0m \u001b[38;2;32;148;243m0.0104012\u001b[0m \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00034143\u001b[0m \u001b[38;2;32;148;243m0.0005064\u001b[0m  \u001b[38;2;32;148;243m0.00023239\u001b[0m \u001b[38;2;32;148;243m0.00035644\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.009008451409977573\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m31\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m32\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m33\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m34\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m35\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5677.87109891\u001b[0m \u001b[38;2;32;148;243m-5799.43835247\u001b[0m \u001b[38;2;32;148;243m-5783.77900075\u001b[0m \u001b[38;2;32;148;243m-5966.2188758\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5679.3788349\u001b[0m  \u001b[38;2;32;148;243m-5801.05951826\u001b[0m \u001b[38;2;32;148;243m-5785.90693956\u001b[0m \u001b[38;2;32;148;243m-5967.61796828\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5677.87109891\u001b[0m \u001b[38;2;32;148;243m-5799.43835247\u001b[0m \u001b[38;2;32;148;243m-5783.77900075\u001b[0m \u001b[38;2;32;148;243m-5966.2188758\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-5679.3788349\u001b[0m  \u001b[38;2;32;148;243m-5801.05951826\u001b[0m \u001b[38;2;32;148;243m-5785.90693956\u001b[0m \u001b[38;2;32;148;243m-5967.61796828\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.30658624\u001b[0m \u001b[38;2;32;148;243m0.31260177\u001b[0m \u001b[38;2;32;148;243m0.31303925\u001b[0m \u001b[38;2;32;148;243m0.31611992\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00207013\u001b[0m  \u001b[38;2;32;148;243m0.00102852\u001b[0m  \u001b[38;2;32;148;243m0.00099099\u001b[0m  \u001b[38;2;32;148;243m0.00199912\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06040742\u001b[0m  \u001b[38;2;32;148;243m0.03001266\u001b[0m  \u001b[38;2;32;148;243m0.02891754\u001b[0m  \u001b[38;2;32;148;243m0.05833535\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.02325924\u001b[0m \u001b[38;2;32;148;243m0.04047365\u001b[0m \u001b[38;2;32;148;243m0.0205901\u001b[0m  \u001b[38;2;32;148;243m0.02235072\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00079708\u001b[0m \u001b[38;2;32;148;243m0.00138701\u001b[0m \u001b[38;2;32;148;243m0.00070561\u001b[0m \u001b[38;2;32;148;243m0.00076595\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008902220811433029\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m36\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m37\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m38\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m39\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m40\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6009.28484422\u001b[0m \u001b[38;2;32;148;243m-6075.42435918\u001b[0m \u001b[38;2;32;148;243m-6195.95087466\u001b[0m \u001b[38;2;32;148;243m-6048.18856638\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6009.38784106\u001b[0m \u001b[38;2;32;148;243m-6076.5575995\u001b[0m  \u001b[38;2;32;148;243m-6197.94839446\u001b[0m \u001b[38;2;32;148;243m-6048.75106049\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6009.28484422\u001b[0m \u001b[38;2;32;148;243m-6075.42435918\u001b[0m \u001b[38;2;32;148;243m-6195.95087466\u001b[0m \u001b[38;2;32;148;243m-6048.18856638\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6009.38784106\u001b[0m \u001b[38;2;32;148;243m-6076.5575995\u001b[0m  \u001b[38;2;32;148;243m-6197.94839446\u001b[0m \u001b[38;2;32;148;243m-6048.75106049\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.32328311\u001b[0m \u001b[38;2;32;148;243m0.33136092\u001b[0m \u001b[38;2;32;148;243m0.33288434\u001b[0m \u001b[38;2;32;148;243m0.33155877\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00087745\u001b[0m \u001b[38;2;32;148;243m-0.00030477\u001b[0m  \u001b[38;2;32;148;243m0.00157488\u001b[0m  \u001b[38;2;32;148;243m0.00408504\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.02560443\u001b[0m \u001b[38;2;32;148;243m-0.00889343\u001b[0m  \u001b[38;2;32;148;243m0.04595583\u001b[0m  \u001b[38;2;32;148;243m0.11920361\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.05894986\u001b[0m \u001b[38;2;32;148;243m0.05110851\u001b[0m \u001b[38;2;32;148;243m0.00843622\u001b[0m \u001b[38;2;32;148;243m0.0193832\u001b[0m \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00202018\u001b[0m \u001b[38;2;32;148;243m0.00175146\u001b[0m \u001b[38;2;32;148;243m0.0002891\u001b[0m  \u001b[38;2;32;148;243m0.00066425\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.008961126836871364\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m41\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m42\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m43\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m44\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m45\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6172.38358228\u001b[0m \u001b[38;2;32;148;243m-6473.29456144\u001b[0m \u001b[38;2;32;148;243m-6406.68919584\u001b[0m \u001b[38;2;32;148;243m-6232.45720644\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6172.72022528\u001b[0m \u001b[38;2;32;148;243m-6471.1347579\u001b[0m  \u001b[38;2;32;148;243m-6407.01878873\u001b[0m \u001b[38;2;32;148;243m-6235.0900963\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6172.38358228\u001b[0m \u001b[38;2;32;148;243m-6473.29456144\u001b[0m \u001b[38;2;32;148;243m-6406.68919584\u001b[0m \u001b[38;2;32;148;243m-6232.45720644\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6172.72022528\u001b[0m \u001b[38;2;32;148;243m-6471.1347579\u001b[0m  \u001b[38;2;32;148;243m-6407.01878873\u001b[0m \u001b[38;2;32;148;243m-6235.0900963\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m0.11534778\u001b[0m \u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m1\u001b[0m.        \u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33577826\u001b[0m \u001b[38;2;32;148;243m0.34108362\u001b[0m \u001b[38;2;32;148;243m0.34569419\u001b[0m \u001b[38;2;32;148;243m0.34125761\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.19948603e-03\u001b[0m \u001b[38;2;32;148;243m-1.70704191e-05\u001b[0m  \u001b[38;2;32;148;243m1.29880814e-03\u001b[0m  \u001b[38;2;32;148;243m1.15764374e-03\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0350016\u001b[0m  \u001b[38;2;32;148;243m-0.00049812\u001b[0m  \u001b[38;2;32;148;243m0.03789987\u001b[0m  \u001b[38;2;32;148;243m0.03378062\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.03684475\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.02928525\u001b[0m \u001b[38;2;32;148;243m0.01172397\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00126265\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00100359\u001b[0m \u001b[38;2;32;148;243m0.00040177\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-0.006980147559740732\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m46\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m47\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m48\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m49\u001b[0m\n[07:56:33] checkSU(x_hmc): (tensor[4] f64 x‚àà[3.429e-16, 3.484e-16] Œº=3.453e-16 œÉ=2.351e-18 [3.442e-16, 3.484e-16,  \n           3.429e-16, 3.458e-16], tensor[4] f64 x‚àà[1.072e-15, 1.171e-15] Œº=1.136e-15 œÉ=4.386e-17 [1.143e-15,       \n           1.157e-15, 1.072e-15, 1.171e-15])                                                                       \n\n           Saving energy to plots-4dSU3/HMC                                                                        \n\n\n\n\nsvg\n\n\n           Saving logprob to plots-4dSU3/HMC                                                                       \n\n\n\n\nsvg\n\n\n           Saving logdet to plots-4dSU3/HMC                                                                        \n\n\n\n\nsvg\n\n\n           Saving acc to plots-4dSU3/HMC                                                                           \n\n\n\n\nsvg\n\n\n           Saving sumlogdet to plots-4dSU3/HMC                                                                     \n\n\n\n\nsvg\n\n\n[07:56:34] Saving acc_mask to plots-4dSU3/HMC                                                                      \n\n\n\n\nsvg\n\n\n           Saving plaqs to plots-4dSU3/HMC                                                                         \n\n\n\n\nsvg\n\n\n           Saving sinQ to plots-4dSU3/HMC                                                                          \n\n\n\n\nsvg\n\n\n           Saving intQ to plots-4dSU3/HMC                                                                          \n\n\n\n\nsvg\n\n\n[07:56:35] Saving dQint to plots-4dSU3/HMC                                                                         \n\n\n\n\nsvg\n\n\n           Saving dQsin to plots-4dSU3/HMC                                                                         \n\n\n\n\nsvg\n\n\n           Saving loss to plots-4dSU3/HMC                                                                          \n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#evaluation",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#evaluation",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "Evaluation",
    "text": "Evaluation\n# ptExpSU3.trainer.dynamics.init_weights(\n#     method='uniform',\n#     min=-1e-16,\n#     max=1e-16,\n#     bias=True,\n#     # xeps=0.001,\n#     # veps=0.001,\n# )\nxeval, history_eval = evaluate(\n    nsteps=50,\n    exp=ptExpSU3,\n    beta=6.0,\n    x=state.x,\n    job_type='eval',\n    nlog=2,\n    nprint=5,\n    grab=True,\n)\nxeval = ptExpSU3.trainer.dynamics.unflatten(xeval)\nconsole.log(f\"checkSU(x_eval): {g.checkSU(xeval)}\")\nplot_metrics(history_eval, title='Evaluate', marker='.')\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n\u001b[38;2;105;105;105m[07/10/23 07:56:45]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m115\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - Running \u001b[38;2;32;148;243m50\u001b[0m steps of eval at \u001b[38;2;125;134;151mbeta\u001b[0m=\u001b[38;2;32;148;243m6\u001b[0m\u001b[38;2;32;148;243m.0000\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:45]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m0\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:46]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m1\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:46]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m2\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:46]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m3\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:47]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m4\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:47]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m5\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:48]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.13661105\u001b[0m \u001b[38;2;32;148;243m-33.63307096\u001b[0m  \u001b[38;2;32;148;243m67.14737865\u001b[0m \u001b[38;2;32;148;243m-44.94287792\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.12019559\u001b[0m \u001b[38;2;32;148;243m-33.67474968\u001b[0m  \u001b[38;2;32;148;243m67.13262028\u001b[0m \u001b[38;2;32;148;243m-45.06121746\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.11640715\u001b[0m \u001b[38;2;32;148;243m-33.7029591\u001b[0m   \u001b[38;2;32;148;243m67.13542667\u001b[0m \u001b[38;2;32;148;243m-45.15853882\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.12597508\u001b[0m \u001b[38;2;32;148;243m-33.71582603\u001b[0m  \u001b[38;2;32;148;243m67.15528762\u001b[0m \u001b[38;2;32;148;243m-45.23443416\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.15009837\u001b[0m \u001b[38;2;32;148;243m-33.71282679\u001b[0m  \u001b[38;2;32;148;243m67.19223232\u001b[0m \u001b[38;2;32;148;243m-45.28949862\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.24409668\u001b[0m \u001b[38;2;32;148;243m-33.55745988\u001b[0m  \u001b[38;2;32;148;243m67.28977981\u001b[0m \u001b[38;2;32;148;243m-45.05889668\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.35293374\u001b[0m \u001b[38;2;32;148;243m-33.38888138\u001b[0m  \u001b[38;2;32;148;243m67.40388327\u001b[0m \u001b[38;2;32;148;243m-44.8080029\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.47661625\u001b[0m \u001b[38;2;32;148;243m-33.20710601\u001b[0m  \u001b[38;2;32;148;243m67.53407019\u001b[0m \u001b[38;2;32;148;243m-44.53600603\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.61403391\u001b[0m \u001b[38;2;32;148;243m-33.01043184\u001b[0m  \u001b[38;2;32;148;243m67.68099845\u001b[0m \u001b[38;2;32;148;243m-44.24220592\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.13661105\u001b[0m \u001b[38;2;32;148;243m-33.63307096\u001b[0m  \u001b[38;2;32;148;243m67.14737865\u001b[0m \u001b[38;2;32;148;243m-44.94287792\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.18594798\u001b[0m \u001b[38;2;32;148;243m-33.64895353\u001b[0m  \u001b[38;2;32;148;243m67.23191696\u001b[0m \u001b[38;2;32;148;243m-44.94255748\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.25009615\u001b[0m \u001b[38;2;32;148;243m-33.65006019\u001b[0m  \u001b[38;2;32;148;243m67.33406416\u001b[0m \u001b[38;2;32;148;243m-44.92096816\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.32862172\u001b[0m \u001b[38;2;32;148;243m-33.63742038\u001b[0m  \u001b[38;2;32;148;243m67.45280265\u001b[0m \u001b[38;2;32;148;243m-44.87768554\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.42163919\u001b[0m \u001b[38;2;32;148;243m-33.61092114\u001b[0m  \u001b[38;2;32;148;243m67.58849517\u001b[0m \u001b[38;2;32;148;243m-44.81350169\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.44700618\u001b[0m \u001b[38;2;32;148;243m-33.47933478\u001b[0m  \u001b[38;2;32;148;243m67.58664812\u001b[0m \u001b[38;2;32;148;243m-44.70191131\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.48678158\u001b[0m \u001b[38;2;32;148;243m-33.33680972\u001b[0m  \u001b[38;2;32;148;243m67.60182722\u001b[0m \u001b[38;2;32;148;243m-44.56979511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.54116027\u001b[0m \u001b[38;2;32;148;243m-33.18273746\u001b[0m  \u001b[38;2;32;148;243m67.634192\u001b[0m   \u001b[38;2;32;148;243m-44.4166053\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m135.60984902\u001b[0m \u001b[38;2;32;148;243m-33.01258723\u001b[0m  \u001b[38;2;32;148;243m67.68334133\u001b[0m \u001b[38;2;32;148;243m-44.24196715\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6.57523818e-02\u001b[0m \u001b[38;2;32;148;243m-2.57961502e-02\u001b[0m \u001b[38;2;32;148;243m-9.92966725e-02\u001b[0m \u001b[38;2;32;148;243m-1.18659983e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.33688996e-01\u001b[0m \u001b[38;2;32;148;243m-5.28989121e-02\u001b[0m \u001b[38;2;32;148;243m-1.98637494e-01\u001b[0m \u001b[38;2;32;148;243m-2.37570657e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.02646646e-01\u001b[0m \u001b[38;2;32;148;243m-7.84056547e-02\u001b[0m \u001b[38;2;32;148;243m-2.97515030e-01\u001b[0m \u001b[38;2;32;148;243m-3.56748619e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.71540826e-01\u001b[0m \u001b[38;2;32;148;243m-1.01905646e-01\u001b[0m \u001b[38;2;32;148;243m-3.96262845e-01\u001b[0m \u001b[38;2;32;148;243m-4.75996937e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.02909501e-01\u001b[0m \u001b[38;2;32;148;243m-7.81251045e-02\u001b[0m \u001b[38;2;32;148;243m-2.96868313e-01\u001b[0m \u001b[38;2;32;148;243m-3.56985365e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.33847838e-01\u001b[0m \u001b[38;2;32;148;243m-5.20716617e-02\u001b[0m \u001b[38;2;32;148;243m-1.97943952e-01\u001b[0m \u001b[38;2;32;148;243m-2.38207787e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6.45440187e-02\u001b[0m \u001b[38;2;32;148;243m-2.43685486e-02\u001b[0m \u001b[38;2;32;148;243m-1.00121811e-01\u001b[0m \u001b[38;2;32;148;243m-1.19400726e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m4.18489492e-03\u001b[0m  \u001b[38;2;32;148;243m2.15538787e-03\u001b[0m \u001b[38;2;32;148;243m-2.34288059e-03\u001b[0m \u001b[38;2;32;148;243m-2.38771971e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06575238\u001b[0m \u001b[38;2;32;148;243m-0.02579615\u001b[0m \u001b[38;2;32;148;243m-0.09929667\u001b[0m \u001b[38;2;32;148;243m-0.11865998\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.133689\u001b[0m   \u001b[38;2;32;148;243m-0.05289891\u001b[0m \u001b[38;2;32;148;243m-0.19863749\u001b[0m \u001b[38;2;32;148;243m-0.23757066\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20264665\u001b[0m \u001b[38;2;32;148;243m-0.07840565\u001b[0m \u001b[38;2;32;148;243m-0.29751503\u001b[0m \u001b[38;2;32;148;243m-0.35674862\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27154083\u001b[0m \u001b[38;2;32;148;243m-0.10190565\u001b[0m \u001b[38;2;32;148;243m-0.39626285\u001b[0m \u001b[38;2;32;148;243m-0.47599694\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.06863133\u001b[0m \u001b[38;2;32;148;243m0.02378054\u001b[0m \u001b[38;2;32;148;243m0.09939453\u001b[0m \u001b[38;2;32;148;243m0.11901157\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.13769299\u001b[0m \u001b[38;2;32;148;243m0.04983398\u001b[0m \u001b[38;2;32;148;243m0.19831889\u001b[0m \u001b[38;2;32;148;243m0.23778915\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20699681\u001b[0m \u001b[38;2;32;148;243m0.0775371\u001b[0m  \u001b[38;2;32;148;243m0.29614103\u001b[0m \u001b[38;2;32;148;243m0.35659621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.27572572\u001b[0m \u001b[38;2;32;148;243m0.10406103\u001b[0m \u001b[38;2;32;148;243m0.39391996\u001b[0m \u001b[38;2;32;148;243m0.47575816\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6.57523818e-02\u001b[0m \u001b[38;2;32;148;243m-2.57961502e-02\u001b[0m \u001b[38;2;32;148;243m-9.92966725e-02\u001b[0m \u001b[38;2;32;148;243m-1.18659983e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.33688996e-01\u001b[0m \u001b[38;2;32;148;243m-5.28989121e-02\u001b[0m \u001b[38;2;32;148;243m-1.98637494e-01\u001b[0m \u001b[38;2;32;148;243m-2.37570657e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.02646646e-01\u001b[0m \u001b[38;2;32;148;243m-7.84056547e-02\u001b[0m \u001b[38;2;32;148;243m-2.97515030e-01\u001b[0m \u001b[38;2;32;148;243m-3.56748619e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.71540826e-01\u001b[0m \u001b[38;2;32;148;243m-1.01905646e-01\u001b[0m \u001b[38;2;32;148;243m-3.96262845e-01\u001b[0m \u001b[38;2;32;148;243m-4.75996937e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.02909501e-01\u001b[0m \u001b[38;2;32;148;243m-7.81251045e-02\u001b[0m \u001b[38;2;32;148;243m-2.96868313e-01\u001b[0m \u001b[38;2;32;148;243m-3.56985365e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.33847838e-01\u001b[0m \u001b[38;2;32;148;243m-5.20716617e-02\u001b[0m \u001b[38;2;32;148;243m-1.97943952e-01\u001b[0m \u001b[38;2;32;148;243m-2.38207787e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-6.45440187e-02\u001b[0m \u001b[38;2;32;148;243m-2.43685486e-02\u001b[0m \u001b[38;2;32;148;243m-1.00121811e-01\u001b[0m \u001b[38;2;32;148;243m-1.19400726e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m4.18489492e-03\u001b[0m  \u001b[38;2;32;148;243m2.15538787e-03\u001b[0m \u001b[38;2;32;148;243m-2.34288059e-03\u001b[0m \u001b[38;2;32;148;243m-2.38771971e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.6229818\u001b[0m  \u001b[38;2;32;148;243m0.53768428\u001b[0m \u001b[38;2;32;148;243m0.58510575\u001b[0m \u001b[38;2;32;148;243m0.49613324\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m-0.00234288\u001b[0m \u001b[38;2;32;148;243m-0\u001b[0m.        \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00451561\u001b[0m \u001b[38;2;32;148;243m-0.00117244\u001b[0m \u001b[38;2;32;148;243m-0.0024079\u001b[0m  \u001b[38;2;32;148;243m-0.00328763\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00482457\u001b[0m \u001b[38;2;32;148;243m-0.001806\u001b[0m   \u001b[38;2;32;148;243m-0.00311093\u001b[0m  \u001b[38;2;32;148;243m0.00384917\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14078351\u001b[0m \u001b[38;2;32;148;243m-0.05270007\u001b[0m \u001b[38;2;32;148;243m-0.09077836\u001b[0m  \u001b[38;2;32;148;243m0.11232063\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00423973\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00014529\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-3.176207358041437e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:48]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m6\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:48]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m7\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:48]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m8\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:49]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m9\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:49]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m10\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:49]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.56401221e+01\u001b[0m  \u001b[38;2;32;148;243m3.01519478e-01\u001b[0m  \u001b[38;2;32;148;243m1.26397106e+02\u001b[0m \u001b[38;2;32;148;243m-8.75141370e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.56823640e+01\u001b[0m  \u001b[38;2;32;148;243m1.45612359e-01\u001b[0m  \u001b[38;2;32;148;243m1.26393890e+02\u001b[0m \u001b[38;2;32;148;243m-8.73955597e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.57109596e+01\u001b[0m  \u001b[38;2;32;148;243m3.95985324e-03\u001b[0m  \u001b[38;2;32;148;243m1.26407219e+02\u001b[0m \u001b[38;2;32;148;243m-8.72563460e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.57253138e+01\u001b[0m \u001b[38;2;32;148;243m-1.23224050e-01\u001b[0m  \u001b[38;2;32;148;243m1.26437241e+02\u001b[0m \u001b[38;2;32;148;243m-8.70966271e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.57257501e+01\u001b[0m \u001b[38;2;32;148;243m-2.36135287e-01\u001b[0m  \u001b[38;2;32;148;243m1.26484182e+02\u001b[0m \u001b[38;2;32;148;243m-8.69163051e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.56167926e+01\u001b[0m \u001b[38;2;32;148;243m-1.52561289e-01\u001b[0m  \u001b[38;2;32;148;243m1.26698581e+02\u001b[0m \u001b[38;2;32;148;243m-8.69189539e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.54921713e+01\u001b[0m \u001b[38;2;32;148;243m-5.40582444e-02\u001b[0m  \u001b[38;2;32;148;243m1.26929478e+02\u001b[0m \u001b[38;2;32;148;243m-8.69016305e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.53528175e+01\u001b[0m  \u001b[38;2;32;148;243m5.86356052e-02\u001b[0m  \u001b[38;2;32;148;243m1.27176913e+02\u001b[0m \u001b[38;2;32;148;243m-8.68641859e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.52006482e+01\u001b[0m  \u001b[38;2;32;148;243m1.85718837e-01\u001b[0m  \u001b[38;2;32;148;243m1.27443679e+02\u001b[0m \u001b[38;2;32;148;243m-8.68062122e+01\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.56401221e+01\u001b[0m  \u001b[38;2;32;148;243m3.01519478e-01\u001b[0m  \u001b[38;2;32;148;243m1.26397106e+02\u001b[0m \u001b[38;2;32;148;243m-8.75141370e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.56248528e+01\u001b[0m  \u001b[38;2;32;148;243m1.73238470e-01\u001b[0m  \u001b[38;2;32;148;243m1.26484219e+02\u001b[0m \u001b[38;2;32;148;243m-8.72781272e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.55952941e+01\u001b[0m  \u001b[38;2;32;148;243m5.89521523e-02\u001b[0m  \u001b[38;2;32;148;243m1.26590094e+02\u001b[0m \u001b[38;2;32;148;243m-8.70213932e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.55488299e+01\u001b[0m \u001b[38;2;32;148;243m-4.13439677e-02\u001b[0m  \u001b[38;2;32;148;243m1.26714724e+02\u001b[0m \u001b[38;2;32;148;243m-8.67439896e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.54873081e+01\u001b[0m \u001b[38;2;32;148;243m-1.27574436e-01\u001b[0m  \u001b[38;2;32;148;243m1.26856942e+02\u001b[0m \u001b[38;2;32;148;243m-8.64458164e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.54413096e+01\u001b[0m \u001b[38;2;32;148;243m-6.93640504e-02\u001b[0m  \u001b[38;2;32;148;243m1.26976549e+02\u001b[0m \u001b[38;2;32;148;243m-8.65662029e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.53811335e+01\u001b[0m  \u001b[38;2;32;148;243m5.41904615e-03\u001b[0m  \u001b[38;2;32;148;243m1.27112514e+02\u001b[0m \u001b[38;2;32;148;243m-8.66661364e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.53069725e+01\u001b[0m  \u001b[38;2;32;148;243m9.42762298e-02\u001b[0m  \u001b[38;2;32;148;243m1.27264945e+02\u001b[0m \u001b[38;2;32;148;243m-8.67460576e+01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.52189787e+01\u001b[0m  \u001b[38;2;32;148;243m1.94748598e-01\u001b[0m  \u001b[38;2;32;148;243m1.27435612e+02\u001b[0m \u001b[38;2;32;148;243m-8.68056112e+01\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05751118\u001b[0m \u001b[38;2;32;148;243m-0.02762611\u001b[0m \u001b[38;2;32;148;243m-0.09032856\u001b[0m \u001b[38;2;32;148;243m-0.11743246\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1156655\u001b[0m  \u001b[38;2;32;148;243m-0.0549923\u001b[0m  \u001b[38;2;32;148;243m-0.18287469\u001b[0m \u001b[38;2;32;148;243m-0.23495288\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17648393\u001b[0m \u001b[38;2;32;148;243m-0.08188008\u001b[0m \u001b[38;2;32;148;243m-0.27748311\u001b[0m \u001b[38;2;32;148;243m-0.35263751\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.23844197\u001b[0m \u001b[38;2;32;148;243m-0.10856085\u001b[0m \u001b[38;2;32;148;243m-0.37275912\u001b[0m \u001b[38;2;32;148;243m-0.47048872\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17548294\u001b[0m \u001b[38;2;32;148;243m-0.08319724\u001b[0m \u001b[38;2;32;148;243m-0.27796796\u001b[0m \u001b[38;2;32;148;243m-0.35275104\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1110378\u001b[0m  \u001b[38;2;32;148;243m-0.05947729\u001b[0m \u001b[38;2;32;148;243m-0.18303625\u001b[0m \u001b[38;2;32;148;243m-0.23549409\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.045845\u001b[0m   \u001b[38;2;32;148;243m-0.03564062\u001b[0m \u001b[38;2;32;148;243m-0.0880325\u001b[0m  \u001b[38;2;32;148;243m-0.11812833\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01833044\u001b[0m \u001b[38;2;32;148;243m-0.00902976\u001b[0m  \u001b[38;2;32;148;243m0.00806685\u001b[0m \u001b[38;2;32;148;243m-0.00060101\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05751118\u001b[0m \u001b[38;2;32;148;243m-0.02762611\u001b[0m \u001b[38;2;32;148;243m-0.09032856\u001b[0m \u001b[38;2;32;148;243m-0.11743246\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1156655\u001b[0m  \u001b[38;2;32;148;243m-0.0549923\u001b[0m  \u001b[38;2;32;148;243m-0.18287469\u001b[0m \u001b[38;2;32;148;243m-0.23495288\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17648393\u001b[0m \u001b[38;2;32;148;243m-0.08188008\u001b[0m \u001b[38;2;32;148;243m-0.27748311\u001b[0m \u001b[38;2;32;148;243m-0.35263751\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.23844197\u001b[0m \u001b[38;2;32;148;243m-0.10856085\u001b[0m \u001b[38;2;32;148;243m-0.37275912\u001b[0m \u001b[38;2;32;148;243m-0.47048872\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.06295902\u001b[0m \u001b[38;2;32;148;243m0.02536361\u001b[0m \u001b[38;2;32;148;243m0.09479116\u001b[0m \u001b[38;2;32;148;243m0.11773768\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.12740417\u001b[0m \u001b[38;2;32;148;243m0.04908356\u001b[0m \u001b[38;2;32;148;243m0.18972287\u001b[0m \u001b[38;2;32;148;243m0.23499463\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19259697\u001b[0m \u001b[38;2;32;148;243m0.07292023\u001b[0m \u001b[38;2;32;148;243m0.28472662\u001b[0m \u001b[38;2;32;148;243m0.35236039\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.25677241\u001b[0m \u001b[38;2;32;148;243m0.09953109\u001b[0m \u001b[38;2;32;148;243m0.38082597\u001b[0m \u001b[38;2;32;148;243m0.46988771\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05751118\u001b[0m \u001b[38;2;32;148;243m-0.02762611\u001b[0m \u001b[38;2;32;148;243m-0.09032856\u001b[0m \u001b[38;2;32;148;243m-0.11743246\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1156655\u001b[0m  \u001b[38;2;32;148;243m-0.0549923\u001b[0m  \u001b[38;2;32;148;243m-0.18287469\u001b[0m \u001b[38;2;32;148;243m-0.23495288\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17648393\u001b[0m \u001b[38;2;32;148;243m-0.08188008\u001b[0m \u001b[38;2;32;148;243m-0.27748311\u001b[0m \u001b[38;2;32;148;243m-0.35263751\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.23844197\u001b[0m \u001b[38;2;32;148;243m-0.10856085\u001b[0m \u001b[38;2;32;148;243m-0.37275912\u001b[0m \u001b[38;2;32;148;243m-0.47048872\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17548294\u001b[0m \u001b[38;2;32;148;243m-0.08319724\u001b[0m \u001b[38;2;32;148;243m-0.27796796\u001b[0m \u001b[38;2;32;148;243m-0.35275104\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1110378\u001b[0m  \u001b[38;2;32;148;243m-0.05947729\u001b[0m \u001b[38;2;32;148;243m-0.18303625\u001b[0m \u001b[38;2;32;148;243m-0.23549409\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.045845\u001b[0m   \u001b[38;2;32;148;243m-0.03564062\u001b[0m \u001b[38;2;32;148;243m-0.0880325\u001b[0m  \u001b[38;2;32;148;243m-0.11812833\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01833044\u001b[0m \u001b[38;2;32;148;243m-0.00902976\u001b[0m  \u001b[38;2;32;148;243m0.00806685\u001b[0m \u001b[38;2;32;148;243m-0.00060101\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.65629595\u001b[0m \u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m0.35398312\u001b[0m \u001b[38;2;32;148;243m0.49236948\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01833044\u001b[0m \u001b[38;2;32;148;243m-0.00902976\u001b[0m  \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m-0.00060101\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00429017\u001b[0m \u001b[38;2;32;148;243m-0.00088047\u001b[0m \u001b[38;2;32;148;243m-0.0019709\u001b[0m  \u001b[38;2;32;148;243m-0.00261991\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00470862\u001b[0m \u001b[38;2;32;148;243m-0.00204245\u001b[0m \u001b[38;2;32;148;243m-0.00337299\u001b[0m  \u001b[38;2;32;148;243m0.00397335\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13739976\u001b[0m \u001b[38;2;32;148;243m-0.05959964\u001b[0m \u001b[38;2;32;148;243m-0.09842568\u001b[0m  \u001b[38;2;32;148;243m0.11594435\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00222099\u001b[0m \u001b[38;2;32;148;243m0.0004814\u001b[0m  \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00228172\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m7.61122078e-05\u001b[0m \u001b[38;2;32;148;243m1.64974062e-05\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m7.81931965e-05\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-3.523570691365356e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:50]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m11\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:50]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m12\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:50]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m13\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:51]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m14\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:51]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m15\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:52]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.08327295\u001b[0m  \u001b[38;2;32;148;243m19.0197769\u001b[0m  \u001b[38;2;32;148;243m-36.65111885\u001b[0m  \u001b[38;2;32;148;243m35.64933259\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.07697097\u001b[0m  \u001b[38;2;32;148;243m18.93400173\u001b[0m \u001b[38;2;32;148;243m-36.74012144\u001b[0m  \u001b[38;2;32;148;243m35.59790233\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.08385286\u001b[0m  \u001b[38;2;32;148;243m18.86262503\u001b[0m \u001b[38;2;32;148;243m-36.81229751\u001b[0m  \u001b[38;2;32;148;243m35.56680775\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.1041726\u001b[0m   \u001b[38;2;32;148;243m18.80744513\u001b[0m \u001b[38;2;32;148;243m-36.86774956\u001b[0m  \u001b[38;2;32;148;243m35.55670459\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.13787963\u001b[0m  \u001b[38;2;32;148;243m18.76616913\u001b[0m \u001b[38;2;32;148;243m-36.9068429\u001b[0m   \u001b[38;2;32;148;243m35.56661673\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.29806806\u001b[0m  \u001b[38;2;32;148;243m18.85372515\u001b[0m \u001b[38;2;32;148;243m-36.78646258\u001b[0m  \u001b[38;2;32;148;243m35.59589835\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.47129009\u001b[0m  \u001b[38;2;32;148;243m18.95604273\u001b[0m \u001b[38;2;32;148;243m-36.64914559\u001b[0m  \u001b[38;2;32;148;243m35.64578086\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.6563732\u001b[0m   \u001b[38;2;32;148;243m19.07405443\u001b[0m \u001b[38;2;32;148;243m-36.494943\u001b[0m    \u001b[38;2;32;148;243m35.71658607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.85494135\u001b[0m  \u001b[38;2;32;148;243m19.20666439\u001b[0m \u001b[38;2;32;148;243m-36.32391534\u001b[0m  \u001b[38;2;32;148;243m35.80825486\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.08327295\u001b[0m  \u001b[38;2;32;148;243m19.0197769\u001b[0m  \u001b[38;2;32;148;243m-36.65111885\u001b[0m  \u001b[38;2;32;148;243m35.64933259\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.14386161\u001b[0m  \u001b[38;2;32;148;243m18.96216574\u001b[0m \u001b[38;2;32;148;243m-36.64341855\u001b[0m  \u001b[38;2;32;148;243m35.7160735\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.21832877\u001b[0m  \u001b[38;2;32;148;243m18.91860861\u001b[0m \u001b[38;2;32;148;243m-36.61893687\u001b[0m  \u001b[38;2;32;148;243m35.80324569\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.30723783\u001b[0m  \u001b[38;2;32;148;243m18.88893401\u001b[0m \u001b[38;2;32;148;243m-36.57886993\u001b[0m  \u001b[38;2;32;148;243m35.91152916\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.41023902\u001b[0m  \u001b[38;2;32;148;243m18.8735014\u001b[0m  \u001b[38;2;32;148;243m-36.52280583\u001b[0m  \u001b[38;2;32;148;243m36.04005679\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.50133881\u001b[0m  \u001b[38;2;32;148;243m18.93349329\u001b[0m \u001b[38;2;32;148;243m-36.49758254\u001b[0m  \u001b[38;2;32;148;243m35.95072537\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.60675344\u001b[0m  \u001b[38;2;32;148;243m19.00765238\u001b[0m \u001b[38;2;32;148;243m-36.45586602\u001b[0m  \u001b[38;2;32;148;243m35.88193507\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.72712714\u001b[0m  \u001b[38;2;32;148;243m19.09626029\u001b[0m \u001b[38;2;32;148;243m-36.39758481\u001b[0m  \u001b[38;2;32;148;243m35.83369873\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m22.86168418\u001b[0m  \u001b[38;2;32;148;243m19.19884493\u001b[0m \u001b[38;2;32;148;243m-36.32274159\u001b[0m  \u001b[38;2;32;148;243m35.80633166\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06689064\u001b[0m \u001b[38;2;32;148;243m-0.02816401\u001b[0m \u001b[38;2;32;148;243m-0.09670289\u001b[0m \u001b[38;2;32;148;243m-0.11817117\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13447591\u001b[0m \u001b[38;2;32;148;243m-0.05598358\u001b[0m \u001b[38;2;32;148;243m-0.19336064\u001b[0m \u001b[38;2;32;148;243m-0.23643794\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20306523\u001b[0m \u001b[38;2;32;148;243m-0.08148888\u001b[0m \u001b[38;2;32;148;243m-0.28887963\u001b[0m \u001b[38;2;32;148;243m-0.35482457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27235939\u001b[0m \u001b[38;2;32;148;243m-0.10733227\u001b[0m \u001b[38;2;32;148;243m-0.38403706\u001b[0m \u001b[38;2;32;148;243m-0.47344005\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20327075\u001b[0m \u001b[38;2;32;148;243m-0.07976814\u001b[0m \u001b[38;2;32;148;243m-0.28888004\u001b[0m \u001b[38;2;32;148;243m-0.35482702\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13546335\u001b[0m \u001b[38;2;32;148;243m-0.05160965\u001b[0m \u001b[38;2;32;148;243m-0.19327958\u001b[0m \u001b[38;2;32;148;243m-0.23615421\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07075393\u001b[0m \u001b[38;2;32;148;243m-0.02220586\u001b[0m \u001b[38;2;32;148;243m-0.09735819\u001b[0m \u001b[38;2;32;148;243m-0.11711267\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00674283\u001b[0m  \u001b[38;2;32;148;243m0.00781946\u001b[0m \u001b[38;2;32;148;243m-0.00117375\u001b[0m  \u001b[38;2;32;148;243m0.0019232\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06689064\u001b[0m \u001b[38;2;32;148;243m-0.02816401\u001b[0m \u001b[38;2;32;148;243m-0.09670289\u001b[0m \u001b[38;2;32;148;243m-0.11817117\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13447591\u001b[0m \u001b[38;2;32;148;243m-0.05598358\u001b[0m \u001b[38;2;32;148;243m-0.19336064\u001b[0m \u001b[38;2;32;148;243m-0.23643794\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20306523\u001b[0m \u001b[38;2;32;148;243m-0.08148888\u001b[0m \u001b[38;2;32;148;243m-0.28887963\u001b[0m \u001b[38;2;32;148;243m-0.35482457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27235939\u001b[0m \u001b[38;2;32;148;243m-0.10733227\u001b[0m \u001b[38;2;32;148;243m-0.38403706\u001b[0m \u001b[38;2;32;148;243m-0.47344005\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.06908864\u001b[0m \u001b[38;2;32;148;243m0.02756413\u001b[0m \u001b[38;2;32;148;243m0.09515702\u001b[0m \u001b[38;2;32;148;243m0.11861303\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.13689604\u001b[0m \u001b[38;2;32;148;243m0.05572262\u001b[0m \u001b[38;2;32;148;243m0.19075749\u001b[0m \u001b[38;2;32;148;243m0.23728585\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20160546\u001b[0m \u001b[38;2;32;148;243m0.08512641\u001b[0m \u001b[38;2;32;148;243m0.28667887\u001b[0m \u001b[38;2;32;148;243m0.35632739\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.26561656\u001b[0m \u001b[38;2;32;148;243m0.11515173\u001b[0m \u001b[38;2;32;148;243m0.38286331\u001b[0m \u001b[38;2;32;148;243m0.47536325\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06689064\u001b[0m \u001b[38;2;32;148;243m-0.02816401\u001b[0m \u001b[38;2;32;148;243m-0.09670289\u001b[0m \u001b[38;2;32;148;243m-0.11817117\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13447591\u001b[0m \u001b[38;2;32;148;243m-0.05598358\u001b[0m \u001b[38;2;32;148;243m-0.19336064\u001b[0m \u001b[38;2;32;148;243m-0.23643794\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20306523\u001b[0m \u001b[38;2;32;148;243m-0.08148888\u001b[0m \u001b[38;2;32;148;243m-0.28887963\u001b[0m \u001b[38;2;32;148;243m-0.35482457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27235939\u001b[0m \u001b[38;2;32;148;243m-0.10733227\u001b[0m \u001b[38;2;32;148;243m-0.38403706\u001b[0m \u001b[38;2;32;148;243m-0.47344005\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20327075\u001b[0m \u001b[38;2;32;148;243m-0.07976814\u001b[0m \u001b[38;2;32;148;243m-0.28888004\u001b[0m \u001b[38;2;32;148;243m-0.35482702\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13546335\u001b[0m \u001b[38;2;32;148;243m-0.05160965\u001b[0m \u001b[38;2;32;148;243m-0.19327958\u001b[0m \u001b[38;2;32;148;243m-0.23615421\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07075393\u001b[0m \u001b[38;2;32;148;243m-0.02220586\u001b[0m \u001b[38;2;32;148;243m-0.09735819\u001b[0m \u001b[38;2;32;148;243m-0.11711267\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00674283\u001b[0m  \u001b[38;2;32;148;243m0.00781946\u001b[0m \u001b[38;2;32;148;243m-0.00117375\u001b[0m  \u001b[38;2;32;148;243m0.0019232\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.45913489\u001b[0m \u001b[38;2;32;148;243m0.83604902\u001b[0m \u001b[38;2;32;148;243m0.72009131\u001b[0m \u001b[38;2;32;148;243m0.85470485\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00674283\u001b[0m  \u001b[38;2;32;148;243m0.00781946\u001b[0m \u001b[38;2;32;148;243m-0.00117375\u001b[0m  \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00410104\u001b[0m  \u001b[38;2;32;148;243m0.00011216\u001b[0m \u001b[38;2;32;148;243m-0.00193722\u001b[0m \u001b[38;2;32;148;243m-0.00172661\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00468274\u001b[0m \u001b[38;2;32;148;243m-0.00197849\u001b[0m \u001b[38;2;32;148;243m-0.0033172\u001b[0m   \u001b[38;2;32;148;243m0.00396172\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13664465\u001b[0m \u001b[38;2;32;148;243m-0.05773323\u001b[0m \u001b[38;2;32;148;243m-0.09679748\u001b[0m  \u001b[38;2;32;148;243m0.11560499\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00490455\u001b[0m \u001b[38;2;32;148;243m0.00606124\u001b[0m \u001b[38;2;32;148;243m0.00438789\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00016808\u001b[0m \u001b[38;2;32;148;243m0.00020772\u001b[0m \u001b[38;2;32;148;243m0.00015037\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-4.064349363399149e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:52]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m16\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:52]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m17\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:52]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m18\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:53]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m19\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:53]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m20\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:54]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.24449011\u001b[0m  \u001b[38;2;32;148;243m157.51395791\u001b[0m \u001b[38;2;32;148;243m-208.48354391\u001b[0m    \u001b[38;2;32;148;243m7.94362976\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.131001\u001b[0m    \u001b[38;2;32;148;243m157.57724448\u001b[0m \u001b[38;2;32;148;243m-208.48275539\u001b[0m    \u001b[38;2;32;148;243m7.79977811\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.03407439\u001b[0m  \u001b[38;2;32;148;243m157.65458278\u001b[0m \u001b[38;2;32;148;243m-208.46456333\u001b[0m    \u001b[38;2;32;148;243m7.67616995\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.94980559\u001b[0m  \u001b[38;2;32;148;243m157.74629708\u001b[0m \u001b[38;2;32;148;243m-208.42972391\u001b[0m    \u001b[38;2;32;148;243m7.57344121\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.87787847\u001b[0m  \u001b[38;2;32;148;243m157.85139826\u001b[0m \u001b[38;2;32;148;243m-208.37822275\u001b[0m    \u001b[38;2;32;148;243m7.49172438\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.86104423\u001b[0m  \u001b[38;2;32;148;243m157.84775292\u001b[0m \u001b[38;2;32;148;243m-208.3583655\u001b[0m     \u001b[38;2;32;148;243m7.50257305\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.86515279\u001b[0m  \u001b[38;2;32;148;243m157.85840203\u001b[0m \u001b[38;2;32;148;243m-208.32204505\u001b[0m    \u001b[38;2;32;148;243m7.53279089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.88936298\u001b[0m  \u001b[38;2;32;148;243m157.8873257\u001b[0m  \u001b[38;2;32;148;243m-208.26938999\u001b[0m    \u001b[38;2;32;148;243m7.58293561\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.93276149\u001b[0m  \u001b[38;2;32;148;243m157.93030545\u001b[0m \u001b[38;2;32;148;243m-208.20040312\u001b[0m    \u001b[38;2;32;148;243m7.65313816\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.24449011\u001b[0m  \u001b[38;2;32;148;243m157.51395791\u001b[0m \u001b[38;2;32;148;243m-208.48354391\u001b[0m    \u001b[38;2;32;148;243m7.94362976\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.18665175\u001b[0m  \u001b[38;2;32;148;243m157.61341561\u001b[0m \u001b[38;2;32;148;243m-208.38213623\u001b[0m    \u001b[38;2;32;148;243m7.91836792\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.14357945\u001b[0m  \u001b[38;2;32;148;243m157.72687855\u001b[0m \u001b[38;2;32;148;243m-208.26400887\u001b[0m    \u001b[38;2;32;148;243m7.91352822\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.11376441\u001b[0m  \u001b[38;2;32;148;243m157.85446265\u001b[0m \u001b[38;2;32;148;243m-208.13028082\u001b[0m    \u001b[38;2;32;148;243m7.92975756\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.09712312\u001b[0m  \u001b[38;2;32;148;243m157.99621367\u001b[0m \u001b[38;2;32;148;243m-207.97971005\u001b[0m    \u001b[38;2;32;148;243m7.96695753\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m18.02461769\u001b[0m  \u001b[38;2;32;148;243m157.95833194\u001b[0m \u001b[38;2;32;148;243m-208.05892191\u001b[0m    \u001b[38;2;32;148;243m7.85916573\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.96958153\u001b[0m  \u001b[38;2;32;148;243m157.93478819\u001b[0m \u001b[38;2;32;148;243m-208.12071791\u001b[0m    \u001b[38;2;32;148;243m7.77120336\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.93172414\u001b[0m  \u001b[38;2;32;148;243m157.92673721\u001b[0m \u001b[38;2;32;148;243m-208.16486932\u001b[0m    \u001b[38;2;32;148;243m7.70347135\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m17.91064328\u001b[0m  \u001b[38;2;32;148;243m157.93285714\u001b[0m \u001b[38;2;32;148;243m-208.19159752\u001b[0m    \u001b[38;2;32;148;243m7.65597587\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05565075\u001b[0m \u001b[38;2;32;148;243m-0.03617114\u001b[0m \u001b[38;2;32;148;243m-0.10061915\u001b[0m \u001b[38;2;32;148;243m-0.1185898\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10950507\u001b[0m \u001b[38;2;32;148;243m-0.07229577\u001b[0m \u001b[38;2;32;148;243m-0.20055447\u001b[0m \u001b[38;2;32;148;243m-0.23735827\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16395882\u001b[0m \u001b[38;2;32;148;243m-0.10816557\u001b[0m \u001b[38;2;32;148;243m-0.29944309\u001b[0m \u001b[38;2;32;148;243m-0.35631635\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21924465\u001b[0m \u001b[38;2;32;148;243m-0.14481541\u001b[0m \u001b[38;2;32;148;243m-0.3985127\u001b[0m  \u001b[38;2;32;148;243m-0.47523315\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16357346\u001b[0m \u001b[38;2;32;148;243m-0.11057902\u001b[0m \u001b[38;2;32;148;243m-0.29944359\u001b[0m \u001b[38;2;32;148;243m-0.35659268\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10442873\u001b[0m \u001b[38;2;32;148;243m-0.07638616\u001b[0m \u001b[38;2;32;148;243m-0.20132714\u001b[0m \u001b[38;2;32;148;243m-0.23841247\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.04236116\u001b[0m \u001b[38;2;32;148;243m-0.0394115\u001b[0m  \u001b[38;2;32;148;243m-0.10452067\u001b[0m \u001b[38;2;32;148;243m-0.12053573\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.02211821\u001b[0m \u001b[38;2;32;148;243m-0.0025517\u001b[0m  \u001b[38;2;32;148;243m-0.0088056\u001b[0m  \u001b[38;2;32;148;243m-0.00283771\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05565075\u001b[0m \u001b[38;2;32;148;243m-0.03617114\u001b[0m \u001b[38;2;32;148;243m-0.10061915\u001b[0m \u001b[38;2;32;148;243m-0.1185898\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10950507\u001b[0m \u001b[38;2;32;148;243m-0.07229577\u001b[0m \u001b[38;2;32;148;243m-0.20055447\u001b[0m \u001b[38;2;32;148;243m-0.23735827\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16395882\u001b[0m \u001b[38;2;32;148;243m-0.10816557\u001b[0m \u001b[38;2;32;148;243m-0.29944309\u001b[0m \u001b[38;2;32;148;243m-0.35631635\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21924465\u001b[0m \u001b[38;2;32;148;243m-0.14481541\u001b[0m \u001b[38;2;32;148;243m-0.3985127\u001b[0m  \u001b[38;2;32;148;243m-0.47523315\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.05567119\u001b[0m \u001b[38;2;32;148;243m0.03423639\u001b[0m \u001b[38;2;32;148;243m0.09906911\u001b[0m \u001b[38;2;32;148;243m0.11864046\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11481592\u001b[0m \u001b[38;2;32;148;243m0.06842925\u001b[0m \u001b[38;2;32;148;243m0.19718556\u001b[0m \u001b[38;2;32;148;243m0.23682067\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.17688349\u001b[0m \u001b[38;2;32;148;243m0.10540391\u001b[0m \u001b[38;2;32;148;243m0.29399203\u001b[0m \u001b[38;2;32;148;243m0.35469741\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.24136286\u001b[0m \u001b[38;2;32;148;243m0.14226372\u001b[0m \u001b[38;2;32;148;243m0.3897071\u001b[0m  \u001b[38;2;32;148;243m0.47239543\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05565075\u001b[0m \u001b[38;2;32;148;243m-0.03617114\u001b[0m \u001b[38;2;32;148;243m-0.10061915\u001b[0m \u001b[38;2;32;148;243m-0.1185898\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10950507\u001b[0m \u001b[38;2;32;148;243m-0.07229577\u001b[0m \u001b[38;2;32;148;243m-0.20055447\u001b[0m \u001b[38;2;32;148;243m-0.23735827\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16395882\u001b[0m \u001b[38;2;32;148;243m-0.10816557\u001b[0m \u001b[38;2;32;148;243m-0.29944309\u001b[0m \u001b[38;2;32;148;243m-0.35631635\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21924465\u001b[0m \u001b[38;2;32;148;243m-0.14481541\u001b[0m \u001b[38;2;32;148;243m-0.3985127\u001b[0m  \u001b[38;2;32;148;243m-0.47523315\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.16357346\u001b[0m \u001b[38;2;32;148;243m-0.11057902\u001b[0m \u001b[38;2;32;148;243m-0.29944359\u001b[0m \u001b[38;2;32;148;243m-0.35659268\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10442873\u001b[0m \u001b[38;2;32;148;243m-0.07638616\u001b[0m \u001b[38;2;32;148;243m-0.20132714\u001b[0m \u001b[38;2;32;148;243m-0.23841247\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.04236116\u001b[0m \u001b[38;2;32;148;243m-0.0394115\u001b[0m  \u001b[38;2;32;148;243m-0.10452067\u001b[0m \u001b[38;2;32;148;243m-0.12053573\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.02211821\u001b[0m \u001b[38;2;32;148;243m-0.0025517\u001b[0m  \u001b[38;2;32;148;243m-0.0088056\u001b[0m  \u001b[38;2;32;148;243m-0.00283771\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m0.65777047\u001b[0m \u001b[38;2;32;148;243m0.74680857\u001b[0m \u001b[38;2;32;148;243m1\u001b[0m.        \u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.02211821\u001b[0m \u001b[38;2;32;148;243m-0\u001b[0m.         \u001b[38;2;32;148;243m-0\u001b[0m.         \u001b[38;2;32;148;243m-0.00283771\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00307229\u001b[0m  \u001b[38;2;32;148;243m0.00081471\u001b[0m \u001b[38;2;32;148;243m-0.00146663\u001b[0m \u001b[38;2;32;148;243m-0.00150205\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00484404\u001b[0m \u001b[38;2;32;148;243m-0.00162107\u001b[0m \u001b[38;2;32;148;243m-0.00354424\u001b[0m  \u001b[38;2;32;148;243m0.00406079\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14135151\u001b[0m \u001b[38;2;32;148;243m-0.04730375\u001b[0m \u001b[38;2;32;148;243m-0.10342278\u001b[0m  \u001b[38;2;32;148;243m0.11849601\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00132971\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00211542\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4.55685873e-05\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m7.24941821e-05\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-4.81144798353746e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:54]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m21\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:54]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m22\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:54]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m23\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:55]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m24\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:55]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m25\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:55]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.02841282\u001b[0m  \u001b[38;2;32;148;243m66.72029544\u001b[0m  \u001b[38;2;32;148;243m59.90481188\u001b[0m \u001b[38;2;32;148;243m146.00124109\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.00555319\u001b[0m  \u001b[38;2;32;148;243m66.74978538\u001b[0m  \u001b[38;2;32;148;243m59.90840465\u001b[0m \u001b[38;2;32;148;243m145.85528037\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m102.99730392\u001b[0m  \u001b[38;2;32;148;243m66.7937695\u001b[0m   \u001b[38;2;32;148;243m59.92887223\u001b[0m \u001b[38;2;32;148;243m145.72930134\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.00125737\u001b[0m  \u001b[38;2;32;148;243m66.85207329\u001b[0m  \u001b[38;2;32;148;243m59.96577299\u001b[0m \u001b[38;2;32;148;243m145.62408096\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.01948883\u001b[0m  \u001b[38;2;32;148;243m66.9247455\u001b[0m   \u001b[38;2;32;148;243m60.01915062\u001b[0m \u001b[38;2;32;148;243m145.53920011\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.20998844\u001b[0m  \u001b[38;2;32;148;243m66.90147596\u001b[0m  \u001b[38;2;32;148;243m60.11104722\u001b[0m \u001b[38;2;32;148;243m145.71750439\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.41490006\u001b[0m  \u001b[38;2;32;148;243m66.89165518\u001b[0m  \u001b[38;2;32;148;243m60.2198083\u001b[0m  \u001b[38;2;32;148;243m145.915704\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.63465314\u001b[0m  \u001b[38;2;32;148;243m66.89507612\u001b[0m  \u001b[38;2;32;148;243m60.34472098\u001b[0m \u001b[38;2;32;148;243m146.1340541\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.86859577\u001b[0m  \u001b[38;2;32;148;243m66.91086793\u001b[0m  \u001b[38;2;32;148;243m60.48597197\u001b[0m \u001b[38;2;32;148;243m146.3725016\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.02841282\u001b[0m  \u001b[38;2;32;148;243m66.72029544\u001b[0m  \u001b[38;2;32;148;243m59.90481188\u001b[0m \u001b[38;2;32;148;243m146.00124109\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.06221521\u001b[0m  \u001b[38;2;32;148;243m66.78220304\u001b[0m  \u001b[38;2;32;148;243m60.00541219\u001b[0m \u001b[38;2;32;148;243m145.97179754\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.11016976\u001b[0m  \u001b[38;2;32;148;243m66.85855726\u001b[0m  \u001b[38;2;32;148;243m60.1232324\u001b[0m  \u001b[38;2;32;148;243m145.96242371\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.17152685\u001b[0m  \u001b[38;2;32;148;243m66.94940619\u001b[0m  \u001b[38;2;32;148;243m60.25727658\u001b[0m \u001b[38;2;32;148;243m145.97369716\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.24708037\u001b[0m  \u001b[38;2;32;148;243m67.05444773\u001b[0m  \u001b[38;2;32;148;243m60.40638075\u001b[0m \u001b[38;2;32;148;243m146.00512372\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.38050002\u001b[0m  \u001b[38;2;32;148;243m66.99928691\u001b[0m  \u001b[38;2;32;148;243m60.40429756\u001b[0m \u001b[38;2;32;148;243m146.06712644\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.52788974\u001b[0m  \u001b[38;2;32;148;243m66.95744795\u001b[0m  \u001b[38;2;32;148;243m60.42047951\u001b[0m \u001b[38;2;32;148;243m146.14933104\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.68961244\u001b[0m  \u001b[38;2;32;148;243m66.92731634\u001b[0m  \u001b[38;2;32;148;243m60.45239386\u001b[0m \u001b[38;2;32;148;243m146.25190874\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m103.86522803\u001b[0m  \u001b[38;2;32;148;243m66.90645727\u001b[0m  \u001b[38;2;32;148;243m60.50043445\u001b[0m \u001b[38;2;32;148;243m146.37474149\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05666201\u001b[0m \u001b[38;2;32;148;243m-0.03241766\u001b[0m \u001b[38;2;32;148;243m-0.09700755\u001b[0m \u001b[38;2;32;148;243m-0.11651717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11286583\u001b[0m \u001b[38;2;32;148;243m-0.06478776\u001b[0m \u001b[38;2;32;148;243m-0.19436017\u001b[0m \u001b[38;2;32;148;243m-0.23312237\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17026948\u001b[0m \u001b[38;2;32;148;243m-0.0973329\u001b[0m  \u001b[38;2;32;148;243m-0.29150359\u001b[0m \u001b[38;2;32;148;243m-0.34961621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.22759154\u001b[0m \u001b[38;2;32;148;243m-0.12970223\u001b[0m \u001b[38;2;32;148;243m-0.38723013\u001b[0m \u001b[38;2;32;148;243m-0.46592362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17051158\u001b[0m \u001b[38;2;32;148;243m-0.09781095\u001b[0m \u001b[38;2;32;148;243m-0.29325034\u001b[0m \u001b[38;2;32;148;243m-0.34962204\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11298968\u001b[0m \u001b[38;2;32;148;243m-0.06579277\u001b[0m \u001b[38;2;32;148;243m-0.20067121\u001b[0m \u001b[38;2;32;148;243m-0.23362704\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0549593\u001b[0m  \u001b[38;2;32;148;243m-0.03224022\u001b[0m \u001b[38;2;32;148;243m-0.10767288\u001b[0m \u001b[38;2;32;148;243m-0.11785464\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00336773\u001b[0m  \u001b[38;2;32;148;243m0.00441065\u001b[0m \u001b[38;2;32;148;243m-0.01446248\u001b[0m \u001b[38;2;32;148;243m-0.0022399\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05666201\u001b[0m \u001b[38;2;32;148;243m-0.03241766\u001b[0m \u001b[38;2;32;148;243m-0.09700755\u001b[0m \u001b[38;2;32;148;243m-0.11651717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11286583\u001b[0m \u001b[38;2;32;148;243m-0.06478776\u001b[0m \u001b[38;2;32;148;243m-0.19436017\u001b[0m \u001b[38;2;32;148;243m-0.23312237\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17026948\u001b[0m \u001b[38;2;32;148;243m-0.0973329\u001b[0m  \u001b[38;2;32;148;243m-0.29150359\u001b[0m \u001b[38;2;32;148;243m-0.34961621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.22759154\u001b[0m \u001b[38;2;32;148;243m-0.12970223\u001b[0m \u001b[38;2;32;148;243m-0.38723013\u001b[0m \u001b[38;2;32;148;243m-0.46592362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.05707996\u001b[0m \u001b[38;2;32;148;243m0.03189128\u001b[0m \u001b[38;2;32;148;243m0.09397978\u001b[0m \u001b[38;2;32;148;243m0.11630157\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11460186\u001b[0m \u001b[38;2;32;148;243m0.06390946\u001b[0m \u001b[38;2;32;148;243m0.18655891\u001b[0m \u001b[38;2;32;148;243m0.23229658\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.17263224\u001b[0m \u001b[38;2;32;148;243m0.09746201\u001b[0m \u001b[38;2;32;148;243m0.27955724\u001b[0m \u001b[38;2;32;148;243m0.34806898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.23095927\u001b[0m \u001b[38;2;32;148;243m0.13411288\u001b[0m \u001b[38;2;32;148;243m0.37276764\u001b[0m \u001b[38;2;32;148;243m0.46368372\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.05666201\u001b[0m \u001b[38;2;32;148;243m-0.03241766\u001b[0m \u001b[38;2;32;148;243m-0.09700755\u001b[0m \u001b[38;2;32;148;243m-0.11651717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11286583\u001b[0m \u001b[38;2;32;148;243m-0.06478776\u001b[0m \u001b[38;2;32;148;243m-0.19436017\u001b[0m \u001b[38;2;32;148;243m-0.23312237\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17026948\u001b[0m \u001b[38;2;32;148;243m-0.0973329\u001b[0m  \u001b[38;2;32;148;243m-0.29150359\u001b[0m \u001b[38;2;32;148;243m-0.34961621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.22759154\u001b[0m \u001b[38;2;32;148;243m-0.12970223\u001b[0m \u001b[38;2;32;148;243m-0.38723013\u001b[0m \u001b[38;2;32;148;243m-0.46592362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17051158\u001b[0m \u001b[38;2;32;148;243m-0.09781095\u001b[0m \u001b[38;2;32;148;243m-0.29325034\u001b[0m \u001b[38;2;32;148;243m-0.34962204\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11298968\u001b[0m \u001b[38;2;32;148;243m-0.06579277\u001b[0m \u001b[38;2;32;148;243m-0.20067121\u001b[0m \u001b[38;2;32;148;243m-0.23362704\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0549593\u001b[0m  \u001b[38;2;32;148;243m-0.03224022\u001b[0m \u001b[38;2;32;148;243m-0.10767288\u001b[0m \u001b[38;2;32;148;243m-0.11785464\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00336773\u001b[0m  \u001b[38;2;32;148;243m0.00441065\u001b[0m \u001b[38;2;32;148;243m-0.01446248\u001b[0m \u001b[38;2;32;148;243m-0.0022399\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.43308762\u001b[0m \u001b[38;2;32;148;243m0.83013924\u001b[0m \u001b[38;2;32;148;243m0.55121929\u001b[0m \u001b[38;2;32;148;243m0.68832071\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0.00441065\u001b[0m \u001b[38;2;32;148;243m-0.01446248\u001b[0m \u001b[38;2;32;148;243m-0\u001b[0m.        \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0027481\u001b[0m   \u001b[38;2;32;148;243m0.00119082\u001b[0m \u001b[38;2;32;148;243m-0.00158445\u001b[0m \u001b[38;2;32;148;243m-0.00089441\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00451238\u001b[0m \u001b[38;2;32;148;243m-0.00182152\u001b[0m \u001b[38;2;32;148;243m-0.0035942\u001b[0m   \u001b[38;2;32;148;243m0.00441841\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13167354\u001b[0m \u001b[38;2;32;148;243m-0.05315281\u001b[0m \u001b[38;2;32;148;243m-0.10488051\u001b[0m  \u001b[38;2;32;148;243m0.12893134\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.0018939\u001b[0m  \u001b[38;2;32;148;243m0.00298696\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m6.49030205e-05\u001b[0m \u001b[38;2;32;148;243m1.02361421e-04\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-3.587542080169492e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:56]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m26\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:56]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m27\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:56]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m28\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:57]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m29\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:57]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m30\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:58]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44430506\u001b[0m \u001b[38;2;32;148;243m-165.95958335\u001b[0m  \u001b[38;2;32;148;243m-15.50481522\u001b[0m \u001b[38;2;32;148;243m-102.40867299\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.43718998\u001b[0m \u001b[38;2;32;148;243m-166.10277443\u001b[0m  \u001b[38;2;32;148;243m-15.62779543\u001b[0m \u001b[38;2;32;148;243m-102.56181693\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44464905\u001b[0m \u001b[38;2;32;148;243m-166.22901843\u001b[0m  \u001b[38;2;32;148;243m-15.7356583\u001b[0m  \u001b[38;2;32;148;243m-102.69496592\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.46736464\u001b[0m \u001b[38;2;32;148;243m-166.33990308\u001b[0m  \u001b[38;2;32;148;243m-15.82781492\u001b[0m \u001b[38;2;32;148;243m-102.80737464\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.50500891\u001b[0m \u001b[38;2;32;148;243m-166.43443664\u001b[0m  \u001b[38;2;32;148;243m-15.90440405\u001b[0m \u001b[38;2;32;148;243m-102.89983611\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.46719889\u001b[0m \u001b[38;2;32;148;243m-166.4180316\u001b[0m   \u001b[38;2;32;148;243m-15.59365182\u001b[0m \u001b[38;2;32;148;243m-102.80127799\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44397975\u001b[0m \u001b[38;2;32;148;243m-166.38658933\u001b[0m  \u001b[38;2;32;148;243m-15.26972746\u001b[0m \u001b[38;2;32;148;243m-102.68257058\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.43542179\u001b[0m \u001b[38;2;32;148;243m-166.34041499\u001b[0m  \u001b[38;2;32;148;243m-14.9318252\u001b[0m  \u001b[38;2;32;148;243m-102.54360961\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44179493\u001b[0m \u001b[38;2;32;148;243m-166.279924\u001b[0m    \u001b[38;2;32;148;243m-14.57940301\u001b[0m \u001b[38;2;32;148;243m-102.38444531\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44430506\u001b[0m \u001b[38;2;32;148;243m-165.95958335\u001b[0m  \u001b[38;2;32;148;243m-15.50481522\u001b[0m \u001b[38;2;32;148;243m-102.40867299\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.50781019\u001b[0m \u001b[38;2;32;148;243m-166.07558872\u001b[0m  \u001b[38;2;32;148;243m-15.54001\u001b[0m    \u001b[38;2;32;148;243m-102.44454202\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.58658104\u001b[0m \u001b[38;2;32;148;243m-166.17276673\u001b[0m  \u001b[38;2;32;148;243m-15.55915382\u001b[0m \u001b[38;2;32;148;243m-102.46024532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.68270227\u001b[0m \u001b[38;2;32;148;243m-166.25379651\u001b[0m  \u001b[38;2;32;148;243m-15.56265621\u001b[0m \u001b[38;2;32;148;243m-102.45555478\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.79468708\u001b[0m \u001b[38;2;32;148;243m-166.31696368\u001b[0m  \u001b[38;2;32;148;243m-15.55021339\u001b[0m \u001b[38;2;32;148;243m-102.43120679\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.68351855\u001b[0m \u001b[38;2;32;148;243m-166.33485863\u001b[0m  \u001b[38;2;32;148;243m-15.3277197\u001b[0m  \u001b[38;2;32;148;243m-102.44957194\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.58743691\u001b[0m \u001b[38;2;32;148;243m-166.3402427\u001b[0m   \u001b[38;2;32;148;243m-15.09050885\u001b[0m \u001b[38;2;32;148;243m-102.44788906\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.50631117\u001b[0m \u001b[38;2;32;148;243m-166.33310876\u001b[0m  \u001b[38;2;32;148;243m-14.83848715\u001b[0m \u001b[38;2;32;148;243m-102.42597688\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m5.44094998\u001b[0m \u001b[38;2;32;148;243m-166.31355254\u001b[0m  \u001b[38;2;32;148;243m-14.57136671\u001b[0m \u001b[38;2;32;148;243m-102.38389437\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07062021\u001b[0m \u001b[38;2;32;148;243m-0.02718572\u001b[0m \u001b[38;2;32;148;243m-0.08778543\u001b[0m \u001b[38;2;32;148;243m-0.11727491\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14193199\u001b[0m \u001b[38;2;32;148;243m-0.0562517\u001b[0m  \u001b[38;2;32;148;243m-0.17650448\u001b[0m \u001b[38;2;32;148;243m-0.23472059\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21533763\u001b[0m \u001b[38;2;32;148;243m-0.08610658\u001b[0m \u001b[38;2;32;148;243m-0.26515871\u001b[0m \u001b[38;2;32;148;243m-0.35181986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28967817\u001b[0m \u001b[38;2;32;148;243m-0.11747296\u001b[0m \u001b[38;2;32;148;243m-0.35419066\u001b[0m \u001b[38;2;32;148;243m-0.46862932\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21631966\u001b[0m \u001b[38;2;32;148;243m-0.08317297\u001b[0m \u001b[38;2;32;148;243m-0.26593212\u001b[0m \u001b[38;2;32;148;243m-0.35170605\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14345716\u001b[0m \u001b[38;2;32;148;243m-0.04634663\u001b[0m \u001b[38;2;32;148;243m-0.17921861\u001b[0m \u001b[38;2;32;148;243m-0.23468152\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07088938\u001b[0m \u001b[38;2;32;148;243m-0.00730623\u001b[0m \u001b[38;2;32;148;243m-0.09333805\u001b[0m \u001b[38;2;32;148;243m-0.11763273\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00084495\u001b[0m  \u001b[38;2;32;148;243m0.03362854\u001b[0m \u001b[38;2;32;148;243m-0.0080363\u001b[0m  \u001b[38;2;32;148;243m-0.00055094\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07062021\u001b[0m \u001b[38;2;32;148;243m-0.02718572\u001b[0m \u001b[38;2;32;148;243m-0.08778543\u001b[0m \u001b[38;2;32;148;243m-0.11727491\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14193199\u001b[0m \u001b[38;2;32;148;243m-0.0562517\u001b[0m  \u001b[38;2;32;148;243m-0.17650448\u001b[0m \u001b[38;2;32;148;243m-0.23472059\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21533763\u001b[0m \u001b[38;2;32;148;243m-0.08610658\u001b[0m \u001b[38;2;32;148;243m-0.26515871\u001b[0m \u001b[38;2;32;148;243m-0.35181986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28967817\u001b[0m \u001b[38;2;32;148;243m-0.11747296\u001b[0m \u001b[38;2;32;148;243m-0.35419066\u001b[0m \u001b[38;2;32;148;243m-0.46862932\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.07335851\u001b[0m \u001b[38;2;32;148;243m0.0343\u001b[0m     \u001b[38;2;32;148;243m0.08825854\u001b[0m \u001b[38;2;32;148;243m0.11692327\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.14622101\u001b[0m \u001b[38;2;32;148;243m0.07112634\u001b[0m \u001b[38;2;32;148;243m0.17497205\u001b[0m \u001b[38;2;32;148;243m0.23394779\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21878879\u001b[0m \u001b[38;2;32;148;243m0.11016673\u001b[0m \u001b[38;2;32;148;243m0.26085261\u001b[0m \u001b[38;2;32;148;243m0.35099659\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.29052312\u001b[0m \u001b[38;2;32;148;243m0.1511015\u001b[0m  \u001b[38;2;32;148;243m0.34615436\u001b[0m \u001b[38;2;32;148;243m0.46807838\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07062021\u001b[0m \u001b[38;2;32;148;243m-0.02718572\u001b[0m \u001b[38;2;32;148;243m-0.08778543\u001b[0m \u001b[38;2;32;148;243m-0.11727491\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14193199\u001b[0m \u001b[38;2;32;148;243m-0.0562517\u001b[0m  \u001b[38;2;32;148;243m-0.17650448\u001b[0m \u001b[38;2;32;148;243m-0.23472059\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21533763\u001b[0m \u001b[38;2;32;148;243m-0.08610658\u001b[0m \u001b[38;2;32;148;243m-0.26515871\u001b[0m \u001b[38;2;32;148;243m-0.35181986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28967817\u001b[0m \u001b[38;2;32;148;243m-0.11747296\u001b[0m \u001b[38;2;32;148;243m-0.35419066\u001b[0m \u001b[38;2;32;148;243m-0.46862932\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21631966\u001b[0m \u001b[38;2;32;148;243m-0.08317297\u001b[0m \u001b[38;2;32;148;243m-0.26593212\u001b[0m \u001b[38;2;32;148;243m-0.35170605\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14345716\u001b[0m \u001b[38;2;32;148;243m-0.04634663\u001b[0m \u001b[38;2;32;148;243m-0.17921861\u001b[0m \u001b[38;2;32;148;243m-0.23468152\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07088938\u001b[0m \u001b[38;2;32;148;243m-0.00730623\u001b[0m \u001b[38;2;32;148;243m-0.09333805\u001b[0m \u001b[38;2;32;148;243m-0.11763273\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00084495\u001b[0m  \u001b[38;2;32;148;243m0.03362854\u001b[0m \u001b[38;2;32;148;243m-0.0080363\u001b[0m  \u001b[38;2;32;148;243m-0.00055094\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m0.39319543\u001b[0m \u001b[38;2;32;148;243m0.97552585\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00084495\u001b[0m  \u001b[38;2;32;148;243m0.03362854\u001b[0m \u001b[38;2;32;148;243m-0\u001b[0m.         \u001b[38;2;32;148;243m-0.00055094\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00267364\u001b[0m  \u001b[38;2;32;148;243m0.00204628\u001b[0m \u001b[38;2;32;148;243m-0.00143384\u001b[0m \u001b[38;2;32;148;243m-0.00045363\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00460961\u001b[0m \u001b[38;2;32;148;243m-0.00176722\u001b[0m \u001b[38;2;32;148;243m-0.00379743\u001b[0m  \u001b[38;2;32;148;243m0.0038541\u001b[0m \u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13451074\u001b[0m \u001b[38;2;32;148;243m-0.05156846\u001b[0m \u001b[38;2;32;148;243m-0.11081098\u001b[0m  \u001b[38;2;32;148;243m0.11246456\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00099198\u001b[0m \u001b[38;2;32;148;243m0.00188247\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00811582\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m3.39945351e-05\u001b[0m \u001b[38;2;32;148;243m6.45112363e-05\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m2.78124805e-04\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-4.729706796001338e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:58]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m31\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:58]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m32\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:59]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m33\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:59]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m34\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:56:59]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m35\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:00]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.24109866\u001b[0m   \u001b[38;2;32;148;243m5.55612112\u001b[0m  \u001b[38;2;32;148;243m-1.76277452\u001b[0m \u001b[38;2;32;148;243m-52.84427962\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.32994306\u001b[0m   \u001b[38;2;32;148;243m5.55140781\u001b[0m  \u001b[38;2;32;148;243m-1.64083871\u001b[0m \u001b[38;2;32;148;243m-52.86777806\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.40531362\u001b[0m   \u001b[38;2;32;148;243m5.56129168\u001b[0m  \u001b[38;2;32;148;243m-1.50469869\u001b[0m \u001b[38;2;32;148;243m-52.87194866\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.46792643\u001b[0m   \u001b[38;2;32;148;243m5.58535052\u001b[0m  \u001b[38;2;32;148;243m-1.35394915\u001b[0m \u001b[38;2;32;148;243m-52.85704699\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.51648618\u001b[0m   \u001b[38;2;32;148;243m5.62468415\u001b[0m  \u001b[38;2;32;148;243m-1.18861717\u001b[0m \u001b[38;2;32;148;243m-52.82292239\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.31153675\u001b[0m   \u001b[38;2;32;148;243m5.73641202\u001b[0m  \u001b[38;2;32;148;243m-1.11288606\u001b[0m \u001b[38;2;32;148;243m-52.65606878\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.09224637\u001b[0m   \u001b[38;2;32;148;243m5.8627936\u001b[0m   \u001b[38;2;32;148;243m-1.02476863\u001b[0m \u001b[38;2;32;148;243m-52.46855894\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-37.85867931\u001b[0m   \u001b[38;2;32;148;243m6.00371097\u001b[0m  \u001b[38;2;32;148;243m-0.92164249\u001b[0m \u001b[38;2;32;148;243m-52.26006541\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-37.6106359\u001b[0m    \u001b[38;2;32;148;243m6.15897688\u001b[0m  \u001b[38;2;32;148;243m-0.80273488\u001b[0m \u001b[38;2;32;148;243m-52.03065188\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.24109866\u001b[0m   \u001b[38;2;32;148;243m5.55612112\u001b[0m  \u001b[38;2;32;148;243m-1.76277452\u001b[0m \u001b[38;2;32;148;243m-52.84427962\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.26222741\u001b[0m   \u001b[38;2;32;148;243m5.57653363\u001b[0m  \u001b[38;2;32;148;243m-1.56187095\u001b[0m \u001b[38;2;32;148;243m-52.7515782\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.26973224\u001b[0m   \u001b[38;2;32;148;243m5.61095297\u001b[0m  \u001b[38;2;32;148;243m-1.34509313\u001b[0m \u001b[38;2;32;148;243m-52.63971354\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.26380994\u001b[0m   \u001b[38;2;32;148;243m5.65981386\u001b[0m  \u001b[38;2;32;148;243m-1.11211757\u001b[0m \u001b[38;2;32;148;243m-52.50928377\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.2439666\u001b[0m    \u001b[38;2;32;148;243m5.72255661\u001b[0m  \u001b[38;2;32;148;243m-0.86315277\u001b[0m \u001b[38;2;32;148;243m-52.35968199\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-38.10907575\u001b[0m   \u001b[38;2;32;148;243m5.81183388\u001b[0m  \u001b[38;2;32;148;243m-0.87027295\u001b[0m \u001b[38;2;32;148;243m-52.30873805\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-37.96184935\u001b[0m   \u001b[38;2;32;148;243m5.91481407\u001b[0m  \u001b[38;2;32;148;243m-0.86351973\u001b[0m \u001b[38;2;32;148;243m-52.23756461\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-37.80125051\u001b[0m   \u001b[38;2;32;148;243m6.03101643\u001b[0m  \u001b[38;2;32;148;243m-0.84187415\u001b[0m \u001b[38;2;32;148;243m-52.14581443\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-37.62641755\u001b[0m   \u001b[38;2;32;148;243m6.15964415\u001b[0m  \u001b[38;2;32;148;243m-0.80499075\u001b[0m \u001b[38;2;32;148;243m-52.03352906\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06771565\u001b[0m \u001b[38;2;32;148;243m-0.02512582\u001b[0m \u001b[38;2;32;148;243m-0.07896776\u001b[0m \u001b[38;2;32;148;243m-0.11619986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13558138\u001b[0m \u001b[38;2;32;148;243m-0.04966129\u001b[0m \u001b[38;2;32;148;243m-0.15960556\u001b[0m \u001b[38;2;32;148;243m-0.23223511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20411649\u001b[0m \u001b[38;2;32;148;243m-0.07446334\u001b[0m \u001b[38;2;32;148;243m-0.24183158\u001b[0m \u001b[38;2;32;148;243m-0.34776322\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27251958\u001b[0m \u001b[38;2;32;148;243m-0.09787246\u001b[0m \u001b[38;2;32;148;243m-0.3254644\u001b[0m  \u001b[38;2;32;148;243m-0.4632404\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.202461\u001b[0m   \u001b[38;2;32;148;243m-0.07542186\u001b[0m \u001b[38;2;32;148;243m-0.24261311\u001b[0m \u001b[38;2;32;148;243m-0.34733073\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13039702\u001b[0m \u001b[38;2;32;148;243m-0.05202047\u001b[0m \u001b[38;2;32;148;243m-0.1612489\u001b[0m  \u001b[38;2;32;148;243m-0.23099433\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0574288\u001b[0m  \u001b[38;2;32;148;243m-0.02730546\u001b[0m \u001b[38;2;32;148;243m-0.07976834\u001b[0m \u001b[38;2;32;148;243m-0.11425098\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01578164\u001b[0m \u001b[38;2;32;148;243m-0.00066727\u001b[0m  \u001b[38;2;32;148;243m0.00225587\u001b[0m  \u001b[38;2;32;148;243m0.00287718\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06771565\u001b[0m \u001b[38;2;32;148;243m-0.02512582\u001b[0m \u001b[38;2;32;148;243m-0.07896776\u001b[0m \u001b[38;2;32;148;243m-0.11619986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13558138\u001b[0m \u001b[38;2;32;148;243m-0.04966129\u001b[0m \u001b[38;2;32;148;243m-0.15960556\u001b[0m \u001b[38;2;32;148;243m-0.23223511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20411649\u001b[0m \u001b[38;2;32;148;243m-0.07446334\u001b[0m \u001b[38;2;32;148;243m-0.24183158\u001b[0m \u001b[38;2;32;148;243m-0.34776322\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27251958\u001b[0m \u001b[38;2;32;148;243m-0.09787246\u001b[0m \u001b[38;2;32;148;243m-0.3254644\u001b[0m  \u001b[38;2;32;148;243m-0.4632404\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.07005858\u001b[0m \u001b[38;2;32;148;243m0.0224506\u001b[0m  \u001b[38;2;32;148;243m0.08285129\u001b[0m \u001b[38;2;32;148;243m0.11590967\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.14212256\u001b[0m \u001b[38;2;32;148;243m0.04585199\u001b[0m \u001b[38;2;32;148;243m0.1642155\u001b[0m  \u001b[38;2;32;148;243m0.23224607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21509078\u001b[0m \u001b[38;2;32;148;243m0.070567\u001b[0m   \u001b[38;2;32;148;243m0.24569606\u001b[0m \u001b[38;2;32;148;243m0.34898942\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.28830122\u001b[0m \u001b[38;2;32;148;243m0.09720519\u001b[0m \u001b[38;2;32;148;243m0.32772027\u001b[0m \u001b[38;2;32;148;243m0.46611758\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06771565\u001b[0m \u001b[38;2;32;148;243m-0.02512582\u001b[0m \u001b[38;2;32;148;243m-0.07896776\u001b[0m \u001b[38;2;32;148;243m-0.11619986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13558138\u001b[0m \u001b[38;2;32;148;243m-0.04966129\u001b[0m \u001b[38;2;32;148;243m-0.15960556\u001b[0m \u001b[38;2;32;148;243m-0.23223511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20411649\u001b[0m \u001b[38;2;32;148;243m-0.07446334\u001b[0m \u001b[38;2;32;148;243m-0.24183158\u001b[0m \u001b[38;2;32;148;243m-0.34776322\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27251958\u001b[0m \u001b[38;2;32;148;243m-0.09787246\u001b[0m \u001b[38;2;32;148;243m-0.3254644\u001b[0m  \u001b[38;2;32;148;243m-0.4632404\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.202461\u001b[0m   \u001b[38;2;32;148;243m-0.07542186\u001b[0m \u001b[38;2;32;148;243m-0.24261311\u001b[0m \u001b[38;2;32;148;243m-0.34733073\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13039702\u001b[0m \u001b[38;2;32;148;243m-0.05202047\u001b[0m \u001b[38;2;32;148;243m-0.1612489\u001b[0m  \u001b[38;2;32;148;243m-0.23099433\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0574288\u001b[0m  \u001b[38;2;32;148;243m-0.02730546\u001b[0m \u001b[38;2;32;148;243m-0.07976834\u001b[0m \u001b[38;2;32;148;243m-0.11425098\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01578164\u001b[0m \u001b[38;2;32;148;243m-0.00066727\u001b[0m  \u001b[38;2;32;148;243m0.00225587\u001b[0m  \u001b[38;2;32;148;243m0.00287718\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.54081332\u001b[0m \u001b[38;2;32;148;243m0.54688156\u001b[0m \u001b[38;2;32;148;243m0.3837424\u001b[0m  \u001b[38;2;32;148;243m0.4445243\u001b[0m \u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01578164\u001b[0m \u001b[38;2;32;148;243m-0.00066727\u001b[0m  \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.40489594e-03\u001b[0m  \u001b[38;2;32;148;243m2.42568817e-03\u001b[0m \u001b[38;2;32;148;243m-1.22128286e-03\u001b[0m  \u001b[38;2;32;148;243m3.33506631e-05\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0044297\u001b[0m  \u001b[38;2;32;148;243m-0.00151298\u001b[0m \u001b[38;2;32;148;243m-0.00355408\u001b[0m  \u001b[38;2;32;148;243m0.00326773\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.12926073\u001b[0m \u001b[38;2;32;148;243m-0.04414946\u001b[0m \u001b[38;2;32;148;243m-0.10370987\u001b[0m  \u001b[38;2;32;148;243m0.09535414\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00126963\u001b[0m \u001b[38;2;32;148;243m0.00183703\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4.35095927e-05\u001b[0m \u001b[38;2;32;148;243m6.29539451e-05\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-2.710630203148566e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:00]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m36\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:01]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m37\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:01]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m38\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:02]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m39\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:02]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m40\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:02]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.53083778\u001b[0m \u001b[38;2;32;148;243m-61.47612458\u001b[0m \u001b[38;2;32;148;243m194.49383362\u001b[0m \u001b[38;2;32;148;243m-75.26659131\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.41314729\u001b[0m \u001b[38;2;32;148;243m-61.56796393\u001b[0m \u001b[38;2;32;148;243m194.42693791\u001b[0m \u001b[38;2;32;148;243m-75.35635768\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.30997375\u001b[0m \u001b[38;2;32;148;243m-61.64422221\u001b[0m \u001b[38;2;32;148;243m194.37883272\u001b[0m \u001b[38;2;32;148;243m-75.42621902\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.21778242\u001b[0m \u001b[38;2;32;148;243m-61.70354439\u001b[0m \u001b[38;2;32;148;243m194.3457032\u001b[0m  \u001b[38;2;32;148;243m-75.47606722\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.1380567\u001b[0m  \u001b[38;2;32;148;243m-61.74728792\u001b[0m \u001b[38;2;32;148;243m194.32642745\u001b[0m \u001b[38;2;32;148;243m-75.5059038\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.18193878\u001b[0m \u001b[38;2;32;148;243m-61.7853854\u001b[0m  \u001b[38;2;32;148;243m194.2253633\u001b[0m  \u001b[38;2;32;148;243m-75.27512306\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.24120223\u001b[0m \u001b[38;2;32;148;243m-61.80516899\u001b[0m \u001b[38;2;32;148;243m194.14110165\u001b[0m \u001b[38;2;32;148;243m-75.02533298\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.31483923\u001b[0m \u001b[38;2;32;148;243m-61.80731799\u001b[0m \u001b[38;2;32;148;243m194.0737638\u001b[0m  \u001b[38;2;32;148;243m-74.75607289\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.40107025\u001b[0m \u001b[38;2;32;148;243m-61.7919109\u001b[0m  \u001b[38;2;32;148;243m194.02513639\u001b[0m \u001b[38;2;32;148;243m-74.46727477\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.53083778\u001b[0m \u001b[38;2;32;148;243m-61.47612458\u001b[0m \u001b[38;2;32;148;243m194.49383362\u001b[0m \u001b[38;2;32;148;243m-75.26659131\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.48417588\u001b[0m \u001b[38;2;32;148;243m-61.54316591\u001b[0m \u001b[38;2;32;148;243m194.51489672\u001b[0m \u001b[38;2;32;148;243m-75.23936232\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.45182683\u001b[0m \u001b[38;2;32;148;243m-61.5952443\u001b[0m  \u001b[38;2;32;148;243m194.55346786\u001b[0m \u001b[38;2;32;148;243m-75.19268807\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.43217035\u001b[0m \u001b[38;2;32;148;243m-61.63209287\u001b[0m \u001b[38;2;32;148;243m194.60743084\u001b[0m \u001b[38;2;32;148;243m-75.1262975\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.42601492\u001b[0m \u001b[38;2;32;148;243m-61.65399555\u001b[0m \u001b[38;2;32;148;243m194.6764139\u001b[0m  \u001b[38;2;32;148;243m-75.03984482\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.3959529\u001b[0m  \u001b[38;2;32;148;243m-61.71622516\u001b[0m \u001b[38;2;32;148;243m194.48553365\u001b[0m \u001b[38;2;32;148;243m-74.92522514\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.38070855\u001b[0m \u001b[38;2;32;148;243m-61.76334278\u001b[0m \u001b[38;2;32;148;243m194.31072335\u001b[0m \u001b[38;2;32;148;243m-74.79112617\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.37999823\u001b[0m \u001b[38;2;32;148;243m-61.79563195\u001b[0m \u001b[38;2;32;148;243m194.15223251\u001b[0m \u001b[38;2;32;148;243m-74.63721938\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m37.39333859\u001b[0m \u001b[38;2;32;148;243m-61.81332954\u001b[0m \u001b[38;2;32;148;243m194.01100144\u001b[0m \u001b[38;2;32;148;243m-74.46363194\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07102859\u001b[0m \u001b[38;2;32;148;243m-0.02479802\u001b[0m \u001b[38;2;32;148;243m-0.08795881\u001b[0m \u001b[38;2;32;148;243m-0.11699536\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14185308\u001b[0m \u001b[38;2;32;148;243m-0.04897791\u001b[0m \u001b[38;2;32;148;243m-0.17463513\u001b[0m \u001b[38;2;32;148;243m-0.23353095\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21438792\u001b[0m \u001b[38;2;32;148;243m-0.07145152\u001b[0m \u001b[38;2;32;148;243m-0.26172765\u001b[0m \u001b[38;2;32;148;243m-0.34976972\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28795822\u001b[0m \u001b[38;2;32;148;243m-0.09329237\u001b[0m \u001b[38;2;32;148;243m-0.34998644\u001b[0m \u001b[38;2;32;148;243m-0.46605898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21401412\u001b[0m \u001b[38;2;32;148;243m-0.06916024\u001b[0m \u001b[38;2;32;148;243m-0.26017036\u001b[0m \u001b[38;2;32;148;243m-0.34989792\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13950632\u001b[0m \u001b[38;2;32;148;243m-0.04182621\u001b[0m \u001b[38;2;32;148;243m-0.16962171\u001b[0m \u001b[38;2;32;148;243m-0.23420681\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06515899\u001b[0m \u001b[38;2;32;148;243m-0.01168603\u001b[0m \u001b[38;2;32;148;243m-0.07846871\u001b[0m \u001b[38;2;32;148;243m-0.11885351\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00773165\u001b[0m  \u001b[38;2;32;148;243m0.02141864\u001b[0m  \u001b[38;2;32;148;243m0.01413494\u001b[0m \u001b[38;2;32;148;243m-0.00364284\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07102859\u001b[0m \u001b[38;2;32;148;243m-0.02479802\u001b[0m \u001b[38;2;32;148;243m-0.08795881\u001b[0m \u001b[38;2;32;148;243m-0.11699536\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14185308\u001b[0m \u001b[38;2;32;148;243m-0.04897791\u001b[0m \u001b[38;2;32;148;243m-0.17463513\u001b[0m \u001b[38;2;32;148;243m-0.23353095\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21438792\u001b[0m \u001b[38;2;32;148;243m-0.07145152\u001b[0m \u001b[38;2;32;148;243m-0.26172765\u001b[0m \u001b[38;2;32;148;243m-0.34976972\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28795822\u001b[0m \u001b[38;2;32;148;243m-0.09329237\u001b[0m \u001b[38;2;32;148;243m-0.34998644\u001b[0m \u001b[38;2;32;148;243m-0.46605898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.0739441\u001b[0m  \u001b[38;2;32;148;243m0.02413213\u001b[0m \u001b[38;2;32;148;243m0.08981609\u001b[0m \u001b[38;2;32;148;243m0.11616105\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.1484519\u001b[0m  \u001b[38;2;32;148;243m0.05146617\u001b[0m \u001b[38;2;32;148;243m0.18036474\u001b[0m \u001b[38;2;32;148;243m0.23185217\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22279923\u001b[0m \u001b[38;2;32;148;243m0.08160634\u001b[0m \u001b[38;2;32;148;243m0.27151774\u001b[0m \u001b[38;2;32;148;243m0.34720547\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.29568987\u001b[0m \u001b[38;2;32;148;243m0.11471101\u001b[0m \u001b[38;2;32;148;243m0.36412139\u001b[0m \u001b[38;2;32;148;243m0.46241614\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07102859\u001b[0m \u001b[38;2;32;148;243m-0.02479802\u001b[0m \u001b[38;2;32;148;243m-0.08795881\u001b[0m \u001b[38;2;32;148;243m-0.11699536\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14185308\u001b[0m \u001b[38;2;32;148;243m-0.04897791\u001b[0m \u001b[38;2;32;148;243m-0.17463513\u001b[0m \u001b[38;2;32;148;243m-0.23353095\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21438792\u001b[0m \u001b[38;2;32;148;243m-0.07145152\u001b[0m \u001b[38;2;32;148;243m-0.26172765\u001b[0m \u001b[38;2;32;148;243m-0.34976972\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28795822\u001b[0m \u001b[38;2;32;148;243m-0.09329237\u001b[0m \u001b[38;2;32;148;243m-0.34998644\u001b[0m \u001b[38;2;32;148;243m-0.46605898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21401412\u001b[0m \u001b[38;2;32;148;243m-0.06916024\u001b[0m \u001b[38;2;32;148;243m-0.26017036\u001b[0m \u001b[38;2;32;148;243m-0.34989792\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13950632\u001b[0m \u001b[38;2;32;148;243m-0.04182621\u001b[0m \u001b[38;2;32;148;243m-0.16962171\u001b[0m \u001b[38;2;32;148;243m-0.23420681\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.06515899\u001b[0m \u001b[38;2;32;148;243m-0.01168603\u001b[0m \u001b[38;2;32;148;243m-0.07846871\u001b[0m \u001b[38;2;32;148;243m-0.11885351\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00773165\u001b[0m  \u001b[38;2;32;148;243m0.02141864\u001b[0m  \u001b[38;2;32;148;243m0.01413494\u001b[0m \u001b[38;2;32;148;243m-0.00364284\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m.        \u001b[38;2;32;148;243m1\u001b[0m.        \u001b[38;2;32;148;243m1\u001b[0m.        \u001b[38;2;32;148;243m0.4480012\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00773165\u001b[0m  \u001b[38;2;32;148;243m0.02141864\u001b[0m  \u001b[38;2;32;148;243m0.01413494\u001b[0m \u001b[38;2;32;148;243m-0\u001b[0m.        \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m0\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00176544\u001b[0m  \u001b[38;2;32;148;243m0.00272047\u001b[0m \u001b[38;2;32;148;243m-0.00086076\u001b[0m  \u001b[38;2;32;148;243m0.00036219\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00437903\u001b[0m \u001b[38;2;32;148;243m-0.00162554\u001b[0m \u001b[38;2;32;148;243m-0.00408489\u001b[0m  \u001b[38;2;32;148;243m0.00312903\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.12778234\u001b[0m \u001b[38;2;32;148;243m-0.047434\u001b[0m   \u001b[38;2;32;148;243m-0.11919906\u001b[0m  \u001b[38;2;32;148;243m0.09130668\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00039654\u001b[0m \u001b[38;2;32;148;243m0.00091485\u001b[0m \u001b[38;2;32;148;243m0.003272\u001b[0m   \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.35893336e-05\u001b[0m \u001b[38;2;32;148;243m3.13513107e-05\u001b[0m \u001b[38;2;32;148;243m1.12129821e-04\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-4.9186839696357544e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:02]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m41\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:03]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m42\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:03]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m43\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:04]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m44\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:04]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m45\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:04]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.62601426\u001b[0m  \u001b[38;2;32;148;243m-58.699203\u001b[0m     \u001b[38;2;32;148;243m59.46849932\u001b[0m \u001b[38;2;32;148;243m-172.36747803\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.5591947\u001b[0m   \u001b[38;2;32;148;243m-58.72665761\u001b[0m   \u001b[38;2;32;148;243m59.54762304\u001b[0m \u001b[38;2;32;148;243m-172.43679004\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.478034\u001b[0m    \u001b[38;2;32;148;243m-58.73975672\u001b[0m   \u001b[38;2;32;148;243m59.6428672\u001b[0m  \u001b[38;2;32;148;243m-172.48654935\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.38301564\u001b[0m  \u001b[38;2;32;148;243m-58.73852857\u001b[0m   \u001b[38;2;32;148;243m59.75374459\u001b[0m \u001b[38;2;32;148;243m-172.51625033\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.27389385\u001b[0m  \u001b[38;2;32;148;243m-58.72284798\u001b[0m   \u001b[38;2;32;148;243m59.88025131\u001b[0m \u001b[38;2;32;148;243m-172.52596124\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.11103216\u001b[0m  \u001b[38;2;32;148;243m-58.75758363\u001b[0m   \u001b[38;2;32;148;243m59.96074514\u001b[0m \u001b[38;2;32;148;243m-172.40155126\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.93446541\u001b[0m  \u001b[38;2;32;148;243m-58.777547\u001b[0m     \u001b[38;2;32;148;243m60.05743232\u001b[0m \u001b[38;2;32;148;243m-172.25787331\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.74060986\u001b[0m  \u001b[38;2;32;148;243m-58.78243594\u001b[0m   \u001b[38;2;32;148;243m60.17052679\u001b[0m \u001b[38;2;32;148;243m-172.09459919\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.52728845\u001b[0m  \u001b[38;2;32;148;243m-58.7714395\u001b[0m    \u001b[38;2;32;148;243m60.30047494\u001b[0m \u001b[38;2;32;148;243m-171.91225775\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.62601426\u001b[0m  \u001b[38;2;32;148;243m-58.699203\u001b[0m     \u001b[38;2;32;148;243m59.46849932\u001b[0m \u001b[38;2;32;148;243m-172.36747803\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.48467085\u001b[0m  \u001b[38;2;32;148;243m-58.69961143\u001b[0m   \u001b[38;2;32;148;243m59.63720058\u001b[0m \u001b[38;2;32;148;243m-172.32092147\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.32967507\u001b[0m  \u001b[38;2;32;148;243m-58.68565043\u001b[0m   \u001b[38;2;32;148;243m59.82288137\u001b[0m \u001b[38;2;32;148;243m-172.25539508\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-59.16351451\u001b[0m  \u001b[38;2;32;148;243m-58.6582891\u001b[0m    \u001b[38;2;32;148;243m60.02368863\u001b[0m \u001b[38;2;32;148;243m-172.17018998\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.98479033\u001b[0m  \u001b[38;2;32;148;243m-58.61718232\u001b[0m   \u001b[38;2;32;148;243m60.23996164\u001b[0m \u001b[38;2;32;148;243m-172.06529574\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.89165025\u001b[0m  \u001b[38;2;32;148;243m-58.67767335\u001b[0m   \u001b[38;2;32;148;243m60.22960664\u001b[0m \u001b[38;2;32;148;243m-172.05530265\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.78459027\u001b[0m  \u001b[38;2;32;148;243m-58.72376757\u001b[0m   \u001b[38;2;32;148;243m60.23384326\u001b[0m \u001b[38;2;32;148;243m-172.02592269\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.66232782\u001b[0m  \u001b[38;2;32;148;243m-58.75541252\u001b[0m   \u001b[38;2;32;148;243m60.2532672\u001b[0m  \u001b[38;2;32;148;243m-171.97623719\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-58.52427607\u001b[0m  \u001b[38;2;32;148;243m-58.77275329\u001b[0m   \u001b[38;2;32;148;243m60.28906012\u001b[0m \u001b[38;2;32;148;243m-171.9071523\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07452385\u001b[0m \u001b[38;2;32;148;243m-0.02704618\u001b[0m \u001b[38;2;32;148;243m-0.08957755\u001b[0m \u001b[38;2;32;148;243m-0.11586856\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14835894\u001b[0m \u001b[38;2;32;148;243m-0.05410629\u001b[0m \u001b[38;2;32;148;243m-0.18001417\u001b[0m \u001b[38;2;32;148;243m-0.23115426\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21950113\u001b[0m \u001b[38;2;32;148;243m-0.08023947\u001b[0m \u001b[38;2;32;148;243m-0.26994404\u001b[0m \u001b[38;2;32;148;243m-0.34606035\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28910352\u001b[0m \u001b[38;2;32;148;243m-0.10566565\u001b[0m \u001b[38;2;32;148;243m-0.35971033\u001b[0m \u001b[38;2;32;148;243m-0.46066551\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21938191\u001b[0m \u001b[38;2;32;148;243m-0.07991027\u001b[0m \u001b[38;2;32;148;243m-0.2688615\u001b[0m  \u001b[38;2;32;148;243m-0.34624861\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14987513\u001b[0m \u001b[38;2;32;148;243m-0.05377943\u001b[0m \u001b[38;2;32;148;243m-0.17641094\u001b[0m \u001b[38;2;32;148;243m-0.23195062\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07828204\u001b[0m \u001b[38;2;32;148;243m-0.02702341\u001b[0m \u001b[38;2;32;148;243m-0.08274041\u001b[0m \u001b[38;2;32;148;243m-0.118362\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00301238\u001b[0m  \u001b[38;2;32;148;243m0.0013138\u001b[0m   \u001b[38;2;32;148;243m0.01141482\u001b[0m \u001b[38;2;32;148;243m-0.00510544\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07452385\u001b[0m \u001b[38;2;32;148;243m-0.02704618\u001b[0m \u001b[38;2;32;148;243m-0.08957755\u001b[0m \u001b[38;2;32;148;243m-0.11586856\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14835894\u001b[0m \u001b[38;2;32;148;243m-0.05410629\u001b[0m \u001b[38;2;32;148;243m-0.18001417\u001b[0m \u001b[38;2;32;148;243m-0.23115426\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21950113\u001b[0m \u001b[38;2;32;148;243m-0.08023947\u001b[0m \u001b[38;2;32;148;243m-0.26994404\u001b[0m \u001b[38;2;32;148;243m-0.34606035\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28910352\u001b[0m \u001b[38;2;32;148;243m-0.10566565\u001b[0m \u001b[38;2;32;148;243m-0.35971033\u001b[0m \u001b[38;2;32;148;243m-0.46066551\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.06972161\u001b[0m \u001b[38;2;32;148;243m0.02575538\u001b[0m \u001b[38;2;32;148;243m0.09084883\u001b[0m \u001b[38;2;32;148;243m0.1144169\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.13922839\u001b[0m \u001b[38;2;32;148;243m0.05188622\u001b[0m \u001b[38;2;32;148;243m0.18329939\u001b[0m \u001b[38;2;32;148;243m0.22871488\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21082148\u001b[0m \u001b[38;2;32;148;243m0.07864224\u001b[0m \u001b[38;2;32;148;243m0.27696992\u001b[0m \u001b[38;2;32;148;243m0.3423035\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.28609114\u001b[0m \u001b[38;2;32;148;243m0.10697945\u001b[0m \u001b[38;2;32;148;243m0.37112515\u001b[0m \u001b[38;2;32;148;243m0.45556006\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07452385\u001b[0m \u001b[38;2;32;148;243m-0.02704618\u001b[0m \u001b[38;2;32;148;243m-0.08957755\u001b[0m \u001b[38;2;32;148;243m-0.11586856\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14835894\u001b[0m \u001b[38;2;32;148;243m-0.05410629\u001b[0m \u001b[38;2;32;148;243m-0.18001417\u001b[0m \u001b[38;2;32;148;243m-0.23115426\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21950113\u001b[0m \u001b[38;2;32;148;243m-0.08023947\u001b[0m \u001b[38;2;32;148;243m-0.26994404\u001b[0m \u001b[38;2;32;148;243m-0.34606035\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.28910352\u001b[0m \u001b[38;2;32;148;243m-0.10566565\u001b[0m \u001b[38;2;32;148;243m-0.35971033\u001b[0m \u001b[38;2;32;148;243m-0.46066551\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21938191\u001b[0m \u001b[38;2;32;148;243m-0.07991027\u001b[0m \u001b[38;2;32;148;243m-0.2688615\u001b[0m  \u001b[38;2;32;148;243m-0.34624861\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.14987513\u001b[0m \u001b[38;2;32;148;243m-0.05377943\u001b[0m \u001b[38;2;32;148;243m-0.17641094\u001b[0m \u001b[38;2;32;148;243m-0.23195062\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.07828204\u001b[0m \u001b[38;2;32;148;243m-0.02702341\u001b[0m \u001b[38;2;32;148;243m-0.08274041\u001b[0m \u001b[38;2;32;148;243m-0.118362\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00301238\u001b[0m  \u001b[38;2;32;148;243m0.0013138\u001b[0m   \u001b[38;2;32;148;243m0.01141482\u001b[0m \u001b[38;2;32;148;243m-0.00510544\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33229299\u001b[0m \u001b[38;2;32;148;243m1\u001b[0m.         \u001b[38;2;32;148;243m0.44018473\u001b[0m \u001b[38;2;32;148;243m0.63107805\u001b[0m\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0\u001b[0m.          \u001b[38;2;32;148;243m0.0013138\u001b[0m   \u001b[38;2;32;148;243m0.01141482\u001b[0m \u001b[38;2;32;148;243m-0.00510544\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00092452\u001b[0m  \u001b[38;2;32;148;243m0.00331762\u001b[0m \u001b[38;2;32;148;243m-0.00037819\u001b[0m  \u001b[38;2;32;148;243m0.00054205\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00458282\u001b[0m \u001b[38;2;32;148;243m-0.00182782\u001b[0m \u001b[38;2;32;148;243m-0.0036927\u001b[0m   \u001b[38;2;32;148;243m0.00349978\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.13372905\u001b[0m \u001b[38;2;32;148;243m-0.05333676\u001b[0m \u001b[38;2;32;148;243m-0.10775497\u001b[0m  \u001b[38;2;32;148;243m0.10212541\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0.00644556\u001b[0m \u001b[38;2;32;148;243m0.00171661\u001b[0m \u001b[38;2;32;148;243m0.00336905\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00000000e+00\u001b[0m \u001b[38;2;32;148;243m2.20885899e-04\u001b[0m \u001b[38;2;32;148;243m5.88271294e-05\u001b[0m \u001b[38;2;32;148;243m1.15455355e-04\u001b[0m\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-3.394048083099028e-05\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:04]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m46\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m47\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:05]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m48\u001b[0m\n\u001b[38;2;105;105;105m[07/10/23 07:57:06]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mexperiment.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m119\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - STEP: \u001b[38;2;32;148;243m49\u001b[0m\n[07:57:06] checkSU(x_eval): (tensor[4] f64 x‚àà[3.845e-16, 3.993e-16] Œº=3.923e-16 œÉ=6.436e-18 [3.955e-16, 3.845e-16, \n           3.901e-16, 3.993e-16], tensor[4] f64 x‚àà[1.405e-15, 1.560e-15] Œº=1.496e-15 œÉ=6.503e-17 [1.560e-15,       \n           1.405e-15, 1.511e-15, 1.507e-15])                                                                       \n\n           Saving energy to plots-4dSU3/Evaluate                                                                   \n\n\n\n\nsvg\n\n\n           Saving logprob to plots-4dSU3/Evaluate                                                                  \n\n\n\n\nsvg\n\n\n[07:57:07] Saving logdet to plots-4dSU3/Evaluate                                                                   \n\n\n\n\nsvg\n\n\n           Saving sldf to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving sldb to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving sld to plots-4dSU3/Evaluate                                                                      \n\n\n\n\nsvg\n\n\n[07:57:08] Saving xeps to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving veps to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving acc to plots-4dSU3/Evaluate                                                                      \n\n\n\n\nsvg\n\n\n           Saving sumlogdet to plots-4dSU3/Evaluate                                                                \n\n\n\n\nsvg\n\n\n[07:57:09] Saving beta to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving acc_mask to plots-4dSU3/Evaluate                                                                 \n\n\n\n\nsvg\n\n\n           Saving plaqs to plots-4dSU3/Evaluate                                                                    \n\n\n\n\nsvg\n\n\n           Saving sinQ to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n[07:57:10] Saving intQ to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg\n\n\n           Saving dQint to plots-4dSU3/Evaluate                                                                    \n\n\n\n\nsvg\n\n\n           Saving dQsin to plots-4dSU3/Evaluate                                                                    \n\n\n\n\nsvg\n\n\n[07:57:11] Saving loss to plots-4dSU3/Evaluate                                                                     \n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#training",
    "href": "posts/ai-for-physics/l2hmc-qcd/4dSU3nb/index-broken.html#training",
    "title": "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)",
    "section": "Training",
    "text": "Training\nhistory = {}\nx = state.x\nfor step in range(50):\n    console.log(f'TRAIN STEP: {step}')\n    x, metrics = ptExpSU3.trainer.train_step((x, state.beta))\n    if (step &gt; 0 and step % 2 == 0):\n        print_dict(metrics, grab=True)\n    if (step &gt; 0 and step % 1 == 0):\n        for key, val in metrics.items():\n            try:\n                history[key].append(val)\n            except KeyError:\n                history[key] = [val]\n\nx = ptExpSU3.trainer.dynamics.unflatten(x)\nconsole.log(f\"checkSU(x_train): {g.checkSU(x)}\")\nplot_metrics(history, title='train', marker='.')\n\n\n\n\n\n\nTipoutput:\n\n\n\n\n\n\n[07:57:15] TRAIN STEP: 0                                                                                           \n\n[07:57:16] TRAIN STEP: 1                                                                                           \n\n           TRAIN STEP: 2                                                                                           \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:17]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m281.36521385\u001b[0m \u001b[38;2;32;148;243m-105.97415137\u001b[0m  \u001b[38;2;32;148;243m-69.97486138\u001b[0m  \u001b[38;2;32;148;243m-68.7094104\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.24054833\u001b[0m \u001b[38;2;32;148;243m-109.07253574\u001b[0m  \u001b[38;2;32;148;243m-86.39965892\u001b[0m  \u001b[38;2;32;148;243m-81.32577003\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.1725606\u001b[0m  \u001b[38;2;32;148;243m-109.04339532\u001b[0m  \u001b[38;2;32;148;243m-86.52495783\u001b[0m  \u001b[38;2;32;148;243m-81.36519938\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.12190109\u001b[0m \u001b[38;2;32;148;243m-109.00002499\u001b[0m  \u001b[38;2;32;148;243m-86.63542547\u001b[0m  \u001b[38;2;32;148;243m-81.39024754\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.08826659\u001b[0m \u001b[38;2;32;148;243m-108.94247239\u001b[0m  \u001b[38;2;32;148;243m-86.72756853\u001b[0m  \u001b[38;2;32;148;243m-81.40051327\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.15071961\u001b[0m \u001b[38;2;32;148;243m-108.77269274\u001b[0m  \u001b[38;2;32;148;243m-86.75297969\u001b[0m  \u001b[38;2;32;148;243m-81.33529329\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.23101691\u001b[0m \u001b[38;2;32;148;243m-108.59060157\u001b[0m  \u001b[38;2;32;148;243m-86.762429\u001b[0m    \u001b[38;2;32;148;243m-81.25362457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.32955656\u001b[0m \u001b[38;2;32;148;243m-108.39687575\u001b[0m  \u001b[38;2;32;148;243m-86.75589511\u001b[0m  \u001b[38;2;32;148;243m-81.15387713\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.44688414\u001b[0m \u001b[38;2;32;148;243m-108.19113989\u001b[0m  \u001b[38;2;32;148;243m-86.73311909\u001b[0m  \u001b[38;2;32;148;243m-81.03775212\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m281.36521385\u001b[0m \u001b[38;2;32;148;243m-105.97415137\u001b[0m  \u001b[38;2;32;148;243m-69.97486138\u001b[0m  \u001b[38;2;32;148;243m-68.7094104\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.34046617\u001b[0m \u001b[38;2;32;148;243m-109.01072961\u001b[0m  \u001b[38;2;32;148;243m-86.38264168\u001b[0m  \u001b[38;2;32;148;243m-81.24452066\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.37307865\u001b[0m \u001b[38;2;32;148;243m-108.92456325\u001b[0m  \u001b[38;2;32;148;243m-86.49242126\u001b[0m  \u001b[38;2;32;148;243m-81.20801101\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.42366401\u001b[0m \u001b[38;2;32;148;243m-108.82480411\u001b[0m  \u001b[38;2;32;148;243m-86.58754075\u001b[0m  \u001b[38;2;32;148;243m-81.15657432\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.49344316\u001b[0m \u001b[38;2;32;148;243m-108.71126581\u001b[0m  \u001b[38;2;32;148;243m-86.66610532\u001b[0m  \u001b[38;2;32;148;243m-81.09002842\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.45194401\u001b[0m \u001b[38;2;32;148;243m-108.59723981\u001b[0m  \u001b[38;2;32;148;243m-86.7045229\u001b[0m   \u001b[38;2;32;148;243m-81.10170009\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.42889533\u001b[0m \u001b[38;2;32;148;243m-108.46916199\u001b[0m  \u001b[38;2;32;148;243m-86.72820528\u001b[0m  \u001b[38;2;32;148;243m-81.098189\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.42369473\u001b[0m \u001b[38;2;32;148;243m-108.32747357\u001b[0m  \u001b[38;2;32;148;243m-86.73779558\u001b[0m  \u001b[38;2;32;148;243m-81.07912734\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m263.43579227\u001b[0m \u001b[38;2;32;148;243m-108.17161087\u001b[0m  \u001b[38;2;32;148;243m-86.73344347\u001b[0m  \u001b[38;2;32;148;243m-81.04469161\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.99178394e-02\u001b[0m \u001b[38;2;32;148;243m-6.18061332e-02\u001b[0m \u001b[38;2;32;148;243m-1.70172453e-02\u001b[0m \u001b[38;2;32;148;243m-8.12493680e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.00518048e-01\u001b[0m \u001b[38;2;32;148;243m-1.18832073e-01\u001b[0m \u001b[38;2;32;148;243m-3.25365743e-02\u001b[0m \u001b[38;2;32;148;243m-1.57188371e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.01762924e-01\u001b[0m \u001b[38;2;32;148;243m-1.75220878e-01\u001b[0m \u001b[38;2;32;148;243m-4.78847161e-02\u001b[0m \u001b[38;2;32;148;243m-2.33673222e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4.05176570e-01\u001b[0m \u001b[38;2;32;148;243m-2.31206581e-01\u001b[0m \u001b[38;2;32;148;243m-6.14632088e-02\u001b[0m \u001b[38;2;32;148;243m-3.10484854e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.01224398e-01\u001b[0m \u001b[38;2;32;148;243m-1.75452932e-01\u001b[0m \u001b[38;2;32;148;243m-4.84567891e-02\u001b[0m \u001b[38;2;32;148;243m-2.33593200e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.97878419e-01\u001b[0m \u001b[38;2;32;148;243m-1.21439581e-01\u001b[0m \u001b[38;2;32;148;243m-3.42237191e-02\u001b[0m \u001b[38;2;32;148;243m-1.55435574e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.41381732e-02\u001b[0m \u001b[38;2;32;148;243m-6.94021838e-02\u001b[0m \u001b[38;2;32;148;243m-1.80995342e-02\u001b[0m \u001b[38;2;32;148;243m-7.47497902e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.10918724e-02\u001b[0m \u001b[38;2;32;148;243m-1.95290252e-02\u001b[0m  \u001b[38;2;32;148;243m3.24386329e-04\u001b[0m  \u001b[38;2;32;148;243m6.93949633e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09991784\u001b[0m \u001b[38;2;32;148;243m-0.06180613\u001b[0m \u001b[38;2;32;148;243m-0.01701725\u001b[0m \u001b[38;2;32;148;243m-0.08124937\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20051805\u001b[0m \u001b[38;2;32;148;243m-0.11883207\u001b[0m \u001b[38;2;32;148;243m-0.03253657\u001b[0m \u001b[38;2;32;148;243m-0.15718837\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30176292\u001b[0m \u001b[38;2;32;148;243m-0.17522088\u001b[0m \u001b[38;2;32;148;243m-0.04788472\u001b[0m \u001b[38;2;32;148;243m-0.23367322\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40517657\u001b[0m \u001b[38;2;32;148;243m-0.23120658\u001b[0m \u001b[38;2;32;148;243m-0.06146321\u001b[0m \u001b[38;2;32;148;243m-0.31048485\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10395217\u001b[0m \u001b[38;2;32;148;243m0.05575365\u001b[0m \u001b[38;2;32;148;243m0.01300642\u001b[0m \u001b[38;2;32;148;243m0.07689165\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20729815\u001b[0m \u001b[38;2;32;148;243m0.109767\u001b[0m   \u001b[38;2;32;148;243m0.02723949\u001b[0m \u001b[38;2;32;148;243m0.15504928\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.3110384\u001b[0m  \u001b[38;2;32;148;243m0.1618044\u001b[0m  \u001b[38;2;32;148;243m0.04336367\u001b[0m \u001b[38;2;32;148;243m0.23573506\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.41626844\u001b[0m \u001b[38;2;32;148;243m0.21167756\u001b[0m \u001b[38;2;32;148;243m0.0617876\u001b[0m  \u001b[38;2;32;148;243m0.31742435\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.99178394e-02\u001b[0m \u001b[38;2;32;148;243m-6.18061332e-02\u001b[0m \u001b[38;2;32;148;243m-1.70172453e-02\u001b[0m \u001b[38;2;32;148;243m-8.12493680e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.00518048e-01\u001b[0m \u001b[38;2;32;148;243m-1.18832073e-01\u001b[0m \u001b[38;2;32;148;243m-3.25365743e-02\u001b[0m \u001b[38;2;32;148;243m-1.57188371e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.01762924e-01\u001b[0m \u001b[38;2;32;148;243m-1.75220878e-01\u001b[0m \u001b[38;2;32;148;243m-4.78847161e-02\u001b[0m \u001b[38;2;32;148;243m-2.33673222e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4.05176570e-01\u001b[0m \u001b[38;2;32;148;243m-2.31206581e-01\u001b[0m \u001b[38;2;32;148;243m-6.14632088e-02\u001b[0m \u001b[38;2;32;148;243m-3.10484854e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.01224398e-01\u001b[0m \u001b[38;2;32;148;243m-1.75452932e-01\u001b[0m \u001b[38;2;32;148;243m-4.84567891e-02\u001b[0m \u001b[38;2;32;148;243m-2.33593200e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.97878419e-01\u001b[0m \u001b[38;2;32;148;243m-1.21439581e-01\u001b[0m \u001b[38;2;32;148;243m-3.42237191e-02\u001b[0m \u001b[38;2;32;148;243m-1.55435574e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.41381732e-02\u001b[0m \u001b[38;2;32;148;243m-6.94021838e-02\u001b[0m \u001b[38;2;32;148;243m-1.80995342e-02\u001b[0m \u001b[38;2;32;148;243m-7.47497902e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.10918724e-02\u001b[0m \u001b[38;2;32;148;243m-1.95290252e-02\u001b[0m  \u001b[38;2;32;148;243m3.24386329e-04\u001b[0m  \u001b[38;2;32;148;243m6.93949633e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01109187\u001b[0m \u001b[38;2;32;148;243m-0.01952903\u001b[0m  \u001b[38;2;32;148;243m0.00032439\u001b[0m  \u001b[38;2;32;148;243m0.0069395\u001b[0m \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.214976548064738e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0061887\u001b[0m   \u001b[38;2;32;148;243m0.00500194\u001b[0m  \u001b[38;2;32;148;243m0.00397052\u001b[0m  \u001b[38;2;32;148;243m0.00286354\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00160074\u001b[0m  \u001b[38;2;32;148;243m0.00051351\u001b[0m \u001b[38;2;32;148;243m-0.00282033\u001b[0m \u001b[38;2;32;148;243m-0.00232394\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0467105\u001b[0m   \u001b[38;2;32;148;243m0.01498444\u001b[0m \u001b[38;2;32;148;243m-0.08229858\u001b[0m \u001b[38;2;32;148;243m-0.06781372\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00360113\u001b[0m \u001b[38;2;32;148;243m0.00411262\u001b[0m \u001b[38;2;32;148;243m0.00122385\u001b[0m \u001b[38;2;32;148;243m0.01062494\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.23408791e-04\u001b[0m \u001b[38;2;32;148;243m1.40937158e-04\u001b[0m \u001b[38;2;32;148;243m4.19407924e-05\u001b[0m \u001b[38;2;32;148;243m3.64110788e-04\u001b[0m\u001b[1m]\u001b[0m\n[07:57:17] TRAIN STEP: 3                                                                                           \n\n           TRAIN STEP: 4                                                                                           \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:18]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m135.11825502\u001b[0m \u001b[38;2;32;148;243m-185.23125091\u001b[0m   \u001b[38;2;32;148;243m39.49801865\u001b[0m  \u001b[38;2;32;148;243m131.48643148\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.29012806\u001b[0m \u001b[38;2;32;148;243m-187.76677412\u001b[0m   \u001b[38;2;32;148;243m21.57755422\u001b[0m  \u001b[38;2;32;148;243m118.32075786\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.24121464\u001b[0m \u001b[38;2;32;148;243m-187.81407012\u001b[0m   \u001b[38;2;32;148;243m21.54918557\u001b[0m  \u001b[38;2;32;148;243m118.22618093\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.21203826\u001b[0m \u001b[38;2;32;148;243m-187.84774093\u001b[0m   \u001b[38;2;32;148;243m21.53445154\u001b[0m  \u001b[38;2;32;148;243m118.14697838\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.20235487\u001b[0m \u001b[38;2;32;148;243m-187.86847227\u001b[0m   \u001b[38;2;32;148;243m21.53313956\u001b[0m  \u001b[38;2;32;148;243m118.08177774\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.33755546\u001b[0m \u001b[38;2;32;148;243m-187.73695847\u001b[0m   \u001b[38;2;32;148;243m21.5237841\u001b[0m   \u001b[38;2;32;148;243m118.21081333\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.49320029\u001b[0m \u001b[38;2;32;148;243m-187.59196912\u001b[0m   \u001b[38;2;32;148;243m21.52970039\u001b[0m  \u001b[38;2;32;148;243m118.35271288\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.67025311\u001b[0m \u001b[38;2;32;148;243m-187.43381451\u001b[0m   \u001b[38;2;32;148;243m21.54991672\u001b[0m  \u001b[38;2;32;148;243m118.5124691\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.86681924\u001b[0m \u001b[38;2;32;148;243m-187.26307202\u001b[0m   \u001b[38;2;32;148;243m21.58393788\u001b[0m  \u001b[38;2;32;148;243m118.68765025\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m135.11825502\u001b[0m \u001b[38;2;32;148;243m-185.23125091\u001b[0m   \u001b[38;2;32;148;243m39.49801865\u001b[0m  \u001b[38;2;32;148;243m131.48643148\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.39238634\u001b[0m \u001b[38;2;32;148;243m-187.712692\u001b[0m     \u001b[38;2;32;148;243m21.61699055\u001b[0m  \u001b[38;2;32;148;243m118.39725088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.45523291\u001b[0m \u001b[38;2;32;148;243m-187.70870488\u001b[0m   \u001b[38;2;32;148;243m21.64805552\u001b[0m  \u001b[38;2;32;148;243m118.37787194\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.53809899\u001b[0m \u001b[38;2;32;148;243m-187.69063165\u001b[0m   \u001b[38;2;32;148;243m21.69314918\u001b[0m  \u001b[38;2;32;148;243m118.37350562\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.6405493\u001b[0m  \u001b[38;2;32;148;243m-187.65779592\u001b[0m   \u001b[38;2;32;148;243m21.75214543\u001b[0m  \u001b[38;2;32;148;243m118.38564832\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.66329968\u001b[0m \u001b[38;2;32;148;243m-187.58144768\u001b[0m   \u001b[38;2;32;148;243m21.68175728\u001b[0m  \u001b[38;2;32;148;243m118.43634456\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.70589156\u001b[0m \u001b[38;2;32;148;243m-187.49115407\u001b[0m   \u001b[38;2;32;148;243m21.62822818\u001b[0m  \u001b[38;2;32;148;243m118.50107276\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.76922139\u001b[0m \u001b[38;2;32;148;243m-187.38620402\u001b[0m   \u001b[38;2;32;148;243m21.58955162\u001b[0m  \u001b[38;2;32;148;243m118.5821923\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m116.85193341\u001b[0m \u001b[38;2;32;148;243m-187.26621096\u001b[0m   \u001b[38;2;32;148;243m21.56478423\u001b[0m  \u001b[38;2;32;148;243m118.67845245\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10225828\u001b[0m \u001b[38;2;32;148;243m-0.05408212\u001b[0m \u001b[38;2;32;148;243m-0.03943634\u001b[0m \u001b[38;2;32;148;243m-0.07649302\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21401826\u001b[0m \u001b[38;2;32;148;243m-0.10536524\u001b[0m \u001b[38;2;32;148;243m-0.09886995\u001b[0m \u001b[38;2;32;148;243m-0.151691\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32606074\u001b[0m \u001b[38;2;32;148;243m-0.15710928\u001b[0m \u001b[38;2;32;148;243m-0.15869764\u001b[0m \u001b[38;2;32;148;243m-0.22652724\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43819443\u001b[0m \u001b[38;2;32;148;243m-0.21067635\u001b[0m \u001b[38;2;32;148;243m-0.21900587\u001b[0m \u001b[38;2;32;148;243m-0.30387058\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32574422\u001b[0m \u001b[38;2;32;148;243m-0.15551078\u001b[0m \u001b[38;2;32;148;243m-0.15797318\u001b[0m \u001b[38;2;32;148;243m-0.22553124\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21269127\u001b[0m \u001b[38;2;32;148;243m-0.10081506\u001b[0m \u001b[38;2;32;148;243m-0.09852779\u001b[0m \u001b[38;2;32;148;243m-0.14835988\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09896827\u001b[0m \u001b[38;2;32;148;243m-0.04761049\u001b[0m \u001b[38;2;32;148;243m-0.0396349\u001b[0m  \u001b[38;2;32;148;243m-0.0697232\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01488583\u001b[0m  \u001b[38;2;32;148;243m0.00313894\u001b[0m  \u001b[38;2;32;148;243m0.01915366\u001b[0m  \u001b[38;2;32;148;243m0.00919779\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10225828\u001b[0m \u001b[38;2;32;148;243m-0.05408212\u001b[0m \u001b[38;2;32;148;243m-0.03943634\u001b[0m \u001b[38;2;32;148;243m-0.07649302\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21401826\u001b[0m \u001b[38;2;32;148;243m-0.10536524\u001b[0m \u001b[38;2;32;148;243m-0.09886995\u001b[0m \u001b[38;2;32;148;243m-0.151691\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32606074\u001b[0m \u001b[38;2;32;148;243m-0.15710928\u001b[0m \u001b[38;2;32;148;243m-0.15869764\u001b[0m \u001b[38;2;32;148;243m-0.22652724\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43819443\u001b[0m \u001b[38;2;32;148;243m-0.21067635\u001b[0m \u001b[38;2;32;148;243m-0.21900587\u001b[0m \u001b[38;2;32;148;243m-0.30387058\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11245021\u001b[0m \u001b[38;2;32;148;243m0.05516556\u001b[0m \u001b[38;2;32;148;243m0.06103269\u001b[0m \u001b[38;2;32;148;243m0.07833934\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22550316\u001b[0m \u001b[38;2;32;148;243m0.10986129\u001b[0m \u001b[38;2;32;148;243m0.12047808\u001b[0m \u001b[38;2;32;148;243m0.1555107\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33922616\u001b[0m \u001b[38;2;32;148;243m0.16306585\u001b[0m \u001b[38;2;32;148;243m0.17937097\u001b[0m \u001b[38;2;32;148;243m0.23414738\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.45308026\u001b[0m \u001b[38;2;32;148;243m0.21381529\u001b[0m \u001b[38;2;32;148;243m0.23815953\u001b[0m \u001b[38;2;32;148;243m0.31306837\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10225828\u001b[0m \u001b[38;2;32;148;243m-0.05408212\u001b[0m \u001b[38;2;32;148;243m-0.03943634\u001b[0m \u001b[38;2;32;148;243m-0.07649302\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21401826\u001b[0m \u001b[38;2;32;148;243m-0.10536524\u001b[0m \u001b[38;2;32;148;243m-0.09886995\u001b[0m \u001b[38;2;32;148;243m-0.151691\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32606074\u001b[0m \u001b[38;2;32;148;243m-0.15710928\u001b[0m \u001b[38;2;32;148;243m-0.15869764\u001b[0m \u001b[38;2;32;148;243m-0.22652724\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43819443\u001b[0m \u001b[38;2;32;148;243m-0.21067635\u001b[0m \u001b[38;2;32;148;243m-0.21900587\u001b[0m \u001b[38;2;32;148;243m-0.30387058\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32574422\u001b[0m \u001b[38;2;32;148;243m-0.15551078\u001b[0m \u001b[38;2;32;148;243m-0.15797318\u001b[0m \u001b[38;2;32;148;243m-0.22553124\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21269127\u001b[0m \u001b[38;2;32;148;243m-0.10081506\u001b[0m \u001b[38;2;32;148;243m-0.09852779\u001b[0m \u001b[38;2;32;148;243m-0.14835988\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09896827\u001b[0m \u001b[38;2;32;148;243m-0.04761049\u001b[0m \u001b[38;2;32;148;243m-0.0396349\u001b[0m  \u001b[38;2;32;148;243m-0.0697232\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01488583\u001b[0m  \u001b[38;2;32;148;243m0.00313894\u001b[0m  \u001b[38;2;32;148;243m0.01915366\u001b[0m  \u001b[38;2;32;148;243m0.00919779\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01488583\u001b[0m \u001b[38;2;32;148;243m0.00313894\u001b[0m \u001b[38;2;32;148;243m0.01915366\u001b[0m \u001b[38;2;32;148;243m0.00919779\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.311273598207552e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00625617\u001b[0m  \u001b[38;2;32;148;243m0.00515697\u001b[0m  \u001b[38;2;32;148;243m0.00406816\u001b[0m  \u001b[38;2;32;148;243m0.00275435\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00169669\u001b[0m  \u001b[38;2;32;148;243m0.00027787\u001b[0m \u001b[38;2;32;148;243m-0.00307472\u001b[0m \u001b[38;2;32;148;243m-0.00243068\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04951016\u001b[0m  \u001b[38;2;32;148;243m0.00810845\u001b[0m \u001b[38;2;32;148;243m-0.08972183\u001b[0m \u001b[38;2;32;148;243m-0.0709284\u001b[0m \u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.0091121\u001b[0m  \u001b[38;2;32;148;243m0.00485531\u001b[0m \u001b[38;2;32;148;243m0.00373837\u001b[0m \u001b[38;2;32;148;243m0.00530226\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00031227\u001b[0m \u001b[38;2;32;148;243m0.00016639\u001b[0m \u001b[38;2;32;148;243m0.00012811\u001b[0m \u001b[38;2;32;148;243m0.00018171\u001b[0m\u001b[1m]\u001b[0m\n[07:57:18] TRAIN STEP: 5                                                                                           \n\n           TRAIN STEP: 6                                                                                           \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:18]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m228.01629364\u001b[0m \u001b[38;2;32;148;243m-281.98565237\u001b[0m  \u001b[38;2;32;148;243m-20.12491938\u001b[0m  \u001b[38;2;32;148;243m-81.93169814\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.54372772\u001b[0m \u001b[38;2;32;148;243m-284.81511328\u001b[0m  \u001b[38;2;32;148;243m-37.93562912\u001b[0m  \u001b[38;2;32;148;243m-94.82221044\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.53314206\u001b[0m \u001b[38;2;32;148;243m-284.86321231\u001b[0m  \u001b[38;2;32;148;243m-37.98213952\u001b[0m  \u001b[38;2;32;148;243m-94.7657871\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.53988816\u001b[0m \u001b[38;2;32;148;243m-284.89900259\u001b[0m  \u001b[38;2;32;148;243m-38.01533459\u001b[0m  \u001b[38;2;32;148;243m-94.6929395\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.56277464\u001b[0m \u001b[38;2;32;148;243m-284.92278355\u001b[0m  \u001b[38;2;32;148;243m-38.03459123\u001b[0m  \u001b[38;2;32;148;243m-94.60412808\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.52202739\u001b[0m \u001b[38;2;32;148;243m-284.81794281\u001b[0m  \u001b[38;2;32;148;243m-37.98911718\u001b[0m  \u001b[38;2;32;148;243m-94.44784165\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.49797583\u001b[0m \u001b[38;2;32;148;243m-284.69947243\u001b[0m  \u001b[38;2;32;148;243m-37.9326838\u001b[0m   \u001b[38;2;32;148;243m-94.27544262\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.49108176\u001b[0m \u001b[38;2;32;148;243m-284.56770054\u001b[0m  \u001b[38;2;32;148;243m-37.864695\u001b[0m    \u001b[38;2;32;148;243m-94.08767484\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.50091155\u001b[0m \u001b[38;2;32;148;243m-284.42249184\u001b[0m  \u001b[38;2;32;148;243m-37.78261324\u001b[0m  \u001b[38;2;32;148;243m-93.88473302\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m228.01629364\u001b[0m \u001b[38;2;32;148;243m-281.98565237\u001b[0m  \u001b[38;2;32;148;243m-20.12491938\u001b[0m  \u001b[38;2;32;148;243m-81.93169814\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.64717122\u001b[0m \u001b[38;2;32;148;243m-284.76978578\u001b[0m  \u001b[38;2;32;148;243m-37.89875392\u001b[0m  \u001b[38;2;32;148;243m-94.73644574\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.73537504\u001b[0m \u001b[38;2;32;148;243m-284.77002068\u001b[0m  \u001b[38;2;32;148;243m-37.89616835\u001b[0m  \u001b[38;2;32;148;243m-94.59029472\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.84174293\u001b[0m \u001b[38;2;32;148;243m-284.75652536\u001b[0m  \u001b[38;2;32;148;243m-37.88147942\u001b[0m  \u001b[38;2;32;148;243m-94.42815844\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.962672\u001b[0m   \u001b[38;2;32;148;243m-284.7292213\u001b[0m   \u001b[38;2;32;148;243m-37.85268786\u001b[0m  \u001b[38;2;32;148;243m-94.25053909\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.82588679\u001b[0m \u001b[38;2;32;148;243m-284.6766064\u001b[0m   \u001b[38;2;32;148;243m-37.85487886\u001b[0m  \u001b[38;2;32;148;243m-94.18370178\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.70632398\u001b[0m \u001b[38;2;32;148;243m-284.6116521\u001b[0m   \u001b[38;2;32;148;243m-37.84305335\u001b[0m  \u001b[38;2;32;148;243m-94.10091561\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.60393282\u001b[0m \u001b[38;2;32;148;243m-284.53535682\u001b[0m  \u001b[38;2;32;148;243m-37.81768024\u001b[0m  \u001b[38;2;32;148;243m-94.00238516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m209.51820993\u001b[0m \u001b[38;2;32;148;243m-284.44869923\u001b[0m  \u001b[38;2;32;148;243m-37.7788019\u001b[0m   \u001b[38;2;32;148;243m-93.88832557\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1034435\u001b[0m  \u001b[38;2;32;148;243m-0.0453275\u001b[0m  \u001b[38;2;32;148;243m-0.0368752\u001b[0m  \u001b[38;2;32;148;243m-0.0857647\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20223298\u001b[0m \u001b[38;2;32;148;243m-0.09319163\u001b[0m \u001b[38;2;32;148;243m-0.08597117\u001b[0m \u001b[38;2;32;148;243m-0.17549238\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30185477\u001b[0m \u001b[38;2;32;148;243m-0.14247724\u001b[0m \u001b[38;2;32;148;243m-0.13385516\u001b[0m \u001b[38;2;32;148;243m-0.26478106\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39989736\u001b[0m \u001b[38;2;32;148;243m-0.19356225\u001b[0m \u001b[38;2;32;148;243m-0.18190337\u001b[0m \u001b[38;2;32;148;243m-0.35358898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3038594\u001b[0m  \u001b[38;2;32;148;243m-0.14133641\u001b[0m \u001b[38;2;32;148;243m-0.13423832\u001b[0m \u001b[38;2;32;148;243m-0.26413986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20834815\u001b[0m \u001b[38;2;32;148;243m-0.08782033\u001b[0m \u001b[38;2;32;148;243m-0.08963045\u001b[0m \u001b[38;2;32;148;243m-0.174527\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11285106\u001b[0m \u001b[38;2;32;148;243m-0.03234373\u001b[0m \u001b[38;2;32;148;243m-0.04701475\u001b[0m \u001b[38;2;32;148;243m-0.08528968\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01729838\u001b[0m  \u001b[38;2;32;148;243m0.02620739\u001b[0m \u001b[38;2;32;148;243m-0.00381135\u001b[0m  \u001b[38;2;32;148;243m0.00359256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1034435\u001b[0m  \u001b[38;2;32;148;243m-0.0453275\u001b[0m  \u001b[38;2;32;148;243m-0.0368752\u001b[0m  \u001b[38;2;32;148;243m-0.0857647\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20223298\u001b[0m \u001b[38;2;32;148;243m-0.09319163\u001b[0m \u001b[38;2;32;148;243m-0.08597117\u001b[0m \u001b[38;2;32;148;243m-0.17549238\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30185477\u001b[0m \u001b[38;2;32;148;243m-0.14247724\u001b[0m \u001b[38;2;32;148;243m-0.13385516\u001b[0m \u001b[38;2;32;148;243m-0.26478106\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39989736\u001b[0m \u001b[38;2;32;148;243m-0.19356225\u001b[0m \u001b[38;2;32;148;243m-0.18190337\u001b[0m \u001b[38;2;32;148;243m-0.35358898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.09603796\u001b[0m \u001b[38;2;32;148;243m0.05222585\u001b[0m \u001b[38;2;32;148;243m0.04766505\u001b[0m \u001b[38;2;32;148;243m0.08944912\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19154921\u001b[0m \u001b[38;2;32;148;243m0.10574193\u001b[0m \u001b[38;2;32;148;243m0.09227292\u001b[0m \u001b[38;2;32;148;243m0.17906198\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.2870463\u001b[0m  \u001b[38;2;32;148;243m0.16121852\u001b[0m \u001b[38;2;32;148;243m0.13488861\u001b[0m \u001b[38;2;32;148;243m0.2682993\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.38259897\u001b[0m \u001b[38;2;32;148;243m0.21976964\u001b[0m \u001b[38;2;32;148;243m0.17809202\u001b[0m \u001b[38;2;32;148;243m0.35718154\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1034435\u001b[0m  \u001b[38;2;32;148;243m-0.0453275\u001b[0m  \u001b[38;2;32;148;243m-0.0368752\u001b[0m  \u001b[38;2;32;148;243m-0.0857647\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20223298\u001b[0m \u001b[38;2;32;148;243m-0.09319163\u001b[0m \u001b[38;2;32;148;243m-0.08597117\u001b[0m \u001b[38;2;32;148;243m-0.17549238\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30185477\u001b[0m \u001b[38;2;32;148;243m-0.14247724\u001b[0m \u001b[38;2;32;148;243m-0.13385516\u001b[0m \u001b[38;2;32;148;243m-0.26478106\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39989736\u001b[0m \u001b[38;2;32;148;243m-0.19356225\u001b[0m \u001b[38;2;32;148;243m-0.18190337\u001b[0m \u001b[38;2;32;148;243m-0.35358898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3038594\u001b[0m  \u001b[38;2;32;148;243m-0.14133641\u001b[0m \u001b[38;2;32;148;243m-0.13423832\u001b[0m \u001b[38;2;32;148;243m-0.26413986\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20834815\u001b[0m \u001b[38;2;32;148;243m-0.08782033\u001b[0m \u001b[38;2;32;148;243m-0.08963045\u001b[0m \u001b[38;2;32;148;243m-0.174527\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.11285106\u001b[0m \u001b[38;2;32;148;243m-0.03234373\u001b[0m \u001b[38;2;32;148;243m-0.04701475\u001b[0m \u001b[38;2;32;148;243m-0.08528968\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01729838\u001b[0m  \u001b[38;2;32;148;243m0.02620739\u001b[0m \u001b[38;2;32;148;243m-0.00381135\u001b[0m  \u001b[38;2;32;148;243m0.00359256\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01729838\u001b[0m  \u001b[38;2;32;148;243m0.02620739\u001b[0m \u001b[38;2;32;148;243m-0.00381135\u001b[0m  \u001b[38;2;32;148;243m0.00359256\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.28664314669938e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00595627\u001b[0m  \u001b[38;2;32;148;243m0.00563947\u001b[0m  \u001b[38;2;32;148;243m0.00427224\u001b[0m  \u001b[38;2;32;148;243m0.00266021\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0015684\u001b[0m   \u001b[38;2;32;148;243m0.000394\u001b[0m   \u001b[38;2;32;148;243m-0.00288902\u001b[0m \u001b[38;2;32;148;243m-0.00230002\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04576675\u001b[0m  \u001b[38;2;32;148;243m0.01149709\u001b[0m \u001b[38;2;32;148;243m-0.08430301\u001b[0m \u001b[38;2;32;148;243m-0.06711567\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00569303\u001b[0m \u001b[38;2;32;148;243m0.00018414\u001b[0m \u001b[38;2;32;148;243m0.00430204\u001b[0m \u001b[38;2;32;148;243m0.0048331\u001b[0m \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.95097159e-04\u001b[0m \u001b[38;2;32;148;243m6.31025768e-06\u001b[0m \u001b[38;2;32;148;243m1.47428747e-04\u001b[0m \u001b[38;2;32;148;243m1.65627571e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 7                                                                                           \n\n[07:57:19] TRAIN STEP: 8                                                                                           \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:19]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m58.07198815\u001b[0m \u001b[38;2;32;148;243m-254.25276437\u001b[0m \u001b[38;2;32;148;243m-172.2577486\u001b[0m    \u001b[38;2;32;148;243m29.085534\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.58967365\u001b[0m \u001b[38;2;32;148;243m-256.77756509\u001b[0m \u001b[38;2;32;148;243m-189.63209473\u001b[0m   \u001b[38;2;32;148;243m16.9107765\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.54131984\u001b[0m \u001b[38;2;32;148;243m-256.74101555\u001b[0m \u001b[38;2;32;148;243m-189.65157019\u001b[0m   \u001b[38;2;32;148;243m16.86084166\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.51063821\u001b[0m \u001b[38;2;32;148;243m-256.69100156\u001b[0m \u001b[38;2;32;148;243m-189.65346392\u001b[0m   \u001b[38;2;32;148;243m16.82947871\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.49779564\u001b[0m \u001b[38;2;32;148;243m-256.63323532\u001b[0m \u001b[38;2;32;148;243m-189.63822452\u001b[0m   \u001b[38;2;32;148;243m16.81279717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.44790192\u001b[0m \u001b[38;2;32;148;243m-256.74596217\u001b[0m \u001b[38;2;32;148;243m-189.52847699\u001b[0m   \u001b[38;2;32;148;243m16.85991159\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.41672204\u001b[0m \u001b[38;2;32;148;243m-256.84462705\u001b[0m \u001b[38;2;32;148;243m-189.40387487\u001b[0m   \u001b[38;2;32;148;243m16.9229498\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.40415924\u001b[0m \u001b[38;2;32;148;243m-256.92936903\u001b[0m \u001b[38;2;32;148;243m-189.26495267\u001b[0m   \u001b[38;2;32;148;243m17.00162406\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.40968237\u001b[0m \u001b[38;2;32;148;243m-257.00031104\u001b[0m \u001b[38;2;32;148;243m-189.11191882\u001b[0m   \u001b[38;2;32;148;243m17.09386957\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m58.07198815\u001b[0m \u001b[38;2;32;148;243m-254.25276437\u001b[0m \u001b[38;2;32;148;243m-172.2577486\u001b[0m    \u001b[38;2;32;148;243m29.085534\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.69108049\u001b[0m \u001b[38;2;32;148;243m-256.73219519\u001b[0m \u001b[38;2;32;148;243m-189.60853741\u001b[0m   \u001b[38;2;32;148;243m16.99823438\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.74834371\u001b[0m \u001b[38;2;32;148;243m-256.65132718\u001b[0m \u001b[38;2;32;148;243m-189.60253545\u001b[0m   \u001b[38;2;32;148;243m17.02556407\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.82415398\u001b[0m \u001b[38;2;32;148;243m-256.55706059\u001b[0m \u001b[38;2;32;148;243m-189.58177739\u001b[0m   \u001b[38;2;32;148;243m17.06940503\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.91900959\u001b[0m \u001b[38;2;32;148;243m-256.45221112\u001b[0m \u001b[38;2;32;148;243m-189.54598199\u001b[0m   \u001b[38;2;32;148;243m17.12813164\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.76089447\u001b[0m \u001b[38;2;32;148;243m-256.61505054\u001b[0m \u001b[38;2;32;148;243m-189.45640459\u001b[0m   \u001b[38;2;32;148;243m17.09995904\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.62166943\u001b[0m \u001b[38;2;32;148;243m-256.76307375\u001b[0m \u001b[38;2;32;148;243m-189.35122961\u001b[0m   \u001b[38;2;32;148;243m17.08707163\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.50106519\u001b[0m \u001b[38;2;32;148;243m-256.89602957\u001b[0m \u001b[38;2;32;148;243m-189.2319903\u001b[0m    \u001b[38;2;32;148;243m17.08934889\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m38.39833993\u001b[0m \u001b[38;2;32;148;243m-257.01404255\u001b[0m \u001b[38;2;32;148;243m-189.09974009\u001b[0m   \u001b[38;2;32;148;243m17.1062827\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10140685\u001b[0m \u001b[38;2;32;148;243m-0.0453699\u001b[0m  \u001b[38;2;32;148;243m-0.02355732\u001b[0m \u001b[38;2;32;148;243m-0.08745788\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20702387\u001b[0m \u001b[38;2;32;148;243m-0.08968837\u001b[0m \u001b[38;2;32;148;243m-0.04903474\u001b[0m \u001b[38;2;32;148;243m-0.16472241\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31351577\u001b[0m \u001b[38;2;32;148;243m-0.13394096\u001b[0m \u001b[38;2;32;148;243m-0.07168653\u001b[0m \u001b[38;2;32;148;243m-0.23992632\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42121395\u001b[0m \u001b[38;2;32;148;243m-0.18102421\u001b[0m \u001b[38;2;32;148;243m-0.09224252\u001b[0m \u001b[38;2;32;148;243m-0.31533447\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31299255\u001b[0m \u001b[38;2;32;148;243m-0.13091163\u001b[0m \u001b[38;2;32;148;243m-0.0720724\u001b[0m  \u001b[38;2;32;148;243m-0.24004744\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20494739\u001b[0m \u001b[38;2;32;148;243m-0.08155329\u001b[0m \u001b[38;2;32;148;243m-0.05264525\u001b[0m \u001b[38;2;32;148;243m-0.16412183\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09690595\u001b[0m \u001b[38;2;32;148;243m-0.03333946\u001b[0m \u001b[38;2;32;148;243m-0.03296237\u001b[0m \u001b[38;2;32;148;243m-0.08772482\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01134244\u001b[0m  \u001b[38;2;32;148;243m0.01373151\u001b[0m \u001b[38;2;32;148;243m-0.01217873\u001b[0m \u001b[38;2;32;148;243m-0.01241313\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10140685\u001b[0m \u001b[38;2;32;148;243m-0.0453699\u001b[0m  \u001b[38;2;32;148;243m-0.02355732\u001b[0m \u001b[38;2;32;148;243m-0.08745788\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20702387\u001b[0m \u001b[38;2;32;148;243m-0.08968837\u001b[0m \u001b[38;2;32;148;243m-0.04903474\u001b[0m \u001b[38;2;32;148;243m-0.16472241\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31351577\u001b[0m \u001b[38;2;32;148;243m-0.13394096\u001b[0m \u001b[38;2;32;148;243m-0.07168653\u001b[0m \u001b[38;2;32;148;243m-0.23992632\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42121395\u001b[0m \u001b[38;2;32;148;243m-0.18102421\u001b[0m \u001b[38;2;32;148;243m-0.09224252\u001b[0m \u001b[38;2;32;148;243m-0.31533447\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.1082214\u001b[0m  \u001b[38;2;32;148;243m0.05011257\u001b[0m \u001b[38;2;32;148;243m0.02017012\u001b[0m \u001b[38;2;32;148;243m0.07528702\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21626657\u001b[0m \u001b[38;2;32;148;243m0.09947091\u001b[0m \u001b[38;2;32;148;243m0.03959727\u001b[0m \u001b[38;2;32;148;243m0.15121264\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.324308\u001b[0m   \u001b[38;2;32;148;243m0.14768475\u001b[0m \u001b[38;2;32;148;243m0.05928015\u001b[0m \u001b[38;2;32;148;243m0.22760964\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.43255639\u001b[0m \u001b[38;2;32;148;243m0.19475572\u001b[0m \u001b[38;2;32;148;243m0.08006379\u001b[0m \u001b[38;2;32;148;243m0.30292134\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10140685\u001b[0m \u001b[38;2;32;148;243m-0.0453699\u001b[0m  \u001b[38;2;32;148;243m-0.02355732\u001b[0m \u001b[38;2;32;148;243m-0.08745788\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20702387\u001b[0m \u001b[38;2;32;148;243m-0.08968837\u001b[0m \u001b[38;2;32;148;243m-0.04903474\u001b[0m \u001b[38;2;32;148;243m-0.16472241\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31351577\u001b[0m \u001b[38;2;32;148;243m-0.13394096\u001b[0m \u001b[38;2;32;148;243m-0.07168653\u001b[0m \u001b[38;2;32;148;243m-0.23992632\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42121395\u001b[0m \u001b[38;2;32;148;243m-0.18102421\u001b[0m \u001b[38;2;32;148;243m-0.09224252\u001b[0m \u001b[38;2;32;148;243m-0.31533447\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31299255\u001b[0m \u001b[38;2;32;148;243m-0.13091163\u001b[0m \u001b[38;2;32;148;243m-0.0720724\u001b[0m  \u001b[38;2;32;148;243m-0.24004744\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20494739\u001b[0m \u001b[38;2;32;148;243m-0.08155329\u001b[0m \u001b[38;2;32;148;243m-0.05264525\u001b[0m \u001b[38;2;32;148;243m-0.16412183\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09690595\u001b[0m \u001b[38;2;32;148;243m-0.03333946\u001b[0m \u001b[38;2;32;148;243m-0.03296237\u001b[0m \u001b[38;2;32;148;243m-0.08772482\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01134244\u001b[0m  \u001b[38;2;32;148;243m0.01373151\u001b[0m \u001b[38;2;32;148;243m-0.01217873\u001b[0m \u001b[38;2;32;148;243m-0.01241313\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01134244\u001b[0m  \u001b[38;2;32;148;243m0.01373151\u001b[0m \u001b[38;2;32;148;243m-0.01217873\u001b[0m \u001b[38;2;32;148;243m-0.01241313\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.173678843041342e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00589752\u001b[0m  \u001b[38;2;32;148;243m0.00556446\u001b[0m  \u001b[38;2;32;148;243m0.00453206\u001b[0m  \u001b[38;2;32;148;243m0.00283429\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0013992\u001b[0m   \u001b[38;2;32;148;243m0.00034847\u001b[0m \u001b[38;2;32;148;243m-0.0030403\u001b[0m  \u001b[38;2;32;148;243m-0.00230766\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04082942\u001b[0m  \u001b[38;2;32;148;243m0.01016853\u001b[0m \u001b[38;2;32;148;243m-0.08871753\u001b[0m \u001b[38;2;32;148;243m-0.06733875\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00390699\u001b[0m \u001b[38;2;32;148;243m0.00238289\u001b[0m \u001b[38;2;32;148;243m0.00855818\u001b[0m \u001b[38;2;32;148;243m0.00216934\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.33890400e-04\u001b[0m \u001b[38;2;32;148;243m8.16602253e-05\u001b[0m \u001b[38;2;32;148;243m2.93284326e-04\u001b[0m \u001b[38;2;32;148;243m7.43419571e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 9                                                                                           \n\n[07:57:20] TRAIN STEP: 10                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:20]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m165.78526004\u001b[0m \u001b[38;2;32;148;243m-158.66660112\u001b[0m \u001b[38;2;32;148;243m-150.84648678\u001b[0m \u001b[38;2;32;148;243m-277.1795612\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.39212947\u001b[0m \u001b[38;2;32;148;243m-160.8891048\u001b[0m  \u001b[38;2;32;148;243m-167.54447157\u001b[0m \u001b[38;2;32;148;243m-290.5208167\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.17045246\u001b[0m \u001b[38;2;32;148;243m-160.83928327\u001b[0m \u001b[38;2;32;148;243m-167.60853844\u001b[0m \u001b[38;2;32;148;243m-290.55458752\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m146.96450675\u001b[0m \u001b[38;2;32;148;243m-160.77671527\u001b[0m \u001b[38;2;32;148;243m-167.65852461\u001b[0m \u001b[38;2;32;148;243m-290.57214886\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m146.77478032\u001b[0m \u001b[38;2;32;148;243m-160.700923\u001b[0m   \u001b[38;2;32;148;243m-167.69478487\u001b[0m \u001b[38;2;32;148;243m-290.5741648\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m146.98532096\u001b[0m \u001b[38;2;32;148;243m-160.72826923\u001b[0m \u001b[38;2;32;148;243m-167.77220345\u001b[0m \u001b[38;2;32;148;243m-290.53358274\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.2134995\u001b[0m  \u001b[38;2;32;148;243m-160.74296164\u001b[0m \u001b[38;2;32;148;243m-167.83705697\u001b[0m \u001b[38;2;32;148;243m-290.4768103\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.45923281\u001b[0m \u001b[38;2;32;148;243m-160.74258706\u001b[0m \u001b[38;2;32;148;243m-167.88795065\u001b[0m \u001b[38;2;32;148;243m-290.40486434\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.72274485\u001b[0m \u001b[38;2;32;148;243m-160.72719985\u001b[0m \u001b[38;2;32;148;243m-167.92486955\u001b[0m \u001b[38;2;32;148;243m-290.31919424\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m165.78526004\u001b[0m \u001b[38;2;32;148;243m-158.66660112\u001b[0m \u001b[38;2;32;148;243m-150.84648678\u001b[0m \u001b[38;2;32;148;243m-277.1795612\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.49634341\u001b[0m \u001b[38;2;32;148;243m-160.85234158\u001b[0m \u001b[38;2;32;148;243m-167.52064545\u001b[0m \u001b[38;2;32;148;243m-290.43531158\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.37500476\u001b[0m \u001b[38;2;32;148;243m-160.76971169\u001b[0m \u001b[38;2;32;148;243m-167.55289547\u001b[0m \u001b[38;2;32;148;243m-290.38673672\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.27085091\u001b[0m \u001b[38;2;32;148;243m-160.67383095\u001b[0m \u001b[38;2;32;148;243m-167.570758\u001b[0m   \u001b[38;2;32;148;243m-290.32414945\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.18408477\u001b[0m \u001b[38;2;32;148;243m-160.56418795\u001b[0m \u001b[38;2;32;148;243m-167.57497862\u001b[0m \u001b[38;2;32;148;243m-290.24798665\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.29124479\u001b[0m \u001b[38;2;32;148;243m-160.627483\u001b[0m   \u001b[38;2;32;148;243m-167.68155488\u001b[0m \u001b[38;2;32;148;243m-290.28472817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.41620449\u001b[0m \u001b[38;2;32;148;243m-160.67938552\u001b[0m \u001b[38;2;32;148;243m-167.77259251\u001b[0m \u001b[38;2;32;148;243m-290.30666732\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.55913924\u001b[0m \u001b[38;2;32;148;243m-160.7151849\u001b[0m  \u001b[38;2;32;148;243m-167.84958544\u001b[0m \u001b[38;2;32;148;243m-290.31370793\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m147.71994084\u001b[0m \u001b[38;2;32;148;243m-160.73486739\u001b[0m \u001b[38;2;32;148;243m-167.91182803\u001b[0m \u001b[38;2;32;148;243m-290.30589063\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10421394\u001b[0m \u001b[38;2;32;148;243m-0.03676322\u001b[0m \u001b[38;2;32;148;243m-0.02382612\u001b[0m \u001b[38;2;32;148;243m-0.08550512\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20455229\u001b[0m \u001b[38;2;32;148;243m-0.06957158\u001b[0m \u001b[38;2;32;148;243m-0.05564296\u001b[0m \u001b[38;2;32;148;243m-0.1678508\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30634415\u001b[0m \u001b[38;2;32;148;243m-0.10288432\u001b[0m \u001b[38;2;32;148;243m-0.08776661\u001b[0m \u001b[38;2;32;148;243m-0.24799941\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40930446\u001b[0m \u001b[38;2;32;148;243m-0.13673505\u001b[0m \u001b[38;2;32;148;243m-0.11980625\u001b[0m \u001b[38;2;32;148;243m-0.32617815\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30592382\u001b[0m \u001b[38;2;32;148;243m-0.10078623\u001b[0m \u001b[38;2;32;148;243m-0.09064857\u001b[0m \u001b[38;2;32;148;243m-0.24885457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20270499\u001b[0m \u001b[38;2;32;148;243m-0.06357612\u001b[0m \u001b[38;2;32;148;243m-0.06446446\u001b[0m \u001b[38;2;32;148;243m-0.17014297\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09990643\u001b[0m \u001b[38;2;32;148;243m-0.02740216\u001b[0m \u001b[38;2;32;148;243m-0.03836522\u001b[0m \u001b[38;2;32;148;243m-0.09115642\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00280402\u001b[0m  \u001b[38;2;32;148;243m0.00766754\u001b[0m \u001b[38;2;32;148;243m-0.01304152\u001b[0m \u001b[38;2;32;148;243m-0.01330361\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10421394\u001b[0m \u001b[38;2;32;148;243m-0.03676322\u001b[0m \u001b[38;2;32;148;243m-0.02382612\u001b[0m \u001b[38;2;32;148;243m-0.08550512\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20455229\u001b[0m \u001b[38;2;32;148;243m-0.06957158\u001b[0m \u001b[38;2;32;148;243m-0.05564296\u001b[0m \u001b[38;2;32;148;243m-0.1678508\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30634415\u001b[0m \u001b[38;2;32;148;243m-0.10288432\u001b[0m \u001b[38;2;32;148;243m-0.08776661\u001b[0m \u001b[38;2;32;148;243m-0.24799941\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40930446\u001b[0m \u001b[38;2;32;148;243m-0.13673505\u001b[0m \u001b[38;2;32;148;243m-0.11980625\u001b[0m \u001b[38;2;32;148;243m-0.32617815\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10338063\u001b[0m \u001b[38;2;32;148;243m0.03594882\u001b[0m \u001b[38;2;32;148;243m0.02915768\u001b[0m \u001b[38;2;32;148;243m0.07732358\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20659947\u001b[0m \u001b[38;2;32;148;243m0.07315893\u001b[0m \u001b[38;2;32;148;243m0.05534179\u001b[0m \u001b[38;2;32;148;243m0.15603518\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.30939802\u001b[0m \u001b[38;2;32;148;243m0.10933289\u001b[0m \u001b[38;2;32;148;243m0.08144103\u001b[0m \u001b[38;2;32;148;243m0.23502173\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.41210847\u001b[0m \u001b[38;2;32;148;243m0.14440259\u001b[0m \u001b[38;2;32;148;243m0.10676473\u001b[0m \u001b[38;2;32;148;243m0.31287454\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10421394\u001b[0m \u001b[38;2;32;148;243m-0.03676322\u001b[0m \u001b[38;2;32;148;243m-0.02382612\u001b[0m \u001b[38;2;32;148;243m-0.08550512\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20455229\u001b[0m \u001b[38;2;32;148;243m-0.06957158\u001b[0m \u001b[38;2;32;148;243m-0.05564296\u001b[0m \u001b[38;2;32;148;243m-0.1678508\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30634415\u001b[0m \u001b[38;2;32;148;243m-0.10288432\u001b[0m \u001b[38;2;32;148;243m-0.08776661\u001b[0m \u001b[38;2;32;148;243m-0.24799941\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40930446\u001b[0m \u001b[38;2;32;148;243m-0.13673505\u001b[0m \u001b[38;2;32;148;243m-0.11980625\u001b[0m \u001b[38;2;32;148;243m-0.32617815\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30592382\u001b[0m \u001b[38;2;32;148;243m-0.10078623\u001b[0m \u001b[38;2;32;148;243m-0.09064857\u001b[0m \u001b[38;2;32;148;243m-0.24885457\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20270499\u001b[0m \u001b[38;2;32;148;243m-0.06357612\u001b[0m \u001b[38;2;32;148;243m-0.06446446\u001b[0m \u001b[38;2;32;148;243m-0.17014297\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09990643\u001b[0m \u001b[38;2;32;148;243m-0.02740216\u001b[0m \u001b[38;2;32;148;243m-0.03836522\u001b[0m \u001b[38;2;32;148;243m-0.09115642\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00280402\u001b[0m  \u001b[38;2;32;148;243m0.00766754\u001b[0m \u001b[38;2;32;148;243m-0.01304152\u001b[0m \u001b[38;2;32;148;243m-0.01330361\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00280402\u001b[0m  \u001b[38;2;32;148;243m0.00766754\u001b[0m \u001b[38;2;32;148;243m-0.01304152\u001b[0m \u001b[38;2;32;148;243m-0.01330361\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.176952518904433e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00560066\u001b[0m  \u001b[38;2;32;148;243m0.00583437\u001b[0m  \u001b[38;2;32;148;243m0.00445981\u001b[0m  \u001b[38;2;32;148;243m0.00269613\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00164278\u001b[0m  \u001b[38;2;32;148;243m0.00039318\u001b[0m \u001b[38;2;32;148;243m-0.0029024\u001b[0m  \u001b[38;2;32;148;243m-0.00230664\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04793717\u001b[0m  \u001b[38;2;32;148;243m0.01147332\u001b[0m \u001b[38;2;32;148;243m-0.08469338\u001b[0m \u001b[38;2;32;148;243m-0.06730904\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00583948\u001b[0m \u001b[38;2;32;148;243m0.00029422\u001b[0m \u001b[38;2;32;148;243m0.00308553\u001b[0m \u001b[38;2;32;148;243m0.00448383\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.00115985e-04\u001b[0m \u001b[38;2;32;148;243m1.00829077e-05\u001b[0m \u001b[38;2;32;148;243m1.05739392e-04\u001b[0m \u001b[38;2;32;148;243m1.53658415e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 11                                                                                          \n\n[07:57:21] TRAIN STEP: 12                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:21]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m188.20505965\u001b[0m  \u001b[38;2;32;148;243m-58.29885144\u001b[0m  \u001b[38;2;32;148;243m-98.18029968\u001b[0m  \u001b[38;2;32;148;243m-54.39963063\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.51710167\u001b[0m  \u001b[38;2;32;148;243m-61.06483545\u001b[0m \u001b[38;2;32;148;243m-116.01752595\u001b[0m  \u001b[38;2;32;148;243m-68.13930872\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.22367662\u001b[0m  \u001b[38;2;32;148;243m-61.02729971\u001b[0m \u001b[38;2;32;148;243m-116.12317278\u001b[0m  \u001b[38;2;32;148;243m-68.35212217\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m169.94726353\u001b[0m  \u001b[38;2;32;148;243m-60.97502657\u001b[0m \u001b[38;2;32;148;243m-116.21178215\u001b[0m  \u001b[38;2;32;148;243m-68.54917981\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m169.6874372\u001b[0m   \u001b[38;2;32;148;243m-60.90769105\u001b[0m \u001b[38;2;32;148;243m-116.28237697\u001b[0m  \u001b[38;2;32;148;243m-68.73040709\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m169.88756791\u001b[0m  \u001b[38;2;32;148;243m-60.60725102\u001b[0m \u001b[38;2;32;148;243m-116.19644423\u001b[0m  \u001b[38;2;32;148;243m-68.68839189\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.10515006\u001b[0m  \u001b[38;2;32;148;243m-60.29350582\u001b[0m \u001b[38;2;32;148;243m-116.09583329\u001b[0m  \u001b[38;2;32;148;243m-68.63115605\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.33946017\u001b[0m  \u001b[38;2;32;148;243m-59.96648684\u001b[0m \u001b[38;2;32;148;243m-115.98075856\u001b[0m  \u001b[38;2;32;148;243m-68.55935268\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.590336\u001b[0m    \u001b[38;2;32;148;243m-59.62290977\u001b[0m \u001b[38;2;32;148;243m-115.85112333\u001b[0m  \u001b[38;2;32;148;243m-68.47245672\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m188.20505965\u001b[0m  \u001b[38;2;32;148;243m-58.29885144\u001b[0m  \u001b[38;2;32;148;243m-98.18029968\u001b[0m  \u001b[38;2;32;148;243m-54.39963063\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.61883772\u001b[0m  \u001b[38;2;32;148;243m-60.99860325\u001b[0m \u001b[38;2;32;148;243m-115.99267874\u001b[0m  \u001b[38;2;32;148;243m-68.05494583\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.42464918\u001b[0m  \u001b[38;2;32;148;243m-60.88261255\u001b[0m \u001b[38;2;32;148;243m-116.07186839\u001b[0m  \u001b[38;2;32;148;243m-68.18439678\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.24744052\u001b[0m  \u001b[38;2;32;148;243m-60.75120359\u001b[0m \u001b[38;2;32;148;243m-116.1365266\u001b[0m   \u001b[38;2;32;148;243m-68.29608566\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.08701925\u001b[0m  \u001b[38;2;32;148;243m-60.60473632\u001b[0m \u001b[38;2;32;148;243m-116.18640188\u001b[0m  \u001b[38;2;32;148;243m-68.3914714\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.18679771\u001b[0m  \u001b[38;2;32;148;243m-60.38249412\u001b[0m \u001b[38;2;32;148;243m-116.11953711\u001b[0m  \u001b[38;2;32;148;243m-68.43541968\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.30402635\u001b[0m  \u001b[38;2;32;148;243m-60.14605486\u001b[0m \u001b[38;2;32;148;243m-116.03781314\u001b[0m  \u001b[38;2;32;148;243m-68.46434924\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.43897919\u001b[0m  \u001b[38;2;32;148;243m-59.8957125\u001b[0m  \u001b[38;2;32;148;243m-115.94174113\u001b[0m  \u001b[38;2;32;148;243m-68.47993056\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m170.5910721\u001b[0m   \u001b[38;2;32;148;243m-59.63004352\u001b[0m \u001b[38;2;32;148;243m-115.83059649\u001b[0m  \u001b[38;2;32;148;243m-68.48065411\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10173606\u001b[0m \u001b[38;2;32;148;243m-0.06623219\u001b[0m \u001b[38;2;32;148;243m-0.02484721\u001b[0m \u001b[38;2;32;148;243m-0.08436289\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20097256\u001b[0m \u001b[38;2;32;148;243m-0.14468717\u001b[0m \u001b[38;2;32;148;243m-0.05130439\u001b[0m \u001b[38;2;32;148;243m-0.16772539\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30017699\u001b[0m \u001b[38;2;32;148;243m-0.22382299\u001b[0m \u001b[38;2;32;148;243m-0.07525555\u001b[0m \u001b[38;2;32;148;243m-0.25309416\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39958205\u001b[0m \u001b[38;2;32;148;243m-0.30295473\u001b[0m \u001b[38;2;32;148;243m-0.09597509\u001b[0m \u001b[38;2;32;148;243m-0.33893569\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2992298\u001b[0m  \u001b[38;2;32;148;243m-0.22475689\u001b[0m \u001b[38;2;32;148;243m-0.07690712\u001b[0m \u001b[38;2;32;148;243m-0.25297222\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19887629\u001b[0m \u001b[38;2;32;148;243m-0.14745096\u001b[0m \u001b[38;2;32;148;243m-0.05802014\u001b[0m \u001b[38;2;32;148;243m-0.16680681\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09951902\u001b[0m \u001b[38;2;32;148;243m-0.07077434\u001b[0m \u001b[38;2;32;148;243m-0.03901743\u001b[0m \u001b[38;2;32;148;243m-0.07942211\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00073611\u001b[0m  \u001b[38;2;32;148;243m0.00713375\u001b[0m \u001b[38;2;32;148;243m-0.02052685\u001b[0m  \u001b[38;2;32;148;243m0.00819739\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10173606\u001b[0m \u001b[38;2;32;148;243m-0.06623219\u001b[0m \u001b[38;2;32;148;243m-0.02484721\u001b[0m \u001b[38;2;32;148;243m-0.08436289\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20097256\u001b[0m \u001b[38;2;32;148;243m-0.14468717\u001b[0m \u001b[38;2;32;148;243m-0.05130439\u001b[0m \u001b[38;2;32;148;243m-0.16772539\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30017699\u001b[0m \u001b[38;2;32;148;243m-0.22382299\u001b[0m \u001b[38;2;32;148;243m-0.07525555\u001b[0m \u001b[38;2;32;148;243m-0.25309416\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39958205\u001b[0m \u001b[38;2;32;148;243m-0.30295473\u001b[0m \u001b[38;2;32;148;243m-0.09597509\u001b[0m \u001b[38;2;32;148;243m-0.33893569\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10035224\u001b[0m \u001b[38;2;32;148;243m0.07819784\u001b[0m \u001b[38;2;32;148;243m0.01906797\u001b[0m \u001b[38;2;32;148;243m0.08596348\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20070576\u001b[0m \u001b[38;2;32;148;243m0.15550378\u001b[0m \u001b[38;2;32;148;243m0.03795495\u001b[0m \u001b[38;2;32;148;243m0.17212888\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.30006303\u001b[0m \u001b[38;2;32;148;243m0.2321804\u001b[0m  \u001b[38;2;32;148;243m0.05695766\u001b[0m \u001b[38;2;32;148;243m0.25951358\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.39884594\u001b[0m \u001b[38;2;32;148;243m0.31008849\u001b[0m \u001b[38;2;32;148;243m0.07544825\u001b[0m \u001b[38;2;32;148;243m0.34713308\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10173606\u001b[0m \u001b[38;2;32;148;243m-0.06623219\u001b[0m \u001b[38;2;32;148;243m-0.02484721\u001b[0m \u001b[38;2;32;148;243m-0.08436289\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20097256\u001b[0m \u001b[38;2;32;148;243m-0.14468717\u001b[0m \u001b[38;2;32;148;243m-0.05130439\u001b[0m \u001b[38;2;32;148;243m-0.16772539\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30017699\u001b[0m \u001b[38;2;32;148;243m-0.22382299\u001b[0m \u001b[38;2;32;148;243m-0.07525555\u001b[0m \u001b[38;2;32;148;243m-0.25309416\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39958205\u001b[0m \u001b[38;2;32;148;243m-0.30295473\u001b[0m \u001b[38;2;32;148;243m-0.09597509\u001b[0m \u001b[38;2;32;148;243m-0.33893569\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2992298\u001b[0m  \u001b[38;2;32;148;243m-0.22475689\u001b[0m \u001b[38;2;32;148;243m-0.07690712\u001b[0m \u001b[38;2;32;148;243m-0.25297222\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19887629\u001b[0m \u001b[38;2;32;148;243m-0.14745096\u001b[0m \u001b[38;2;32;148;243m-0.05802014\u001b[0m \u001b[38;2;32;148;243m-0.16680681\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09951902\u001b[0m \u001b[38;2;32;148;243m-0.07077434\u001b[0m \u001b[38;2;32;148;243m-0.03901743\u001b[0m \u001b[38;2;32;148;243m-0.07942211\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00073611\u001b[0m  \u001b[38;2;32;148;243m0.00713375\u001b[0m \u001b[38;2;32;148;243m-0.02052685\u001b[0m  \u001b[38;2;32;148;243m0.00819739\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00073611\u001b[0m  \u001b[38;2;32;148;243m0.00713375\u001b[0m \u001b[38;2;32;148;243m-0.02052685\u001b[0m  \u001b[38;2;32;148;243m0.00819739\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.275198253756771e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00565215\u001b[0m  \u001b[38;2;32;148;243m0.00597338\u001b[0m  \u001b[38;2;32;148;243m0.00471459\u001b[0m  \u001b[38;2;32;148;243m0.00279347\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.64529269e-03\u001b[0m  \u001b[38;2;32;148;243m5.24680611e-05\u001b[0m \u001b[38;2;32;148;243m-2.97667902e-03\u001b[0m \u001b[38;2;32;148;243m-2.65912988e-03\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04801046\u001b[0m  \u001b[38;2;32;148;243m0.00153104\u001b[0m \u001b[38;2;32;148;243m-0.08686098\u001b[0m \u001b[38;2;32;148;243m-0.07759474\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00065245\u001b[0m \u001b[38;2;32;148;243m0.00969285\u001b[0m \u001b[38;2;32;148;243m0.00241307\u001b[0m \u001b[38;2;32;148;243m0.0080844\u001b[0m \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.23591304e-05\u001b[0m \u001b[38;2;32;148;243m3.32168887e-04\u001b[0m \u001b[38;2;32;148;243m8.26946588e-05\u001b[0m \u001b[38;2;32;148;243m2.77047880e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 13                                                                                          \n\n[07:57:22] TRAIN STEP: 14                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:22]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m269.43140031\u001b[0m \u001b[38;2;32;148;243m-78.92513987\u001b[0m  \u001b[38;2;32;148;243m32.34792115\u001b[0m \u001b[38;2;32;148;243m113.77488245\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.52566438\u001b[0m \u001b[38;2;32;148;243m-83.0934488\u001b[0m   \u001b[38;2;32;148;243m14.569342\u001b[0m   \u001b[38;2;32;148;243m100.76386849\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.51054733\u001b[0m \u001b[38;2;32;148;243m-83.03842171\u001b[0m  \u001b[38;2;32;148;243m14.48931617\u001b[0m \u001b[38;2;32;148;243m100.64609339\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.51146935\u001b[0m \u001b[38;2;32;148;243m-82.96954958\u001b[0m  \u001b[38;2;32;148;243m14.42328181\u001b[0m \u001b[38;2;32;148;243m100.54350263\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.52862743\u001b[0m \u001b[38;2;32;148;243m-82.88674771\u001b[0m  \u001b[38;2;32;148;243m14.37082778\u001b[0m \u001b[38;2;32;148;243m100.4575535\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.58961371\u001b[0m \u001b[38;2;32;148;243m-83.01337977\u001b[0m  \u001b[38;2;32;148;243m14.46234277\u001b[0m \u001b[38;2;32;148;243m100.48350857\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.66604833\u001b[0m \u001b[38;2;32;148;243m-83.12516719\u001b[0m  \u001b[38;2;32;148;243m14.5679644\u001b[0m  \u001b[38;2;32;148;243m100.52532797\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.75806246\u001b[0m \u001b[38;2;32;148;243m-83.22390956\u001b[0m  \u001b[38;2;32;148;243m14.68536563\u001b[0m \u001b[38;2;32;148;243m100.58193137\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.86680332\u001b[0m \u001b[38;2;32;148;243m-83.30966923\u001b[0m  \u001b[38;2;32;148;243m14.81512122\u001b[0m \u001b[38;2;32;148;243m100.65259476\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m269.43140031\u001b[0m \u001b[38;2;32;148;243m-78.92513987\u001b[0m  \u001b[38;2;32;148;243m32.34792115\u001b[0m \u001b[38;2;32;148;243m113.77488245\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.61992512\u001b[0m \u001b[38;2;32;148;243m-83.05632952\u001b[0m  \u001b[38;2;32;148;243m14.6020026\u001b[0m  \u001b[38;2;32;148;243m100.85210239\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.69159598\u001b[0m \u001b[38;2;32;148;243m-82.96117521\u001b[0m  \u001b[38;2;32;148;243m14.57372486\u001b[0m \u001b[38;2;32;148;243m100.81378112\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.77872241\u001b[0m \u001b[38;2;32;148;243m-82.85454899\u001b[0m  \u001b[38;2;32;148;243m14.56012068\u001b[0m \u001b[38;2;32;148;243m100.79105526\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.88195949\u001b[0m \u001b[38;2;32;148;243m-82.73377657\u001b[0m  \u001b[38;2;32;148;243m14.55859979\u001b[0m \u001b[38;2;32;148;243m100.78363819\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.8571183\u001b[0m  \u001b[38;2;32;148;243m-82.89666386\u001b[0m  \u001b[38;2;32;148;243m14.59964566\u001b[0m \u001b[38;2;32;148;243m100.7307771\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.84671938\u001b[0m \u001b[38;2;32;148;243m-83.04389711\u001b[0m  \u001b[38;2;32;148;243m14.65428118\u001b[0m \u001b[38;2;32;148;243m100.69242974\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.85183089\u001b[0m \u001b[38;2;32;148;243m-83.17870223\u001b[0m  \u001b[38;2;32;148;243m14.72263822\u001b[0m \u001b[38;2;32;148;243m100.6694879\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m250.87622229\u001b[0m \u001b[38;2;32;148;243m-83.30090252\u001b[0m  \u001b[38;2;32;148;243m14.80466478\u001b[0m \u001b[38;2;32;148;243m100.66222142\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09426074\u001b[0m \u001b[38;2;32;148;243m-0.03711928\u001b[0m \u001b[38;2;32;148;243m-0.0326606\u001b[0m  \u001b[38;2;32;148;243m-0.08823389\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18104865\u001b[0m \u001b[38;2;32;148;243m-0.0772465\u001b[0m  \u001b[38;2;32;148;243m-0.08440869\u001b[0m \u001b[38;2;32;148;243m-0.16768772\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.26725305\u001b[0m \u001b[38;2;32;148;243m-0.11500059\u001b[0m \u001b[38;2;32;148;243m-0.13683887\u001b[0m \u001b[38;2;32;148;243m-0.24755263\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35333206\u001b[0m \u001b[38;2;32;148;243m-0.15297115\u001b[0m \u001b[38;2;32;148;243m-0.18777202\u001b[0m \u001b[38;2;32;148;243m-0.32608469\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.26750458\u001b[0m \u001b[38;2;32;148;243m-0.11671591\u001b[0m \u001b[38;2;32;148;243m-0.13730289\u001b[0m \u001b[38;2;32;148;243m-0.24726853\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18067105\u001b[0m \u001b[38;2;32;148;243m-0.08127008\u001b[0m \u001b[38;2;32;148;243m-0.08631679\u001b[0m \u001b[38;2;32;148;243m-0.16710177\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09376843\u001b[0m \u001b[38;2;32;148;243m-0.04520733\u001b[0m \u001b[38;2;32;148;243m-0.03727259\u001b[0m \u001b[38;2;32;148;243m-0.08755653\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00941898\u001b[0m \u001b[38;2;32;148;243m-0.0087667\u001b[0m   \u001b[38;2;32;148;243m0.01045645\u001b[0m \u001b[38;2;32;148;243m-0.00962666\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09426074\u001b[0m \u001b[38;2;32;148;243m-0.03711928\u001b[0m \u001b[38;2;32;148;243m-0.0326606\u001b[0m  \u001b[38;2;32;148;243m-0.08823389\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18104865\u001b[0m \u001b[38;2;32;148;243m-0.0772465\u001b[0m  \u001b[38;2;32;148;243m-0.08440869\u001b[0m \u001b[38;2;32;148;243m-0.16768772\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.26725305\u001b[0m \u001b[38;2;32;148;243m-0.11500059\u001b[0m \u001b[38;2;32;148;243m-0.13683887\u001b[0m \u001b[38;2;32;148;243m-0.24755263\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35333206\u001b[0m \u001b[38;2;32;148;243m-0.15297115\u001b[0m \u001b[38;2;32;148;243m-0.18777202\u001b[0m \u001b[38;2;32;148;243m-0.32608469\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.08582748\u001b[0m \u001b[38;2;32;148;243m0.03625524\u001b[0m \u001b[38;2;32;148;243m0.05046912\u001b[0m \u001b[38;2;32;148;243m0.07881616\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.17266101\u001b[0m \u001b[38;2;32;148;243m0.07170107\u001b[0m \u001b[38;2;32;148;243m0.10145523\u001b[0m \u001b[38;2;32;148;243m0.15898292\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.25956363\u001b[0m \u001b[38;2;32;148;243m0.10776382\u001b[0m \u001b[38;2;32;148;243m0.15049943\u001b[0m \u001b[38;2;32;148;243m0.23852816\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.34391308\u001b[0m \u001b[38;2;32;148;243m0.14420444\u001b[0m \u001b[38;2;32;148;243m0.19822846\u001b[0m \u001b[38;2;32;148;243m0.31645803\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09426074\u001b[0m \u001b[38;2;32;148;243m-0.03711928\u001b[0m \u001b[38;2;32;148;243m-0.0326606\u001b[0m  \u001b[38;2;32;148;243m-0.08823389\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18104865\u001b[0m \u001b[38;2;32;148;243m-0.0772465\u001b[0m  \u001b[38;2;32;148;243m-0.08440869\u001b[0m \u001b[38;2;32;148;243m-0.16768772\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.26725305\u001b[0m \u001b[38;2;32;148;243m-0.11500059\u001b[0m \u001b[38;2;32;148;243m-0.13683887\u001b[0m \u001b[38;2;32;148;243m-0.24755263\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35333206\u001b[0m \u001b[38;2;32;148;243m-0.15297115\u001b[0m \u001b[38;2;32;148;243m-0.18777202\u001b[0m \u001b[38;2;32;148;243m-0.32608469\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.26750458\u001b[0m \u001b[38;2;32;148;243m-0.11671591\u001b[0m \u001b[38;2;32;148;243m-0.13730289\u001b[0m \u001b[38;2;32;148;243m-0.24726853\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18067105\u001b[0m \u001b[38;2;32;148;243m-0.08127008\u001b[0m \u001b[38;2;32;148;243m-0.08631679\u001b[0m \u001b[38;2;32;148;243m-0.16710177\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09376843\u001b[0m \u001b[38;2;32;148;243m-0.04520733\u001b[0m \u001b[38;2;32;148;243m-0.03727259\u001b[0m \u001b[38;2;32;148;243m-0.08755653\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00941898\u001b[0m \u001b[38;2;32;148;243m-0.0087667\u001b[0m   \u001b[38;2;32;148;243m0.01045645\u001b[0m \u001b[38;2;32;148;243m-0.00962666\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00941898\u001b[0m \u001b[38;2;32;148;243m-0.0087667\u001b[0m   \u001b[38;2;32;148;243m0.01045645\u001b[0m \u001b[38;2;32;148;243m-0.00962666\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.288034143291682e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00545839\u001b[0m  \u001b[38;2;32;148;243m0.00615163\u001b[0m  \u001b[38;2;32;148;243m0.0047064\u001b[0m   \u001b[38;2;32;148;243m0.00285683\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00169113\u001b[0m  \u001b[38;2;32;148;243m0.00022278\u001b[0m \u001b[38;2;32;148;243m-0.00285758\u001b[0m \u001b[38;2;32;148;243m-0.00260122\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04934804\u001b[0m  \u001b[38;2;32;148;243m0.00650095\u001b[0m \u001b[38;2;32;148;243m-0.08338556\u001b[0m \u001b[38;2;32;148;243m-0.07590503\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00654428\u001b[0m \u001b[38;2;32;148;243m0.00071274\u001b[0m \u001b[38;2;32;148;243m0.00170216\u001b[0m \u001b[38;2;32;148;243m0.00521421\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.24269016e-04\u001b[0m \u001b[38;2;32;148;243m2.44251559e-05\u001b[0m \u001b[38;2;32;148;243m5.83322748e-05\u001b[0m \u001b[38;2;32;148;243m1.78688118e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 15                                                                                          \n\n[07:57:23] TRAIN STEP: 16                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:23]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m242.09111141\u001b[0m \u001b[38;2;32;148;243m-167.78069176\u001b[0m  \u001b[38;2;32;148;243m-86.79127201\u001b[0m   \u001b[38;2;32;148;243m-1.71409733\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.42479069\u001b[0m \u001b[38;2;32;148;243m-170.8975103\u001b[0m  \u001b[38;2;32;148;243m-104.09194289\u001b[0m  \u001b[38;2;32;148;243m-15.06808349\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.32836168\u001b[0m \u001b[38;2;32;148;243m-171.01752667\u001b[0m \u001b[38;2;32;148;243m-104.26316404\u001b[0m  \u001b[38;2;32;148;243m-15.13329744\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.25220575\u001b[0m \u001b[38;2;32;148;243m-171.12311605\u001b[0m \u001b[38;2;32;148;243m-104.41971763\u001b[0m  \u001b[38;2;32;148;243m-15.18359855\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.19583803\u001b[0m \u001b[38;2;32;148;243m-171.21411865\u001b[0m \u001b[38;2;32;148;243m-104.56149024\u001b[0m  \u001b[38;2;32;148;243m-15.21926476\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.23732721\u001b[0m \u001b[38;2;32;148;243m-171.07503408\u001b[0m \u001b[38;2;32;148;243m-104.45847981\u001b[0m  \u001b[38;2;32;148;243m-15.15402874\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.2982538\u001b[0m  \u001b[38;2;32;148;243m-170.91796681\u001b[0m \u001b[38;2;32;148;243m-104.34035922\u001b[0m  \u001b[38;2;32;148;243m-15.07306938\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.37934147\u001b[0m \u001b[38;2;32;148;243m-170.74700095\u001b[0m \u001b[38;2;32;148;243m-104.20937461\u001b[0m  \u001b[38;2;32;148;243m-14.97519778\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.48054702\u001b[0m \u001b[38;2;32;148;243m-170.56258876\u001b[0m \u001b[38;2;32;148;243m-104.06378562\u001b[0m  \u001b[38;2;32;148;243m-14.86043875\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m242.09111141\u001b[0m \u001b[38;2;32;148;243m-167.78069176\u001b[0m  \u001b[38;2;32;148;243m-86.79127201\u001b[0m   \u001b[38;2;32;148;243m-1.71409733\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.52786528\u001b[0m \u001b[38;2;32;148;243m-170.83137805\u001b[0m \u001b[38;2;32;148;243m-104.0718157\u001b[0m   \u001b[38;2;32;148;243m-14.98056815\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.54494286\u001b[0m \u001b[38;2;32;148;243m-170.88452904\u001b[0m \u001b[38;2;32;148;243m-104.2145884\u001b[0m   \u001b[38;2;32;148;243m-14.96318368\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.58203094\u001b[0m \u001b[38;2;32;148;243m-170.92414762\u001b[0m \u001b[38;2;32;148;243m-104.34489498\u001b[0m  \u001b[38;2;32;148;243m-14.93017888\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.63913253\u001b[0m \u001b[38;2;32;148;243m-170.95000627\u001b[0m \u001b[38;2;32;148;243m-104.46195817\u001b[0m  \u001b[38;2;32;148;243m-14.8814643\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.56698162\u001b[0m \u001b[38;2;32;148;243m-170.87777937\u001b[0m \u001b[38;2;32;148;243m-104.38605005\u001b[0m  \u001b[38;2;32;148;243m-14.90105953\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.51387208\u001b[0m \u001b[38;2;32;148;243m-170.79101929\u001b[0m \u001b[38;2;32;148;243m-104.29603278\u001b[0m  \u001b[38;2;32;148;243m-14.90494681\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.48004487\u001b[0m \u001b[38;2;32;148;243m-170.6902614\u001b[0m  \u001b[38;2;32;148;243m-104.19119749\u001b[0m  \u001b[38;2;32;148;243m-14.89268621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m223.46577315\u001b[0m \u001b[38;2;32;148;243m-170.57526562\u001b[0m \u001b[38;2;32;148;243m-104.07214949\u001b[0m  \u001b[38;2;32;148;243m-14.86422353\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10307459\u001b[0m \u001b[38;2;32;148;243m-0.06613225\u001b[0m \u001b[38;2;32;148;243m-0.02012719\u001b[0m \u001b[38;2;32;148;243m-0.08751534\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21658118\u001b[0m \u001b[38;2;32;148;243m-0.13299763\u001b[0m \u001b[38;2;32;148;243m-0.04857564\u001b[0m \u001b[38;2;32;148;243m-0.17011376\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32982519\u001b[0m \u001b[38;2;32;148;243m-0.19896844\u001b[0m \u001b[38;2;32;148;243m-0.07482265\u001b[0m \u001b[38;2;32;148;243m-0.25341967\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.4432945\u001b[0m  \u001b[38;2;32;148;243m-0.26411238\u001b[0m \u001b[38;2;32;148;243m-0.09953207\u001b[0m \u001b[38;2;32;148;243m-0.33780046\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32965441\u001b[0m \u001b[38;2;32;148;243m-0.19725471\u001b[0m \u001b[38;2;32;148;243m-0.07242976\u001b[0m \u001b[38;2;32;148;243m-0.25296921\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21561828\u001b[0m \u001b[38;2;32;148;243m-0.12694752\u001b[0m \u001b[38;2;32;148;243m-0.04432644\u001b[0m \u001b[38;2;32;148;243m-0.16812257\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1007034\u001b[0m  \u001b[38;2;32;148;243m-0.05673955\u001b[0m \u001b[38;2;32;148;243m-0.01817712\u001b[0m \u001b[38;2;32;148;243m-0.08251156\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01477387\u001b[0m  \u001b[38;2;32;148;243m0.01267686\u001b[0m  \u001b[38;2;32;148;243m0.00836387\u001b[0m  \u001b[38;2;32;148;243m0.00378478\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10307459\u001b[0m \u001b[38;2;32;148;243m-0.06613225\u001b[0m \u001b[38;2;32;148;243m-0.02012719\u001b[0m \u001b[38;2;32;148;243m-0.08751534\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21658118\u001b[0m \u001b[38;2;32;148;243m-0.13299763\u001b[0m \u001b[38;2;32;148;243m-0.04857564\u001b[0m \u001b[38;2;32;148;243m-0.17011376\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32982519\u001b[0m \u001b[38;2;32;148;243m-0.19896844\u001b[0m \u001b[38;2;32;148;243m-0.07482265\u001b[0m \u001b[38;2;32;148;243m-0.25341967\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.4432945\u001b[0m  \u001b[38;2;32;148;243m-0.26411238\u001b[0m \u001b[38;2;32;148;243m-0.09953207\u001b[0m \u001b[38;2;32;148;243m-0.33780046\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.1136401\u001b[0m  \u001b[38;2;32;148;243m0.06685767\u001b[0m \u001b[38;2;32;148;243m0.02710231\u001b[0m \u001b[38;2;32;148;243m0.08483125\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22767622\u001b[0m \u001b[38;2;32;148;243m0.13716486\u001b[0m \u001b[38;2;32;148;243m0.05520562\u001b[0m \u001b[38;2;32;148;243m0.1696779\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.34259111\u001b[0m \u001b[38;2;32;148;243m0.20737283\u001b[0m \u001b[38;2;32;148;243m0.08135495\u001b[0m \u001b[38;2;32;148;243m0.2552889\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.45806837\u001b[0m \u001b[38;2;32;148;243m0.27678924\u001b[0m \u001b[38;2;32;148;243m0.10789594\u001b[0m \u001b[38;2;32;148;243m0.34158524\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10307459\u001b[0m \u001b[38;2;32;148;243m-0.06613225\u001b[0m \u001b[38;2;32;148;243m-0.02012719\u001b[0m \u001b[38;2;32;148;243m-0.08751534\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21658118\u001b[0m \u001b[38;2;32;148;243m-0.13299763\u001b[0m \u001b[38;2;32;148;243m-0.04857564\u001b[0m \u001b[38;2;32;148;243m-0.17011376\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32982519\u001b[0m \u001b[38;2;32;148;243m-0.19896844\u001b[0m \u001b[38;2;32;148;243m-0.07482265\u001b[0m \u001b[38;2;32;148;243m-0.25341967\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.4432945\u001b[0m  \u001b[38;2;32;148;243m-0.26411238\u001b[0m \u001b[38;2;32;148;243m-0.09953207\u001b[0m \u001b[38;2;32;148;243m-0.33780046\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32965441\u001b[0m \u001b[38;2;32;148;243m-0.19725471\u001b[0m \u001b[38;2;32;148;243m-0.07242976\u001b[0m \u001b[38;2;32;148;243m-0.25296921\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21561828\u001b[0m \u001b[38;2;32;148;243m-0.12694752\u001b[0m \u001b[38;2;32;148;243m-0.04432644\u001b[0m \u001b[38;2;32;148;243m-0.16812257\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1007034\u001b[0m  \u001b[38;2;32;148;243m-0.05673955\u001b[0m \u001b[38;2;32;148;243m-0.01817712\u001b[0m \u001b[38;2;32;148;243m-0.08251156\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01477387\u001b[0m  \u001b[38;2;32;148;243m0.01267686\u001b[0m  \u001b[38;2;32;148;243m0.00836387\u001b[0m  \u001b[38;2;32;148;243m0.00378478\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01477387\u001b[0m \u001b[38;2;32;148;243m0.01267686\u001b[0m \u001b[38;2;32;148;243m0.00836387\u001b[0m \u001b[38;2;32;148;243m0.00378478\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.286711824528633e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00537043\u001b[0m  \u001b[38;2;32;148;243m0.00654723\u001b[0m  \u001b[38;2;32;148;243m0.0046871\u001b[0m   \u001b[38;2;32;148;243m0.00286848\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0014679\u001b[0m   \u001b[38;2;32;148;243m0.00035176\u001b[0m \u001b[38;2;32;148;243m-0.00312108\u001b[0m \u001b[38;2;32;148;243m-0.00251439\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04283408\u001b[0m  \u001b[38;2;32;148;243m0.01026443\u001b[0m \u001b[38;2;32;148;243m-0.09107459\u001b[0m \u001b[38;2;32;148;243m-0.07337109\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00142679\u001b[0m \u001b[38;2;32;148;243m0.00507351\u001b[0m \u001b[38;2;32;148;243m0.00434687\u001b[0m \u001b[38;2;32;148;243m0.00288916\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4.88952829e-05\u001b[0m \u001b[38;2;32;148;243m1.73866583e-04\u001b[0m \u001b[38;2;32;148;243m1.48964780e-04\u001b[0m \u001b[38;2;32;148;243m9.90099206e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 17                                                                                          \n\n[07:57:24] TRAIN STEP: 18                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:24]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m51.81364669\u001b[0m \u001b[38;2;32;148;243m-276.10671185\u001b[0m  \u001b[38;2;32;148;243m-98.60682104\u001b[0m  \u001b[38;2;32;148;243m-25.36370694\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.66548524\u001b[0m \u001b[38;2;32;148;243m-279.85187586\u001b[0m \u001b[38;2;32;148;243m-116.04757011\u001b[0m  \u001b[38;2;32;148;243m-37.27420888\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.52539767\u001b[0m \u001b[38;2;32;148;243m-279.95203661\u001b[0m \u001b[38;2;32;148;243m-116.18756296\u001b[0m  \u001b[38;2;32;148;243m-37.35219963\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.40266348\u001b[0m \u001b[38;2;32;148;243m-280.0364063\u001b[0m  \u001b[38;2;32;148;243m-116.31266057\u001b[0m  \u001b[38;2;32;148;243m-37.41251265\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.2975883\u001b[0m  \u001b[38;2;32;148;243m-280.10401611\u001b[0m \u001b[38;2;32;148;243m-116.42371203\u001b[0m  \u001b[38;2;32;148;243m-37.45611136\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.49407266\u001b[0m \u001b[38;2;32;148;243m-279.90120261\u001b[0m \u001b[38;2;32;148;243m-116.42109307\u001b[0m  \u001b[38;2;32;148;243m-37.38052488\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.70561809\u001b[0m \u001b[38;2;32;148;243m-279.68370345\u001b[0m \u001b[38;2;32;148;243m-116.40390229\u001b[0m  \u001b[38;2;32;148;243m-37.28787851\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.9320363\u001b[0m  \u001b[38;2;32;148;243m-279.45238646\u001b[0m \u001b[38;2;32;148;243m-116.3725013\u001b[0m   \u001b[38;2;32;148;243m-37.17660581\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m33.17450914\u001b[0m \u001b[38;2;32;148;243m-279.20755491\u001b[0m \u001b[38;2;32;148;243m-116.32766274\u001b[0m  \u001b[38;2;32;148;243m-37.04654594\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m51.81364669\u001b[0m \u001b[38;2;32;148;243m-276.10671185\u001b[0m  \u001b[38;2;32;148;243m-98.60682104\u001b[0m  \u001b[38;2;32;148;243m-25.36370694\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.76189104\u001b[0m \u001b[38;2;32;148;243m-279.82955433\u001b[0m \u001b[38;2;32;148;243m-116.02372562\u001b[0m  \u001b[38;2;32;148;243m-37.18231376\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.71911899\u001b[0m \u001b[38;2;32;148;243m-279.90477912\u001b[0m \u001b[38;2;32;148;243m-116.13872567\u001b[0m  \u001b[38;2;32;148;243m-37.17473898\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.693671\u001b[0m   \u001b[38;2;32;148;243m-279.96520078\u001b[0m \u001b[38;2;32;148;243m-116.2393825\u001b[0m   \u001b[38;2;32;148;243m-37.1508859\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.68587057\u001b[0m \u001b[38;2;32;148;243m-280.00999821\u001b[0m \u001b[38;2;32;148;243m-116.32586348\u001b[0m  \u001b[38;2;32;148;243m-37.11121438\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.78485093\u001b[0m \u001b[38;2;32;148;243m-279.8297702\u001b[0m  \u001b[38;2;32;148;243m-116.34805175\u001b[0m  \u001b[38;2;32;148;243m-37.1188895\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m32.89988208\u001b[0m \u001b[38;2;32;148;243m-279.63562624\u001b[0m \u001b[38;2;32;148;243m-116.35767199\u001b[0m  \u001b[38;2;32;148;243m-37.11027228\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m33.03055209\u001b[0m \u001b[38;2;32;148;243m-279.42760771\u001b[0m \u001b[38;2;32;148;243m-116.3539882\u001b[0m   \u001b[38;2;32;148;243m-37.08474785\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m33.17727777\u001b[0m \u001b[38;2;32;148;243m-279.20475654\u001b[0m \u001b[38;2;32;148;243m-116.33262468\u001b[0m  \u001b[38;2;32;148;243m-37.04216334\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0964058\u001b[0m  \u001b[38;2;32;148;243m-0.02232153\u001b[0m \u001b[38;2;32;148;243m-0.02384449\u001b[0m \u001b[38;2;32;148;243m-0.09189513\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19372132\u001b[0m \u001b[38;2;32;148;243m-0.04725749\u001b[0m \u001b[38;2;32;148;243m-0.04883729\u001b[0m \u001b[38;2;32;148;243m-0.17746065\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29100752\u001b[0m \u001b[38;2;32;148;243m-0.07120551\u001b[0m \u001b[38;2;32;148;243m-0.07327806\u001b[0m \u001b[38;2;32;148;243m-0.26162675\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.38828227\u001b[0m \u001b[38;2;32;148;243m-0.0940179\u001b[0m  \u001b[38;2;32;148;243m-0.09784855\u001b[0m \u001b[38;2;32;148;243m-0.34489698\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29077828\u001b[0m \u001b[38;2;32;148;243m-0.07143241\u001b[0m \u001b[38;2;32;148;243m-0.07304131\u001b[0m \u001b[38;2;32;148;243m-0.26163538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19426399\u001b[0m \u001b[38;2;32;148;243m-0.0480772\u001b[0m  \u001b[38;2;32;148;243m-0.0462303\u001b[0m  \u001b[38;2;32;148;243m-0.17760622\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09851579\u001b[0m \u001b[38;2;32;148;243m-0.02477875\u001b[0m \u001b[38;2;32;148;243m-0.0185131\u001b[0m  \u001b[38;2;32;148;243m-0.09185795\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00276863\u001b[0m \u001b[38;2;32;148;243m-0.00279837\u001b[0m  \u001b[38;2;32;148;243m0.00496193\u001b[0m \u001b[38;2;32;148;243m-0.0043826\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0964058\u001b[0m  \u001b[38;2;32;148;243m-0.02232153\u001b[0m \u001b[38;2;32;148;243m-0.02384449\u001b[0m \u001b[38;2;32;148;243m-0.09189513\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19372132\u001b[0m \u001b[38;2;32;148;243m-0.04725749\u001b[0m \u001b[38;2;32;148;243m-0.04883729\u001b[0m \u001b[38;2;32;148;243m-0.17746065\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29100752\u001b[0m \u001b[38;2;32;148;243m-0.07120551\u001b[0m \u001b[38;2;32;148;243m-0.07327806\u001b[0m \u001b[38;2;32;148;243m-0.26162675\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.38828227\u001b[0m \u001b[38;2;32;148;243m-0.0940179\u001b[0m  \u001b[38;2;32;148;243m-0.09784855\u001b[0m \u001b[38;2;32;148;243m-0.34489698\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.09750399\u001b[0m \u001b[38;2;32;148;243m0.02258548\u001b[0m \u001b[38;2;32;148;243m0.02480724\u001b[0m \u001b[38;2;32;148;243m0.0832616\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19401828\u001b[0m \u001b[38;2;32;148;243m0.04594069\u001b[0m \u001b[38;2;32;148;243m0.05161825\u001b[0m \u001b[38;2;32;148;243m0.16729076\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.28976648\u001b[0m \u001b[38;2;32;148;243m0.06923915\u001b[0m \u001b[38;2;32;148;243m0.07933545\u001b[0m \u001b[38;2;32;148;243m0.25303903\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.38551364\u001b[0m \u001b[38;2;32;148;243m0.09121953\u001b[0m \u001b[38;2;32;148;243m0.10281049\u001b[0m \u001b[38;2;32;148;243m0.34051439\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0964058\u001b[0m  \u001b[38;2;32;148;243m-0.02232153\u001b[0m \u001b[38;2;32;148;243m-0.02384449\u001b[0m \u001b[38;2;32;148;243m-0.09189513\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19372132\u001b[0m \u001b[38;2;32;148;243m-0.04725749\u001b[0m \u001b[38;2;32;148;243m-0.04883729\u001b[0m \u001b[38;2;32;148;243m-0.17746065\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29100752\u001b[0m \u001b[38;2;32;148;243m-0.07120551\u001b[0m \u001b[38;2;32;148;243m-0.07327806\u001b[0m \u001b[38;2;32;148;243m-0.26162675\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.38828227\u001b[0m \u001b[38;2;32;148;243m-0.0940179\u001b[0m  \u001b[38;2;32;148;243m-0.09784855\u001b[0m \u001b[38;2;32;148;243m-0.34489698\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29077828\u001b[0m \u001b[38;2;32;148;243m-0.07143241\u001b[0m \u001b[38;2;32;148;243m-0.07304131\u001b[0m \u001b[38;2;32;148;243m-0.26163538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19426399\u001b[0m \u001b[38;2;32;148;243m-0.0480772\u001b[0m  \u001b[38;2;32;148;243m-0.0462303\u001b[0m  \u001b[38;2;32;148;243m-0.17760622\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09851579\u001b[0m \u001b[38;2;32;148;243m-0.02477875\u001b[0m \u001b[38;2;32;148;243m-0.0185131\u001b[0m  \u001b[38;2;32;148;243m-0.09185795\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00276863\u001b[0m \u001b[38;2;32;148;243m-0.00279837\u001b[0m  \u001b[38;2;32;148;243m0.00496193\u001b[0m \u001b[38;2;32;148;243m-0.0043826\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00276863\u001b[0m \u001b[38;2;32;148;243m-0.00279837\u001b[0m  \u001b[38;2;32;148;243m0.00496193\u001b[0m \u001b[38;2;32;148;243m-0.0043826\u001b[0m \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.167386663631978e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00517545\u001b[0m  \u001b[38;2;32;148;243m0.00667307\u001b[0m  \u001b[38;2;32;148;243m0.00507462\u001b[0m  \u001b[38;2;32;148;243m0.00313774\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00132024\u001b[0m  \u001b[38;2;32;148;243m0.00044875\u001b[0m \u001b[38;2;32;148;243m-0.002744\u001b[0m   \u001b[38;2;32;148;243m-0.00245262\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.03852533\u001b[0m  \u001b[38;2;32;148;243m0.01309472\u001b[0m \u001b[38;2;32;148;243m-0.08007142\u001b[0m \u001b[38;2;32;148;243m-0.0715688\u001b[0m \u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m7.28081614e-03\u001b[0m \u001b[38;2;32;148;243m6.66048468e-06\u001b[0m \u001b[38;2;32;148;243m4.84043390e-03\u001b[0m \u001b[38;2;32;148;243m3.36405003e-03\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.49509636e-04\u001b[0m \u001b[38;2;32;148;243m2.28251212e-07\u001b[0m \u001b[38;2;32;148;243m1.65879055e-04\u001b[0m \u001b[38;2;32;148;243m1.15284177e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 19                                                                                          \n\n[07:57:25] TRAIN STEP: 20                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:25]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m123.0916713\u001b[0m  \u001b[38;2;32;148;243m-368.39530166\u001b[0m   \u001b[38;2;32;148;243m33.58539175\u001b[0m  \u001b[38;2;32;148;243m-34.38175277\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.52159903\u001b[0m \u001b[38;2;32;148;243m-371.9245264\u001b[0m    \u001b[38;2;32;148;243m16.25876955\u001b[0m  \u001b[38;2;32;148;243m-46.83411547\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.49818912\u001b[0m \u001b[38;2;32;148;243m-371.99175699\u001b[0m   \u001b[38;2;32;148;243m16.25033885\u001b[0m  \u001b[38;2;32;148;243m-46.90479335\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.49279164\u001b[0m \u001b[38;2;32;148;243m-372.04895247\u001b[0m   \u001b[38;2;32;148;243m16.25593112\u001b[0m  \u001b[38;2;32;148;243m-46.95916726\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.5056771\u001b[0m  \u001b[38;2;32;148;243m-372.0929779\u001b[0m    \u001b[38;2;32;148;243m16.27542596\u001b[0m  \u001b[38;2;32;148;243m-46.99594976\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.58569049\u001b[0m \u001b[38;2;32;148;243m-372.03068088\u001b[0m   \u001b[38;2;32;148;243m16.33807126\u001b[0m  \u001b[38;2;32;148;243m-46.87584595\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.68441208\u001b[0m \u001b[38;2;32;148;243m-371.95640792\u001b[0m   \u001b[38;2;32;148;243m16.41538247\u001b[0m  \u001b[38;2;32;148;243m-46.74498565\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.80248382\u001b[0m \u001b[38;2;32;148;243m-371.86939321\u001b[0m   \u001b[38;2;32;148;243m16.50716943\u001b[0m  \u001b[38;2;32;148;243m-46.60248449\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.94033489\u001b[0m \u001b[38;2;32;148;243m-371.76738451\u001b[0m   \u001b[38;2;32;148;243m16.61384277\u001b[0m  \u001b[38;2;32;148;243m-46.44620817\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m123.0916713\u001b[0m  \u001b[38;2;32;148;243m-368.39530166\u001b[0m   \u001b[38;2;32;148;243m33.58539175\u001b[0m  \u001b[38;2;32;148;243m-34.38175277\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.62409357\u001b[0m \u001b[38;2;32;148;243m-371.88212063\u001b[0m   \u001b[38;2;32;148;243m16.27096835\u001b[0m  \u001b[38;2;32;148;243m-46.74644487\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.71044289\u001b[0m \u001b[38;2;32;148;243m-371.89183418\u001b[0m   \u001b[38;2;32;148;243m16.2822088\u001b[0m   \u001b[38;2;32;148;243m-46.73869286\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.81537939\u001b[0m \u001b[38;2;32;148;243m-371.88864557\u001b[0m   \u001b[38;2;32;148;243m16.30635963\u001b[0m  \u001b[38;2;32;148;243m-46.71547364\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.93916614\u001b[0m \u001b[38;2;32;148;243m-371.8720773\u001b[0m    \u001b[38;2;32;148;243m16.34372148\u001b[0m  \u001b[38;2;32;148;243m-46.6760762\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.90804543\u001b[0m \u001b[38;2;32;148;243m-371.87005391\u001b[0m   \u001b[38;2;32;148;243m16.38865795\u001b[0m  \u001b[38;2;32;148;243m-46.63093433\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.89474182\u001b[0m \u001b[38;2;32;148;243m-371.85431278\u001b[0m   \u001b[38;2;32;148;243m16.44826651\u001b[0m  \u001b[38;2;32;148;243m-46.57274808\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.90017294\u001b[0m \u001b[38;2;32;148;243m-371.82514128\u001b[0m   \u001b[38;2;32;148;243m16.52183202\u001b[0m  \u001b[38;2;32;148;243m-46.50121273\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m103.92583081\u001b[0m \u001b[38;2;32;148;243m-371.78192182\u001b[0m   \u001b[38;2;32;148;243m16.61100638\u001b[0m  \u001b[38;2;32;148;243m-46.4154334\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10249453\u001b[0m \u001b[38;2;32;148;243m-0.04240577\u001b[0m \u001b[38;2;32;148;243m-0.0121988\u001b[0m  \u001b[38;2;32;148;243m-0.0876706\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21225377\u001b[0m \u001b[38;2;32;148;243m-0.09992281\u001b[0m \u001b[38;2;32;148;243m-0.03186996\u001b[0m \u001b[38;2;32;148;243m-0.16610049\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32258775\u001b[0m \u001b[38;2;32;148;243m-0.1603069\u001b[0m  \u001b[38;2;32;148;243m-0.05042851\u001b[0m \u001b[38;2;32;148;243m-0.24369362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43348904\u001b[0m \u001b[38;2;32;148;243m-0.2209006\u001b[0m  \u001b[38;2;32;148;243m-0.06829553\u001b[0m \u001b[38;2;32;148;243m-0.31987357\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32235494\u001b[0m \u001b[38;2;32;148;243m-0.16062696\u001b[0m \u001b[38;2;32;148;243m-0.05058669\u001b[0m \u001b[38;2;32;148;243m-0.24491162\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21032974\u001b[0m \u001b[38;2;32;148;243m-0.10209513\u001b[0m \u001b[38;2;32;148;243m-0.03288404\u001b[0m \u001b[38;2;32;148;243m-0.17223757\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09768913\u001b[0m \u001b[38;2;32;148;243m-0.04425193\u001b[0m \u001b[38;2;32;148;243m-0.01466259\u001b[0m \u001b[38;2;32;148;243m-0.10127176\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01450408\u001b[0m  \u001b[38;2;32;148;243m0.01453731\u001b[0m  \u001b[38;2;32;148;243m0.0028364\u001b[0m  \u001b[38;2;32;148;243m-0.03077477\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10249453\u001b[0m \u001b[38;2;32;148;243m-0.04240577\u001b[0m \u001b[38;2;32;148;243m-0.0121988\u001b[0m  \u001b[38;2;32;148;243m-0.0876706\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21225377\u001b[0m \u001b[38;2;32;148;243m-0.09992281\u001b[0m \u001b[38;2;32;148;243m-0.03186996\u001b[0m \u001b[38;2;32;148;243m-0.16610049\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32258775\u001b[0m \u001b[38;2;32;148;243m-0.1603069\u001b[0m  \u001b[38;2;32;148;243m-0.05042851\u001b[0m \u001b[38;2;32;148;243m-0.24369362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43348904\u001b[0m \u001b[38;2;32;148;243m-0.2209006\u001b[0m  \u001b[38;2;32;148;243m-0.06829553\u001b[0m \u001b[38;2;32;148;243m-0.31987357\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11113411\u001b[0m \u001b[38;2;32;148;243m0.06027364\u001b[0m \u001b[38;2;32;148;243m0.01770883\u001b[0m \u001b[38;2;32;148;243m0.07496195\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.2231593\u001b[0m  \u001b[38;2;32;148;243m0.11880547\u001b[0m \u001b[38;2;32;148;243m0.03541149\u001b[0m \u001b[38;2;32;148;243m0.147636\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33579992\u001b[0m \u001b[38;2;32;148;243m0.17664867\u001b[0m \u001b[38;2;32;148;243m0.05363294\u001b[0m \u001b[38;2;32;148;243m0.2186018\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.44799312\u001b[0m \u001b[38;2;32;148;243m0.23543791\u001b[0m \u001b[38;2;32;148;243m0.07113192\u001b[0m \u001b[38;2;32;148;243m0.2890988\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10249453\u001b[0m \u001b[38;2;32;148;243m-0.04240577\u001b[0m \u001b[38;2;32;148;243m-0.0121988\u001b[0m  \u001b[38;2;32;148;243m-0.0876706\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21225377\u001b[0m \u001b[38;2;32;148;243m-0.09992281\u001b[0m \u001b[38;2;32;148;243m-0.03186996\u001b[0m \u001b[38;2;32;148;243m-0.16610049\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32258775\u001b[0m \u001b[38;2;32;148;243m-0.1603069\u001b[0m  \u001b[38;2;32;148;243m-0.05042851\u001b[0m \u001b[38;2;32;148;243m-0.24369362\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43348904\u001b[0m \u001b[38;2;32;148;243m-0.2209006\u001b[0m  \u001b[38;2;32;148;243m-0.06829553\u001b[0m \u001b[38;2;32;148;243m-0.31987357\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32235494\u001b[0m \u001b[38;2;32;148;243m-0.16062696\u001b[0m \u001b[38;2;32;148;243m-0.05058669\u001b[0m \u001b[38;2;32;148;243m-0.24491162\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21032974\u001b[0m \u001b[38;2;32;148;243m-0.10209513\u001b[0m \u001b[38;2;32;148;243m-0.03288404\u001b[0m \u001b[38;2;32;148;243m-0.17223757\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09768913\u001b[0m \u001b[38;2;32;148;243m-0.04425193\u001b[0m \u001b[38;2;32;148;243m-0.01466259\u001b[0m \u001b[38;2;32;148;243m-0.10127176\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01450408\u001b[0m  \u001b[38;2;32;148;243m0.01453731\u001b[0m  \u001b[38;2;32;148;243m0.0028364\u001b[0m  \u001b[38;2;32;148;243m-0.03077477\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01450408\u001b[0m  \u001b[38;2;32;148;243m0.01453731\u001b[0m  \u001b[38;2;32;148;243m0.0028364\u001b[0m  \u001b[38;2;32;148;243m-0.03077477\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.258356095911575e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00516376\u001b[0m  \u001b[38;2;32;148;243m0.00676524\u001b[0m  \u001b[38;2;32;148;243m0.00537446\u001b[0m  \u001b[38;2;32;148;243m0.00314183\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00137951\u001b[0m  \u001b[38;2;32;148;243m0.00029458\u001b[0m \u001b[38;2;32;148;243m-0.00284336\u001b[0m \u001b[38;2;32;148;243m-0.00246712\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0402548\u001b[0m   \u001b[38;2;32;148;243m0.00859586\u001b[0m \u001b[38;2;32;148;243m-0.08297054\u001b[0m \u001b[38;2;32;148;243m-0.07199194\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01094545\u001b[0m \u001b[38;2;32;148;243m0.00412099\u001b[0m \u001b[38;2;32;148;243m0.00106453\u001b[0m \u001b[38;2;32;148;243m0.00203444\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m3.75094787e-04\u001b[0m \u001b[38;2;32;148;243m1.41224095e-04\u001b[0m \u001b[38;2;32;148;243m3.64808917e-05\u001b[0m \u001b[38;2;32;148;243m6.97190191e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 21                                                                                          \n\n[07:57:26] TRAIN STEP: 22                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:26]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m262.81068213\u001b[0m \u001b[38;2;32;148;243m-221.53230965\u001b[0m  \u001b[38;2;32;148;243m-85.89856373\u001b[0m \u001b[38;2;32;148;243m-124.36697529\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.0466881\u001b[0m  \u001b[38;2;32;148;243m-225.56388349\u001b[0m \u001b[38;2;32;148;243m-103.67656562\u001b[0m \u001b[38;2;32;148;243m-137.33725402\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m243.97921278\u001b[0m \u001b[38;2;32;148;243m-225.5258324\u001b[0m  \u001b[38;2;32;148;243m-103.81282295\u001b[0m \u001b[38;2;32;148;243m-137.34152247\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m243.9295502\u001b[0m  \u001b[38;2;32;148;243m-225.4739091\u001b[0m  \u001b[38;2;32;148;243m-103.93755735\u001b[0m \u001b[38;2;32;148;243m-137.33042661\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m243.89742265\u001b[0m \u001b[38;2;32;148;243m-225.40839491\u001b[0m \u001b[38;2;32;148;243m-104.04975512\u001b[0m \u001b[38;2;32;148;243m-137.30418556\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.13875959\u001b[0m \u001b[38;2;32;148;243m-225.26466851\u001b[0m \u001b[38;2;32;148;243m-103.9470228\u001b[0m  \u001b[38;2;32;148;243m-137.18562375\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.39817786\u001b[0m \u001b[38;2;32;148;243m-225.10681087\u001b[0m \u001b[38;2;32;148;243m-103.83079731\u001b[0m \u001b[38;2;32;148;243m-137.05137395\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.67516855\u001b[0m \u001b[38;2;32;148;243m-224.93451782\u001b[0m \u001b[38;2;32;148;243m-103.70118309\u001b[0m \u001b[38;2;32;148;243m-136.90126371\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.97020268\u001b[0m \u001b[38;2;32;148;243m-224.74824293\u001b[0m \u001b[38;2;32;148;243m-103.55778437\u001b[0m \u001b[38;2;32;148;243m-136.73499005\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m262.81068213\u001b[0m \u001b[38;2;32;148;243m-221.53230965\u001b[0m  \u001b[38;2;32;148;243m-85.89856373\u001b[0m \u001b[38;2;32;148;243m-124.36697529\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.14750674\u001b[0m \u001b[38;2;32;148;243m-225.54050097\u001b[0m \u001b[38;2;32;148;243m-103.65166962\u001b[0m \u001b[38;2;32;148;243m-137.2466387\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.18664367\u001b[0m \u001b[38;2;32;148;243m-225.48139629\u001b[0m \u001b[38;2;32;148;243m-103.75803865\u001b[0m \u001b[38;2;32;148;243m-137.16439118\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.24333905\u001b[0m \u001b[38;2;32;148;243m-225.40797576\u001b[0m \u001b[38;2;32;148;243m-103.85609319\u001b[0m \u001b[38;2;32;148;243m-137.06719523\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.31720171\u001b[0m \u001b[38;2;32;148;243m-225.31967898\u001b[0m \u001b[38;2;32;148;243m-103.94353926\u001b[0m \u001b[38;2;32;148;243m-136.95526835\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.45239498\u001b[0m \u001b[38;2;32;148;243m-225.19812353\u001b[0m \u001b[38;2;32;148;243m-103.86575155\u001b[0m \u001b[38;2;32;148;243m-136.9220462\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.60599805\u001b[0m \u001b[38;2;32;148;243m-225.06183681\u001b[0m \u001b[38;2;32;148;243m-103.77287375\u001b[0m \u001b[38;2;32;148;243m-136.87291166\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.77792238\u001b[0m \u001b[38;2;32;148;243m-224.91099768\u001b[0m \u001b[38;2;32;148;243m-103.66528316\u001b[0m \u001b[38;2;32;148;243m-136.80800178\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m244.96821729\u001b[0m \u001b[38;2;32;148;243m-224.74552135\u001b[0m \u001b[38;2;32;148;243m-103.54270102\u001b[0m \u001b[38;2;32;148;243m-136.72752315\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10081864\u001b[0m \u001b[38;2;32;148;243m-0.02338253\u001b[0m \u001b[38;2;32;148;243m-0.024896\u001b[0m   \u001b[38;2;32;148;243m-0.09061532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20743089\u001b[0m \u001b[38;2;32;148;243m-0.04443612\u001b[0m \u001b[38;2;32;148;243m-0.0547843\u001b[0m  \u001b[38;2;32;148;243m-0.17713129\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31378886\u001b[0m \u001b[38;2;32;148;243m-0.06593334\u001b[0m \u001b[38;2;32;148;243m-0.08146416\u001b[0m \u001b[38;2;32;148;243m-0.26323138\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41977907\u001b[0m \u001b[38;2;32;148;243m-0.08871593\u001b[0m \u001b[38;2;32;148;243m-0.10621586\u001b[0m \u001b[38;2;32;148;243m-0.34891721\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3136354\u001b[0m  \u001b[38;2;32;148;243m-0.06654498\u001b[0m \u001b[38;2;32;148;243m-0.08127125\u001b[0m \u001b[38;2;32;148;243m-0.26357756\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20782019\u001b[0m \u001b[38;2;32;148;243m-0.04497407\u001b[0m \u001b[38;2;32;148;243m-0.05792356\u001b[0m \u001b[38;2;32;148;243m-0.17846229\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10275383\u001b[0m \u001b[38;2;32;148;243m-0.02352013\u001b[0m \u001b[38;2;32;148;243m-0.03589992\u001b[0m \u001b[38;2;32;148;243m-0.09326193\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00198538\u001b[0m \u001b[38;2;32;148;243m-0.00272157\u001b[0m \u001b[38;2;32;148;243m-0.01508335\u001b[0m \u001b[38;2;32;148;243m-0.0074669\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10081864\u001b[0m \u001b[38;2;32;148;243m-0.02338253\u001b[0m \u001b[38;2;32;148;243m-0.024896\u001b[0m   \u001b[38;2;32;148;243m-0.09061532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20743089\u001b[0m \u001b[38;2;32;148;243m-0.04443612\u001b[0m \u001b[38;2;32;148;243m-0.0547843\u001b[0m  \u001b[38;2;32;148;243m-0.17713129\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31378886\u001b[0m \u001b[38;2;32;148;243m-0.06593334\u001b[0m \u001b[38;2;32;148;243m-0.08146416\u001b[0m \u001b[38;2;32;148;243m-0.26323138\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41977907\u001b[0m \u001b[38;2;32;148;243m-0.08871593\u001b[0m \u001b[38;2;32;148;243m-0.10621586\u001b[0m \u001b[38;2;32;148;243m-0.34891721\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10614367\u001b[0m \u001b[38;2;32;148;243m0.02217095\u001b[0m \u001b[38;2;32;148;243m0.02494461\u001b[0m \u001b[38;2;32;148;243m0.08533966\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21195887\u001b[0m \u001b[38;2;32;148;243m0.04374187\u001b[0m \u001b[38;2;32;148;243m0.0482923\u001b[0m  \u001b[38;2;32;148;243m0.17045493\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.31702524\u001b[0m \u001b[38;2;32;148;243m0.0651958\u001b[0m  \u001b[38;2;32;148;243m0.07031594\u001b[0m \u001b[38;2;32;148;243m0.25565528\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.42176445\u001b[0m \u001b[38;2;32;148;243m0.08599436\u001b[0m \u001b[38;2;32;148;243m0.09113251\u001b[0m \u001b[38;2;32;148;243m0.34145031\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10081864\u001b[0m \u001b[38;2;32;148;243m-0.02338253\u001b[0m \u001b[38;2;32;148;243m-0.024896\u001b[0m   \u001b[38;2;32;148;243m-0.09061532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20743089\u001b[0m \u001b[38;2;32;148;243m-0.04443612\u001b[0m \u001b[38;2;32;148;243m-0.0547843\u001b[0m  \u001b[38;2;32;148;243m-0.17713129\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31378886\u001b[0m \u001b[38;2;32;148;243m-0.06593334\u001b[0m \u001b[38;2;32;148;243m-0.08146416\u001b[0m \u001b[38;2;32;148;243m-0.26323138\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41977907\u001b[0m \u001b[38;2;32;148;243m-0.08871593\u001b[0m \u001b[38;2;32;148;243m-0.10621586\u001b[0m \u001b[38;2;32;148;243m-0.34891721\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3136354\u001b[0m  \u001b[38;2;32;148;243m-0.06654498\u001b[0m \u001b[38;2;32;148;243m-0.08127125\u001b[0m \u001b[38;2;32;148;243m-0.26357756\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20782019\u001b[0m \u001b[38;2;32;148;243m-0.04497407\u001b[0m \u001b[38;2;32;148;243m-0.05792356\u001b[0m \u001b[38;2;32;148;243m-0.17846229\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10275383\u001b[0m \u001b[38;2;32;148;243m-0.02352013\u001b[0m \u001b[38;2;32;148;243m-0.03589992\u001b[0m \u001b[38;2;32;148;243m-0.09326193\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00198538\u001b[0m \u001b[38;2;32;148;243m-0.00272157\u001b[0m \u001b[38;2;32;148;243m-0.01508335\u001b[0m \u001b[38;2;32;148;243m-0.0074669\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00198538\u001b[0m \u001b[38;2;32;148;243m-0.00272157\u001b[0m \u001b[38;2;32;148;243m-0.01508335\u001b[0m \u001b[38;2;32;148;243m-0.0074669\u001b[0m \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.203359341330946e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00490634\u001b[0m  \u001b[38;2;32;148;243m0.00699433\u001b[0m  \u001b[38;2;32;148;243m0.00557357\u001b[0m  \u001b[38;2;32;148;243m0.00328262\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00137312\u001b[0m  \u001b[38;2;32;148;243m0.00036101\u001b[0m \u001b[38;2;32;148;243m-0.0028145\u001b[0m  \u001b[38;2;32;148;243m-0.00263894\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04006824\u001b[0m  \u001b[38;2;32;148;243m0.01053447\u001b[0m \u001b[38;2;32;148;243m-0.0821286\u001b[0m  \u001b[38;2;32;148;243m-0.07700553\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00260182\u001b[0m \u001b[38;2;32;148;243m0.00359335\u001b[0m \u001b[38;2;32;148;243m0.00417618\u001b[0m \u001b[38;2;32;148;243m0.00081342\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m8.91629785e-05\u001b[0m \u001b[38;2;32;148;243m1.23142058e-04\u001b[0m \u001b[38;2;32;148;243m1.43115374e-04\u001b[0m \u001b[38;2;32;148;243m2.78753748e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 23                                                                                          \n\n[07:57:27] TRAIN STEP: 24                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:27]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m53.29549314\u001b[0m  \u001b[38;2;32;148;243m-58.76586695\u001b[0m \u001b[38;2;32;148;243m-244.18392685\u001b[0m  \u001b[38;2;32;148;243m-90.47824155\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.57995877\u001b[0m  \u001b[38;2;32;148;243m-62.69294363\u001b[0m \u001b[38;2;32;148;243m-262.28875795\u001b[0m \u001b[38;2;32;148;243m-104.3813051\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.47438861\u001b[0m  \u001b[38;2;32;148;243m-62.83474894\u001b[0m \u001b[38;2;32;148;243m-262.34322091\u001b[0m \u001b[38;2;32;148;243m-104.45432688\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.3856592\u001b[0m   \u001b[38;2;32;148;243m-62.9622492\u001b[0m  \u001b[38;2;32;148;243m-262.38208482\u001b[0m \u001b[38;2;32;148;243m-104.51525265\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.31450599\u001b[0m  \u001b[38;2;32;148;243m-63.07517595\u001b[0m \u001b[38;2;32;148;243m-262.40400217\u001b[0m \u001b[38;2;32;148;243m-104.56176039\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.47641167\u001b[0m  \u001b[38;2;32;148;243m-63.00415612\u001b[0m \u001b[38;2;32;148;243m-262.27248643\u001b[0m \u001b[38;2;32;148;243m-104.62725646\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.65607385\u001b[0m  \u001b[38;2;32;148;243m-62.91995838\u001b[0m \u001b[38;2;32;148;243m-262.12895522\u001b[0m \u001b[38;2;32;148;243m-104.676091\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.85403748\u001b[0m  \u001b[38;2;32;148;243m-62.81988525\u001b[0m \u001b[38;2;32;148;243m-261.97383069\u001b[0m \u001b[38;2;32;148;243m-104.70795625\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m35.07040043\u001b[0m  \u001b[38;2;32;148;243m-62.70322397\u001b[0m \u001b[38;2;32;148;243m-261.80467069\u001b[0m \u001b[38;2;32;148;243m-104.72640427\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m53.29549314\u001b[0m  \u001b[38;2;32;148;243m-58.76586695\u001b[0m \u001b[38;2;32;148;243m-244.18392685\u001b[0m  \u001b[38;2;32;148;243m-90.47824155\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.68201044\u001b[0m  \u001b[38;2;32;148;243m-62.64211138\u001b[0m \u001b[38;2;32;148;243m-262.267517\u001b[0m   \u001b[38;2;32;148;243m-104.30220296\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.67827523\u001b[0m  \u001b[38;2;32;148;243m-62.71990458\u001b[0m \u001b[38;2;32;148;243m-262.29424895\u001b[0m \u001b[38;2;32;148;243m-104.29103486\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.69104203\u001b[0m  \u001b[38;2;32;148;243m-62.78368168\u001b[0m \u001b[38;2;32;148;243m-262.30681754\u001b[0m \u001b[38;2;32;148;243m-104.26609628\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.72116752\u001b[0m  \u001b[38;2;32;148;243m-62.83294363\u001b[0m \u001b[38;2;32;148;243m-262.30487786\u001b[0m \u001b[38;2;32;148;243m-104.22593336\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.78192114\u001b[0m  \u001b[38;2;32;148;243m-62.82211379\u001b[0m \u001b[38;2;32;148;243m-262.19717421\u001b[0m \u001b[38;2;32;148;243m-104.3771953\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.85994349\u001b[0m  \u001b[38;2;32;148;243m-62.79763485\u001b[0m \u001b[38;2;32;148;243m-262.07585442\u001b[0m \u001b[38;2;32;148;243m-104.51235589\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m34.95536497\u001b[0m  \u001b[38;2;32;148;243m-62.75964481\u001b[0m \u001b[38;2;32;148;243m-261.9409464\u001b[0m  \u001b[38;2;32;148;243m-104.63123031\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m35.06841863\u001b[0m  \u001b[38;2;32;148;243m-62.70751068\u001b[0m \u001b[38;2;32;148;243m-261.79191975\u001b[0m \u001b[38;2;32;148;243m-104.73542137\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10205166\u001b[0m \u001b[38;2;32;148;243m-0.05083225\u001b[0m \u001b[38;2;32;148;243m-0.02124095\u001b[0m \u001b[38;2;32;148;243m-0.07910213\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20388662\u001b[0m \u001b[38;2;32;148;243m-0.11484436\u001b[0m \u001b[38;2;32;148;243m-0.04897196\u001b[0m \u001b[38;2;32;148;243m-0.16329202\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30538284\u001b[0m \u001b[38;2;32;148;243m-0.17856752\u001b[0m \u001b[38;2;32;148;243m-0.07526728\u001b[0m \u001b[38;2;32;148;243m-0.24915637\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40666153\u001b[0m \u001b[38;2;32;148;243m-0.24223232\u001b[0m \u001b[38;2;32;148;243m-0.09912432\u001b[0m \u001b[38;2;32;148;243m-0.33582703\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30550947\u001b[0m \u001b[38;2;32;148;243m-0.18204233\u001b[0m \u001b[38;2;32;148;243m-0.07531222\u001b[0m \u001b[38;2;32;148;243m-0.25006116\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20386965\u001b[0m \u001b[38;2;32;148;243m-0.12232353\u001b[0m \u001b[38;2;32;148;243m-0.0531008\u001b[0m  \u001b[38;2;32;148;243m-0.16373511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10132749\u001b[0m \u001b[38;2;32;148;243m-0.06024043\u001b[0m \u001b[38;2;32;148;243m-0.03288429\u001b[0m \u001b[38;2;32;148;243m-0.07672595\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0019818\u001b[0m   \u001b[38;2;32;148;243m0.00428671\u001b[0m \u001b[38;2;32;148;243m-0.01275094\u001b[0m  \u001b[38;2;32;148;243m0.0090171\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10205166\u001b[0m \u001b[38;2;32;148;243m-0.05083225\u001b[0m \u001b[38;2;32;148;243m-0.02124095\u001b[0m \u001b[38;2;32;148;243m-0.07910213\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20388662\u001b[0m \u001b[38;2;32;148;243m-0.11484436\u001b[0m \u001b[38;2;32;148;243m-0.04897196\u001b[0m \u001b[38;2;32;148;243m-0.16329202\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30538284\u001b[0m \u001b[38;2;32;148;243m-0.17856752\u001b[0m \u001b[38;2;32;148;243m-0.07526728\u001b[0m \u001b[38;2;32;148;243m-0.24915637\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40666153\u001b[0m \u001b[38;2;32;148;243m-0.24223232\u001b[0m \u001b[38;2;32;148;243m-0.09912432\u001b[0m \u001b[38;2;32;148;243m-0.33582703\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10115205\u001b[0m \u001b[38;2;32;148;243m0.06018998\u001b[0m \u001b[38;2;32;148;243m0.0238121\u001b[0m  \u001b[38;2;32;148;243m0.08576588\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20279188\u001b[0m \u001b[38;2;32;148;243m0.11990879\u001b[0m \u001b[38;2;32;148;243m0.04602352\u001b[0m \u001b[38;2;32;148;243m0.17209193\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.30533404\u001b[0m \u001b[38;2;32;148;243m0.18199188\u001b[0m \u001b[38;2;32;148;243m0.06624003\u001b[0m \u001b[38;2;32;148;243m0.25910108\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.40864333\u001b[0m \u001b[38;2;32;148;243m0.24651903\u001b[0m \u001b[38;2;32;148;243m0.08637338\u001b[0m \u001b[38;2;32;148;243m0.34484413\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10205166\u001b[0m \u001b[38;2;32;148;243m-0.05083225\u001b[0m \u001b[38;2;32;148;243m-0.02124095\u001b[0m \u001b[38;2;32;148;243m-0.07910213\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20388662\u001b[0m \u001b[38;2;32;148;243m-0.11484436\u001b[0m \u001b[38;2;32;148;243m-0.04897196\u001b[0m \u001b[38;2;32;148;243m-0.16329202\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30538284\u001b[0m \u001b[38;2;32;148;243m-0.17856752\u001b[0m \u001b[38;2;32;148;243m-0.07526728\u001b[0m \u001b[38;2;32;148;243m-0.24915637\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40666153\u001b[0m \u001b[38;2;32;148;243m-0.24223232\u001b[0m \u001b[38;2;32;148;243m-0.09912432\u001b[0m \u001b[38;2;32;148;243m-0.33582703\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30550947\u001b[0m \u001b[38;2;32;148;243m-0.18204233\u001b[0m \u001b[38;2;32;148;243m-0.07531222\u001b[0m \u001b[38;2;32;148;243m-0.25006116\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20386965\u001b[0m \u001b[38;2;32;148;243m-0.12232353\u001b[0m \u001b[38;2;32;148;243m-0.0531008\u001b[0m  \u001b[38;2;32;148;243m-0.16373511\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10132749\u001b[0m \u001b[38;2;32;148;243m-0.06024043\u001b[0m \u001b[38;2;32;148;243m-0.03288429\u001b[0m \u001b[38;2;32;148;243m-0.07672595\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0019818\u001b[0m   \u001b[38;2;32;148;243m0.00428671\u001b[0m \u001b[38;2;32;148;243m-0.01275094\u001b[0m  \u001b[38;2;32;148;243m0.0090171\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0019818\u001b[0m   \u001b[38;2;32;148;243m0.00428671\u001b[0m \u001b[38;2;32;148;243m-0.01275094\u001b[0m  \u001b[38;2;32;148;243m0.0090171\u001b[0m \u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.199918126428102e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00464369\u001b[0m  \u001b[38;2;32;148;243m0.00702943\u001b[0m  \u001b[38;2;32;148;243m0.00568062\u001b[0m  \u001b[38;2;32;148;243m0.00344332\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00160992\u001b[0m  \u001b[38;2;32;148;243m0.0003247\u001b[0m  \u001b[38;2;32;148;243m-0.00290013\u001b[0m \u001b[38;2;32;148;243m-0.00234132\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04697816\u001b[0m  \u001b[38;2;32;148;243m0.00947497\u001b[0m \u001b[38;2;32;148;243m-0.08462732\u001b[0m \u001b[38;2;32;148;243m-0.06832074\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00490065\u001b[0m \u001b[38;2;32;148;243m0.00466015\u001b[0m \u001b[38;2;32;148;243m0.00849919\u001b[0m \u001b[38;2;32;148;243m0.00734464\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00016794\u001b[0m \u001b[38;2;32;148;243m0.0001597\u001b[0m  \u001b[38;2;32;148;243m0.00029126\u001b[0m \u001b[38;2;32;148;243m0.0002517\u001b[0m \u001b[1m]\u001b[0m\n           TRAIN STEP: 25                                                                                          \n\n[07:57:28] TRAIN STEP: 26                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:28]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m145.56268985\u001b[0m \u001b[38;2;32;148;243m-250.90061932\u001b[0m   \u001b[38;2;32;148;243m58.73238516\u001b[0m  \u001b[38;2;32;148;243m-73.52151453\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.27648138\u001b[0m \u001b[38;2;32;148;243m-254.11582955\u001b[0m   \u001b[38;2;32;148;243m40.89072731\u001b[0m  \u001b[38;2;32;148;243m-87.21799879\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.24154442\u001b[0m \u001b[38;2;32;148;243m-254.20254897\u001b[0m   \u001b[38;2;32;148;243m40.83512463\u001b[0m  \u001b[38;2;32;148;243m-87.32131832\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.2226123\u001b[0m  \u001b[38;2;32;148;243m-254.27667566\u001b[0m   \u001b[38;2;32;148;243m40.79727028\u001b[0m  \u001b[38;2;32;148;243m-87.41032588\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.22042926\u001b[0m \u001b[38;2;32;148;243m-254.33751424\u001b[0m   \u001b[38;2;32;148;243m40.77621894\u001b[0m  \u001b[38;2;32;148;243m-87.48500866\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.28697941\u001b[0m \u001b[38;2;32;148;243m-254.27357731\u001b[0m   \u001b[38;2;32;148;243m40.81122568\u001b[0m  \u001b[38;2;32;148;243m-87.29897074\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.37044421\u001b[0m \u001b[38;2;32;148;243m-254.19652122\u001b[0m   \u001b[38;2;32;148;243m40.86115183\u001b[0m  \u001b[38;2;32;148;243m-87.09686641\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.4704619\u001b[0m  \u001b[38;2;32;148;243m-254.10639685\u001b[0m   \u001b[38;2;32;148;243m40.9265964\u001b[0m   \u001b[38;2;32;148;243m-86.87836757\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.58721126\u001b[0m \u001b[38;2;32;148;243m-254.00235699\u001b[0m   \u001b[38;2;32;148;243m41.00782063\u001b[0m  \u001b[38;2;32;148;243m-86.64472854\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m145.56268985\u001b[0m \u001b[38;2;32;148;243m-250.90061932\u001b[0m   \u001b[38;2;32;148;243m58.73238516\u001b[0m  \u001b[38;2;32;148;243m-73.52151453\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.36641975\u001b[0m \u001b[38;2;32;148;243m-254.092928\u001b[0m     \u001b[38;2;32;148;243m40.90759934\u001b[0m  \u001b[38;2;32;148;243m-87.1375361\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.42468866\u001b[0m \u001b[38;2;32;148;243m-254.14419272\u001b[0m   \u001b[38;2;32;148;243m40.86953976\u001b[0m  \u001b[38;2;32;148;243m-87.1632774\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.50060579\u001b[0m \u001b[38;2;32;148;243m-254.18180556\u001b[0m   \u001b[38;2;32;148;243m40.84666217\u001b[0m  \u001b[38;2;32;148;243m-87.17378558\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.59386801\u001b[0m \u001b[38;2;32;148;243m-254.20585361\u001b[0m   \u001b[38;2;32;148;243m40.83913233\u001b[0m  \u001b[38;2;32;148;243m-87.16897545\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.56524509\u001b[0m \u001b[38;2;32;148;243m-254.18121627\u001b[0m   \u001b[38;2;32;148;243m40.86224539\u001b[0m  \u001b[38;2;32;148;243m-87.06220381\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.55353401\u001b[0m \u001b[38;2;32;148;243m-254.14693932\u001b[0m   \u001b[38;2;32;148;243m40.90091196\u001b[0m  \u001b[38;2;32;148;243m-86.94020992\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.55866354\u001b[0m \u001b[38;2;32;148;243m-254.10066525\u001b[0m   \u001b[38;2;32;148;243m40.95487408\u001b[0m  \u001b[38;2;32;148;243m-86.80282657\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m126.58095921\u001b[0m \u001b[38;2;32;148;243m-254.03758118\u001b[0m   \u001b[38;2;32;148;243m41.02396249\u001b[0m  \u001b[38;2;32;148;243m-86.65028484\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08993836\u001b[0m \u001b[38;2;32;148;243m-0.02290155\u001b[0m \u001b[38;2;32;148;243m-0.01687203\u001b[0m \u001b[38;2;32;148;243m-0.0804627\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18314424\u001b[0m \u001b[38;2;32;148;243m-0.05835625\u001b[0m \u001b[38;2;32;148;243m-0.03441513\u001b[0m \u001b[38;2;32;148;243m-0.15804092\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27799349\u001b[0m \u001b[38;2;32;148;243m-0.0948701\u001b[0m  \u001b[38;2;32;148;243m-0.04939189\u001b[0m \u001b[38;2;32;148;243m-0.23654031\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.37343874\u001b[0m \u001b[38;2;32;148;243m-0.13166064\u001b[0m \u001b[38;2;32;148;243m-0.06291339\u001b[0m \u001b[38;2;32;148;243m-0.31603321\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27826568\u001b[0m \u001b[38;2;32;148;243m-0.09236104\u001b[0m \u001b[38;2;32;148;243m-0.05101971\u001b[0m \u001b[38;2;32;148;243m-0.23676693\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1830898\u001b[0m  \u001b[38;2;32;148;243m-0.0495819\u001b[0m  \u001b[38;2;32;148;243m-0.03976013\u001b[0m \u001b[38;2;32;148;243m-0.15665649\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08820164\u001b[0m \u001b[38;2;32;148;243m-0.0057316\u001b[0m  \u001b[38;2;32;148;243m-0.02827768\u001b[0m \u001b[38;2;32;148;243m-0.075541\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00625205\u001b[0m  \u001b[38;2;32;148;243m0.03522419\u001b[0m \u001b[38;2;32;148;243m-0.01614186\u001b[0m  \u001b[38;2;32;148;243m0.00555631\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08993836\u001b[0m \u001b[38;2;32;148;243m-0.02290155\u001b[0m \u001b[38;2;32;148;243m-0.01687203\u001b[0m \u001b[38;2;32;148;243m-0.0804627\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18314424\u001b[0m \u001b[38;2;32;148;243m-0.05835625\u001b[0m \u001b[38;2;32;148;243m-0.03441513\u001b[0m \u001b[38;2;32;148;243m-0.15804092\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27799349\u001b[0m \u001b[38;2;32;148;243m-0.0948701\u001b[0m  \u001b[38;2;32;148;243m-0.04939189\u001b[0m \u001b[38;2;32;148;243m-0.23654031\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.37343874\u001b[0m \u001b[38;2;32;148;243m-0.13166064\u001b[0m \u001b[38;2;32;148;243m-0.06291339\u001b[0m \u001b[38;2;32;148;243m-0.31603321\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.09517307\u001b[0m \u001b[38;2;32;148;243m0.03929959\u001b[0m \u001b[38;2;32;148;243m0.01189369\u001b[0m \u001b[38;2;32;148;243m0.07926628\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19034894\u001b[0m \u001b[38;2;32;148;243m0.08207873\u001b[0m \u001b[38;2;32;148;243m0.02315326\u001b[0m \u001b[38;2;32;148;243m0.15937672\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.2852371\u001b[0m  \u001b[38;2;32;148;243m0.12592904\u001b[0m \u001b[38;2;32;148;243m0.03463571\u001b[0m \u001b[38;2;32;148;243m0.24049221\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.37969079\u001b[0m \u001b[38;2;32;148;243m0.16688482\u001b[0m \u001b[38;2;32;148;243m0.04677153\u001b[0m \u001b[38;2;32;148;243m0.32158951\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08993836\u001b[0m \u001b[38;2;32;148;243m-0.02290155\u001b[0m \u001b[38;2;32;148;243m-0.01687203\u001b[0m \u001b[38;2;32;148;243m-0.0804627\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18314424\u001b[0m \u001b[38;2;32;148;243m-0.05835625\u001b[0m \u001b[38;2;32;148;243m-0.03441513\u001b[0m \u001b[38;2;32;148;243m-0.15804092\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27799349\u001b[0m \u001b[38;2;32;148;243m-0.0948701\u001b[0m  \u001b[38;2;32;148;243m-0.04939189\u001b[0m \u001b[38;2;32;148;243m-0.23654031\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.37343874\u001b[0m \u001b[38;2;32;148;243m-0.13166064\u001b[0m \u001b[38;2;32;148;243m-0.06291339\u001b[0m \u001b[38;2;32;148;243m-0.31603321\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27826568\u001b[0m \u001b[38;2;32;148;243m-0.09236104\u001b[0m \u001b[38;2;32;148;243m-0.05101971\u001b[0m \u001b[38;2;32;148;243m-0.23676693\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.1830898\u001b[0m  \u001b[38;2;32;148;243m-0.0495819\u001b[0m  \u001b[38;2;32;148;243m-0.03976013\u001b[0m \u001b[38;2;32;148;243m-0.15665649\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08820164\u001b[0m \u001b[38;2;32;148;243m-0.0057316\u001b[0m  \u001b[38;2;32;148;243m-0.02827768\u001b[0m \u001b[38;2;32;148;243m-0.075541\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00625205\u001b[0m  \u001b[38;2;32;148;243m0.03522419\u001b[0m \u001b[38;2;32;148;243m-0.01614186\u001b[0m  \u001b[38;2;32;148;243m0.00555631\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00625205\u001b[0m  \u001b[38;2;32;148;243m0.03522419\u001b[0m \u001b[38;2;32;148;243m-0.01614186\u001b[0m  \u001b[38;2;32;148;243m0.00555631\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.29218625393476e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00441948\u001b[0m  \u001b[38;2;32;148;243m0.00714393\u001b[0m  \u001b[38;2;32;148;243m0.00583822\u001b[0m  \u001b[38;2;32;148;243m0.00372959\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00167111\u001b[0m  \u001b[38;2;32;148;243m0.00027887\u001b[0m \u001b[38;2;32;148;243m-0.00268236\u001b[0m \u001b[38;2;32;148;243m-0.00261393\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04876376\u001b[0m  \u001b[38;2;32;148;243m0.00813762\u001b[0m \u001b[38;2;32;148;243m-0.07827249\u001b[0m \u001b[38;2;32;148;243m-0.07627567\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00064774\u001b[0m \u001b[38;2;32;148;243m0.00074784\u001b[0m \u001b[38;2;32;148;243m0.00113602\u001b[0m \u001b[38;2;32;148;243m0.00841213\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.21975696e-05\u001b[0m \u001b[38;2;32;148;243m2.56281275e-05\u001b[0m \u001b[38;2;32;148;243m3.89306736e-05\u001b[0m \u001b[38;2;32;148;243m2.88279188e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 27                                                                                          \n\n[07:57:29] TRAIN STEP: 28                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:29]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m171.15931665\u001b[0m   \u001b[38;2;32;148;243m15.3638884\u001b[0m  \u001b[38;2;32;148;243m-201.77147589\u001b[0m  \u001b[38;2;32;148;243m-93.17897621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.88147376\u001b[0m   \u001b[38;2;32;148;243m11.79418133\u001b[0m \u001b[38;2;32;148;243m-218.98901622\u001b[0m \u001b[38;2;32;148;243m-106.07141897\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.85071746\u001b[0m   \u001b[38;2;32;148;243m11.78524517\u001b[0m \u001b[38;2;32;148;243m-218.9201588\u001b[0m  \u001b[38;2;32;148;243m-106.10069885\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.83872619\u001b[0m   \u001b[38;2;32;148;243m11.78844414\u001b[0m \u001b[38;2;32;148;243m-218.83784101\u001b[0m \u001b[38;2;32;148;243m-106.11383911\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.84627233\u001b[0m   \u001b[38;2;32;148;243m11.80707467\u001b[0m \u001b[38;2;32;148;243m-218.74149497\u001b[0m \u001b[38;2;32;148;243m-106.1110771\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.9395231\u001b[0m    \u001b[38;2;32;148;243m11.7743522\u001b[0m  \u001b[38;2;32;148;243m-218.71824208\u001b[0m \u001b[38;2;32;148;243m-105.92181133\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.05147054\u001b[0m   \u001b[38;2;32;148;243m11.75387696\u001b[0m \u001b[38;2;32;148;243m-218.67960987\u001b[0m \u001b[38;2;32;148;243m-105.71477454\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.18197841\u001b[0m   \u001b[38;2;32;148;243m11.74386838\u001b[0m \u001b[38;2;32;148;243m-218.62650409\u001b[0m \u001b[38;2;32;148;243m-105.49266828\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.33148059\u001b[0m   \u001b[38;2;32;148;243m11.74512414\u001b[0m \u001b[38;2;32;148;243m-218.56000431\u001b[0m \u001b[38;2;32;148;243m-105.25598557\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m171.15931665\u001b[0m   \u001b[38;2;32;148;243m15.3638884\u001b[0m  \u001b[38;2;32;148;243m-201.77147589\u001b[0m  \u001b[38;2;32;148;243m-93.17897621\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m151.98643516\u001b[0m   \u001b[38;2;32;148;243m11.82994944\u001b[0m \u001b[38;2;32;148;243m-218.9758738\u001b[0m  \u001b[38;2;32;148;243m-105.98897581\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.06660101\u001b[0m   \u001b[38;2;32;148;243m11.85246911\u001b[0m \u001b[38;2;32;148;243m-218.88795818\u001b[0m \u001b[38;2;32;148;243m-105.93663796\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.1655778\u001b[0m    \u001b[38;2;32;148;243m11.88824259\u001b[0m \u001b[38;2;32;148;243m-218.78497323\u001b[0m \u001b[38;2;32;148;243m-105.86945202\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.28377714\u001b[0m   \u001b[38;2;32;148;243m11.93838745\u001b[0m \u001b[38;2;32;148;243m-218.6679944\u001b[0m  \u001b[38;2;32;148;243m-105.78800194\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.26684222\u001b[0m   \u001b[38;2;32;148;243m11.87633823\u001b[0m \u001b[38;2;32;148;243m-218.66502018\u001b[0m \u001b[38;2;32;148;243m-105.67750282\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.26917284\u001b[0m   \u001b[38;2;32;148;243m11.82832167\u001b[0m \u001b[38;2;32;148;243m-218.64756474\u001b[0m \u001b[38;2;32;148;243m-105.55123251\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.29036215\u001b[0m   \u001b[38;2;32;148;243m11.79368232\u001b[0m \u001b[38;2;32;148;243m-218.61564241\u001b[0m \u001b[38;2;32;148;243m-105.40984507\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m152.33036729\u001b[0m   \u001b[38;2;32;148;243m11.77296525\u001b[0m \u001b[38;2;32;148;243m-218.56916079\u001b[0m \u001b[38;2;32;148;243m-105.25359312\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10496139\u001b[0m \u001b[38;2;32;148;243m-0.03576811\u001b[0m \u001b[38;2;32;148;243m-0.01314242\u001b[0m \u001b[38;2;32;148;243m-0.08244316\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21588355\u001b[0m \u001b[38;2;32;148;243m-0.06722394\u001b[0m \u001b[38;2;32;148;243m-0.03220063\u001b[0m \u001b[38;2;32;148;243m-0.16406089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32685161\u001b[0m \u001b[38;2;32;148;243m-0.09979845\u001b[0m \u001b[38;2;32;148;243m-0.05286778\u001b[0m \u001b[38;2;32;148;243m-0.24438709\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43750481\u001b[0m \u001b[38;2;32;148;243m-0.13131278\u001b[0m \u001b[38;2;32;148;243m-0.07350057\u001b[0m \u001b[38;2;32;148;243m-0.32307516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32731913\u001b[0m \u001b[38;2;32;148;243m-0.10198602\u001b[0m \u001b[38;2;32;148;243m-0.05322189\u001b[0m \u001b[38;2;32;148;243m-0.24430852\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2177023\u001b[0m  \u001b[38;2;32;148;243m-0.07444471\u001b[0m \u001b[38;2;32;148;243m-0.03204513\u001b[0m \u001b[38;2;32;148;243m-0.16354203\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10838375\u001b[0m \u001b[38;2;32;148;243m-0.04981394\u001b[0m \u001b[38;2;32;148;243m-0.01086168\u001b[0m \u001b[38;2;32;148;243m-0.0828232\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0011133\u001b[0m  \u001b[38;2;32;148;243m-0.02784111\u001b[0m  \u001b[38;2;32;148;243m0.00915648\u001b[0m \u001b[38;2;32;148;243m-0.00239244\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10496139\u001b[0m \u001b[38;2;32;148;243m-0.03576811\u001b[0m \u001b[38;2;32;148;243m-0.01314242\u001b[0m \u001b[38;2;32;148;243m-0.08244316\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21588355\u001b[0m \u001b[38;2;32;148;243m-0.06722394\u001b[0m \u001b[38;2;32;148;243m-0.03220063\u001b[0m \u001b[38;2;32;148;243m-0.16406089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32685161\u001b[0m \u001b[38;2;32;148;243m-0.09979845\u001b[0m \u001b[38;2;32;148;243m-0.05286778\u001b[0m \u001b[38;2;32;148;243m-0.24438709\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43750481\u001b[0m \u001b[38;2;32;148;243m-0.13131278\u001b[0m \u001b[38;2;32;148;243m-0.07350057\u001b[0m \u001b[38;2;32;148;243m-0.32307516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11018568\u001b[0m \u001b[38;2;32;148;243m0.02932676\u001b[0m \u001b[38;2;32;148;243m0.02027868\u001b[0m \u001b[38;2;32;148;243m0.07876664\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21980251\u001b[0m \u001b[38;2;32;148;243m0.05686807\u001b[0m \u001b[38;2;32;148;243m0.04145544\u001b[0m \u001b[38;2;32;148;243m0.15953313\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.32912106\u001b[0m \u001b[38;2;32;148;243m0.08149885\u001b[0m \u001b[38;2;32;148;243m0.0626389\u001b[0m  \u001b[38;2;32;148;243m0.24025196\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.43861811\u001b[0m \u001b[38;2;32;148;243m0.10347167\u001b[0m \u001b[38;2;32;148;243m0.08265705\u001b[0m \u001b[38;2;32;148;243m0.32068272\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10496139\u001b[0m \u001b[38;2;32;148;243m-0.03576811\u001b[0m \u001b[38;2;32;148;243m-0.01314242\u001b[0m \u001b[38;2;32;148;243m-0.08244316\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21588355\u001b[0m \u001b[38;2;32;148;243m-0.06722394\u001b[0m \u001b[38;2;32;148;243m-0.03220063\u001b[0m \u001b[38;2;32;148;243m-0.16406089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32685161\u001b[0m \u001b[38;2;32;148;243m-0.09979845\u001b[0m \u001b[38;2;32;148;243m-0.05286778\u001b[0m \u001b[38;2;32;148;243m-0.24438709\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43750481\u001b[0m \u001b[38;2;32;148;243m-0.13131278\u001b[0m \u001b[38;2;32;148;243m-0.07350057\u001b[0m \u001b[38;2;32;148;243m-0.32307516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32731913\u001b[0m \u001b[38;2;32;148;243m-0.10198602\u001b[0m \u001b[38;2;32;148;243m-0.05322189\u001b[0m \u001b[38;2;32;148;243m-0.24430852\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2177023\u001b[0m  \u001b[38;2;32;148;243m-0.07444471\u001b[0m \u001b[38;2;32;148;243m-0.03204513\u001b[0m \u001b[38;2;32;148;243m-0.16354203\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10838375\u001b[0m \u001b[38;2;32;148;243m-0.04981394\u001b[0m \u001b[38;2;32;148;243m-0.01086168\u001b[0m \u001b[38;2;32;148;243m-0.0828232\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0011133\u001b[0m  \u001b[38;2;32;148;243m-0.02784111\u001b[0m  \u001b[38;2;32;148;243m0.00915648\u001b[0m \u001b[38;2;32;148;243m-0.00239244\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0011133\u001b[0m  \u001b[38;2;32;148;243m-0.02784111\u001b[0m  \u001b[38;2;32;148;243m0.00915648\u001b[0m \u001b[38;2;32;148;243m-0.00239244\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.292362240828847e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00431864\u001b[0m  \u001b[38;2;32;148;243m0.00723347\u001b[0m  \u001b[38;2;32;148;243m0.00602306\u001b[0m  \u001b[38;2;32;148;243m0.00394892\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00173084\u001b[0m  \u001b[38;2;32;148;243m0.0003554\u001b[0m  \u001b[38;2;32;148;243m-0.00279759\u001b[0m \u001b[38;2;32;148;243m-0.00244461\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.05050673\u001b[0m  \u001b[38;2;32;148;243m0.01037071\u001b[0m \u001b[38;2;32;148;243m-0.08163518\u001b[0m \u001b[38;2;32;148;243m-0.07133497\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00456065\u001b[0m \u001b[38;2;32;148;243m0.00044\u001b[0m    \u001b[38;2;32;148;243m0.00186585\u001b[0m \u001b[38;2;32;148;243m0.00040742\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.56291176e-04\u001b[0m \u001b[38;2;32;148;243m1.50785662e-05\u001b[0m \u001b[38;2;32;148;243m6.39416478e-05\u001b[0m \u001b[38;2;32;148;243m1.39619870e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 29                                                                                          \n\n[07:57:30] TRAIN STEP: 30                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:30]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m184.34203524\u001b[0m \u001b[38;2;32;148;243m-103.47477517\u001b[0m  \u001b[38;2;32;148;243m-46.02384416\u001b[0m  \u001b[38;2;32;148;243m178.62854614\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.39374778\u001b[0m \u001b[38;2;32;148;243m-106.90385803\u001b[0m  \u001b[38;2;32;148;243m-64.75457232\u001b[0m  \u001b[38;2;32;148;243m165.33959469\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.26513605\u001b[0m \u001b[38;2;32;148;243m-106.92917044\u001b[0m  \u001b[38;2;32;148;243m-64.84065599\u001b[0m  \u001b[38;2;32;148;243m165.37948522\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.15602636\u001b[0m \u001b[38;2;32;148;243m-106.93950103\u001b[0m  \u001b[38;2;32;148;243m-64.91302965\u001b[0m  \u001b[38;2;32;148;243m165.43531311\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.06680062\u001b[0m \u001b[38;2;32;148;243m-106.93442205\u001b[0m  \u001b[38;2;32;148;243m-64.97232719\u001b[0m  \u001b[38;2;32;148;243m165.50844993\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.32277271\u001b[0m \u001b[38;2;32;148;243m-106.8860604\u001b[0m   \u001b[38;2;32;148;243m-64.97473127\u001b[0m  \u001b[38;2;32;148;243m165.60670896\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.59922593\u001b[0m \u001b[38;2;32;148;243m-106.82227902\u001b[0m  \u001b[38;2;32;148;243m-64.96399892\u001b[0m  \u001b[38;2;32;148;243m165.72146782\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.89629594\u001b[0m \u001b[38;2;32;148;243m-106.74322528\u001b[0m  \u001b[38;2;32;148;243m-64.93942739\u001b[0m  \u001b[38;2;32;148;243m165.85356863\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m165.21408407\u001b[0m \u001b[38;2;32;148;243m-106.64911548\u001b[0m  \u001b[38;2;32;148;243m-64.90107888\u001b[0m  \u001b[38;2;32;148;243m166.00337226\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m184.34203524\u001b[0m \u001b[38;2;32;148;243m-103.47477517\u001b[0m  \u001b[38;2;32;148;243m-46.02384416\u001b[0m  \u001b[38;2;32;148;243m178.62854614\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.49729319\u001b[0m \u001b[38;2;32;148;243m-106.88829307\u001b[0m  \u001b[38;2;32;148;243m-64.7255811\u001b[0m   \u001b[38;2;32;148;243m165.43337029\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.48182743\u001b[0m \u001b[38;2;32;148;243m-106.90023352\u001b[0m  \u001b[38;2;32;148;243m-64.7705743\u001b[0m   \u001b[38;2;32;148;243m165.56511887\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.48637093\u001b[0m \u001b[38;2;32;148;243m-106.89777808\u001b[0m  \u001b[38;2;32;148;243m-64.80198698\u001b[0m  \u001b[38;2;32;148;243m165.71206936\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.5109001\u001b[0m  \u001b[38;2;32;148;243m-106.88084364\u001b[0m  \u001b[38;2;32;148;243m-64.81951543\u001b[0m  \u001b[38;2;32;148;243m165.87682369\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.65273741\u001b[0m \u001b[38;2;32;148;243m-106.84415659\u001b[0m  \u001b[38;2;32;148;243m-64.86410283\u001b[0m  \u001b[38;2;32;148;243m165.88372877\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.81423185\u001b[0m \u001b[38;2;32;148;243m-106.79258864\u001b[0m  \u001b[38;2;32;148;243m-64.89568017\u001b[0m  \u001b[38;2;32;148;243m165.907229\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m164.99581419\u001b[0m \u001b[38;2;32;148;243m-106.72681573\u001b[0m  \u001b[38;2;32;148;243m-64.91397325\u001b[0m  \u001b[38;2;32;148;243m165.94707031\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m165.19745045\u001b[0m \u001b[38;2;32;148;243m-106.64633033\u001b[0m  \u001b[38;2;32;148;243m-64.91893936\u001b[0m  \u001b[38;2;32;148;243m166.00303581\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.03545409e-01\u001b[0m \u001b[38;2;32;148;243m-1.55649636e-02\u001b[0m \u001b[38;2;32;148;243m-2.89912179e-02\u001b[0m \u001b[38;2;32;148;243m-9.37756002e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.16691378e-01\u001b[0m \u001b[38;2;32;148;243m-2.89369247e-02\u001b[0m \u001b[38;2;32;148;243m-7.00816870e-02\u001b[0m \u001b[38;2;32;148;243m-1.85633657e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.30344565e-01\u001b[0m \u001b[38;2;32;148;243m-4.17229547e-02\u001b[0m \u001b[38;2;32;148;243m-1.11042663e-01\u001b[0m \u001b[38;2;32;148;243m-2.76756255e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4.44099477e-01\u001b[0m \u001b[38;2;32;148;243m-5.35784063e-02\u001b[0m \u001b[38;2;32;148;243m-1.52811765e-01\u001b[0m \u001b[38;2;32;148;243m-3.68373758e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.29964703e-01\u001b[0m \u001b[38;2;32;148;243m-4.19038148e-02\u001b[0m \u001b[38;2;32;148;243m-1.10628446e-01\u001b[0m \u001b[38;2;32;148;243m-2.77019806e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.15005919e-01\u001b[0m \u001b[38;2;32;148;243m-2.96903798e-02\u001b[0m \u001b[38;2;32;148;243m-6.83187461e-02\u001b[0m \u001b[38;2;32;148;243m-1.85761180e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.95182431e-02\u001b[0m \u001b[38;2;32;148;243m-1.64095427e-02\u001b[0m \u001b[38;2;32;148;243m-2.54541349e-02\u001b[0m \u001b[38;2;32;148;243m-9.35016869e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.66336164e-02\u001b[0m \u001b[38;2;32;148;243m-2.78514421e-03\u001b[0m  \u001b[38;2;32;148;243m1.78604829e-02\u001b[0m  \u001b[38;2;32;148;243m3.36451029e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10354541\u001b[0m \u001b[38;2;32;148;243m-0.01556496\u001b[0m \u001b[38;2;32;148;243m-0.02899122\u001b[0m \u001b[38;2;32;148;243m-0.0937756\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21669138\u001b[0m \u001b[38;2;32;148;243m-0.02893692\u001b[0m \u001b[38;2;32;148;243m-0.07008169\u001b[0m \u001b[38;2;32;148;243m-0.18563366\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.33034456\u001b[0m \u001b[38;2;32;148;243m-0.04172295\u001b[0m \u001b[38;2;32;148;243m-0.11104266\u001b[0m \u001b[38;2;32;148;243m-0.27675626\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.44409948\u001b[0m \u001b[38;2;32;148;243m-0.05357841\u001b[0m \u001b[38;2;32;148;243m-0.15281176\u001b[0m \u001b[38;2;32;148;243m-0.36837376\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11413477\u001b[0m \u001b[38;2;32;148;243m0.01167459\u001b[0m \u001b[38;2;32;148;243m0.04218332\u001b[0m \u001b[38;2;32;148;243m0.09135395\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22909356\u001b[0m \u001b[38;2;32;148;243m0.02388803\u001b[0m \u001b[38;2;32;148;243m0.08449302\u001b[0m \u001b[38;2;32;148;243m0.18261258\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.34458123\u001b[0m \u001b[38;2;32;148;243m0.03716886\u001b[0m \u001b[38;2;32;148;243m0.12735763\u001b[0m \u001b[38;2;32;148;243m0.27487207\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.46073309\u001b[0m \u001b[38;2;32;148;243m0.05079326\u001b[0m \u001b[38;2;32;148;243m0.17067225\u001b[0m \u001b[38;2;32;148;243m0.36871021\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m  \u001b[38;2;32;148;243m0.00000000e+00\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-1.03545409e-01\u001b[0m \u001b[38;2;32;148;243m-1.55649636e-02\u001b[0m \u001b[38;2;32;148;243m-2.89912179e-02\u001b[0m \u001b[38;2;32;148;243m-9.37756002e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.16691378e-01\u001b[0m \u001b[38;2;32;148;243m-2.89369247e-02\u001b[0m \u001b[38;2;32;148;243m-7.00816870e-02\u001b[0m \u001b[38;2;32;148;243m-1.85633657e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.30344565e-01\u001b[0m \u001b[38;2;32;148;243m-4.17229547e-02\u001b[0m \u001b[38;2;32;148;243m-1.11042663e-01\u001b[0m \u001b[38;2;32;148;243m-2.76756255e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-4.44099477e-01\u001b[0m \u001b[38;2;32;148;243m-5.35784063e-02\u001b[0m \u001b[38;2;32;148;243m-1.52811765e-01\u001b[0m \u001b[38;2;32;148;243m-3.68373758e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-3.29964703e-01\u001b[0m \u001b[38;2;32;148;243m-4.19038148e-02\u001b[0m \u001b[38;2;32;148;243m-1.10628446e-01\u001b[0m \u001b[38;2;32;148;243m-2.77019806e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-2.15005919e-01\u001b[0m \u001b[38;2;32;148;243m-2.96903798e-02\u001b[0m \u001b[38;2;32;148;243m-6.83187461e-02\u001b[0m \u001b[38;2;32;148;243m-1.85761180e-01\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-9.95182431e-02\u001b[0m \u001b[38;2;32;148;243m-1.64095427e-02\u001b[0m \u001b[38;2;32;148;243m-2.54541349e-02\u001b[0m \u001b[38;2;32;148;243m-9.35016869e-02\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m1.66336164e-02\u001b[0m \u001b[38;2;32;148;243m-2.78514421e-03\u001b[0m  \u001b[38;2;32;148;243m1.78604829e-02\u001b[0m  \u001b[38;2;32;148;243m3.36451029e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01663362\u001b[0m \u001b[38;2;32;148;243m-0.00278514\u001b[0m  \u001b[38;2;32;148;243m0.01786048\u001b[0m  \u001b[38;2;32;148;243m0.00033645\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.241730249547891e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00392473\u001b[0m  \u001b[38;2;32;148;243m0.00744468\u001b[0m  \u001b[38;2;32;148;243m0.00624059\u001b[0m  \u001b[38;2;32;148;243m0.00392888\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00157616\u001b[0m  \u001b[38;2;32;148;243m0.00043167\u001b[0m \u001b[38;2;32;148;243m-0.00271804\u001b[0m \u001b[38;2;32;148;243m-0.0023798\u001b[0m \u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04599303\u001b[0m  \u001b[38;2;32;148;243m0.01259622\u001b[0m \u001b[38;2;32;148;243m-0.07931388\u001b[0m \u001b[38;2;32;148;243m-0.06944374\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00434508\u001b[0m \u001b[38;2;32;148;243m0.00624341\u001b[0m \u001b[38;2;32;148;243m0.00080301\u001b[0m \u001b[38;2;32;148;243m0.00256726\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.48903642e-04\u001b[0m \u001b[38;2;32;148;243m2.13958444e-04\u001b[0m \u001b[38;2;32;148;243m2.75186210e-05\u001b[0m \u001b[38;2;32;148;243m8.79785320e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 31                                                                                          \n\n[07:57:31] TRAIN STEP: 32                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:31]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m50.52861395\u001b[0m \u001b[38;2;32;148;243m-178.41428574\u001b[0m   \u001b[38;2;32;148;243m20.79589968\u001b[0m   \u001b[38;2;32;148;243m76.51722088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.68718719\u001b[0m \u001b[38;2;32;148;243m-181.9700319\u001b[0m     \u001b[38;2;32;148;243m2.48696532\u001b[0m   \u001b[38;2;32;148;243m64.31002245\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.56933446\u001b[0m \u001b[38;2;32;148;243m-181.85597192\u001b[0m    \u001b[38;2;32;148;243m2.39757479\u001b[0m   \u001b[38;2;32;148;243m64.28251078\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.47024408\u001b[0m \u001b[38;2;32;148;243m-181.72791593\u001b[0m    \u001b[38;2;32;148;243m2.32202127\u001b[0m   \u001b[38;2;32;148;243m64.26822319\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.39068275\u001b[0m \u001b[38;2;32;148;243m-181.58547459\u001b[0m    \u001b[38;2;32;148;243m2.26278958\u001b[0m   \u001b[38;2;32;148;243m64.26821479\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.41953563\u001b[0m \u001b[38;2;32;148;243m-181.59829776\u001b[0m    \u001b[38;2;32;148;243m2.330283\u001b[0m     \u001b[38;2;32;148;243m64.40132027\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.46732514\u001b[0m \u001b[38;2;32;148;243m-181.59647438\u001b[0m    \u001b[38;2;32;148;243m2.41208281\u001b[0m   \u001b[38;2;32;148;243m64.54989607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.53428071\u001b[0m \u001b[38;2;32;148;243m-181.58025227\u001b[0m    \u001b[38;2;32;148;243m2.50768149\u001b[0m   \u001b[38;2;32;148;243m64.71337351\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.62024889\u001b[0m \u001b[38;2;32;148;243m-181.55003025\u001b[0m    \u001b[38;2;32;148;243m2.61772195\u001b[0m   \u001b[38;2;32;148;243m64.89076471\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m50.52861395\u001b[0m \u001b[38;2;32;148;243m-178.41428574\u001b[0m   \u001b[38;2;32;148;243m20.79589968\u001b[0m   \u001b[38;2;32;148;243m76.51722088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.79259493\u001b[0m \u001b[38;2;32;148;243m-181.94913384\u001b[0m    \u001b[38;2;32;148;243m2.52072261\u001b[0m   \u001b[38;2;32;148;243m64.38750977\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.78516527\u001b[0m \u001b[38;2;32;148;243m-181.81811405\u001b[0m    \u001b[38;2;32;148;243m2.47226402\u001b[0m   \u001b[38;2;32;148;243m64.43159795\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.79691782\u001b[0m \u001b[38;2;32;148;243m-181.67298377\u001b[0m    \u001b[38;2;32;148;243m2.43749044\u001b[0m   \u001b[38;2;32;148;243m64.48994943\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.82821999\u001b[0m \u001b[38;2;32;148;243m-181.51333533\u001b[0m    \u001b[38;2;32;148;243m2.41778558\u001b[0m   \u001b[38;2;32;148;243m64.56256728\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.7459287\u001b[0m  \u001b[38;2;32;148;243m-181.54410271\u001b[0m    \u001b[38;2;32;148;243m2.44612143\u001b[0m   \u001b[38;2;32;148;243m64.62293961\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.68204797\u001b[0m \u001b[38;2;32;148;243m-181.56005962\u001b[0m    \u001b[38;2;32;148;243m2.48865531\u001b[0m   \u001b[38;2;32;148;243m64.698162\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.63676858\u001b[0m \u001b[38;2;32;148;243m-181.561427\u001b[0m      \u001b[38;2;32;148;243m2.54493974\u001b[0m   \u001b[38;2;32;148;243m64.78863651\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m30.61013569\u001b[0m \u001b[38;2;32;148;243m-181.54824353\u001b[0m    \u001b[38;2;32;148;243m2.6148425\u001b[0m    \u001b[38;2;32;148;243m64.89438964\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10540775\u001b[0m \u001b[38;2;32;148;243m-0.02089805\u001b[0m \u001b[38;2;32;148;243m-0.03375729\u001b[0m \u001b[38;2;32;148;243m-0.07748732\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21583081\u001b[0m \u001b[38;2;32;148;243m-0.03785787\u001b[0m \u001b[38;2;32;148;243m-0.07468923\u001b[0m \u001b[38;2;32;148;243m-0.14908717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32667373\u001b[0m \u001b[38;2;32;148;243m-0.05493215\u001b[0m \u001b[38;2;32;148;243m-0.11546918\u001b[0m \u001b[38;2;32;148;243m-0.22172624\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43753723\u001b[0m \u001b[38;2;32;148;243m-0.07213926\u001b[0m \u001b[38;2;32;148;243m-0.154996\u001b[0m   \u001b[38;2;32;148;243m-0.29435249\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32639307\u001b[0m \u001b[38;2;32;148;243m-0.05419505\u001b[0m \u001b[38;2;32;148;243m-0.11583844\u001b[0m \u001b[38;2;32;148;243m-0.22161934\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21472283\u001b[0m \u001b[38;2;32;148;243m-0.03641476\u001b[0m \u001b[38;2;32;148;243m-0.0765725\u001b[0m  \u001b[38;2;32;148;243m-0.14826593\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10248787\u001b[0m \u001b[38;2;32;148;243m-0.01882527\u001b[0m \u001b[38;2;32;148;243m-0.03725825\u001b[0m \u001b[38;2;32;148;243m-0.075263\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0101132\u001b[0m  \u001b[38;2;32;148;243m-0.00178672\u001b[0m  \u001b[38;2;32;148;243m0.00287945\u001b[0m \u001b[38;2;32;148;243m-0.00362494\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10540775\u001b[0m \u001b[38;2;32;148;243m-0.02089805\u001b[0m \u001b[38;2;32;148;243m-0.03375729\u001b[0m \u001b[38;2;32;148;243m-0.07748732\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21583081\u001b[0m \u001b[38;2;32;148;243m-0.03785787\u001b[0m \u001b[38;2;32;148;243m-0.07468923\u001b[0m \u001b[38;2;32;148;243m-0.14908717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32667373\u001b[0m \u001b[38;2;32;148;243m-0.05493215\u001b[0m \u001b[38;2;32;148;243m-0.11546918\u001b[0m \u001b[38;2;32;148;243m-0.22172624\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43753723\u001b[0m \u001b[38;2;32;148;243m-0.07213926\u001b[0m \u001b[38;2;32;148;243m-0.154996\u001b[0m   \u001b[38;2;32;148;243m-0.29435249\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.11114417\u001b[0m \u001b[38;2;32;148;243m0.01794421\u001b[0m \u001b[38;2;32;148;243m0.03915757\u001b[0m \u001b[38;2;32;148;243m0.07273315\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22281441\u001b[0m \u001b[38;2;32;148;243m0.03572449\u001b[0m \u001b[38;2;32;148;243m0.0784235\u001b[0m  \u001b[38;2;32;148;243m0.14608656\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33504936\u001b[0m \u001b[38;2;32;148;243m0.05331399\u001b[0m \u001b[38;2;32;148;243m0.11773775\u001b[0m \u001b[38;2;32;148;243m0.21908949\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.44765043\u001b[0m \u001b[38;2;32;148;243m0.07035254\u001b[0m \u001b[38;2;32;148;243m0.15787545\u001b[0m \u001b[38;2;32;148;243m0.29072755\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10540775\u001b[0m \u001b[38;2;32;148;243m-0.02089805\u001b[0m \u001b[38;2;32;148;243m-0.03375729\u001b[0m \u001b[38;2;32;148;243m-0.07748732\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21583081\u001b[0m \u001b[38;2;32;148;243m-0.03785787\u001b[0m \u001b[38;2;32;148;243m-0.07468923\u001b[0m \u001b[38;2;32;148;243m-0.14908717\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32667373\u001b[0m \u001b[38;2;32;148;243m-0.05493215\u001b[0m \u001b[38;2;32;148;243m-0.11546918\u001b[0m \u001b[38;2;32;148;243m-0.22172624\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43753723\u001b[0m \u001b[38;2;32;148;243m-0.07213926\u001b[0m \u001b[38;2;32;148;243m-0.154996\u001b[0m   \u001b[38;2;32;148;243m-0.29435249\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32639307\u001b[0m \u001b[38;2;32;148;243m-0.05419505\u001b[0m \u001b[38;2;32;148;243m-0.11583844\u001b[0m \u001b[38;2;32;148;243m-0.22161934\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21472283\u001b[0m \u001b[38;2;32;148;243m-0.03641476\u001b[0m \u001b[38;2;32;148;243m-0.0765725\u001b[0m  \u001b[38;2;32;148;243m-0.14826593\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10248787\u001b[0m \u001b[38;2;32;148;243m-0.01882527\u001b[0m \u001b[38;2;32;148;243m-0.03725825\u001b[0m \u001b[38;2;32;148;243m-0.075263\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0101132\u001b[0m  \u001b[38;2;32;148;243m-0.00178672\u001b[0m  \u001b[38;2;32;148;243m0.00287945\u001b[0m \u001b[38;2;32;148;243m-0.00362494\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0101132\u001b[0m  \u001b[38;2;32;148;243m-0.00178672\u001b[0m  \u001b[38;2;32;148;243m0.00287945\u001b[0m \u001b[38;2;32;148;243m-0.00362494\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.155062018783672e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00374981\u001b[0m  \u001b[38;2;32;148;243m0.00761301\u001b[0m  \u001b[38;2;32;148;243m0.00619221\u001b[0m  \u001b[38;2;32;148;243m0.0041061\u001b[0m \u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00154897\u001b[0m  \u001b[38;2;32;148;243m0.00034634\u001b[0m \u001b[38;2;32;148;243m-0.0027607\u001b[0m  \u001b[38;2;32;148;243m-0.00228755\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04519968\u001b[0m  \u001b[38;2;32;148;243m0.01010646\u001b[0m \u001b[38;2;32;148;243m-0.08055862\u001b[0m \u001b[38;2;32;148;243m-0.06675195\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00463783\u001b[0m \u001b[38;2;32;148;243m0.00145371\u001b[0m \u001b[38;2;32;148;243m0.00271898\u001b[0m \u001b[38;2;32;148;243m0.00451945\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.58935901e-04\u001b[0m \u001b[38;2;32;148;243m4.98178924e-05\u001b[0m \u001b[38;2;32;148;243m9.31778366e-05\u001b[0m \u001b[38;2;32;148;243m1.54879109e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 33                                                                                          \n\n[07:57:32] TRAIN STEP: 34                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:32]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m74.92880994\u001b[0m \u001b[38;2;32;148;243m-182.70511458\u001b[0m  \u001b[38;2;32;148;243m-39.69537499\u001b[0m  \u001b[38;2;32;148;243m-27.25250162\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.79239625\u001b[0m \u001b[38;2;32;148;243m-186.09473615\u001b[0m  \u001b[38;2;32;148;243m-57.22733036\u001b[0m  \u001b[38;2;32;148;243m-40.41684613\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.67299931\u001b[0m \u001b[38;2;32;148;243m-186.18214434\u001b[0m  \u001b[38;2;32;148;243m-57.18027841\u001b[0m  \u001b[38;2;32;148;243m-40.48199145\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.5705083\u001b[0m  \u001b[38;2;32;148;243m-186.2533408\u001b[0m   \u001b[38;2;32;148;243m-57.11750375\u001b[0m  \u001b[38;2;32;148;243m-40.5343663\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.48475137\u001b[0m \u001b[38;2;32;148;243m-186.30814703\u001b[0m  \u001b[38;2;32;148;243m-57.03990315\u001b[0m  \u001b[38;2;32;148;243m-40.56818088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.72676428\u001b[0m \u001b[38;2;32;148;243m-186.29876425\u001b[0m  \u001b[38;2;32;148;243m-57.01873247\u001b[0m  \u001b[38;2;32;148;243m-40.47357665\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.98598735\u001b[0m \u001b[38;2;32;148;243m-186.27614725\u001b[0m  \u001b[38;2;32;148;243m-56.98330972\u001b[0m  \u001b[38;2;32;148;243m-40.36414313\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.26179828\u001b[0m \u001b[38;2;32;148;243m-186.24337663\u001b[0m  \u001b[38;2;32;148;243m-56.93307792\u001b[0m  \u001b[38;2;32;148;243m-40.24023115\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.55504835\u001b[0m \u001b[38;2;32;148;243m-186.19948866\u001b[0m  \u001b[38;2;32;148;243m-56.86766223\u001b[0m  \u001b[38;2;32;148;243m-40.09930656\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m74.92880994\u001b[0m \u001b[38;2;32;148;243m-182.70511458\u001b[0m  \u001b[38;2;32;148;243m-39.69537499\u001b[0m  \u001b[38;2;32;148;243m-27.25250162\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.89426131\u001b[0m \u001b[38;2;32;148;243m-186.04645579\u001b[0m  \u001b[38;2;32;148;243m-57.2091828\u001b[0m   \u001b[38;2;32;148;243m-40.34048656\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.87253804\u001b[0m \u001b[38;2;32;148;243m-186.07667698\u001b[0m  \u001b[38;2;32;148;243m-57.14775794\u001b[0m  \u001b[38;2;32;148;243m-40.33015975\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.86671099\u001b[0m \u001b[38;2;32;148;243m-186.09203927\u001b[0m  \u001b[38;2;32;148;243m-57.07307576\u001b[0m  \u001b[38;2;32;148;243m-40.30627388\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m55.87789084\u001b[0m \u001b[38;2;32;148;243m-186.09214799\u001b[0m  \u001b[38;2;32;148;243m-56.98304617\u001b[0m  \u001b[38;2;32;148;243m-40.2653189\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.0221772\u001b[0m  \u001b[38;2;32;148;243m-186.13770233\u001b[0m  \u001b[38;2;32;148;243m-56.97548894\u001b[0m  \u001b[38;2;32;148;243m-40.24410023\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.18357892\u001b[0m \u001b[38;2;32;148;243m-186.16823336\u001b[0m  \u001b[38;2;32;148;243m-56.95284355\u001b[0m  \u001b[38;2;32;148;243m-40.20777472\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.36188957\u001b[0m \u001b[38;2;32;148;243m-186.18267865\u001b[0m  \u001b[38;2;32;148;243m-56.91529636\u001b[0m  \u001b[38;2;32;148;243m-40.15668495\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m56.55740189\u001b[0m \u001b[38;2;32;148;243m-186.18156121\u001b[0m  \u001b[38;2;32;148;243m-56.86264086\u001b[0m  \u001b[38;2;32;148;243m-40.08977762\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10186505\u001b[0m \u001b[38;2;32;148;243m-0.04828036\u001b[0m \u001b[38;2;32;148;243m-0.01814756\u001b[0m \u001b[38;2;32;148;243m-0.07635958\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19953872\u001b[0m \u001b[38;2;32;148;243m-0.10546736\u001b[0m \u001b[38;2;32;148;243m-0.03252047\u001b[0m \u001b[38;2;32;148;243m-0.1518317\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29620269\u001b[0m \u001b[38;2;32;148;243m-0.16130153\u001b[0m \u001b[38;2;32;148;243m-0.04442799\u001b[0m \u001b[38;2;32;148;243m-0.22809242\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39313947\u001b[0m \u001b[38;2;32;148;243m-0.21599903\u001b[0m \u001b[38;2;32;148;243m-0.05685698\u001b[0m \u001b[38;2;32;148;243m-0.30286198\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29541292\u001b[0m \u001b[38;2;32;148;243m-0.16106192\u001b[0m \u001b[38;2;32;148;243m-0.04324352\u001b[0m \u001b[38;2;32;148;243m-0.22947642\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19759157\u001b[0m \u001b[38;2;32;148;243m-0.10791389\u001b[0m \u001b[38;2;32;148;243m-0.03046616\u001b[0m \u001b[38;2;32;148;243m-0.15636841\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10009129\u001b[0m \u001b[38;2;32;148;243m-0.06069797\u001b[0m \u001b[38;2;32;148;243m-0.01778156\u001b[0m \u001b[38;2;32;148;243m-0.08354619\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00235355\u001b[0m \u001b[38;2;32;148;243m-0.01792746\u001b[0m \u001b[38;2;32;148;243m-0.00502137\u001b[0m \u001b[38;2;32;148;243m-0.00952894\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10186505\u001b[0m \u001b[38;2;32;148;243m-0.04828036\u001b[0m \u001b[38;2;32;148;243m-0.01814756\u001b[0m \u001b[38;2;32;148;243m-0.07635958\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19953872\u001b[0m \u001b[38;2;32;148;243m-0.10546736\u001b[0m \u001b[38;2;32;148;243m-0.03252047\u001b[0m \u001b[38;2;32;148;243m-0.1518317\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29620269\u001b[0m \u001b[38;2;32;148;243m-0.16130153\u001b[0m \u001b[38;2;32;148;243m-0.04442799\u001b[0m \u001b[38;2;32;148;243m-0.22809242\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39313947\u001b[0m \u001b[38;2;32;148;243m-0.21599903\u001b[0m \u001b[38;2;32;148;243m-0.05685698\u001b[0m \u001b[38;2;32;148;243m-0.30286198\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.09772655\u001b[0m \u001b[38;2;32;148;243m0.05493711\u001b[0m \u001b[38;2;32;148;243m0.01361346\u001b[0m \u001b[38;2;32;148;243m0.07338556\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.1955479\u001b[0m  \u001b[38;2;32;148;243m0.10808514\u001b[0m \u001b[38;2;32;148;243m0.02639081\u001b[0m \u001b[38;2;32;148;243m0.14649357\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.29304819\u001b[0m \u001b[38;2;32;148;243m0.15530106\u001b[0m \u001b[38;2;32;148;243m0.03907542\u001b[0m \u001b[38;2;32;148;243m0.21931579\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.39078593\u001b[0m \u001b[38;2;32;148;243m0.19807158\u001b[0m \u001b[38;2;32;148;243m0.05183561\u001b[0m \u001b[38;2;32;148;243m0.29333304\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10186505\u001b[0m \u001b[38;2;32;148;243m-0.04828036\u001b[0m \u001b[38;2;32;148;243m-0.01814756\u001b[0m \u001b[38;2;32;148;243m-0.07635958\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19953872\u001b[0m \u001b[38;2;32;148;243m-0.10546736\u001b[0m \u001b[38;2;32;148;243m-0.03252047\u001b[0m \u001b[38;2;32;148;243m-0.1518317\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29620269\u001b[0m \u001b[38;2;32;148;243m-0.16130153\u001b[0m \u001b[38;2;32;148;243m-0.04442799\u001b[0m \u001b[38;2;32;148;243m-0.22809242\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39313947\u001b[0m \u001b[38;2;32;148;243m-0.21599903\u001b[0m \u001b[38;2;32;148;243m-0.05685698\u001b[0m \u001b[38;2;32;148;243m-0.30286198\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29541292\u001b[0m \u001b[38;2;32;148;243m-0.16106192\u001b[0m \u001b[38;2;32;148;243m-0.04324352\u001b[0m \u001b[38;2;32;148;243m-0.22947642\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19759157\u001b[0m \u001b[38;2;32;148;243m-0.10791389\u001b[0m \u001b[38;2;32;148;243m-0.03046616\u001b[0m \u001b[38;2;32;148;243m-0.15636841\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10009129\u001b[0m \u001b[38;2;32;148;243m-0.06069797\u001b[0m \u001b[38;2;32;148;243m-0.01778156\u001b[0m \u001b[38;2;32;148;243m-0.08354619\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00235355\u001b[0m \u001b[38;2;32;148;243m-0.01792746\u001b[0m \u001b[38;2;32;148;243m-0.00502137\u001b[0m \u001b[38;2;32;148;243m-0.00952894\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00235355\u001b[0m \u001b[38;2;32;148;243m-0.01792746\u001b[0m \u001b[38;2;32;148;243m-0.00502137\u001b[0m \u001b[38;2;32;148;243m-0.00952894\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.247447757482707e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00354041\u001b[0m  \u001b[38;2;32;148;243m0.00763568\u001b[0m  \u001b[38;2;32;148;243m0.00653372\u001b[0m  \u001b[38;2;32;148;243m0.00412247\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0013728\u001b[0m   \u001b[38;2;32;148;243m0.0003291\u001b[0m  \u001b[38;2;32;148;243m-0.00278975\u001b[0m \u001b[38;2;32;148;243m-0.00219927\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04005891\u001b[0m  \u001b[38;2;32;148;243m0.00960323\u001b[0m \u001b[38;2;32;148;243m-0.08140624\u001b[0m \u001b[38;2;32;148;243m-0.0641757\u001b[0m \u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00467942\u001b[0m \u001b[38;2;32;148;243m0.00249438\u001b[0m \u001b[38;2;32;148;243m0.0030545\u001b[0m  \u001b[38;2;32;148;243m0.00207526\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.60361062e-04\u001b[0m \u001b[38;2;32;148;243m8.54808986e-05\u001b[0m \u001b[38;2;32;148;243m1.04676151e-04\u001b[0m \u001b[38;2;32;148;243m7.11178738e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 35                                                                                          \n\n[07:57:33] TRAIN STEP: 36                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:33]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m112.6789316\u001b[0m  \u001b[38;2;32;148;243m-137.6519396\u001b[0m    \u001b[38;2;32;148;243m37.65671306\u001b[0m \u001b[38;2;32;148;243m-127.87433435\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.48502218\u001b[0m \u001b[38;2;32;148;243m-141.14225385\u001b[0m   \u001b[38;2;32;148;243m19.30991479\u001b[0m \u001b[38;2;32;148;243m-140.16098179\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.31094607\u001b[0m \u001b[38;2;32;148;243m-141.08719399\u001b[0m   \u001b[38;2;32;148;243m19.31376414\u001b[0m \u001b[38;2;32;148;243m-140.16379303\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.15358912\u001b[0m \u001b[38;2;32;148;243m-141.01793853\u001b[0m   \u001b[38;2;32;148;243m19.33327433\u001b[0m \u001b[38;2;32;148;243m-140.15081693\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.01351514\u001b[0m \u001b[38;2;32;148;243m-140.93436227\u001b[0m   \u001b[38;2;32;148;243m19.36809026\u001b[0m \u001b[38;2;32;148;243m-140.12320538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.05707812\u001b[0m \u001b[38;2;32;148;243m-140.90245986\u001b[0m   \u001b[38;2;32;148;243m19.468945\u001b[0m   \u001b[38;2;32;148;243m-140.04413358\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.1166652\u001b[0m  \u001b[38;2;32;148;243m-140.85705571\u001b[0m   \u001b[38;2;32;148;243m19.58659885\u001b[0m \u001b[38;2;32;148;243m-139.94935126\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.19322\u001b[0m    \u001b[38;2;32;148;243m-140.79827396\u001b[0m   \u001b[38;2;32;148;243m19.72094828\u001b[0m \u001b[38;2;32;148;243m-139.83858442\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.28646643\u001b[0m \u001b[38;2;32;148;243m-140.72621824\u001b[0m   \u001b[38;2;32;148;243m19.87126243\u001b[0m \u001b[38;2;32;148;243m-139.71186011\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m112.6789316\u001b[0m  \u001b[38;2;32;148;243m-137.6519396\u001b[0m    \u001b[38;2;32;148;243m37.65671306\u001b[0m \u001b[38;2;32;148;243m-127.87433435\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.58072677\u001b[0m \u001b[38;2;32;148;243m-141.10652899\u001b[0m   \u001b[38;2;32;148;243m19.33345276\u001b[0m \u001b[38;2;32;148;243m-140.07861647\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.49763661\u001b[0m \u001b[38;2;32;148;243m-141.00212212\u001b[0m   \u001b[38;2;32;148;243m19.35291461\u001b[0m \u001b[38;2;32;148;243m-139.99543486\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.43223269\u001b[0m \u001b[38;2;32;148;243m-140.88650419\u001b[0m   \u001b[38;2;32;148;243m19.38712363\u001b[0m \u001b[38;2;32;148;243m-139.89656251\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.38567723\u001b[0m \u001b[38;2;32;148;243m-140.75798639\u001b[0m   \u001b[38;2;32;148;243m19.43627117\u001b[0m \u001b[38;2;32;148;243m-139.78371247\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.33387416\u001b[0m \u001b[38;2;32;148;243m-140.77229949\u001b[0m   \u001b[38;2;32;148;243m19.52270199\u001b[0m \u001b[38;2;32;148;243m-139.7890863\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.29644736\u001b[0m \u001b[38;2;32;148;243m-140.77297197\u001b[0m   \u001b[38;2;32;148;243m19.62780006\u001b[0m \u001b[38;2;32;148;243m-139.78037698\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.27601996\u001b[0m \u001b[38;2;32;148;243m-140.76043489\u001b[0m   \u001b[38;2;32;148;243m19.75113299\u001b[0m \u001b[38;2;32;148;243m-139.75674949\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m92.27332048\u001b[0m \u001b[38;2;32;148;243m-140.73462654\u001b[0m   \u001b[38;2;32;148;243m19.89106076\u001b[0m \u001b[38;2;32;148;243m-139.7174389\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0957046\u001b[0m  \u001b[38;2;32;148;243m-0.03572485\u001b[0m \u001b[38;2;32;148;243m-0.02353797\u001b[0m \u001b[38;2;32;148;243m-0.08236532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18669054\u001b[0m \u001b[38;2;32;148;243m-0.08507187\u001b[0m \u001b[38;2;32;148;243m-0.03915047\u001b[0m \u001b[38;2;32;148;243m-0.16835817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27864358\u001b[0m \u001b[38;2;32;148;243m-0.13143433\u001b[0m \u001b[38;2;32;148;243m-0.0538493\u001b[0m  \u001b[38;2;32;148;243m-0.25425443\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3721621\u001b[0m  \u001b[38;2;32;148;243m-0.17637587\u001b[0m \u001b[38;2;32;148;243m-0.06818091\u001b[0m \u001b[38;2;32;148;243m-0.33949291\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27679604\u001b[0m \u001b[38;2;32;148;243m-0.13016037\u001b[0m \u001b[38;2;32;148;243m-0.053757\u001b[0m   \u001b[38;2;32;148;243m-0.25504728\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17978216\u001b[0m \u001b[38;2;32;148;243m-0.08408374\u001b[0m \u001b[38;2;32;148;243m-0.04120121\u001b[0m \u001b[38;2;32;148;243m-0.16897428\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08279996\u001b[0m \u001b[38;2;32;148;243m-0.03783907\u001b[0m \u001b[38;2;32;148;243m-0.03018471\u001b[0m \u001b[38;2;32;148;243m-0.08183493\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01314594\u001b[0m  \u001b[38;2;32;148;243m0.0084083\u001b[0m  \u001b[38;2;32;148;243m-0.01979833\u001b[0m  \u001b[38;2;32;148;243m0.00557879\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0957046\u001b[0m  \u001b[38;2;32;148;243m-0.03572485\u001b[0m \u001b[38;2;32;148;243m-0.02353797\u001b[0m \u001b[38;2;32;148;243m-0.08236532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18669054\u001b[0m \u001b[38;2;32;148;243m-0.08507187\u001b[0m \u001b[38;2;32;148;243m-0.03915047\u001b[0m \u001b[38;2;32;148;243m-0.16835817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27864358\u001b[0m \u001b[38;2;32;148;243m-0.13143433\u001b[0m \u001b[38;2;32;148;243m-0.0538493\u001b[0m  \u001b[38;2;32;148;243m-0.25425443\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3721621\u001b[0m  \u001b[38;2;32;148;243m-0.17637587\u001b[0m \u001b[38;2;32;148;243m-0.06818091\u001b[0m \u001b[38;2;32;148;243m-0.33949291\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.09536606\u001b[0m \u001b[38;2;32;148;243m0.0462155\u001b[0m  \u001b[38;2;32;148;243m0.01442392\u001b[0m \u001b[38;2;32;148;243m0.08444563\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.19237994\u001b[0m \u001b[38;2;32;148;243m0.09229213\u001b[0m \u001b[38;2;32;148;243m0.0269797\u001b[0m  \u001b[38;2;32;148;243m0.17051863\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.28936214\u001b[0m \u001b[38;2;32;148;243m0.13853681\u001b[0m \u001b[38;2;32;148;243m0.0379962\u001b[0m  \u001b[38;2;32;148;243m0.25765798\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.38530804\u001b[0m \u001b[38;2;32;148;243m0.18478417\u001b[0m \u001b[38;2;32;148;243m0.04838258\u001b[0m \u001b[38;2;32;148;243m0.3450717\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.0957046\u001b[0m  \u001b[38;2;32;148;243m-0.03572485\u001b[0m \u001b[38;2;32;148;243m-0.02353797\u001b[0m \u001b[38;2;32;148;243m-0.08236532\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18669054\u001b[0m \u001b[38;2;32;148;243m-0.08507187\u001b[0m \u001b[38;2;32;148;243m-0.03915047\u001b[0m \u001b[38;2;32;148;243m-0.16835817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27864358\u001b[0m \u001b[38;2;32;148;243m-0.13143433\u001b[0m \u001b[38;2;32;148;243m-0.0538493\u001b[0m  \u001b[38;2;32;148;243m-0.25425443\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3721621\u001b[0m  \u001b[38;2;32;148;243m-0.17637587\u001b[0m \u001b[38;2;32;148;243m-0.06818091\u001b[0m \u001b[38;2;32;148;243m-0.33949291\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27679604\u001b[0m \u001b[38;2;32;148;243m-0.13016037\u001b[0m \u001b[38;2;32;148;243m-0.053757\u001b[0m   \u001b[38;2;32;148;243m-0.25504728\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.17978216\u001b[0m \u001b[38;2;32;148;243m-0.08408374\u001b[0m \u001b[38;2;32;148;243m-0.04120121\u001b[0m \u001b[38;2;32;148;243m-0.16897428\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.08279996\u001b[0m \u001b[38;2;32;148;243m-0.03783907\u001b[0m \u001b[38;2;32;148;243m-0.03018471\u001b[0m \u001b[38;2;32;148;243m-0.08183493\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01314594\u001b[0m  \u001b[38;2;32;148;243m0.0084083\u001b[0m  \u001b[38;2;32;148;243m-0.01979833\u001b[0m  \u001b[38;2;32;148;243m0.00557879\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01314594\u001b[0m  \u001b[38;2;32;148;243m0.0084083\u001b[0m  \u001b[38;2;32;148;243m-0.01979833\u001b[0m  \u001b[38;2;32;148;243m0.00557879\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.248725889206352e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00357988\u001b[0m  \u001b[38;2;32;148;243m0.00777211\u001b[0m  \u001b[38;2;32;148;243m0.00669951\u001b[0m  \u001b[38;2;32;148;243m0.00430707\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00171328\u001b[0m  \u001b[38;2;32;148;243m0.00033568\u001b[0m \u001b[38;2;32;148;243m-0.00260917\u001b[0m \u001b[38;2;32;148;243m-0.00238742\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04999435\u001b[0m  \u001b[38;2;32;148;243m0.00979537\u001b[0m \u001b[38;2;32;148;243m-0.0761368\u001b[0m  \u001b[38;2;32;148;243m-0.06966602\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00540308\u001b[0m \u001b[38;2;32;148;243m0.00142743\u001b[0m \u001b[38;2;32;148;243m0.00242872\u001b[0m \u001b[38;2;32;148;243m0.00676989\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.85160666e-04\u001b[0m \u001b[38;2;32;148;243m4.89173385e-05\u001b[0m \u001b[38;2;32;148;243m8.32309639e-05\u001b[0m \u001b[38;2;32;148;243m2.32000474e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 37                                                                                          \n\n[07:57:34] TRAIN STEP: 38                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:34]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m44.88891258\u001b[0m \u001b[38;2;32;148;243m-203.76869411\u001b[0m \u001b[38;2;32;148;243m-297.67307078\u001b[0m \u001b[38;2;32;148;243m-111.9452155\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.72224401\u001b[0m \u001b[38;2;32;148;243m-207.45985592\u001b[0m \u001b[38;2;32;148;243m-316.47312288\u001b[0m \u001b[38;2;32;148;243m-124.67860952\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.5962375\u001b[0m  \u001b[38;2;32;148;243m-207.45053717\u001b[0m \u001b[38;2;32;148;243m-316.4805086\u001b[0m  \u001b[38;2;32;148;243m-124.77768652\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.48895162\u001b[0m \u001b[38;2;32;148;243m-207.42991488\u001b[0m \u001b[38;2;32;148;243m-316.47232253\u001b[0m \u001b[38;2;32;148;243m-124.8620405\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.39992623\u001b[0m \u001b[38;2;32;148;243m-207.39850667\u001b[0m \u001b[38;2;32;148;243m-316.44825811\u001b[0m \u001b[38;2;32;148;243m-124.93155662\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.54442062\u001b[0m \u001b[38;2;32;148;243m-207.36245976\u001b[0m \u001b[38;2;32;148;243m-316.42564629\u001b[0m \u001b[38;2;32;148;243m-124.80034997\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.70779707\u001b[0m \u001b[38;2;32;148;243m-207.31224841\u001b[0m \u001b[38;2;32;148;243m-316.38686339\u001b[0m \u001b[38;2;32;148;243m-124.65260372\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.89045669\u001b[0m \u001b[38;2;32;148;243m-207.24856859\u001b[0m \u001b[38;2;32;148;243m-316.33340037\u001b[0m \u001b[38;2;32;148;243m-124.48746799\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.09195134\u001b[0m \u001b[38;2;32;148;243m-207.17084009\u001b[0m \u001b[38;2;32;148;243m-316.26924213\u001b[0m \u001b[38;2;32;148;243m-124.30832288\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m44.88891258\u001b[0m \u001b[38;2;32;148;243m-203.76869411\u001b[0m \u001b[38;2;32;148;243m-297.67307078\u001b[0m \u001b[38;2;32;148;243m-111.9452155\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.82369672\u001b[0m \u001b[38;2;32;148;243m-207.43635382\u001b[0m \u001b[38;2;32;148;243m-316.45012639\u001b[0m \u001b[38;2;32;148;243m-124.60277519\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.8067966\u001b[0m  \u001b[38;2;32;148;243m-207.3947834\u001b[0m  \u001b[38;2;32;148;243m-316.42468676\u001b[0m \u001b[38;2;32;148;243m-124.62493316\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.80797489\u001b[0m \u001b[38;2;32;148;243m-207.33856477\u001b[0m \u001b[38;2;32;148;243m-316.3857758\u001b[0m  \u001b[38;2;32;148;243m-124.63191608\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.82757997\u001b[0m \u001b[38;2;32;148;243m-207.26767998\u001b[0m \u001b[38;2;32;148;243m-316.33307999\u001b[0m \u001b[38;2;32;148;243m-124.62345937\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.86317585\u001b[0m \u001b[38;2;32;148;243m-207.2735048\u001b[0m  \u001b[38;2;32;148;243m-316.33977392\u001b[0m \u001b[38;2;32;148;243m-124.570238\u001b[0m  \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.9169385\u001b[0m  \u001b[38;2;32;148;243m-207.26600792\u001b[0m \u001b[38;2;32;148;243m-316.331626\u001b[0m   \u001b[38;2;32;148;243m-124.50130283\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.98971303\u001b[0m \u001b[38;2;32;148;243m-207.24698827\u001b[0m \u001b[38;2;32;148;243m-316.30938657\u001b[0m \u001b[38;2;32;148;243m-124.4163161\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.08210632\u001b[0m \u001b[38;2;32;148;243m-207.21502822\u001b[0m \u001b[38;2;32;148;243m-316.27460538\u001b[0m \u001b[38;2;32;148;243m-124.31645819\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10145271\u001b[0m \u001b[38;2;32;148;243m-0.0235021\u001b[0m  \u001b[38;2;32;148;243m-0.02299649\u001b[0m \u001b[38;2;32;148;243m-0.07583434\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21055909\u001b[0m \u001b[38;2;32;148;243m-0.05575377\u001b[0m \u001b[38;2;32;148;243m-0.05582184\u001b[0m \u001b[38;2;32;148;243m-0.15275336\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31902328\u001b[0m \u001b[38;2;32;148;243m-0.09135011\u001b[0m \u001b[38;2;32;148;243m-0.08654673\u001b[0m \u001b[38;2;32;148;243m-0.23012442\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42765374\u001b[0m \u001b[38;2;32;148;243m-0.13082669\u001b[0m \u001b[38;2;32;148;243m-0.11517812\u001b[0m \u001b[38;2;32;148;243m-0.30809725\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31875523\u001b[0m \u001b[38;2;32;148;243m-0.08895496\u001b[0m \u001b[38;2;32;148;243m-0.08587237\u001b[0m \u001b[38;2;32;148;243m-0.23011197\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20914143\u001b[0m \u001b[38;2;32;148;243m-0.04624049\u001b[0m \u001b[38;2;32;148;243m-0.0552374\u001b[0m  \u001b[38;2;32;148;243m-0.15130089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09925634\u001b[0m \u001b[38;2;32;148;243m-0.00158032\u001b[0m \u001b[38;2;32;148;243m-0.02401379\u001b[0m \u001b[38;2;32;148;243m-0.07115189\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00984501\u001b[0m  \u001b[38;2;32;148;243m0.04418814\u001b[0m  \u001b[38;2;32;148;243m0.00536325\u001b[0m  \u001b[38;2;32;148;243m0.00813531\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10145271\u001b[0m \u001b[38;2;32;148;243m-0.0235021\u001b[0m  \u001b[38;2;32;148;243m-0.02299649\u001b[0m \u001b[38;2;32;148;243m-0.07583434\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21055909\u001b[0m \u001b[38;2;32;148;243m-0.05575377\u001b[0m \u001b[38;2;32;148;243m-0.05582184\u001b[0m \u001b[38;2;32;148;243m-0.15275336\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31902328\u001b[0m \u001b[38;2;32;148;243m-0.09135011\u001b[0m \u001b[38;2;32;148;243m-0.08654673\u001b[0m \u001b[38;2;32;148;243m-0.23012442\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42765374\u001b[0m \u001b[38;2;32;148;243m-0.13082669\u001b[0m \u001b[38;2;32;148;243m-0.11517812\u001b[0m \u001b[38;2;32;148;243m-0.30809725\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10889852\u001b[0m \u001b[38;2;32;148;243m0.04187173\u001b[0m \u001b[38;2;32;148;243m0.02930575\u001b[0m \u001b[38;2;32;148;243m0.07798527\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21851231\u001b[0m \u001b[38;2;32;148;243m0.0845862\u001b[0m  \u001b[38;2;32;148;243m0.05994072\u001b[0m \u001b[38;2;32;148;243m0.15679636\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.3283974\u001b[0m  \u001b[38;2;32;148;243m0.12924637\u001b[0m \u001b[38;2;32;148;243m0.09116432\u001b[0m \u001b[38;2;32;148;243m0.23694535\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.43749876\u001b[0m \u001b[38;2;32;148;243m0.17501483\u001b[0m \u001b[38;2;32;148;243m0.12054137\u001b[0m \u001b[38;2;32;148;243m0.31623255\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10145271\u001b[0m \u001b[38;2;32;148;243m-0.0235021\u001b[0m  \u001b[38;2;32;148;243m-0.02299649\u001b[0m \u001b[38;2;32;148;243m-0.07583434\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21055909\u001b[0m \u001b[38;2;32;148;243m-0.05575377\u001b[0m \u001b[38;2;32;148;243m-0.05582184\u001b[0m \u001b[38;2;32;148;243m-0.15275336\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31902328\u001b[0m \u001b[38;2;32;148;243m-0.09135011\u001b[0m \u001b[38;2;32;148;243m-0.08654673\u001b[0m \u001b[38;2;32;148;243m-0.23012442\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.42765374\u001b[0m \u001b[38;2;32;148;243m-0.13082669\u001b[0m \u001b[38;2;32;148;243m-0.11517812\u001b[0m \u001b[38;2;32;148;243m-0.30809725\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.31875523\u001b[0m \u001b[38;2;32;148;243m-0.08895496\u001b[0m \u001b[38;2;32;148;243m-0.08587237\u001b[0m \u001b[38;2;32;148;243m-0.23011197\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20914143\u001b[0m \u001b[38;2;32;148;243m-0.04624049\u001b[0m \u001b[38;2;32;148;243m-0.0552374\u001b[0m  \u001b[38;2;32;148;243m-0.15130089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09925634\u001b[0m \u001b[38;2;32;148;243m-0.00158032\u001b[0m \u001b[38;2;32;148;243m-0.02401379\u001b[0m \u001b[38;2;32;148;243m-0.07115189\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00984501\u001b[0m  \u001b[38;2;32;148;243m0.04418814\u001b[0m  \u001b[38;2;32;148;243m0.00536325\u001b[0m  \u001b[38;2;32;148;243m0.00813531\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00984501\u001b[0m \u001b[38;2;32;148;243m0.04418814\u001b[0m \u001b[38;2;32;148;243m0.00536325\u001b[0m \u001b[38;2;32;148;243m0.00813531\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.194705207402027e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00332281\u001b[0m  \u001b[38;2;32;148;243m0.00789375\u001b[0m  \u001b[38;2;32;148;243m0.0067447\u001b[0m   \u001b[38;2;32;148;243m0.00430028\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00186687\u001b[0m  \u001b[38;2;32;148;243m0.00015468\u001b[0m \u001b[38;2;32;148;243m-0.00251314\u001b[0m \u001b[38;2;32;148;243m-0.00228563\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.05447631\u001b[0m  \u001b[38;2;32;148;243m0.00451359\u001b[0m \u001b[38;2;32;148;243m-0.0733346\u001b[0m  \u001b[38;2;32;148;243m-0.06669579\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00073056\u001b[0m \u001b[38;2;32;148;243m0.00145581\u001b[0m \u001b[38;2;32;148;243m0.00766154\u001b[0m \u001b[38;2;32;148;243m0.00384\u001b[0m   \u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.50358021e-05\u001b[0m \u001b[38;2;32;148;243m4.98899584e-05\u001b[0m \u001b[38;2;32;148;243m2.62556895e-04\u001b[0m \u001b[38;2;32;148;243m1.31594731e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 39                                                                                          \n\n[07:57:35] TRAIN STEP: 40                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:35]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m106.23528662\u001b[0m \u001b[38;2;32;148;243m-290.17062525\u001b[0m \u001b[38;2;32;148;243m-159.6201671\u001b[0m  \u001b[38;2;32;148;243m-189.98648922\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.52688055\u001b[0m \u001b[38;2;32;148;243m-293.9108656\u001b[0m  \u001b[38;2;32;148;243m-177.48515651\u001b[0m \u001b[38;2;32;148;243m-202.2620761\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.44024672\u001b[0m \u001b[38;2;32;148;243m-294.01300049\u001b[0m \u001b[38;2;32;148;243m-177.44132191\u001b[0m \u001b[38;2;32;148;243m-202.12991156\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.37026265\u001b[0m \u001b[38;2;32;148;243m-294.10072964\u001b[0m \u001b[38;2;32;148;243m-177.38028803\u001b[0m \u001b[38;2;32;148;243m-201.98193368\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.31699528\u001b[0m \u001b[38;2;32;148;243m-294.17204307\u001b[0m \u001b[38;2;32;148;243m-177.30478544\u001b[0m \u001b[38;2;32;148;243m-201.81823139\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.41639208\u001b[0m \u001b[38;2;32;148;243m-294.14967811\u001b[0m \u001b[38;2;32;148;243m-177.21605084\u001b[0m \u001b[38;2;32;148;243m-201.77056058\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.53433558\u001b[0m \u001b[38;2;32;148;243m-294.11341036\u001b[0m \u001b[38;2;32;148;243m-177.11594323\u001b[0m \u001b[38;2;32;148;243m-201.70800504\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.67081597\u001b[0m \u001b[38;2;32;148;243m-294.06376415\u001b[0m \u001b[38;2;32;148;243m-177.00296784\u001b[0m \u001b[38;2;32;148;243m-201.6293551\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.82586154\u001b[0m \u001b[38;2;32;148;243m-294.00074864\u001b[0m \u001b[38;2;32;148;243m-176.87646334\u001b[0m \u001b[38;2;32;148;243m-201.53455858\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m106.23528662\u001b[0m \u001b[38;2;32;148;243m-290.17062525\u001b[0m \u001b[38;2;32;148;243m-159.6201671\u001b[0m  \u001b[38;2;32;148;243m-189.98648922\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.62777361\u001b[0m \u001b[38;2;32;148;243m-293.89374808\u001b[0m \u001b[38;2;32;148;243m-177.44790123\u001b[0m \u001b[38;2;32;148;243m-202.18025038\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.6431835\u001b[0m  \u001b[38;2;32;148;243m-293.97496572\u001b[0m \u001b[38;2;32;148;243m-177.36083902\u001b[0m \u001b[38;2;32;148;243m-201.96654809\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.67588402\u001b[0m \u001b[38;2;32;148;243m-294.04011126\u001b[0m \u001b[38;2;32;148;243m-177.25894581\u001b[0m \u001b[38;2;32;148;243m-201.73726089\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.72654302\u001b[0m \u001b[38;2;32;148;243m-294.08316652\u001b[0m \u001b[38;2;32;148;243m-177.14315312\u001b[0m \u001b[38;2;32;148;243m-201.49251313\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.72027525\u001b[0m \u001b[38;2;32;148;243m-294.09045697\u001b[0m \u001b[38;2;32;148;243m-177.09408032\u001b[0m \u001b[38;2;32;148;243m-201.52553054\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.7316803\u001b[0m  \u001b[38;2;32;148;243m-294.08278775\u001b[0m \u001b[38;2;32;148;243m-177.03225268\u001b[0m \u001b[38;2;32;148;243m-201.54339144\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.76107002\u001b[0m \u001b[38;2;32;148;243m-294.06306558\u001b[0m \u001b[38;2;32;148;243m-176.95709584\u001b[0m \u001b[38;2;32;148;243m-201.54577551\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m85.80858922\u001b[0m \u001b[38;2;32;148;243m-294.03111542\u001b[0m \u001b[38;2;32;148;243m-176.8681786\u001b[0m  \u001b[38;2;32;148;243m-201.53272987\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10089306\u001b[0m \u001b[38;2;32;148;243m-0.01711752\u001b[0m \u001b[38;2;32;148;243m-0.03725528\u001b[0m \u001b[38;2;32;148;243m-0.08182572\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20293678\u001b[0m \u001b[38;2;32;148;243m-0.03803477\u001b[0m \u001b[38;2;32;148;243m-0.08048289\u001b[0m \u001b[38;2;32;148;243m-0.16336347\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30562137\u001b[0m \u001b[38;2;32;148;243m-0.06061839\u001b[0m \u001b[38;2;32;148;243m-0.12134221\u001b[0m \u001b[38;2;32;148;243m-0.24467278\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40954774\u001b[0m \u001b[38;2;32;148;243m-0.08887655\u001b[0m \u001b[38;2;32;148;243m-0.16163232\u001b[0m \u001b[38;2;32;148;243m-0.32571826\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30388316\u001b[0m \u001b[38;2;32;148;243m-0.05922114\u001b[0m \u001b[38;2;32;148;243m-0.12197052\u001b[0m \u001b[38;2;32;148;243m-0.24503005\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19734472\u001b[0m \u001b[38;2;32;148;243m-0.03062261\u001b[0m \u001b[38;2;32;148;243m-0.08369055\u001b[0m \u001b[38;2;32;148;243m-0.1646136\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09025406\u001b[0m \u001b[38;2;32;148;243m-0.00069856\u001b[0m \u001b[38;2;32;148;243m-0.045872\u001b[0m   \u001b[38;2;32;148;243m-0.08357959\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01727232\u001b[0m  \u001b[38;2;32;148;243m0.03036678\u001b[0m \u001b[38;2;32;148;243m-0.00828474\u001b[0m \u001b[38;2;32;148;243m-0.00182871\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10089306\u001b[0m \u001b[38;2;32;148;243m-0.01711752\u001b[0m \u001b[38;2;32;148;243m-0.03725528\u001b[0m \u001b[38;2;32;148;243m-0.08182572\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20293678\u001b[0m \u001b[38;2;32;148;243m-0.03803477\u001b[0m \u001b[38;2;32;148;243m-0.08048289\u001b[0m \u001b[38;2;32;148;243m-0.16336347\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30562137\u001b[0m \u001b[38;2;32;148;243m-0.06061839\u001b[0m \u001b[38;2;32;148;243m-0.12134221\u001b[0m \u001b[38;2;32;148;243m-0.24467278\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40954774\u001b[0m \u001b[38;2;32;148;243m-0.08887655\u001b[0m \u001b[38;2;32;148;243m-0.16163232\u001b[0m \u001b[38;2;32;148;243m-0.32571826\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10566457\u001b[0m \u001b[38;2;32;148;243m0.02965541\u001b[0m \u001b[38;2;32;148;243m0.0396618\u001b[0m  \u001b[38;2;32;148;243m0.08068821\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.21220301\u001b[0m \u001b[38;2;32;148;243m0.05825393\u001b[0m \u001b[38;2;32;148;243m0.07794177\u001b[0m \u001b[38;2;32;148;243m0.16110465\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.31929368\u001b[0m \u001b[38;2;32;148;243m0.08817798\u001b[0m \u001b[38;2;32;148;243m0.11576032\u001b[0m \u001b[38;2;32;148;243m0.24213867\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.42682006\u001b[0m \u001b[38;2;32;148;243m0.11924332\u001b[0m \u001b[38;2;32;148;243m0.15334758\u001b[0m \u001b[38;2;32;148;243m0.32388955\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10089306\u001b[0m \u001b[38;2;32;148;243m-0.01711752\u001b[0m \u001b[38;2;32;148;243m-0.03725528\u001b[0m \u001b[38;2;32;148;243m-0.08182572\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20293678\u001b[0m \u001b[38;2;32;148;243m-0.03803477\u001b[0m \u001b[38;2;32;148;243m-0.08048289\u001b[0m \u001b[38;2;32;148;243m-0.16336347\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30562137\u001b[0m \u001b[38;2;32;148;243m-0.06061839\u001b[0m \u001b[38;2;32;148;243m-0.12134221\u001b[0m \u001b[38;2;32;148;243m-0.24467278\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.40954774\u001b[0m \u001b[38;2;32;148;243m-0.08887655\u001b[0m \u001b[38;2;32;148;243m-0.16163232\u001b[0m \u001b[38;2;32;148;243m-0.32571826\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30388316\u001b[0m \u001b[38;2;32;148;243m-0.05922114\u001b[0m \u001b[38;2;32;148;243m-0.12197052\u001b[0m \u001b[38;2;32;148;243m-0.24503005\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19734472\u001b[0m \u001b[38;2;32;148;243m-0.03062261\u001b[0m \u001b[38;2;32;148;243m-0.08369055\u001b[0m \u001b[38;2;32;148;243m-0.1646136\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09025406\u001b[0m \u001b[38;2;32;148;243m-0.00069856\u001b[0m \u001b[38;2;32;148;243m-0.045872\u001b[0m   \u001b[38;2;32;148;243m-0.08357959\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01727232\u001b[0m  \u001b[38;2;32;148;243m0.03036678\u001b[0m \u001b[38;2;32;148;243m-0.00828474\u001b[0m \u001b[38;2;32;148;243m-0.00182871\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.01727232\u001b[0m  \u001b[38;2;32;148;243m0.03036678\u001b[0m \u001b[38;2;32;148;243m-0.00828474\u001b[0m \u001b[38;2;32;148;243m-0.00182871\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.17654446569214e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00304076\u001b[0m  \u001b[38;2;32;148;243m0.00786173\u001b[0m  \u001b[38;2;32;148;243m0.00719686\u001b[0m  \u001b[38;2;32;148;243m0.00432946\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00173932\u001b[0m  \u001b[38;2;32;148;243m0.00026521\u001b[0m \u001b[38;2;32;148;243m-0.00291428\u001b[0m \u001b[38;2;32;148;243m-0.00230536\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0507541\u001b[0m   \u001b[38;2;32;148;243m0.00773885\u001b[0m \u001b[38;2;32;148;243m-0.08504023\u001b[0m \u001b[38;2;32;148;243m-0.06727142\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00199336\u001b[0m \u001b[38;2;32;148;243m0.00863884\u001b[0m \u001b[38;2;32;148;243m0.00459806\u001b[0m \u001b[38;2;32;148;243m0.00080989\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m6.83114666e-05\u001b[0m \u001b[38;2;32;148;243m2.96048251e-04\u001b[0m \u001b[38;2;32;148;243m1.57573049e-04\u001b[0m \u001b[38;2;32;148;243m2.77545685e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 41                                                                                          \n\n[07:57:36] TRAIN STEP: 42                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:36]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m45.08247249\u001b[0m \u001b[38;2;32;148;243m-218.94467148\u001b[0m  \u001b[38;2;32;148;243m-40.42705107\u001b[0m  \u001b[38;2;32;148;243m-45.87979538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.88875382\u001b[0m \u001b[38;2;32;148;243m-221.68344916\u001b[0m  \u001b[38;2;32;148;243m-57.74491095\u001b[0m  \u001b[38;2;32;148;243m-58.84500785\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.72697675\u001b[0m \u001b[38;2;32;148;243m-221.74890706\u001b[0m  \u001b[38;2;32;148;243m-57.85437104\u001b[0m  \u001b[38;2;32;148;243m-58.87851347\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.58233039\u001b[0m \u001b[38;2;32;148;243m-221.80001817\u001b[0m  \u001b[38;2;32;148;243m-57.95455121\u001b[0m  \u001b[38;2;32;148;243m-58.89820102\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.45405754\u001b[0m \u001b[38;2;32;148;243m-221.83648852\u001b[0m  \u001b[38;2;32;148;243m-58.04099729\u001b[0m  \u001b[38;2;32;148;243m-58.90403978\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.6740094\u001b[0m  \u001b[38;2;32;148;243m-221.74836851\u001b[0m  \u001b[38;2;32;148;243m-57.87524269\u001b[0m  \u001b[38;2;32;148;243m-58.87469989\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.90952716\u001b[0m \u001b[38;2;32;148;243m-221.64615476\u001b[0m  \u001b[38;2;32;148;243m-57.69795089\u001b[0m  \u001b[38;2;32;148;243m-58.83046746\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.16189711\u001b[0m \u001b[38;2;32;148;243m-221.53004749\u001b[0m  \u001b[38;2;32;148;243m-57.50675058\u001b[0m  \u001b[38;2;32;148;243m-58.77083429\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.43115449\u001b[0m \u001b[38;2;32;148;243m-221.39974347\u001b[0m  \u001b[38;2;32;148;243m-57.30083285\u001b[0m  \u001b[38;2;32;148;243m-58.69653692\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m45.08247249\u001b[0m \u001b[38;2;32;148;243m-218.94467148\u001b[0m  \u001b[38;2;32;148;243m-40.42705107\u001b[0m  \u001b[38;2;32;148;243m-45.87979538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.9834256\u001b[0m  \u001b[38;2;32;148;243m-221.67081513\u001b[0m  \u001b[38;2;32;148;243m-57.72006693\u001b[0m  \u001b[38;2;32;148;243m-58.76554207\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.91149183\u001b[0m \u001b[38;2;32;148;243m-221.71545445\u001b[0m  \u001b[38;2;32;148;243m-57.79256646\u001b[0m  \u001b[38;2;32;148;243m-58.72944584\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.85490919\u001b[0m \u001b[38;2;32;148;243m-221.74436731\u001b[0m  \u001b[38;2;32;148;243m-57.8533987\u001b[0m   \u001b[38;2;32;148;243m-58.6786763\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.81371571\u001b[0m \u001b[38;2;32;148;243m-221.75770916\u001b[0m  \u001b[38;2;32;148;243m-57.90064845\u001b[0m  \u001b[38;2;32;148;243m-58.61294603\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m24.94740352\u001b[0m \u001b[38;2;32;148;243m-221.69404354\u001b[0m  \u001b[38;2;32;148;243m-57.77196138\u001b[0m  \u001b[38;2;32;148;243m-58.65529608\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.09656817\u001b[0m \u001b[38;2;32;148;243m-221.61617355\u001b[0m  \u001b[38;2;32;148;243m-57.62947867\u001b[0m  \u001b[38;2;32;148;243m-58.68317078\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.26184398\u001b[0m \u001b[38;2;32;148;243m-221.52461979\u001b[0m  \u001b[38;2;32;148;243m-57.47290454\u001b[0m  \u001b[38;2;32;148;243m-58.69769633\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m25.44320293\u001b[0m \u001b[38;2;32;148;243m-221.41931996\u001b[0m  \u001b[38;2;32;148;243m-57.30269866\u001b[0m  \u001b[38;2;32;148;243m-58.69763577\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09467178\u001b[0m \u001b[38;2;32;148;243m-0.01263403\u001b[0m \u001b[38;2;32;148;243m-0.02484402\u001b[0m \u001b[38;2;32;148;243m-0.07946579\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18451508\u001b[0m \u001b[38;2;32;148;243m-0.03345261\u001b[0m \u001b[38;2;32;148;243m-0.06180458\u001b[0m \u001b[38;2;32;148;243m-0.14906764\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2725788\u001b[0m  \u001b[38;2;32;148;243m-0.05565086\u001b[0m \u001b[38;2;32;148;243m-0.1011525\u001b[0m  \u001b[38;2;32;148;243m-0.21952472\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35965817\u001b[0m \u001b[38;2;32;148;243m-0.07877937\u001b[0m \u001b[38;2;32;148;243m-0.14034884\u001b[0m \u001b[38;2;32;148;243m-0.29109375\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27339412\u001b[0m \u001b[38;2;32;148;243m-0.05432498\u001b[0m \u001b[38;2;32;148;243m-0.10328132\u001b[0m \u001b[38;2;32;148;243m-0.21940382\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.187041\u001b[0m   \u001b[38;2;32;148;243m-0.02998121\u001b[0m \u001b[38;2;32;148;243m-0.06847222\u001b[0m \u001b[38;2;32;148;243m-0.14729668\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09994687\u001b[0m \u001b[38;2;32;148;243m-0.0054277\u001b[0m  \u001b[38;2;32;148;243m-0.03384605\u001b[0m \u001b[38;2;32;148;243m-0.07313796\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01204845\u001b[0m  \u001b[38;2;32;148;243m0.01957649\u001b[0m  \u001b[38;2;32;148;243m0.00186582\u001b[0m  \u001b[38;2;32;148;243m0.00109885\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09467178\u001b[0m \u001b[38;2;32;148;243m-0.01263403\u001b[0m \u001b[38;2;32;148;243m-0.02484402\u001b[0m \u001b[38;2;32;148;243m-0.07946579\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18451508\u001b[0m \u001b[38;2;32;148;243m-0.03345261\u001b[0m \u001b[38;2;32;148;243m-0.06180458\u001b[0m \u001b[38;2;32;148;243m-0.14906764\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2725788\u001b[0m  \u001b[38;2;32;148;243m-0.05565086\u001b[0m \u001b[38;2;32;148;243m-0.1011525\u001b[0m  \u001b[38;2;32;148;243m-0.21952472\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35965817\u001b[0m \u001b[38;2;32;148;243m-0.07877937\u001b[0m \u001b[38;2;32;148;243m-0.14034884\u001b[0m \u001b[38;2;32;148;243m-0.29109375\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.08626405\u001b[0m \u001b[38;2;32;148;243m0.02445439\u001b[0m \u001b[38;2;32;148;243m0.03706752\u001b[0m \u001b[38;2;32;148;243m0.07168994\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.17261717\u001b[0m \u001b[38;2;32;148;243m0.04879816\u001b[0m \u001b[38;2;32;148;243m0.07187662\u001b[0m \u001b[38;2;32;148;243m0.14379708\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.2597113\u001b[0m  \u001b[38;2;32;148;243m0.07335167\u001b[0m \u001b[38;2;32;148;243m0.10650279\u001b[0m \u001b[38;2;32;148;243m0.21795579\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.34760972\u001b[0m \u001b[38;2;32;148;243m0.09835586\u001b[0m \u001b[38;2;32;148;243m0.14221466\u001b[0m \u001b[38;2;32;148;243m0.2921926\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09467178\u001b[0m \u001b[38;2;32;148;243m-0.01263403\u001b[0m \u001b[38;2;32;148;243m-0.02484402\u001b[0m \u001b[38;2;32;148;243m-0.07946579\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.18451508\u001b[0m \u001b[38;2;32;148;243m-0.03345261\u001b[0m \u001b[38;2;32;148;243m-0.06180458\u001b[0m \u001b[38;2;32;148;243m-0.14906764\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2725788\u001b[0m  \u001b[38;2;32;148;243m-0.05565086\u001b[0m \u001b[38;2;32;148;243m-0.1011525\u001b[0m  \u001b[38;2;32;148;243m-0.21952472\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.35965817\u001b[0m \u001b[38;2;32;148;243m-0.07877937\u001b[0m \u001b[38;2;32;148;243m-0.14034884\u001b[0m \u001b[38;2;32;148;243m-0.29109375\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.27339412\u001b[0m \u001b[38;2;32;148;243m-0.05432498\u001b[0m \u001b[38;2;32;148;243m-0.10328132\u001b[0m \u001b[38;2;32;148;243m-0.21940382\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.187041\u001b[0m   \u001b[38;2;32;148;243m-0.02998121\u001b[0m \u001b[38;2;32;148;243m-0.06847222\u001b[0m \u001b[38;2;32;148;243m-0.14729668\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09994687\u001b[0m \u001b[38;2;32;148;243m-0.0054277\u001b[0m  \u001b[38;2;32;148;243m-0.03384605\u001b[0m \u001b[38;2;32;148;243m-0.07313796\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01204845\u001b[0m  \u001b[38;2;32;148;243m0.01957649\u001b[0m  \u001b[38;2;32;148;243m0.00186582\u001b[0m  \u001b[38;2;32;148;243m0.00109885\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.01204845\u001b[0m  \u001b[38;2;32;148;243m0.01957649\u001b[0m  \u001b[38;2;32;148;243m0.00186582\u001b[0m  \u001b[38;2;32;148;243m0.00109885\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.235780692896638e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00284199\u001b[0m  \u001b[38;2;32;148;243m0.00793582\u001b[0m  \u001b[38;2;32;148;243m0.00717097\u001b[0m  \u001b[38;2;32;148;243m0.00465891\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.0016943\u001b[0m   \u001b[38;2;32;148;243m0.00023331\u001b[0m \u001b[38;2;32;148;243m-0.00275654\u001b[0m \u001b[38;2;32;148;243m-0.00244255\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04944038\u001b[0m  \u001b[38;2;32;148;243m0.00680803\u001b[0m \u001b[38;2;32;148;243m-0.08043712\u001b[0m \u001b[38;2;32;148;243m-0.07127484\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00743408\u001b[0m \u001b[38;2;32;148;243m0.0035648\u001b[0m  \u001b[38;2;32;148;243m0.00570171\u001b[0m \u001b[38;2;32;148;243m0.00128239\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m2.54762047e-04\u001b[0m \u001b[38;2;32;148;243m1.22163862e-04\u001b[0m \u001b[38;2;32;148;243m1.95394465e-04\u001b[0m \u001b[38;2;32;148;243m4.39469331e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 43                                                                                          \n\n[07:57:37] TRAIN STEP: 44                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:37]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m120.82488687\u001b[0m  \u001b[38;2;32;148;243m-80.38012025\u001b[0m \u001b[38;2;32;148;243m-117.15967936\u001b[0m  \u001b[38;2;32;148;243m-56.73565516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.44898882\u001b[0m  \u001b[38;2;32;148;243m-83.71729572\u001b[0m \u001b[38;2;32;148;243m-134.59798425\u001b[0m  \u001b[38;2;32;148;243m-69.69895569\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.43184524\u001b[0m  \u001b[38;2;32;148;243m-83.84781282\u001b[0m \u001b[38;2;32;148;243m-134.73144051\u001b[0m  \u001b[38;2;32;148;243m-69.65093221\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.43349918\u001b[0m  \u001b[38;2;32;148;243m-83.96609418\u001b[0m \u001b[38;2;32;148;243m-134.8506462\u001b[0m   \u001b[38;2;32;148;243m-69.58857939\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.45425475\u001b[0m  \u001b[38;2;32;148;243m-84.07282237\u001b[0m \u001b[38;2;32;148;243m-134.95632605\u001b[0m  \u001b[38;2;32;148;243m-69.51176483\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.55769326\u001b[0m  \u001b[38;2;32;148;243m-84.02587068\u001b[0m \u001b[38;2;32;148;243m-135.11515693\u001b[0m  \u001b[38;2;32;148;243m-69.52300587\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.68058191\u001b[0m  \u001b[38;2;32;148;243m-83.96676659\u001b[0m \u001b[38;2;32;148;243m-135.26063242\u001b[0m  \u001b[38;2;32;148;243m-69.51917375\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.82265078\u001b[0m  \u001b[38;2;32;148;243m-83.89354142\u001b[0m \u001b[38;2;32;148;243m-135.39055237\u001b[0m  \u001b[38;2;32;148;243m-69.50092255\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.98405095\u001b[0m  \u001b[38;2;32;148;243m-83.80279629\u001b[0m \u001b[38;2;32;148;243m-135.50265454\u001b[0m  \u001b[38;2;32;148;243m-69.46834829\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m120.82488687\u001b[0m  \u001b[38;2;32;148;243m-80.38012025\u001b[0m \u001b[38;2;32;148;243m-117.15967936\u001b[0m  \u001b[38;2;32;148;243m-56.73565516\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.55466438\u001b[0m  \u001b[38;2;32;148;243m-83.68789026\u001b[0m \u001b[38;2;32;148;243m-134.57612433\u001b[0m  \u001b[38;2;32;148;243m-69.61969084\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.64720342\u001b[0m  \u001b[38;2;32;148;243m-83.78541926\u001b[0m \u001b[38;2;32;148;243m-134.67928772\u001b[0m  \u001b[38;2;32;148;243m-69.50125134\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.75908795\u001b[0m  \u001b[38;2;32;148;243m-83.8697308\u001b[0m  \u001b[38;2;32;148;243m-134.76893385\u001b[0m  \u001b[38;2;32;148;243m-69.36737332\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.88979462\u001b[0m  \u001b[38;2;32;148;243m-83.94078676\u001b[0m \u001b[38;2;32;148;243m-134.84457667\u001b[0m  \u001b[38;2;32;148;243m-69.21946834\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.88324237\u001b[0m  \u001b[38;2;32;148;243m-83.92860548\u001b[0m \u001b[38;2;32;148;243m-135.03380797\u001b[0m  \u001b[38;2;32;148;243m-69.30044316\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.89561884\u001b[0m  \u001b[38;2;32;148;243m-83.90316738\u001b[0m \u001b[38;2;32;148;243m-135.20938141\u001b[0m  \u001b[38;2;32;148;243m-69.36620395\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.92665192\u001b[0m  \u001b[38;2;32;148;243m-83.86385788\u001b[0m \u001b[38;2;32;148;243m-135.37009709\u001b[0m  \u001b[38;2;32;148;243m-69.41882816\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m100.97673539\u001b[0m  \u001b[38;2;32;148;243m-83.80878115\u001b[0m \u001b[38;2;32;148;243m-135.5148116\u001b[0m   \u001b[38;2;32;148;243m-69.45886986\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10567556\u001b[0m \u001b[38;2;32;148;243m-0.02940546\u001b[0m \u001b[38;2;32;148;243m-0.02185992\u001b[0m \u001b[38;2;32;148;243m-0.07926485\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21535818\u001b[0m \u001b[38;2;32;148;243m-0.06239356\u001b[0m \u001b[38;2;32;148;243m-0.05215279\u001b[0m \u001b[38;2;32;148;243m-0.14968088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32558877\u001b[0m \u001b[38;2;32;148;243m-0.09636339\u001b[0m \u001b[38;2;32;148;243m-0.08171235\u001b[0m \u001b[38;2;32;148;243m-0.22120607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43553987\u001b[0m \u001b[38;2;32;148;243m-0.13203561\u001b[0m \u001b[38;2;32;148;243m-0.11174938\u001b[0m \u001b[38;2;32;148;243m-0.29229649\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3255491\u001b[0m  \u001b[38;2;32;148;243m-0.0972652\u001b[0m  \u001b[38;2;32;148;243m-0.08134897\u001b[0m \u001b[38;2;32;148;243m-0.22256271\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21503693\u001b[0m \u001b[38;2;32;148;243m-0.0635992\u001b[0m  \u001b[38;2;32;148;243m-0.05125101\u001b[0m \u001b[38;2;32;148;243m-0.1529698\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10400114\u001b[0m \u001b[38;2;32;148;243m-0.02968355\u001b[0m \u001b[38;2;32;148;243m-0.02045528\u001b[0m \u001b[38;2;32;148;243m-0.0820944\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00731556\u001b[0m  \u001b[38;2;32;148;243m0.00598486\u001b[0m  \u001b[38;2;32;148;243m0.01215706\u001b[0m \u001b[38;2;32;148;243m-0.00947843\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10567556\u001b[0m \u001b[38;2;32;148;243m-0.02940546\u001b[0m \u001b[38;2;32;148;243m-0.02185992\u001b[0m \u001b[38;2;32;148;243m-0.07926485\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21535818\u001b[0m \u001b[38;2;32;148;243m-0.06239356\u001b[0m \u001b[38;2;32;148;243m-0.05215279\u001b[0m \u001b[38;2;32;148;243m-0.14968088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32558877\u001b[0m \u001b[38;2;32;148;243m-0.09636339\u001b[0m \u001b[38;2;32;148;243m-0.08171235\u001b[0m \u001b[38;2;32;148;243m-0.22120607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43553987\u001b[0m \u001b[38;2;32;148;243m-0.13203561\u001b[0m \u001b[38;2;32;148;243m-0.11174938\u001b[0m \u001b[38;2;32;148;243m-0.29229649\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10999077\u001b[0m \u001b[38;2;32;148;243m0.03477041\u001b[0m \u001b[38;2;32;148;243m0.03040042\u001b[0m \u001b[38;2;32;148;243m0.06973378\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.22050294\u001b[0m \u001b[38;2;32;148;243m0.06843641\u001b[0m \u001b[38;2;32;148;243m0.06049837\u001b[0m \u001b[38;2;32;148;243m0.1393267\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.33153873\u001b[0m \u001b[38;2;32;148;243m0.10235206\u001b[0m \u001b[38;2;32;148;243m0.0912941\u001b[0m  \u001b[38;2;32;148;243m0.21020209\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.44285543\u001b[0m \u001b[38;2;32;148;243m0.13802046\u001b[0m \u001b[38;2;32;148;243m0.12390645\u001b[0m \u001b[38;2;32;148;243m0.28281806\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10567556\u001b[0m \u001b[38;2;32;148;243m-0.02940546\u001b[0m \u001b[38;2;32;148;243m-0.02185992\u001b[0m \u001b[38;2;32;148;243m-0.07926485\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21535818\u001b[0m \u001b[38;2;32;148;243m-0.06239356\u001b[0m \u001b[38;2;32;148;243m-0.05215279\u001b[0m \u001b[38;2;32;148;243m-0.14968088\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.32558877\u001b[0m \u001b[38;2;32;148;243m-0.09636339\u001b[0m \u001b[38;2;32;148;243m-0.08171235\u001b[0m \u001b[38;2;32;148;243m-0.22120607\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.43553987\u001b[0m \u001b[38;2;32;148;243m-0.13203561\u001b[0m \u001b[38;2;32;148;243m-0.11174938\u001b[0m \u001b[38;2;32;148;243m-0.29229649\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.3255491\u001b[0m  \u001b[38;2;32;148;243m-0.0972652\u001b[0m  \u001b[38;2;32;148;243m-0.08134897\u001b[0m \u001b[38;2;32;148;243m-0.22256271\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.21503693\u001b[0m \u001b[38;2;32;148;243m-0.0635992\u001b[0m  \u001b[38;2;32;148;243m-0.05125101\u001b[0m \u001b[38;2;32;148;243m-0.1529698\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10400114\u001b[0m \u001b[38;2;32;148;243m-0.02968355\u001b[0m \u001b[38;2;32;148;243m-0.02045528\u001b[0m \u001b[38;2;32;148;243m-0.0820944\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00731556\u001b[0m  \u001b[38;2;32;148;243m0.00598486\u001b[0m  \u001b[38;2;32;148;243m0.01215706\u001b[0m \u001b[38;2;32;148;243m-0.00947843\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00731556\u001b[0m  \u001b[38;2;32;148;243m0.00598486\u001b[0m  \u001b[38;2;32;148;243m0.01215706\u001b[0m \u001b[38;2;32;148;243m-0.00947843\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.295091598065646e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00255669\u001b[0m  \u001b[38;2;32;148;243m0.00833024\u001b[0m  \u001b[38;2;32;148;243m0.00734708\u001b[0m  \u001b[38;2;32;148;243m0.00485666\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00154346\u001b[0m  \u001b[38;2;32;148;243m0.00020992\u001b[0m \u001b[38;2;32;148;243m-0.00263622\u001b[0m \u001b[38;2;32;148;243m-0.00245675\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04503892\u001b[0m  \u001b[38;2;32;148;243m0.00612545\u001b[0m \u001b[38;2;32;148;243m-0.07692619\u001b[0m \u001b[38;2;32;148;243m-0.07168927\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.01355264\u001b[0m \u001b[38;2;32;148;243m0.0006327\u001b[0m  \u001b[38;2;32;148;243m0.0003954\u001b[0m  \u001b[38;2;32;148;243m0.00245302\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4.64441511e-04\u001b[0m \u001b[38;2;32;148;243m2.16821831e-05\u001b[0m \u001b[38;2;32;148;243m1.35499786e-05\u001b[0m \u001b[38;2;32;148;243m8.40638310e-05\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 45                                                                                          \n\n[07:57:38] TRAIN STEP: 46                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:38]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m10.15674593\u001b[0m \u001b[38;2;32;148;243m-229.7782156\u001b[0m  \u001b[38;2;32;148;243m-199.41260428\u001b[0m   \u001b[38;2;32;148;243m-7.53168592\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.22709283\u001b[0m \u001b[38;2;32;148;243m-232.61536672\u001b[0m \u001b[38;2;32;148;243m-218.57611715\u001b[0m  \u001b[38;2;32;148;243m-21.60021188\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.31483575\u001b[0m \u001b[38;2;32;148;243m-232.68137878\u001b[0m \u001b[38;2;32;148;243m-218.62675399\u001b[0m  \u001b[38;2;32;148;243m-21.6446776\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.3851185\u001b[0m  \u001b[38;2;32;148;243m-232.73202897\u001b[0m \u001b[38;2;32;148;243m-218.66655071\u001b[0m  \u001b[38;2;32;148;243m-21.67507296\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.43760149\u001b[0m \u001b[38;2;32;148;243m-232.76664194\u001b[0m \u001b[38;2;32;148;243m-218.6949896\u001b[0m   \u001b[38;2;32;148;243m-21.69079443\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.39041625\u001b[0m \u001b[38;2;32;148;243m-232.76763588\u001b[0m \u001b[38;2;32;148;243m-218.7120165\u001b[0m   \u001b[38;2;32;148;243m-21.69326403\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.32384235\u001b[0m \u001b[38;2;32;148;243m-232.75399958\u001b[0m \u001b[38;2;32;148;243m-218.71590497\u001b[0m  \u001b[38;2;32;148;243m-21.6800835\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.23898794\u001b[0m \u001b[38;2;32;148;243m-232.72707336\u001b[0m \u001b[38;2;32;148;243m-218.7065521\u001b[0m   \u001b[38;2;32;148;243m-21.65108882\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.13646712\u001b[0m \u001b[38;2;32;148;243m-232.68624622\u001b[0m \u001b[38;2;32;148;243m-218.68362209\u001b[0m  \u001b[38;2;32;148;243m-21.60739353\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[38;2;32;148;243m10.15674593\u001b[0m \u001b[38;2;32;148;243m-229.7782156\u001b[0m  \u001b[38;2;32;148;243m-199.41260428\u001b[0m   \u001b[38;2;32;148;243m-7.53168592\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.13188797\u001b[0m \u001b[38;2;32;148;243m-232.58404038\u001b[0m \u001b[38;2;32;148;243m-218.53631176\u001b[0m  \u001b[38;2;32;148;243m-21.52838041\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.11906447\u001b[0m \u001b[38;2;32;148;243m-232.61731533\u001b[0m \u001b[38;2;32;148;243m-218.53610938\u001b[0m  \u001b[38;2;32;148;243m-21.50981832\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.08922291\u001b[0m \u001b[38;2;32;148;243m-232.63614521\u001b[0m \u001b[38;2;32;148;243m-218.52289796\u001b[0m  \u001b[38;2;32;148;243m-21.47709538\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.04217127\u001b[0m \u001b[38;2;32;148;243m-232.64017045\u001b[0m \u001b[38;2;32;148;243m-218.49665518\u001b[0m  \u001b[38;2;32;148;243m-21.42751084\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.09543195\u001b[0m \u001b[38;2;32;148;243m-232.67357259\u001b[0m \u001b[38;2;32;148;243m-218.56801253\u001b[0m  \u001b[38;2;32;148;243m-21.49694953\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.13024304\u001b[0m \u001b[38;2;32;148;243m-232.69460456\u001b[0m \u001b[38;2;32;148;243m-218.62520443\u001b[0m  \u001b[38;2;32;148;243m-21.54936568\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.14706559\u001b[0m \u001b[38;2;32;148;243m-232.70117806\u001b[0m \u001b[38;2;32;148;243m-218.6696094\u001b[0m   \u001b[38;2;32;148;243m-21.58309844\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-10.14627466\u001b[0m \u001b[38;2;32;148;243m-232.69477256\u001b[0m \u001b[38;2;32;148;243m-218.70164225\u001b[0m  \u001b[38;2;32;148;243m-21.60146162\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09520486\u001b[0m \u001b[38;2;32;148;243m-0.03132634\u001b[0m \u001b[38;2;32;148;243m-0.0398054\u001b[0m  \u001b[38;2;32;148;243m-0.07183147\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19577128\u001b[0m \u001b[38;2;32;148;243m-0.06406345\u001b[0m \u001b[38;2;32;148;243m-0.09064461\u001b[0m \u001b[38;2;32;148;243m-0.13485928\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29589559\u001b[0m \u001b[38;2;32;148;243m-0.09588376\u001b[0m \u001b[38;2;32;148;243m-0.14365275\u001b[0m \u001b[38;2;32;148;243m-0.19797758\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39543022\u001b[0m \u001b[38;2;32;148;243m-0.12647149\u001b[0m \u001b[38;2;32;148;243m-0.19833442\u001b[0m \u001b[38;2;32;148;243m-0.2632836\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2949843\u001b[0m  \u001b[38;2;32;148;243m-0.0940633\u001b[0m  \u001b[38;2;32;148;243m-0.14400397\u001b[0m \u001b[38;2;32;148;243m-0.1963145\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19359931\u001b[0m \u001b[38;2;32;148;243m-0.05939502\u001b[0m \u001b[38;2;32;148;243m-0.09070054\u001b[0m \u001b[38;2;32;148;243m-0.13071782\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09192235\u001b[0m \u001b[38;2;32;148;243m-0.02589531\u001b[0m \u001b[38;2;32;148;243m-0.0369427\u001b[0m  \u001b[38;2;32;148;243m-0.06799038\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00980754\u001b[0m  \u001b[38;2;32;148;243m0.00852633\u001b[0m  \u001b[38;2;32;148;243m0.01802016\u001b[0m \u001b[38;2;32;148;243m-0.00593191\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09520486\u001b[0m \u001b[38;2;32;148;243m-0.03132634\u001b[0m \u001b[38;2;32;148;243m-0.0398054\u001b[0m  \u001b[38;2;32;148;243m-0.07183147\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19577128\u001b[0m \u001b[38;2;32;148;243m-0.06406345\u001b[0m \u001b[38;2;32;148;243m-0.09064461\u001b[0m \u001b[38;2;32;148;243m-0.13485928\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29589559\u001b[0m \u001b[38;2;32;148;243m-0.09588376\u001b[0m \u001b[38;2;32;148;243m-0.14365275\u001b[0m \u001b[38;2;32;148;243m-0.19797758\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39543022\u001b[0m \u001b[38;2;32;148;243m-0.12647149\u001b[0m \u001b[38;2;32;148;243m-0.19833442\u001b[0m \u001b[38;2;32;148;243m-0.2632836\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10044592\u001b[0m \u001b[38;2;32;148;243m0.0324082\u001b[0m  \u001b[38;2;32;148;243m0.05433045\u001b[0m \u001b[38;2;32;148;243m0.0669691\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20183091\u001b[0m \u001b[38;2;32;148;243m0.06707647\u001b[0m \u001b[38;2;32;148;243m0.10763388\u001b[0m \u001b[38;2;32;148;243m0.13256578\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.30350787\u001b[0m \u001b[38;2;32;148;243m0.10057619\u001b[0m \u001b[38;2;32;148;243m0.16139172\u001b[0m \u001b[38;2;32;148;243m0.19529321\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.40523776\u001b[0m \u001b[38;2;32;148;243m0.13499783\u001b[0m \u001b[38;2;32;148;243m0.21635457\u001b[0m \u001b[38;2;32;148;243m0.25735168\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09520486\u001b[0m \u001b[38;2;32;148;243m-0.03132634\u001b[0m \u001b[38;2;32;148;243m-0.0398054\u001b[0m  \u001b[38;2;32;148;243m-0.07183147\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19577128\u001b[0m \u001b[38;2;32;148;243m-0.06406345\u001b[0m \u001b[38;2;32;148;243m-0.09064461\u001b[0m \u001b[38;2;32;148;243m-0.13485928\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.29589559\u001b[0m \u001b[38;2;32;148;243m-0.09588376\u001b[0m \u001b[38;2;32;148;243m-0.14365275\u001b[0m \u001b[38;2;32;148;243m-0.19797758\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.39543022\u001b[0m \u001b[38;2;32;148;243m-0.12647149\u001b[0m \u001b[38;2;32;148;243m-0.19833442\u001b[0m \u001b[38;2;32;148;243m-0.2632836\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2949843\u001b[0m  \u001b[38;2;32;148;243m-0.0940633\u001b[0m  \u001b[38;2;32;148;243m-0.14400397\u001b[0m \u001b[38;2;32;148;243m-0.1963145\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.19359931\u001b[0m \u001b[38;2;32;148;243m-0.05939502\u001b[0m \u001b[38;2;32;148;243m-0.09070054\u001b[0m \u001b[38;2;32;148;243m-0.13071782\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.09192235\u001b[0m \u001b[38;2;32;148;243m-0.02589531\u001b[0m \u001b[38;2;32;148;243m-0.0369427\u001b[0m  \u001b[38;2;32;148;243m-0.06799038\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00980754\u001b[0m  \u001b[38;2;32;148;243m0.00852633\u001b[0m  \u001b[38;2;32;148;243m0.01802016\u001b[0m \u001b[38;2;32;148;243m-0.00593191\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00980754\u001b[0m  \u001b[38;2;32;148;243m0.00852633\u001b[0m  \u001b[38;2;32;148;243m0.01802016\u001b[0m \u001b[38;2;32;148;243m-0.00593191\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.249904370901665e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00249081\u001b[0m  \u001b[38;2;32;148;243m0.00863583\u001b[0m  \u001b[38;2;32;148;243m0.00730841\u001b[0m  \u001b[38;2;32;148;243m0.00507512\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00190839\u001b[0m  \u001b[38;2;32;148;243m0.00011151\u001b[0m \u001b[38;2;32;148;243m-0.00263163\u001b[0m \u001b[38;2;32;148;243m-0.00243161\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.05568786\u001b[0m  \u001b[38;2;32;148;243m0.00325387\u001b[0m \u001b[38;2;32;148;243m-0.07679241\u001b[0m \u001b[38;2;32;148;243m-0.07095555\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00386778\u001b[0m \u001b[38;2;32;148;243m0.00657023\u001b[0m \u001b[38;2;32;148;243m0.00308145\u001b[0m \u001b[38;2;32;148;243m0.00856097\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00013255\u001b[0m \u001b[38;2;32;148;243m0.00022516\u001b[0m \u001b[38;2;32;148;243m0.0001056\u001b[0m  \u001b[38;2;32;148;243m0.00029338\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 47                                                                                          \n\n[07:57:39] TRAIN STEP: 48                                                                                          \n\n\u001b[38;2;105;105;105m[07/10/23 07:57:39]\u001b[0m\u001b[34m[INFO]\u001b[0m\u001b[2;38;2;144;144;144m[\u001b[0m\u001b[2;38;2;144;144;144mcommon.py\u001b[0m\u001b[2;38;2;144;144;144m:\u001b[0m\u001b[2;38;2;144;144;144m97\u001b[0m\u001b[2;38;2;144;144;144m]\u001b[0m - energy: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m7.36263574\u001b[0m \u001b[38;2;32;148;243m-110.8740819\u001b[0m  \u001b[38;2;32;148;243m-134.56757381\u001b[0m \u001b[38;2;32;148;243m-138.70569471\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-14.02149814\u001b[0m \u001b[38;2;32;148;243m-113.02669004\u001b[0m \u001b[38;2;32;148;243m-153.51544871\u001b[0m \u001b[38;2;32;148;243m-152.45722335\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-14.08668762\u001b[0m \u001b[38;2;32;148;243m-113.05181156\u001b[0m \u001b[38;2;32;148;243m-153.56075138\u001b[0m \u001b[38;2;32;148;243m-152.47923199\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-14.13392908\u001b[0m \u001b[38;2;32;148;243m-113.06433546\u001b[0m \u001b[38;2;32;148;243m-153.58899227\u001b[0m \u001b[38;2;32;148;243m-152.48700377\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-14.16258838\u001b[0m \u001b[38;2;32;148;243m-113.06065644\u001b[0m \u001b[38;2;32;148;243m-153.60185673\u001b[0m \u001b[38;2;32;148;243m-152.47998551\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-14.0554813\u001b[0m  \u001b[38;2;32;148;243m-113.09346307\u001b[0m \u001b[38;2;32;148;243m-153.50577637\u001b[0m \u001b[38;2;32;148;243m-152.39727388\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.93091566\u001b[0m \u001b[38;2;32;148;243m-113.1092577\u001b[0m  \u001b[38;2;32;148;243m-153.39433411\u001b[0m \u001b[38;2;32;148;243m-152.30002726\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.7889218\u001b[0m  \u001b[38;2;32;148;243m-113.11145403\u001b[0m \u001b[38;2;32;148;243m-153.26921104\u001b[0m \u001b[38;2;32;148;243m-152.18820749\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.63012791\u001b[0m \u001b[38;2;32;148;243m-113.10198911\u001b[0m \u001b[38;2;32;148;243m-153.13019419\u001b[0m \u001b[38;2;32;148;243m-152.06212176\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogprob: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m   \u001b[38;2;32;148;243m7.36263574\u001b[0m \u001b[38;2;32;148;243m-110.8740819\u001b[0m  \u001b[38;2;32;148;243m-134.56757381\u001b[0m \u001b[38;2;32;148;243m-138.70569471\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.91661817\u001b[0m \u001b[38;2;32;148;243m-112.99635708\u001b[0m \u001b[38;2;32;148;243m-153.49891346\u001b[0m \u001b[38;2;32;148;243m-152.37632023\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.88031232\u001b[0m \u001b[38;2;32;148;243m-112.98328332\u001b[0m \u001b[38;2;32;148;243m-153.52751651\u001b[0m \u001b[38;2;32;148;243m-152.32566146\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.8252355\u001b[0m  \u001b[38;2;32;148;243m-112.95702826\u001b[0m \u001b[38;2;32;148;243m-153.54035112\u001b[0m \u001b[38;2;32;148;243m-152.26239636\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.75068682\u001b[0m \u001b[38;2;32;148;243m-112.91669689\u001b[0m \u001b[38;2;32;148;243m-153.53809365\u001b[0m \u001b[38;2;32;148;243m-152.18323152\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.74708251\u001b[0m \u001b[38;2;32;148;243m-112.98494292\u001b[0m \u001b[38;2;32;148;243m-153.45570978\u001b[0m \u001b[38;2;32;148;243m-152.1746215\u001b[0m \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.72595966\u001b[0m \u001b[38;2;32;148;243m-113.03786467\u001b[0m \u001b[38;2;32;148;243m-153.35744618\u001b[0m \u001b[38;2;32;148;243m-152.15229908\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.68718583\u001b[0m \u001b[38;2;32;148;243m-113.07703105\u001b[0m \u001b[38;2;32;148;243m-153.24791401\u001b[0m \u001b[38;2;32;148;243m-152.11639257\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m-13.63130354\u001b[0m \u001b[38;2;32;148;243m-113.10312522\u001b[0m \u001b[38;2;32;148;243m-153.12666469\u001b[0m \u001b[38;2;32;148;243m-152.0668372\u001b[0m \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10487997\u001b[0m \u001b[38;2;32;148;243m-0.03033296\u001b[0m \u001b[38;2;32;148;243m-0.01653525\u001b[0m \u001b[38;2;32;148;243m-0.08090312\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2063753\u001b[0m  \u001b[38;2;32;148;243m-0.06852823\u001b[0m \u001b[38;2;32;148;243m-0.03323487\u001b[0m \u001b[38;2;32;148;243m-0.15357053\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30869358\u001b[0m \u001b[38;2;32;148;243m-0.1073072\u001b[0m  \u001b[38;2;32;148;243m-0.04864114\u001b[0m \u001b[38;2;32;148;243m-0.22460741\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41190155\u001b[0m \u001b[38;2;32;148;243m-0.14395956\u001b[0m \u001b[38;2;32;148;243m-0.06376308\u001b[0m \u001b[38;2;32;148;243m-0.29675398\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30839879\u001b[0m \u001b[38;2;32;148;243m-0.10852015\u001b[0m \u001b[38;2;32;148;243m-0.05006659\u001b[0m \u001b[38;2;32;148;243m-0.22265237\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20495601\u001b[0m \u001b[38;2;32;148;243m-0.07139304\u001b[0m \u001b[38;2;32;148;243m-0.03688793\u001b[0m \u001b[38;2;32;148;243m-0.14772817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10173597\u001b[0m \u001b[38;2;32;148;243m-0.03442298\u001b[0m \u001b[38;2;32;148;243m-0.02129703\u001b[0m \u001b[38;2;32;148;243m-0.07181491\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00117563\u001b[0m  \u001b[38;2;32;148;243m0.00113611\u001b[0m \u001b[38;2;32;148;243m-0.0035295\u001b[0m   \u001b[38;2;32;148;243m0.00471544\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldf: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10487997\u001b[0m \u001b[38;2;32;148;243m-0.03033296\u001b[0m \u001b[38;2;32;148;243m-0.01653525\u001b[0m \u001b[38;2;32;148;243m-0.08090312\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2063753\u001b[0m  \u001b[38;2;32;148;243m-0.06852823\u001b[0m \u001b[38;2;32;148;243m-0.03323487\u001b[0m \u001b[38;2;32;148;243m-0.15357053\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30869358\u001b[0m \u001b[38;2;32;148;243m-0.1073072\u001b[0m  \u001b[38;2;32;148;243m-0.04864114\u001b[0m \u001b[38;2;32;148;243m-0.22460741\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41190155\u001b[0m \u001b[38;2;32;148;243m-0.14395956\u001b[0m \u001b[38;2;32;148;243m-0.06376308\u001b[0m \u001b[38;2;32;148;243m-0.29675398\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsldb: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.         \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.10350276\u001b[0m \u001b[38;2;32;148;243m0.0354394\u001b[0m  \u001b[38;2;32;148;243m0.01369649\u001b[0m \u001b[38;2;32;148;243m0.07410161\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.20694555\u001b[0m \u001b[38;2;32;148;243m0.07256652\u001b[0m \u001b[38;2;32;148;243m0.02687515\u001b[0m \u001b[38;2;32;148;243m0.14902581\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.31016558\u001b[0m \u001b[38;2;32;148;243m0.10953658\u001b[0m \u001b[38;2;32;148;243m0.04246605\u001b[0m \u001b[38;2;32;148;243m0.22493907\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.41307718\u001b[0m \u001b[38;2;32;148;243m0.14509566\u001b[0m \u001b[38;2;32;148;243m0.06023357\u001b[0m \u001b[38;2;32;148;243m0.30146942\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nsld: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m, \u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.          \u001b[38;2;32;148;243m0\u001b[0m.        \u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10487997\u001b[0m \u001b[38;2;32;148;243m-0.03033296\u001b[0m \u001b[38;2;32;148;243m-0.01653525\u001b[0m \u001b[38;2;32;148;243m-0.08090312\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.2063753\u001b[0m  \u001b[38;2;32;148;243m-0.06852823\u001b[0m \u001b[38;2;32;148;243m-0.03323487\u001b[0m \u001b[38;2;32;148;243m-0.15357053\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30869358\u001b[0m \u001b[38;2;32;148;243m-0.1073072\u001b[0m  \u001b[38;2;32;148;243m-0.04864114\u001b[0m \u001b[38;2;32;148;243m-0.22460741\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.41190155\u001b[0m \u001b[38;2;32;148;243m-0.14395956\u001b[0m \u001b[38;2;32;148;243m-0.06376308\u001b[0m \u001b[38;2;32;148;243m-0.29675398\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.30839879\u001b[0m \u001b[38;2;32;148;243m-0.10852015\u001b[0m \u001b[38;2;32;148;243m-0.05006659\u001b[0m \u001b[38;2;32;148;243m-0.22265237\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.20495601\u001b[0m \u001b[38;2;32;148;243m-0.07139304\u001b[0m \u001b[38;2;32;148;243m-0.03688793\u001b[0m \u001b[38;2;32;148;243m-0.14772817\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.10173597\u001b[0m \u001b[38;2;32;148;243m-0.03442298\u001b[0m \u001b[38;2;32;148;243m-0.02129703\u001b[0m \u001b[38;2;32;148;243m-0.07181491\u001b[0m\u001b[1m]\u001b[0m\n \u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00117563\u001b[0m  \u001b[38;2;32;148;243m0.00113611\u001b[0m \u001b[38;2;32;148;243m-0.0035295\u001b[0m   \u001b[38;2;32;148;243m0.00471544\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\nxeps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nveps: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m \u001b[38;2;32;148;243m0.001\u001b[0m\u001b[1m]\u001b[0m\nacc: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nsumlogdet: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00117563\u001b[0m  \u001b[38;2;32;148;243m0.00113611\u001b[0m \u001b[38;2;32;148;243m-0.0035295\u001b[0m   \u001b[38;2;32;148;243m0.00471544\u001b[0m\u001b[1m]\u001b[0m\nbeta: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[38;2;32;148;243m6.0\u001b[0m\nacc_mask: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m. \u001b[38;2;32;148;243m1\u001b[0m.\u001b[1m]\u001b[0m\nloss: \u001b[3;38;2;255;0;255mNone\u001b[0m \u001b[3;38;2;255;0;255mNone\u001b[0m \n\u001b[38;2;32;148;243m-9.236717849885805e-05\u001b[0m\nplaqs: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m-0.00234236\u001b[0m  \u001b[38;2;32;148;243m0.00869283\u001b[0m  \u001b[38;2;32;148;243m0.00738453\u001b[0m  \u001b[38;2;32;148;243m0.00525129\u001b[0m\u001b[1m]\u001b[0m\nsinQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.00163193\u001b[0m  \u001b[38;2;32;148;243m0.00023077\u001b[0m \u001b[38;2;32;148;243m-0.00261078\u001b[0m \u001b[38;2;32;148;243m-0.00241911\u001b[0m\u001b[1m]\u001b[0m\nintQ: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m \u001b[38;2;32;148;243m0.04762047\u001b[0m  \u001b[38;2;32;148;243m0.0067341\u001b[0m  \u001b[38;2;32;148;243m-0.07618373\u001b[0m \u001b[38;2;32;148;243m-0.07059076\u001b[0m\u001b[1m]\u001b[0m\ndQint: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m0.00388472\u001b[0m \u001b[38;2;32;148;243m0.00230856\u001b[0m \u001b[38;2;32;148;243m0.00034175\u001b[0m \u001b[38;2;32;148;243m0.00356939\u001b[0m\u001b[1m]\u001b[0m\ndQsin: \u001b[1;38;2;255;0;255mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float64 \n\u001b[1m[\u001b[0m\u001b[38;2;32;148;243m1.33127299e-04\u001b[0m \u001b[38;2;32;148;243m7.91132352e-05\u001b[0m \u001b[38;2;32;148;243m1.17115752e-05\u001b[0m \u001b[38;2;32;148;243m1.22320953e-04\u001b[0m\u001b[1m]\u001b[0m\n           TRAIN STEP: 49                                                                                          \n\n[07:57:40] checkSU(x_train): (tensor[4] f64 x‚àà[3.858e-16, 4.047e-16] Œº=3.933e-16 œÉ=8.569e-18 [3.951e-16, 3.858e-16,\n           3.877e-16, 4.047e-16], tensor[4] f64 x‚àà[1.270e-15, 1.337e-15] Œº=1.305e-15 œÉ=2.739e-17 [1.303e-15,       \n           1.337e-15, 1.270e-15, 1.310e-15])                                                                       \n\n           Saving energy to plots-4dSU3/train                                                                      \n\n\n\n\nsvg\n\n\n           Saving logprob to plots-4dSU3/train                                                                     \n\n\n\n\nsvg\n\n\n           Saving logdet to plots-4dSU3/train                                                                      \n\n\n\n\nsvg\n\n\n           Saving sldf to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n[07:57:41] Saving sldb to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n           Saving sld to plots-4dSU3/train                                                                         \n\n\n\n\nsvg\n\n\n           Saving xeps to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n           Saving veps to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n[07:57:42] Saving acc to plots-4dSU3/train                                                                         \n\n\n\n\nsvg\n\n\n           Saving sumlogdet to plots-4dSU3/train                                                                   \n\n\n\n\nsvg\n\n\n           Saving beta to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n           Saving acc_mask to plots-4dSU3/train                                                                    \n\n\n\n\nsvg\n\n\n[07:57:43] Saving loss to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n           Saving plaqs to plots-4dSU3/train                                                                       \n\n\n\n\nsvg\n\n\n           Saving sinQ to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n[07:57:44] Saving intQ to plots-4dSU3/train                                                                        \n\n\n\n\nsvg\n\n\n           Saving dQint to plots-4dSU3/train                                                                       \n\n\n\n\nsvg\n\n\n           Saving dQsin to plots-4dSU3/train                                                                       \n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "4dSU3nb",
      "üï∏Ô∏è l2hmc-qcd Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/index.html",
    "href": "posts/ai-for-physics/index.html",
    "title": "‚öõÔ∏è AI for Physics",
    "section": "",
    "text": "CitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {‚öõÔ∏è {AI} for {Physics}},\n  url = {https://samforeman.me/posts/ai-for-physics/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äú‚öõÔ∏è AI for Physics.‚Äù https://samforeman.me/posts/ai-for-physics/."
  },
  {
    "objectID": "posts/AuroraGPT/startup-times/index.html#response",
    "href": "posts/AuroraGPT/startup-times/index.html#response",
    "title": "üê¢ Starting Up Distributed Training on Aurora",
    "section": "Response",
    "text": "Response\n\nIn Measuring / Calculating Startup Time,I provide a summary of how the startup time is identified and calculated.\nI‚Äôm not sure exactly I understand\n\nWill the measurement methodology be the same for distributed training? For examples, we can measure the start-up time for the rank0?\n\nThe startup time is being measured for distributed training (logs only created on RANK = 0)\nI discuss in Minimal Working Example a minimal example that can be used to measure the startup times.\n\nThis is using a library I‚Äôve been working on, ezpz that is designed to help simplify the process of setting up / initializing distributed training across many GPUs.\n\n\n\nMeasuring / Calculating Startup Time\n\nThe startup timing was identified by parsing the logfiles from existing runs and calculating the difference \\delta t = t_{1} - t_{0},\n\nt_{0} is the time stamp at the very beginning of the shell script (defined here) which then launches\nmpiexec ${mpi-args} python3 [...]\n\nt_{0} appears in the logfile as:\nJob started at: 2023-11-02-183323 on x3004c0s13b0n0\n\nt_{1} is identified as the timestamp associated with the completion of the first training step\n\nt_{1} appears in the logfile as:\n[2023-11-02 18:34:13,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]\n\n\nBelow is an example of the bash script use to parse the logfiles and identify these timestamps:\n  $ for f in $(tail -5 logfiles) ; do echo $f; cat $f | grep -E \"Job started|step=0\\,\" | uniq ; echo \"\\n\" ; done\n  /lus/grand/projects/datascience/foremans/locations/polaris/projects/argonne-lcf/Megatron-DeepSpeed/outputs/gpt_actCkpt_GPT1T_4L_z1_seqlen2048_mp8_pp2_sp1_nl4_hs25600_gb16_mb1/logs/foremans-x3004c0s13b0n0-nhosts4-ngpu16-2023-11-02-183323.log\n  Job started at: 2023-11-02-183323 on x3004c0s13b0n0\n  [2023-11-02 18:34:13,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]\n\n  /lus/grand/projects/datascience/foremans/locations/polaris/projects/argonne-lcf/Megatron-DeepSpeed/outputs/gpt_SP_actCkpt_GPT125M_z0_seqlen2048_mp16_pp1_sp1_nl12_hs768_gb1_mb1/logs/foremans-x3015c0s37b0n0-nhosts4-ngpu16-2023-11-02-184240.log\n  Job started at: 2023-11-02-184240 on x3015c0s37b0n0\n\n  /lus/grand/projects/datascience/foremans/locations/polaris/projects/argonne-lcf/Megatron-DeepSpeed/outputs/gpt_SP_actCkpt_GPT125M_z0_seqlen2048_mp16_pp1_sp1_nl12_hs768_gb1_mb1/logs/foremans-x3015c0s37b0n0-nhosts4-ngpu16-2023-11-02-184259.log\n  Job started at: 2023-11-02-184259 on x3015c0s37b0n0\n  [2023-11-02 18:43:23,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]\n\n  /lus/grand/projects/datascience/foremans/locations/polaris/projects/argonne-lcf/Megatron-DeepSpeed/outputs/gpt_SP_actCkpt_GPT125M_z0_seqlen2048_mp16_pp1_sp1_nl12_hs768_gb1_mb1/logs/foremans-x3004c0s13b0n0-nhosts4-ngpu16-2023-11-02-184407.log\n  Job started at: 2023-11-02-184407 on x3004c0s13b0n0\n  [2023-11-02 18:44:32,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]\n\n  /lus/grand/projects/datascience/foremans/locations/polaris/projects/argonne-lcf/Megatron-DeepSpeed/outputs/gpt_actCkpt_GPT1T_4L_z1_seqlen2048_mp8_pp2_sp1_nl4_hs25600_gb16_mb2/logs/foremans-x3108c0s25b1n0-nhosts2-ngpu8-2023-11-02-192739.log\n  Job started at: 2023-11-02-192739 on x3108c0s25b1n0\n\n\n\n\n\n\n\nTip Startup Times (Perlmutter)\n\n\n\n\n\n\n\n\nTable¬†1: Startup times on Perlmutter\n\n\n\n\nStartup times on Perlmutter\n\n\n\n\n\n\n\n\n\n\n\n\n****\nmodel_size\nworld_size\nstart\nstop\nt0\nt1\ndt\n\n\n\n\nforemans-nid008217-nhosts2-ngpu8-2023-10-05-191101.log\nGPT1T_1L\n8\n2023-10-05-191101\n2023-10-05-191215\n191101\n191215\n114\n\n\nforemans-nid008217-nhosts2-ngpu8-2023-10-05-191400.log\nGPT1T_1L\n8\n2023-10-05-191400\n2023-10-05-191511\n191400\n191511\n111\n\n\nforemans-nid008217-nhosts2-ngpu8-2023-10-05-191707.log\nGPT1T_1L\n8\n2023-10-05-191707\n2023-10-05-191817\n191707\n191817\n110\n\n\nforemans-nid008553-nhosts2-ngpu8-2023-10-15-114506.log\nGPT1T_2L\n8\n2023-10-15-114506\n2023-10-15-114616\n114506\n114616\n110\n\n\nforemans-nid008572-nhosts2-ngpu8-2023-10-15-133531.log\nGPT2_7B\n8\n2023-10-15-133531\n2023-10-15-133745\n133531\n133745\n214\n\n\nforemans-nid008572-nhosts2-ngpu8-2023-10-15-135041.log\nGPT2_7B\n8\n2023-10-15-135041\n2023-10-15-135255\n135041\n135255\n214\n\n\nforemans-nid008572-nhosts2-ngpu8-2023-10-15-140806.log\nGPT2_7B\n8\n2023-10-15-140806\n2023-10-15-141236\n140806\n141236\n430\n\n\nforemans-nid008572-nhosts2-ngpu8-2023-10-15-143120.log\nGPT2_7B\n8\n2023-10-15-143120\n2023-10-15-143655\n143120\n143655\n535\n\n\nforemans-nid008268-nhosts2-ngpu8-2023-10-15-154337.log\nGPT2_7B\n8\n2023-10-15-154337\n2023-10-15-154446\n154337\n154446\n109\n\n\nforemans-nid008268-nhosts2-ngpu8-2023-10-15-154943.log\nGPT1T_1L\n8\n2023-10-15-154943\n2023-10-15-155317\n154943\n155317\n374\n\n\nforemans-nid008268-nhosts2-ngpu8-2023-10-15-162315.log\nGPT1T_1L\n8\n2023-10-15-162315\n2023-10-15-162441\n162315\n162441\n126\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-180714.log\nGPT2_7B\n8\n2023-10-15-180714\n2023-10-15-180805\n180714\n180805\n91\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-181733.log\nGPT2_7B\n8\n2023-10-15-181733\n2023-10-15-181834\n181733\n181834\n101\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-182228.log\nGPT1T_1L\n8\n2023-10-15-182228\n2023-10-15-183031\n182228\n183031\n803\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-183345.log\nGPT1T_2L\n8\n2023-10-15-183345\n2023-10-15-183750\n183345\n183750\n405\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-184442.log\nGPT1T_2L\n8\n2023-10-15-184442\n2023-10-15-184727\n184442\n184727\n285\n\n\nforemans-login12-nhosts2-ngpu8-2023-10-15-185952.log\nGPT1T_1L\n8\n2023-10-15-185952\n2023-10-15-190046\n185952\n190046\n4094\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-15-191508.log\nGPT2_7B\n8\n2023-10-15-191508\n2023-10-15-191608\n191508\n191608\n100\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-15-192404.log\nGPT2_7B\n8\n2023-10-15-192404\n2023-10-15-192504\n192404\n192504\n100\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-15-193041.log\nGPT2_7B\n8\n2023-10-15-193041\n2023-10-15-193137\n193041\n193137\n96\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-15-193448.log\nGPT2_7B\n8\n2023-10-15-193448\n2023-10-15-193540\n193448\n193540\n92\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-195802.log\nGPT1T_1L\n16\n2023-10-15-195802\n2023-10-15-195904\n195802\n195904\n102\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-200019.log\nGPT2_7B\n16\n2023-10-15-200019\n2023-10-15-200258\n200019\n200258\n239\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-200902.log\nGPT2_7B\n16\n2023-10-15-200902\n2023-10-15-201239\n200902\n201239\n337\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-201524.log\nGPT2_7B\n16\n2023-10-15-201524\n2023-10-15-201612\n201524\n201612\n88\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-201834.log\nGPT2_7B\n16\n2023-10-15-201834\n2023-10-15-201923\n201834\n201923\n89\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-202402.log\nGPT2_7B\n16\n2023-10-15-202402\n2023-10-15-202501\n202402\n202501\n99\n\n\nforemans-login12-nhosts4-ngpu16-2023-10-15-202606.log\nGPT2_7B\n16\n2023-10-15-202606\n2023-10-15-202713\n202606\n202713\n107\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-16-084033.log\nGPT1T_1L\n8\n2023-10-16-084033\n2023-10-16-084212\n84033\n84212\n179\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-16-084628.log\nGPT1T_1L\n8\n2023-10-16-084628\n2023-10-16-084728\n84628\n84728\n100\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-16-085401.log\nGPT1T_1L\n8\n2023-10-16-085401\n2023-10-16-085505\n85401\n85505\n104\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-16-090142.log\nGPT1T_1L\n8\n2023-10-16-090142\n2023-10-16-090305\n90142\n90305\n163\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-16-093404.log\nactCkpt_GPT13B\n8\n2023-10-16-093404\n2023-10-16-093504\n93404\n93504\n100\n\n\nforemans-nid008572-nhosts4-ngpu16-2023-10-16-101437.log\nGPT1T_1L\n16\n2023-10-16-101437\n2023-10-16-101549\n101437\n101549\n112\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-101512.log\nGPT1T_1L\n16\n2023-10-16-101512\n2023-10-16-101615\n101512\n101615\n103\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-102217.log\nactCkpt_GPT25B\n16\n2023-10-16-102217\n2023-10-16-102452\n102217\n102452\n235\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-102750.log\nactCkpt_GPT25B\n16\n2023-10-16-102750\n2023-10-16-103243\n102750\n103243\n493\n\n\nforemans-nid008572-nhosts4-ngpu16-2023-10-16-103113.log\nactCkpt_GPT25B\n16\n2023-10-16-103113\n2023-10-16-103237\n103113\n103237\n124\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-104037.log\nactCkpt_GPT25B\n16\n2023-10-16-104037\n2023-10-16-104148\n104037\n104148\n111\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-104819.log\nactCkpt_GPT25B\n16\n2023-10-16-104819\n2023-10-16-110002\n104819\n110002\n5183\n\n\nforemans-nid008396-nhosts4-ngpu16-2023-10-16-110119.log\nactCkpt_GPT25B\n16\n2023-10-16-110119\n2023-10-16-110225\n110119\n110225\n106\n\n\nforemans-nid008701-nhosts4-ngpu16-2023-10-16-113715.log\nactCkpt_GPT25B\n16\n2023-10-16-113715\n2023-10-16-113824\n113715\n113824\n109\n\n\nforemans-nid008701-nhosts4-ngpu16-2023-10-16-114236.log\nGPT1T_1L\n16\n2023-10-16-114236\n2023-10-16-114338\n114236\n114338\n102\n\n\nforemans-nid008701-nhosts4-ngpu16-2023-10-16-114610.log\nGPT1T_1L\n16\n2023-10-16-114610\n2023-10-16-114711\n114610\n114711\n101\n\n\nforemans-nid008701-nhosts4-ngpu16-2023-10-16-114819.log\nGPT1T_2L\n16\n2023-10-16-114819\n2023-10-16-114953\n114819\n114953\n134\n\n\nforemans-nid008701-nhosts4-ngpu16-2023-10-16-131058.log\nGPT1T_2L\n16\n2023-10-16-131058\n2023-10-16-131203\n131058\n131203\n145\n\n\nforemans-nid008576-nhosts1-ngpu4-2023-10-16-151427.log\nGPT1T_1L\n4\n2023-10-16-151427\n2023-10-16-151600\n151427\n151600\n173\n\n\nforemans-nid008576-nhosts1-ngpu4-2023-10-16-152528.log\nGPT1T_1L\n4\n2023-10-16-152528\n2023-10-16-152640\n152528\n152640\n112\n\n\nforemans-nid008224-nhosts1-ngpu4-2023-10-16-175717.log\nGPT1T_1L\n4\n2023-10-16-175717\n2023-10-16-175829\n175717\n175829\n112\n\n\nforemans-nid008224-nhosts1-ngpu4-2023-10-16-180457.log\nGPT1T_1L\n4\n2023-10-16-180457\n2023-10-16-180605\n180457\n180605\n148\n\n\nforemans-nid008224-nhosts1-ngpu4-2023-10-16-183116.log\nGPT1T_1L\n4\n2023-10-16-183116\n2023-10-16-183216\n183116\n183216\n100\n\n\nforemans-nid008224-nhosts1-ngpu4-2023-10-16-183921.log\nGPT1T_1L\n4\n2023-10-16-183921\n2023-10-16-184033\n183921\n184033\n112\n\n\nforemans-nid008237-nhosts1-ngpu4-2023-10-16-215614.log\nGPT1T_1L\n4\n2023-10-16-215614\n2023-10-16-215815\n215614\n215815\n201\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-052944.log\nGPT1T_1L\n4\n2023-10-17-052944\n2023-10-17-053139\n52944\n53139\n195\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-053529.log\nGPT1T_1L\n4\n2023-10-17-053529\n2023-10-17-053650\n53529\n53650\n121\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-053910.log\nGPT1T_1L\n4\n2023-10-17-053910\n2023-10-17-054120\n53910\n54120\n210\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-054238.log\nGPT2_7B\n4\n2023-10-17-054238\n2023-10-17-054346\n54238\n54346\n108\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-060418.log\nGPT1T_1L\n4\n2023-10-17-060418\n2023-10-17-060600\n60418\n60600\n182\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-061514.log\nGPT1T_1L\n4\n2023-10-17-061514\n2023-10-17-061653\n61514\n61653\n139\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-062102.log\nGPT1T_1L\n4\n2023-10-17-062102\n2023-10-17-062252\n62102\n62252\n150\n\n\nforemans-nid008385-nhosts1-ngpu4-2023-10-17-062445.log\nGPT1T_1L\n4\n2023-10-17-062445\n2023-10-17-062720\n62445\n62720\n275\n\n\nforemans-nid008333-nhosts2-ngpu8-2023-10-17-064643.log\nGPT1T_1L\n8\n2023-10-17-064643\n2023-10-17-064848\n64643\n64848\n205\n\n\nforemans-nid008333-nhosts2-ngpu8-2023-10-17-065806.log\nGPT1T_2L\n8\n2023-10-17-065806\n2023-10-17-070003\n65806\n70003\n4197\n\n\nforemans-nid008333-nhosts2-ngpu8-2023-10-17-075152.log\nGPT1T_2L\n8\n2023-10-17-075152\n2023-10-17-075502\n75152\n75502\n350\n\n\nforemans-nid008333-nhosts2-ngpu8-2023-10-17-080059.log\nGPT1T_2L\n8\n2023-10-17-080059\n2023-10-17-080434\n80059\n80434\n375\n\n\nforemans-nid008333-nhosts2-ngpu8-2023-10-17-081404.log\nGPT1T_2L\n8\n2023-10-17-081404\n2023-10-17-081920\n81404\n81920\n516\n\n\nforemans-nid008228-nhosts1-ngpu4-2023-10-17-090344.log\nGPT1T_1L\n4\n2023-10-17-090344\n2023-10-17-090714\n90344\n90714\n370\n\n\nforemans-nid008228-nhosts1-ngpu4-2023-10-17-100759.log\nGPT1T_1L\n4\n2023-10-17-100759\n2023-10-17-100957\n100759\n100957\n198\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-182501.log\nGPT1T_1L\n16\n2023-10-17-182501\n2023-10-17-184001\n182501\n184001\n1500\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-193736.log\nGPT1T_1L\n16\n2023-10-17-193736\n2023-10-17-193856\n193736\n193856\n120\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-195432.log\nGPT1T_1L\n16\n2023-10-17-195432\n2023-10-17-195536\n195432\n195536\n104\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-201659.log\nGPT1T_2L\n16\n2023-10-17-201659\n2023-10-17-201823\n201659\n201823\n164\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-202949.log\nGPT1T_2L\n16\n2023-10-17-202949\n2023-10-17-203054\n202949\n203054\n105\n\n\nforemans-nid008404-nhosts4-ngpu16-2023-10-17-205848.log\nGPT1T_1L\n16\n2023-10-17-205848\n2023-10-17-205952\n205848\n205952\n104\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-213244.log\nGPT1T_1L\n32\n2023-10-17-213244\n2023-10-17-213406\n213244\n213406\n162\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-213558.log\nGPT1T_1L\n32\n2023-10-17-213558\n2023-10-17-213720\n213558\n213720\n162\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-214900.log\nGPT1T_2L\n32\n2023-10-17-214900\n2023-10-17-214959\n214900\n214959\n59\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-215201.log\nGPT1T_2L\n32\n2023-10-17-215201\n2023-10-17-215309\n215201\n215309\n108\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-215612.log\nGPT1T_2L\n32\n2023-10-17-215612\n2023-10-17-215726\n215612\n215726\n114\n\n\nforemans-nid008577-nhosts8-ngpu32-2023-10-17-215938.log\nGPT1T_2L\n32\n2023-10-17-215938\n2023-10-17-220044\n215938\n220044\n4106\n\n\nforemans-nid008529-nhosts8-ngpu32-2023-10-18-110001.log\nGPT1T_4L\n32\n2023-10-18-110001\n2023-10-18-110143\n110001\n110143\n142\n\n\nforemans-nid008529-nhosts8-ngpu32-2023-10-18-110424.log\nGPT1T_8L\n32\n2023-10-18-110424\n2023-10-18-110550\n110424\n110550\n126\n\n\nforemans-nid008244-nhosts4-ngpu16-2023-10-18-110821.log\nGPT1T_8L\n16\n2023-10-18-110821\n2023-10-18-110952\n110821\n110952\n131\n\n\nforemans-nid008529-nhosts8-ngpu32-2023-10-18-111345.log\nGPT1T_8L\n32\n2023-10-18-111345\n2023-10-18-111458\n111345\n111458\n113\n\n\nforemans-nid008197-nhosts16-ngpu64-2023-10-18-112531.log\nGPT1T_16L\n64\n2023-10-18-112531\n2023-10-18-112728\n112531\n112728\n197\n\n\nforemans-nid008456-nhosts16-ngpu64-2023-10-18-113119.log\nGPT1T_16L\n64\n2023-10-18-113119\n2023-10-18-113343\n113119\n113343\n224\n\n\nforemans-nid008244-nhosts4-ngpu16-2023-10-18-113131.log\nGPT1T_4L\n16\n2023-10-18-113131\n2023-10-18-113257\n113131\n113257\n126\n\n\nforemans-nid008244-nhosts4-ngpu16-2023-10-18-113920.log\nGPT1T_4L\n16\n2023-10-18-113920\n2023-10-18-114157\n113920\n114157\n237\n\n\nforemans-nid008197-nhosts16-ngpu64-2023-10-18-114549.log\nGPT1T_16L\n64\n2023-10-18-114549\n2023-10-18-114721\n114549\n114721\n172\n\n\nforemans-nid008456-nhosts16-ngpu64-2023-10-18-114636.log\nGPT1T_16L\n64\n2023-10-18-114636\n2023-10-18-114805\n114636\n114805\n169\n\n\nforemans-nid008244-nhosts4-ngpu16-2023-10-18-115808.log\nGPT1T_4L\n16\n2023-10-18-115808\n2023-10-18-120146\n115808\n120146\n4338\n\n\nforemans-nid008456-nhosts16-ngpu64-2023-10-18-123039.log\nGPT1T_16L\n64\n2023-10-18-123039\n2023-10-18-123221\n123039\n123221\n182\n\n\nforemans-nid008389-nhosts2-ngpu8-2023-10-18-123135.log\nGPT1T_4L\n8\n2023-10-18-123135\n2023-10-18-123300\n123135\n123300\n165\n\n\nforemans-nid008244-nhosts4-ngpu16-2023-10-18-123206.log\nGPT1T_4L\n16\n2023-10-18-123206\n2023-10-18-123352\n123206\n123352\n146\n\n\nforemans-nid008456-nhosts16-ngpu64-2023-10-18-125022.log\nGPT1T_16L\n64\n2023-10-18-125022\n2023-10-18-125146\n125022\n125146\n124\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-122736.log\nGPT1T_8L\n32\n2023-10-22-122736\n2023-10-22-122844\n122736\n122844\n108\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-123824.log\nGPT1T_8L\n32\n2023-10-22-123824\n2023-10-22-123945\n123824\n123945\n121\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-130148.log\nGPT1T_8L\n32\n2023-10-22-130148\n2023-10-22-130256\n130148\n130256\n108\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-131746.log\nGPT1T_8L\n32\n2023-10-22-131746\n2023-10-22-131909\n131746\n131909\n163\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-132700.log\nGPT1T_8L\n32\n2023-10-22-132700\n2023-10-22-132817\n132700\n132817\n117\n\n\nforemans-nid008256-nhosts8-ngpu32-2023-10-22-133459.log\nGPT1T_8L\n32\n2023-10-22-133459\n2023-10-22-133708\n133459\n133708\n249\n\n\nforemans-nid008380-nhosts4-ngpu16-2023-10-22-175049.log\nactCkpt_GPT25B\n16\n2023-10-22-175049\n2023-10-22-175230\n175049\n175230\n181\n\n\nforemans-nid008649-nhosts4-ngpu16-2023-10-22-192352.log\nGPT1T_4L\n16\n2023-10-22-192352\n2023-10-22-192530\n192352\n192530\n178\n\n\nforemans-nid008212-nhosts16-ngpu64-2023-10-23-081527.log\nGPT1T_8L\n64\n2023-10-23-081527\n2023-10-23-081702\n81527\n81702\n175\n\n\nforemans-nid008344-nhosts2-ngpu8-2023-10-23-091436.log\nGPT1T_2L\n8\n2023-10-23-091436\n2023-10-23-091610\n91436\n91610\n174\n\n\nforemans-nid008197-nhosts32-ngpu128-2023-10-24-102617.log\nGPT1T_32L\n128\n2023-10-24-102617\n2023-10-24-102826\n102617\n102826\n209\n\n\nforemans-nid008192-nhosts64-ngpu256-2023-10-24-191748.log\nGPT1T_64L\n256\n2023-10-24-191748\n2023-10-24-192021\n191748\n192021\n273\n\n\nforemans-nid008192-nhosts128-ngpu512-2023-10-24-201243.log\nGPT1T_128L\n512\n2023-10-24-201243\n2023-10-24-201629\n201243\n201629\n386\n\n\nforemans-nid008192-nhosts128-ngpu512-2023-10-26-005401.log\nGPT1T_128L\n512\n2023-10-26-005401\n2023-10-26-005811\n5401\n5811\n410\n\n\nforemans-nid008192-nhosts32-ngpu128-2023-10-26-082710.log\nGPT1T_32L\n128\n2023-10-26-082710\n2023-10-26-083049\n82710\n83049\n339\n\n\nforemans-nid008585-nhosts2-ngpu8-2023-10-31-044203.log\nGPT1T_2L\n8\n2023-10-31-044203\n2023-10-31-044533\n44203\n44533\n330\n\n\nforemans-nid008272-nhosts4-ngpu16-2023-10-31-072717.log\nGPT1T_4L\n16\n2023-10-31-072717\n2023-10-31-073131\n72717\n73131\n414\n\n\nforemans-nid008221-nhosts8-ngpu32-2023-10-31-083055.log\nGPT1T_8L\n32\n2023-10-31-083055\n2023-10-31-083545\n83055\n83545\n490\n\n\nforemans-nid008196-nhosts16-ngpu64-2023-10-31-100336.log\nGPT1T_16L\n64\n2023-10-31-100336\n2023-10-31-100848\n100336\n100848\n512\n\n\nforemans-nid008285-nhosts2-ngpu8-2023-11-01-200430.log\nGPT1T_2L\n8\n2023-11-01-200430\n2023-11-01-200829\n200430\n200829\n399\n\n\nforemans-nid008193-nhosts8-ngpu32-2023-11-01-201702.log\nGPT1T_8L\n32\n2023-11-01-201702\n2023-11-01-202131\n201702\n202131\n429\n\n\nforemans-nid008240-nhosts16-ngpu64-2023-11-01-210454.log\nGPT1T_16L\n64\n2023-11-01-210454\n2023-11-01-211007\n210454\n211007\n553\n\n\nforemans-nid008321-nhosts2-ngpu8-2023-11-02-154438.log\nGPT1T_2L\n8\n2023-11-02-154438\n2023-11-02-154949\n154438\n154949\n511\n\n\nforemans-nid008192-nhosts128-ngpu512-2023-11-04-001717.log\nGPT1T_128L\n512\n2023-11-04-001717\n2023-11-04-002124\n1717\n2124\n407",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üê¢ Starting Up Distributed Training on Aurora"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/startup-times/index.html#minimal-working-example",
    "href": "posts/AuroraGPT/startup-times/index.html#minimal-working-example",
    "title": "üê¢ Starting Up Distributed Training on Aurora",
    "section": "Minimal Working Example",
    "text": "Minimal Working Example\n\nAs for 3:\n\nIf we need to report the startup time for the DL applications, do we need to collect measurements using the actual Aurora NRE workloads or some small benchmarking test cases? For example, we can try to recreate the typical start-up scenarios, like library imports, and measure those separately as shown below.\n\n\nI‚Äôve been working on a library to help simplify this:\n ezpz\nMinimal library that handles the initialization of distributed training\n\n¬† Working on Aurora, example:\n\nSetup / Install:\n# launch job\n$ qsub -q EarlyAppAccess -A Aurora_Deployment -l walltime=2:00:00 -l select=4 -I\n\n# load frameworks\n$ module use -a /soft/modulefiles ; module --ignore_cache load frameworks\n$ module load frameworks/.2023.12.15.001\n\n# install `ezpz`\n$ git clone https://github.com/saforem2/ezpz\n$ cd ezpz\n$ mkdir -p venvs/aurora/2023.12.15.001\n$ python3 -m venv venvs/aurora/2023.12.15.001 --system-site-packages\n$ source venvs/aurora/2023.12.15.001/bin/activate\n$ python3 -m pip install -e .\n\n# print job info and define `launch` alias\n$ source ezpz/src/ezpz/bin/savejobenv\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ [Hosts]:\n‚îÇ     ‚Ä¢ x4415c6s5b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov\nx4415c6s6b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov\nx4415c6s7b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov\nx4415c7s0b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ [DIST INFO]:\n‚îÇ     ‚Ä¢ Loading job env from: /home/foremans/.pbsenv\n‚îÇ     ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n‚îÇ     ‚Ä¢ NHOSTS: 4\n‚îÇ     ‚Ä¢ NGPU_PER_HOST: 12\n‚îÇ     ‚Ä¢ NGPUS (NHOSTS x NGPU_PER_HOST): 48\n‚îÇ     ‚Ä¢ DIST_LAUNCH: mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n‚îÇ     ‚Ä¢ Defining alias: launch: aliased to mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLaunch with framework=pytorch, backend=DDP:\n# ----------------------------------------------------------\n# launch + startup on all workers with\n# ‚Ä¢ `framework` ‚àà {`pytorch`, `tensorflow`}\n# ‚Ä¢ `backend` ‚àà {`horovod`, `deepspeed`, `DDP`}\n# where `deepspeed` and `DDP` only available for `pytorch`\n# ----------------------------------------------------------\n$ launch python3 -m ezpz framework=pytorch backend=DDP\n[2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'\n[2023-12-19 13:33:26][INFO][dist.py:243] - Using DDP for distributed training\n[2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 1 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 2 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 3 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 4 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 0 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 5 / 47\n[2023-12-19 13:33:35][INFO][__main__.py:49] - {\n    \"_target_\": \"ezpz.configs.TrainConfig\",\n    \"framework\": \"pytorch\",\n    \"backend\": \"DDP\",\n    \"ds_config_path\": null,\n    \"port\": null,\n    \"seed\": null,\n    \"use_wandb\": true,\n    \"wandb_project_name\": null,\n    \"precision\": null,\n    \"ngpus\": null\n}\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 9 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 10 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 11 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 7 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 8 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 6 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 12 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 13 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 14 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 15 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 18 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 19 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 20 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 21 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 22 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 23 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 24 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 25 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 26 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 27 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 30 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 16 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 17 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 28 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 32 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 33 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 36 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 37 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 38 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 39 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 43 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 46 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 29 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 47 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 31 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 34 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 35 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 42 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 41 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 44 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 45 / 47\n[2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 40 / 47\n[2023-12-19 13:33:47][INFO][dist.py:415] - Setting up wandb from rank: 0\n[2023-12-19 13:33:47][INFO][dist.py:416] - Using: WB PROJECT: ezpz\n[2023-12-19 13:33:58][INFO][dist.py:448] - W&B RUN: [flowing-wood-8](https://wandb.ai/l2hmc-qcd/ezpz/runs/uya29gm5)\n[2023-12-19 13:33:58][INFO][dist.py:490] - Running on x4415c6s5b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov\n[2023-12-19 13:33:58][INFO][dist.py:506] - Reading hosts from /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n[2023-12-19 13:33:58][INFO][__main__.py:57] - Output dir: /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17\n[2023-12-19 13:33:58][CRITICAL][dist.py:519] - üöÄ flowing-wood-8\n[2023-12-19 13:33:58][CRITICAL][dist.py:520] - üîó https://wandb.ai/l2hmc-qcd/ezpz/runs/uya29gm5\n[2023-12-19 13:33:58][CRITICAL][dist.py:521] - üìÇ/: /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/wandb/run-20231219_133354-uya29gm5/files\n[2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/ezpz-pt-DDP-xpu.log to W&B artifact...\n[2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/__main__.log to W&B artifact...\n[2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/main_debug.log to W&B artifact...\n[2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-16/__main__.log to W&B artifact...",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üê¢ Starting Up Distributed Training on Aurora"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/mpi4py-reproducer/index.html",
    "href": "posts/AuroraGPT/mpi4py-reproducer/index.html",
    "title": "üêõ mpi4py bug on Sunspot",
    "section": "",
    "text": "Simple reproducer:\n\nLoad my anl_24_q2_release conda environment:\n#[08:42:38 AM][foremans@x1922c2s3b0n0][~]\n$ eval \"$(~/miniconda3/bin/conda shell.zsh hook)\" ; conda activate anl_24_q2_release\nTry python3 -c 'from mpi4py import MPI'\n\nfails ‚ùå\n\n# [08:44:41 AM][foremans@x1922c2s3b0n0][~][anl_24_q2_release]\n$ python3 -c 'from mpi4py import MPI'\nTraceback (most recent call last):\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nImportError: /home/foremans/miniconda3/envs/anl_24_q2_release/lib/python3.9/site-packages/mpi4py/MPI.cpython-39-x86_64-linux-gnu.so: undefined symbol: MPI_Message_c2f\n[1]    14910 exit 1     python3 -c 'from mpi4py import MPI'\nLoad correct modules:\n# [08:44:58 AM][foremans@x1922c2s3b0n0][~][anl_24_q2_release]\n$ module use /home/ftartagl/graphics-compute-runtime/modulefiles ; module load graphics-compute-runtime/agama-ci-devel-803.29 spack-pe-gcc/0.6.1-23.275.2 gcc/12.2.0 ; module use /soft/preview-modulefiles/24.086.0 ; module load oneapi/release/2024.04.15.001\n     UMD: agama-ci-devel-803.29 successfully loaded:\n     UMD: graphics-compute-runtime/agama-ci-devel-803.29\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) mpich-config/collective-tuning/1024\n\nThe following have been reloaded with a version change:\n  1) intel_compute_runtime/release/agama-devel-736.25 =&gt; intel_compute_runtime/release/775.20     2) mpich/icc-all-pmix-gpu/52.2 =&gt; mpich/icc-all-pmix-gpu/20231026     3) oneapi/eng-compiler/2023.12.15.002 =&gt; oneapi/release/2024.04.15.001\nRetry with new modules:\n\nworks ‚úÖ\n\n# [08:45:01 AM][foremans@x1922c2s3b0n0][~][anl_24_q2_release]\n$ python3 -c 'from mpi4py import MPI; print(MPI.__file__)'\n/home/foremans/miniconda3/envs/anl_24_q2_release/lib/python3.9/site-packages/mpi4py/MPI.cpython-39-x86_64-linux-gnu.so\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2024,\n  author = {Foreman, Sam},\n  title = {üêõ `Mpi4py` Bug on {Sunspot}},\n  date = {2024-05-25},\n  url = {https://samforeman.me/posts/AuroraGPT/mpi4py-reproducer/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2024. ‚Äúüêõ `Mpi4py` Bug on Sunspot.‚Äù May 25,\n2024. https://samforeman.me/posts/AuroraGPT/mpi4py-reproducer/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üêõ `mpi4py` bug on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/index.html",
    "href": "posts/AuroraGPT/index.html",
    "title": "ü§ñ AuroraGPT",
    "section": "",
    "text": "Order By\n      Default\n      \n        When - Oldest\n      \n      \n        When - Newest\n      \n      \n        What\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nWhat\n\n\n\nWhen\n\n\n\nCategories\n\n\n\n\n\n\n\n\nüíæ Converting Checkpoints\n\n\n2024-10-17\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüèîÔ∏è Spike Skipper\n\n\n2024-09-17\n\n\nAuroraGPT\n\n\n\n\n\n\nüé∞ Deterministic flash-attn\n\n\n2024-06-17\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüì∏ flash-attn on Sunspot\n\n\n2024-06-17\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüèéÔ∏è Megatron-DeepSpeed on Intel XPU\n\n\n2024-06-15\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüêõ mpi4py bug on Sunspot\n\n\n2024-05-25\n\n\nAuroraGPT\n\n\n\n\n\n\nüê¢ Starting Up Distributed Training on Aurora\n\n\n2024-03-21\n\n\nAuroraGPT\n\n\n\n\n\n\nüöÇ Loooooooong Sequence Lengths\n\n\n2024-02-12\n\n\nAuroraGPT\n\n\n\n\n\n\nNo matching items\nCitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {ü§ñ {AuroraGPT}},\n  url = {https://samforeman.me/posts/AuroraGPT/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äúü§ñ AuroraGPT.‚Äù https://samforeman.me/posts/AuroraGPT/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/determinstic-flash-attn/index.html",
    "href": "posts/AuroraGPT/determinstic-flash-attn/index.html",
    "title": "üé∞ Deterministic flash-attn",
    "section": "",
    "text": "[NOTE]: For additional details, refer to the W&B Report.\n\nSimple tests to confirm the loss is exactly reproducible across independent runs (when launched with the same seed).\n\nIn particular, we set:\noutput = flash_attn_func(q, k, v, None, self.causal, deterministic=True)\nin all the flash_attn_func(...) calls from megatron/model/transformer.py\nAll experiments ran on Polaris @ ALCF, using:\nmachine: Polaris\nargs.zero_stage: 1\nargs.num_layers: 32\nargs.micro_batch_size: 1\nargs.optimizer: \"adamw\"\nargs.use_flash_attn: true\nenv.DFL_STEM: \"books\"\nenv.GRAD_ACC_STEPS: 8\nenv.WORLD_SIZE: 8\n\n\n\n\n\n\n\nFigure¬†1: Plot of the loss curve for 3 independent runs with deterministic=True\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2024,\n  author = {Foreman, Sam},\n  title = {üé∞ {Deterministic} `Flash-Attn`},\n  date = {2024-06-17},\n  url = {https://samforeman.me/posts/AuroraGPT/determinstic-flash-attn/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2024. ‚Äúüé∞ Deterministic `Flash-Attn`.‚Äù June\n17, 2024. https://samforeman.me/posts/AuroraGPT/determinstic-flash-attn/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üé∞ Deterministic `flash-attn`"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/aurora-gpt/index.html#install-setup",
    "href": "posts/AuroraGPT/aurora-gpt/index.html#install-setup",
    "title": "üèéÔ∏è Megatron-DeepSpeed on Intel XPU",
    "section": "Install / Setup",
    "text": "Install / Setup\n\nSetup script / history:\n\n\nInteractive Session\n\n$ export HTTP_PROXY=http://proxy.alcf.anl.gov:3128\n$ export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\n$ export http_proxy=http://proxy.alcf.anl.gov:3128\n$ export https_proxy=http://proxy.alcf.anl.gov:3128\n\n$ export DRM_LIB=\"$(pwd)/usr/include/libdrm\"\n# $ export PATH=\"${HOME}/miniconda3/bin:$PATH\"\n\n$ conda create --name anl_release_q4 python=3.9 --y\n$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n$ bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n$ eval \"$(${HOME} shell.zsh hook)\"\n\n$ export DRM_LIB=\"$(pwd)/usr/include/libdrm\"\n$ conda config --add channels conda-forge && conda install -c conda-forge mpi4py -y --no-deps && conda install -c conda-forge libssh -y && conda uninstall mpi -y && python3 -m pip install -r requirements.txt && python3 -m pip install *.whl\n\n$ module unload oneapi/eng-compiler/2022.12.30.003\n$ module unload intel_compute_runtime/release/agama-devel-551\n$ module use -a /soft/modulefiles\n$ module load oneapi/release/2023.12.15.001\n$ module use /home/ftartagl/graphics-compute-runtime/modulefiles\n$ module load graphics-compute-runtime/agama-ci-devel-736.9\n# one-liner for modules:\n# module unload oneapi/eng-compiler/2022.12.30.003 && module unload intel_compute_runtime/release/agama-devel-551&& module use -a /soft/modulefiles && module load oneapi/release/2023.12.15.001 && module use /home/ftartagl/graphics-compute-runtime/modulefiles && module load graphics-compute-runtime/agama-ci-devel-736.9\n\n$ cd torch-ccl\n$ ls\n$ COMPUTE_BACKEND=dpcpp python3 setup.py develop |& tee build.log\n$ cd ../\n\n$ cd intel-extension-for-deepspeed\n$ python3 setup.py develop |& tee build.log\n$ cd ../\n\n$ cd DeepSpeed\n$ ls\n$ python3 -m pip install -r requirements/requirements.txt\n$ python3 setup.py develop |& tee build.log",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèéÔ∏è Megatron-DeepSpeed on Intel XPU"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/aurora-gpt/index.html#running",
    "href": "posts/AuroraGPT/aurora-gpt/index.html#running",
    "title": "üèéÔ∏è Megatron-DeepSpeed on Intel XPU",
    "section": "Running",
    "text": "Running\n\nUsing launch\n\nSetup:\n\n\nSetup\n\n$ qsub -q EarlyAppAccess -A Aurora_Deployment -l walltime=08:00:00 -l select=2 -I\nqsub: waiting for job 604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov to start\nqsub: job 604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov ready\n\n$ module unload oneapi/eng-compiler/2022.12.30.003 && module unload intel_compute_runtime/release/agama-devel-551&& module use -a /soft/modulefiles && module load oneapi/release/2023.12.15.001 && module use /home/ftartagl/graphics-compute-runtime/modulefiles && module load graphics-compute-runtime/agama-ci-devel-736.9\n UMD: agama-ci-devel-736.9 successfully loaded:\n UMD: graphics-compute-runtime/agama-ci-devel-736.9\n\n$ eval \"$(/home/foremans/miniconda3/bin/conda shell.zsh hook)\"\n\n$ conda activate anl_release_q4\n\n$ git clone https://github.com/saforem2/ezpz\n$ python3 -m pip install -e \"ezpz[dev]\"\n# [BUG] for some reason, need to run twice ¬Ø\\_(„ÉÑ)_/¬Ø\n$ source ./ezpz/src/ezpz/bin/savejobenv && source ./ezpz/src/ezpz/bin/savejobenv\n\n\nOutput\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ Writing PBS vars to /home/foremans/.pbsenv\n‚îÇ HOSTFILE: /var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n‚îÇ NHOSTS: 2\n‚îÇ NGPU_PER_HOST: 12 GPUs per host\n‚îÇ NGPUS: 24 GPUs total\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ [DIST INFO]:\n‚îÇ   ‚Ä¢ Writing Job info to /home/foremans/.pbsenv\n‚îÇ     ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n‚îÇ     ‚Ä¢ NHOSTS: 2\n‚îÇ     ‚Ä¢ NGPU_PER_HOST: 12\n‚îÇ     ‚Ä¢ NGPUS = (NHOSTS * NGPU_PER_HOST) = 24\n‚îÇ [Hosts]:\n‚îÇ       ‚Ä¢ x4502c0s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov, x4502c0s2b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\n‚îÇ [Launch]:\n‚îÇ     ‚Ä¢ Use: 'launch' (=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov)\n‚îÇ       to launch job\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ YOU ARE HERE: /home/foremans\n‚îÇ Run 'source ./bin/getjobenv' in a NEW SHELL to automatically set env vars\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\n[WIP] Building out python API\n\n$ python3 -m ezpz.savejobenv\n/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'If you dont plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?'\n  warn(\n[2024-01-23 10:02:37][INFO][jobs:185] - Saving job env to /home/foremans/PBS-jobs/604319/jobenv.sh\n[2024-01-23 10:02:37][INFO][jobs:193] - Saving job env to dot-env (.env) file in /home/foremans\n[2024-01-23 10:02:37][INFO][jobs:211] - Saving job env to /home/foremans/PBS-jobs/604319/jobenv.json\n[2024-01-23 10:02:37][INFO][jobs:225] - Saving job env to /home/foremans/PBS-jobs/604319/jobenv.yaml\n[2024-01-23 10:02:37][INFO][jobs:253] - Writing PBS env vars to /home/foremans/PBS-jobs/604319 / jobenv{.sh, .yaml, .json}\n[2024-01-23 10:02:37][INFO][jobs:258] - jobenv={\n    \"BACKEND\": \"gloo\",\n    \"DEVICE\": \"xpu\",\n    \"DEVICE_ID\": \"xpu:0\",\n    \"DISTRIBUTED_BACKEND\": \"gloo\",\n    \"FRAMEWORK\": \"pytorch\",\n    \"GPUS_PER_NODE\": 12,\n    \"HOSTFILE\": \"/var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\n    \"HOSTNAME\": \"x4502c0s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\",\n    \"HOSTS\": \"[x4502c0s0b0n0, x4502c0s2b0n0]\",\n    \"LAUNCH_CMD\": \"mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\n    \"LOCAL_RANK\": 0,\n    \"MACHINE\": \"Aurora\",\n    \"NGPUS\": 24,\n    \"NGPU_PER_HOST\": \"12\",\n    \"NHOSTS\": \"2\",\n    \"NODE_ID\": 0,\n    \"NUM_NODES\": 2,\n    \"PBS_ACCOUNT\": \"Aurora_Deployment\",\n    \"PBS_ENVIRONMENT\": \"PBS_INTERACTIVE\",\n    \"PBS_HOOK_RESOURCES\": \"eJyVUV1vwjAM/EOblHZbgUV54yfs3TKp22bkozgJqP9+LjAJ9jYpD7HvfL5L0Pt0AbQ21VjATmSPMKDzlck0Gq9opBGLOxOspZVriit2Qe5BShoTL2bvsmVaMeTlDpZlpj/AoXIEXjWM0rYyk6x90H1tPza73a7rNq1SejoECKknM3gsepptABdwJGNTmGshKJQLtKp9V03TfMnlremgUUO3lelo55pNq6MDppwqWzJYOTHqKKK2CJbOxKsncTN7FEIWI4VYz5y+hQIzu8SuLMLltK48oD0Oznt5gkz+ppKjvfk8Vex1SQX9YyilL1IVF8io7adScvSpUiV4Dnjv/TPmberZQiaWYDDKdyYY8tXrtTOlQE+NM3rXgwSivORCIZs75eV3+Ady/coN\",\n    \"PBS_JOBCOOKIE\": \"6B8C4F9D774B0AA5174EAAFB6E2CC14F\",\n    \"PBS_JOBDIR\": \"/home/foremans\",\n    \"PBS_JOBID\": \"604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\n    \"PBS_JOBNAME\": \"STDIN\",\n    \"PBS_MOMPORT\": \"15003\",\n    \"PBS_NODEFILE\": \"/var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\n    \"PBS_NODENUM\": \"0\",\n    \"PBS_O_HOME\": \"/home/foremans\",\n    \"PBS_O_HOST\": \"aurora-uan-0010.hostmgmt1000.cm.aurora.alcf.anl.gov\",\n    \"PBS_O_LANG\": \"en_US.UTF-8\",\n    \"PBS_O_LOGNAME\": \"foremans\",\n    \"PBS_O_MAIL\": \"/var/spool/mail/foremans\",\n    \"PBS_O_PATH\": \"/home/foremans/.nvm/versions/node/v21.5.0/bin:/home/foremans/homebrew/bin:/home/foremans/homebrew/sbin:/opt/cray/pals/1.3.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/aurora/23.073.0/support/libraries/intel-compute-samples/2021.27.01:/opt/aurora/23.073.0/support/libraries/khronos/clinfo/default/bin:/opt/aurora/23.073.0/support/tools/gpu_validation:/opt/aurora/23.073.0/intel-gpu-umd/agama-devel-551/compiler/bin:/opt/aurora/23.073.0/intel-gpu-umd/agama-devel-551/driver/bin:/opt/aurora/23.073.0/CNDA/mpich/51.2/mpich-ofi-all-icc-default-pmix-gpu-drop51/bin:/opt/aurora/23.073.0/support/tools/mpi_wrapper_utils:/opt/aurora/23.073.0/oneapi/debugger/2023.0.0/gdb/intel64/bin:/opt/aurora/23.073.0/CNDA/oneapi/compiler/trunk-20230201/dpcpp-ct/bin:/opt/aurora/23.073.0/oneapi/advisor/2023.0.0/bin64:/opt/aurora/23.073.0/CNDA/oneapi/vtune/2023.0.0_624810_nda/bin64:/opt/aurora/23.073.0/CNDA/oneapi/compiler/trunk-20230201/compiler/linux/bin/intel64:/opt/aurora/23.073.0/CNDA/oneapi/compiler/trunk-20230201/compiler/linux/bin:/opt/aurora/23.073.0/oneapi/inspector/2023.0.0/bin64:/opt/cray/pe/gcc/11.2.0/snos/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/home/foremans/.local/bin:/home/foremans/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/foremans/.local/share/kitty-ssh-kitten/kitty/bin:/home/foremans/.cargo/bin:/home/foremans/.fzf/bin:/home/foremans/.luarocks/bin:/home/foremans/.luarocks/bin\",\n    \"PBS_O_QUEUE\": \"EarlyAppAccess\",\n    \"PBS_O_SHELL\": \"/bin/zsh\",\n    \"PBS_O_SYSTEM\": \"Linux\",\n    \"PBS_O_TZ\": \"America/Chicago\",\n    \"PBS_O_WORKDIR\": \"/home/foremans\",\n    \"PBS_QUEUE\": \"LustreApps\",\n    \"PBS_TASKNUM\": \"1\",\n    \"RANK\": 0,\n    \"SCHEDULER\": \"PBS\",\n    \"WORLD_SIZE_IN_USE\": 1,\n    \"WORLD_SIZE_TOTAL\": 24,\n    \"jobfile_json\": \"/home/foremans/PBS-jobs/604319/jobenv.json\",\n    \"jobfile_sh\": \"/home/foremans/PBS-jobs/604319/jobenv.sh\",\n    \"jobfile_yaml\": \"/home/foremans/PBS-jobs/604319/jobenv.yaml\"\n}\n\n$ source \"$(tail -1 ~/PBS-jobs.log)/jobenv.sh\"\n$ which launch\nlaunch: aliased to mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/604319.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\nTake 1: Crash with\nRuntimeError: oneCCL: global.cpp:150 getenv_local_coord: EXCEPTION: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n\n\nRun:\n\n$ launch python3 pretrain_llama.py \\\n    --tensor-model-parallel-size 1 \\\n    --pipeline-model-parallel-size 1 \\\n    --num-layers 32 \\\n    --hidden-size 4096 \\\n    --ffn-hidden-size 5504 \\\n    --num-attention-heads 32 \\\n    --micro-batch-size 1 \\\n    --global-batch-size 24 \\\n    --seq-length 2048 \\\n    --max-position-embeddings 2048 \\\n    --train-iters 250000 \\\n    --save /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 \\\n    --load /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 \\\n    --data-path \\\n    --data-impl mmap \\\n    --tokenizer-type GPTSentencePieceTokenizer \\\n    --tokenizer-model ./tmp/tokenizer.model \\\n    --split 949,50,1 \\\n    --distributed-backend ccl \\\n    --lr 3e-4 \\\n    --lr-decay-style cosine \\\n    --min-lr 3e-5 \\\n    --weight-decay 0.1 \\\n    --clip-grad 1 \\\n    --lr-warmup-iters 2000 \\\n    --optimizer adam \\\n    --adam-beta1 0.9 \\\n    --adam-beta2 0.95 \\\n    --log-interval 1 \\\n    --save-interval 10000 \\\n    --eval-interval 1000 \\\n    --eval-iters 10 \\\n    --bf16 \\\n    --no-query-key-layer-scaling \\\n    --attention-dropout 0 \\\n    --hidden-dropout 0 \\\n    --use-rotary-position-embeddings \\\n    --untie-embeddings-and-output-weightss \\\n    --swiglus \\\n    --normalization rmsnorms \\\n    --disable-bias-linears \\\n    --num-key-value-heads 4s \\\n    --tensorboard-dir /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/outputs/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_ \\\n    hs4096_gb24_mb1/tensorboard \\\n    --log-timers-to-tensorboard \\\n    --tensorboard-log-interval 1 \\\n    --data-path /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/BookCorpusDataset_text_documents \\\n    --vocab-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-vocab.json \\\n    --merge-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-merges.txt \\\n    --zero-stage=3 \\\n    --deepspeed_config=/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/deepspeed.json \\\n    --deepspeed\n\nConnected to tcp://x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov:7919\nFound executable /home/foremans/miniconda3/envs/anl_release_q4/bin/python3\nLaunching application 2e559157-da5e-4185-9902-dc8d932e8bb3\n/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'If you dont plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?'\n  warn(\n[2024-01-23 00:02:13,326] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-01-23 00:02:19,177] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-01-23 00:02:19,177] [INFO] [comm.py:637:init_distributed] cdb=None\n[2024-01-23 00:02:19,177] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=9, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=11, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=4, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=5, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=6, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=7, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=8, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=10, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,889] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=5, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=7, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=9, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=4, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=6, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=8, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=10, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:19,888] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=11, world_size=24, master_addr=10.115.53.137, master_port=29500\n[2024-01-23 00:02:20][INFO][dist:257] - DistInfo={\n    \"DEVICE\": \"xpu\",\n    \"DEVICE_ID\": \"xpu:0\",\n    \"DISTRIBUTED_BACKEND\": \"gloo\",\n    \"GPUS_PER_NODE\": 12,\n    \"HOSTFILE\": \"/var/spool/pbs/aux/604213.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\n    \"HOSTNAME\": \"x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\",\n    \"HOSTS\": \"['x4502c1s0b0n0', 'x4502c1s3b0n0']\",\n    \"LOCAL_RANK\": 0,\n    \"MACHINE\": \"Aurora\",\n    \"NGPUS\": 24,\n    \"NODE_ID\": 0,\n    \"NUM_NODES\": 2,\n    \"RANK\": 0,\n    \"SCHEDULER\": \"PBS\",\n    \"WORLD_SIZE_IN_USE\": 24,\n    \"WORLD_SIZE_TOTAL\": 24\n}\n[2024-01-23 00:02:20,987] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n--------------------------------------------------\nDeepSpeed C++/CUDA extension op report\n--------------------------------------------------\nNOTE: Ops not installed will be just-in-time (JIT) compiled at\n      runtime if needed. Op compatibility means that your system\n      meet the required dependencies to JIT install the op.\n--------------------------------------------------\nJIT compiled ops requires ninja\nninja .................. [OKAY]\n--------------------------------------------------\nop name ................ installed .. compatible\n--------------------------------------------------\n[2024-01-23 00:02:20][INFO][spawn:38] - icx -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/foremans/miniconda3/envs/anl_release_q4/include -fPIC -O2 -isystem /home/foremans/miniconda3/envs/anl_release_q4/include -fPIC -c /tmp/tmph01efr3s/test.c -o /tmp/tmph01efr3s/test.o\nWARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.\n2024:01:23-00:02:21:(122507) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(122510) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122515) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122507) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122508) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122509) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122511) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122512) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122513) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122514) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122516) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122517) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(122518) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141071) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141072) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141073) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141075) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141076) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141078) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141079) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141081) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141074) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141077) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141080) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:02:21:(141071) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141075) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141078) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141081) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141072) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141073) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141074) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141076) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141077) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141079) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n2024:01:23-00:02:21:(141080) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nto get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\nTraceback (most recent call last):\n  File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/pretrain_llama.py\", line 583, in &lt;module&gt;\n    model = main()\n  File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/pretrain_llama.py\", line 561, in main\n    model = pretrain(\n  File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/megatron/training.py\", line 136, in pretrain\n    torch.distributed.all_reduce(start_time_tensor,\n  File \"/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torch/distributed/c10d_logger.py\", line 47, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 2050, in all_reduce\n    work = group.allreduce([tensor], opts)\n\nRuntimeError: oneCCL: global.cpp:150 getenv_local_coord: EXCEPTION: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\n\n&lt;/details&gt;\nTake 2: Trying with CCL_ZE_IPC_EXCHANGE=sockets (still no luck)\n\n\nRun:\n\n$ CCL_ZE_IPC_EXCHANGE=sockets !!\n[...]\n2024:01:23-00:03:41:(123335) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\n2024:01:23-00:03:41:(123330) |CCL_WARN| sockets exchange mode is set. It may cause potential problem of 'Too many open file descriptors'\n2024:01:23-00:03:41:(123337) |CCL_WARN| sockets exchange mode is set. It may cause potential problem of 'Too many open file descriptors'\n2024:01:23-00:03:41:(123327) |CCL_WARN| sockets exchange mode is set. It may cause potential problem of 'Too many open file descriptors'\n[...]\nRuntimeError: oneCCL: global.cpp:150 getenv_local_coord: EXCEPTION: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèéÔ∏è Megatron-DeepSpeed on Intel XPU"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/aurora-gpt/index.html#using-deepspeed",
    "href": "posts/AuroraGPT/aurora-gpt/index.html#using-deepspeed",
    "title": "üèéÔ∏è Megatron-DeepSpeed on Intel XPU",
    "section": "Using deepspeed",
    "text": "Using deepspeed\n\nSetup:\n\n\nSetup:\n\n$ cat $PBS_NODEFILE &gt; hostfile ; sed -e 's/$/ slots=12/' -i hostfile\n$ echo \"PATH=${PATH}\" &gt;&gt; .deepspeed_env ; echo \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" &gt;&gt; .deepspeed_env ; echo \"http_proxy=${http_proxy}\" &gt;&gt; .deepspeed_env ; echo \"https_proxy=${https_proxy}\" &gt;&gt; .deepspeed_env\nRun:\n\nCommand:\n  $ RANK=0 LOCAL_RANK=0 MASTER_ADDR=localhost deepspeed --hostfile hostfile pretrain_llama.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --num-layers 32 --hidden-size 4096 --ffn-hidden-size 5504 --num-attention-heads 32 --micro-batch-size 1 --global-batch-size 24 --seq-length 2048 --max-position-embeddings 2048 --train-iters 250000 --save /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 --load /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 --data-path --data-impl mmap --tokenizer-type GPTSentencePieceTokenizer --tokenizer-model ./tmp/tokenizer.model --split 949,50,1 --distributed-backend ccl --lr 3e-4 --lr-decay-style cosine --min-lr 3e-5 --weight-decay 0.1 --clip-grad 1 --lr-warmup-iters 2000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --log-interval 1 --save-interval 10000 --eval-interval 1000 --eval-iters 10 --bf16 --no-query-key-layer-scaling --attention-dropout 0 --hidden-dropout 0 --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization rmsnorm --disable-bias-linear --num-key-value-heads 4 --tensorboard-dir /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/outputs/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1/tensorboard --log-timers-to-tensorboard --tensorboard-log-interval 1 --data-path /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/BookCorpusDataset_text_document --vocab-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-vocab.json --merge-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-merges.txt --zero-stage=3 --deepspeed_config=/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/deepspeed.json --deepspeed\nOutput:\n\n\nOutput\n\n$ RANK=0 LOCAL_RANK=0 MASTER_ADDR=localhost deepspeed --hostfile hostfile pretrain_llama.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --num-layers 32 --hidden-size 4096 --ffn-hidden-size 5504 --num-attention-heads 32 --micro-batch-size 1 --global-batch-size 24 --seq-length 2048 --max-position-embeddings 2048 --train-iters 250000 --save /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 --load /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1 --data-path --data-impl mmap --tokenizer-type GPTSentencePieceTokenizer --tokenizer-model ./tmp/tokenizer.model --split 949,50,1 --distributed-backend ccl --lr 3e-4 --lr-decay-style cosine --min-lr 3e-5 --weight-decay 0.1 --clip-grad 1 --lr-warmup-iters 2000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --log-interval 1 --save-interval 10000 --eval-interval 1000 --eval-iters 10 --bf16 --no-query-key-layer-scaling --attention-dropout 0 --hidden-dropout 0 --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization rmsnorm --disable-bias-linear --num-key-value-heads 4 --tensorboard-dir /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/outputs/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1/tensorboard --log-timers-to-tensorboard --tensorboard-log-interval 1 --data-path /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/BookCorpusDataset_text_document --vocab-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-vocab.json --merge-file /lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-merges.txt --zero-stage=3 --deepspeed_config=/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/deepspeed.json --deepspeed \n\nhome/foremans/miniconda3/envs/anl_release_q4/bin/deepspeed:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  __import__('pkg_resources').require('deepspeed==0.12.3+6ea44d02')\n/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'If you dont plan on using image functionality from `torchvision.io`, you can igno re this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?'\n  warn(\nMy guessed rank = 0\n[2024-01-23 00:09:56,016] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-01-23 00:10:00,790] [INFO] [runner.py:463:main] Using IP address of 10.115.53.137 for node x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\n[2024-01-23 00:10:00,812] [INFO] [runner.py:559:main] deepspeed_env file = .deepspeed_env\n[2024-01-23 00:10:00,813] [INFO] [runner.py:559:main] deepspeed_env file = .deepspeed_env\n[2024-01-23 00:10:00,813] [INFO] [multinode_runner.py:72:get_cmd] Running on the following workers: x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov,x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\n[2024-01-23 00:10:00,813] [INFO] [runner.py:570:main] cmd = pdsh -S -f 1024 -w x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov,x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov export PYTHONSTARTUP=/etc/pythonstart; export PYTHONPATH=/l\nus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed:/soft/compilers/oneapi/2023.12.15.001/oneapi/advisor/2024.0/pythonapi; export PATH=/home/ftartagl/graphics-compute-runtime/agama-ci-devel-736.9/u\nsr/bin:/soft/tools/gpu_validation:/soft/libraries/khronos/clinfo/master-13ae34-2020.12.14/bin:/soft/libraries/intel-compute-samples/2021.27.01:/soft/libraries/intel-gpu-umd/stable_736_25_20231031/compiler/bin:/soft/libraries/intel-gpu-umd\n/stable_736_25_20231031/driver/bin:/soft/restricted/CNDA/updates/mpich/52.2/mpich-ofi-all-icc-default-pmix-gpu-drop52/bin:/soft/tools/mpi_wrapper_utils:/soft/compilers/oneapi/2023.12.15.001/oneapi/dpcpp-ct/2024.0/bin:/soft/compilers/oneap\ni/2023.12.15.001/oneapi/advisor/2024.0/bin64:/soft/compilers/oneapi/2023.12.15.001/oneapi/vtune/2024.0/bin64:/soft/compilers/oneapi/2023.12.15.001/oneapi/inspector/2024.0/bin64:/soft/compilers/oneapi/2023.12.15.001/oneapi/debugger/2024.0/\nopt/debugger/bin:/soft/compilers/oneapi/2023.12.15.001/oneapi/mkl/2024.0/bin:/soft/compilers/oneapi/2023.12.15.001/oneapi/compiler/2024.0/bin:/home/foremans/miniconda3/envs/anl_release_q4/bin:/home/foremans/miniconda3/condabin:/home/forem\nans/.nvm/versions/node/v21.5.0/bin:/home/foremans/homebrew/bin:/home/foremans/homebrew/sbin:/opt/cray/pals/1.3.2/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/cray/pe/gcc/11.2.0/snos/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/b\nin:/home/foremans/.local/bin:/home/foremans/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/foremans/.local/share/kitty-ssh-kitten/kitty/bin:/home/foremans/.cargo/bin:/home/foremans\n/.fzf/bin:/home/foremans/.luarocks/bin; export LD_LIBRARY_PATH=/home/ftartagl/graphics-compute-runtime/agama-ci-devel-736.9/usr/lib64/dri:/home/ftartagl/graphics-compute-runtime/agama-ci-devel-736.9/usr/lib64/mfx:/home/ftartagl/graphics-c\nompute-runtime/agama-ci-devel-736.9/usr/lib64/intel-opencl:/home/ftartagl/graphics-compute-runtime/agama-ci-devel-736.9/usr/lib64:/soft/libraries/khronos/loader/master-2022.05.18/lib64:/soft/libraries/intel-gpu-umd/stable_736_25_20231031/\ncompiler/lib64:/soft/libraries/intel-gpu-umd/stable_736_25_20231031/driver/lib64/intel-opencl:/soft/libraries/intel-gpu-umd/stable_736_25_20231031/driver/lib64:/soft/restricted/CNDA/updates/mpich/52.2/mpich-ofi-all-icc-default-pmix-gpu-dr\nop52/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/ipp/2021.10/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/ippcp/2021.9/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/dpl/2022.3/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/d\nebugger/2024.0/opt/debugger/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/ccl/2021.11/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/dal/2024.0/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/dnnl/2024.0/lib:/soft/compilers/oneapi/2\n023.12.15.001/oneapi/tbb/2021.11/lib/intel64/gcc4.8:/soft/compilers/oneapi/2023.12.15.001/oneapi/mkl/2024.0/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/compiler/2024.0/opt/compiler/lib:/soft/compilers/oneapi/2023.12.15.001/oneapi/com\npiler/2024.0/lib:/opt/cray/libfabric/1.15.2.0/lib64:/opt/cray/pe/gcc/11.2.0/snos/lib64; export http_proxy=http://proxy-01.pub.alcf.anl.gov:3128; export https_proxy=http://proxy.alcf.anl.gov:3128;  cd /lus/gecko/projects/Aurora_deployment/\nforemans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed; /home/foremans/miniconda3/envs/anl_release_q4/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJ4NDUwMmMxczBiMG4wLmhvc3RtZ210MjUwMi5jbS5hdXJvcmEuYWxjZi5hbmwuZ292IjogWzAsI\nDEsIDIsIDMsIDQsIDUsIDYsIDcsIDgsIDksIDEwLCAxMV0sICJ4NDUwMmMxczNiMG4wLmhvc3RtZ210MjUwMi5jbS5hdXJvcmEuYWxjZi5hbmwuZ292IjogWzAsIDEsIDIsIDMsIDQsIDUsIDYsIDcsIDgsIDksIDEwLCAxMV19 --node_rank=%n --master_addr=10.115.53.137 --master_port=29500 pre\ntrain_llama.py --tensor-model-parallel-size '1' --pipeline-model-parallel-size '1' --num-layers '32' --hidden-size '4096' --ffn-hidden-size '5504' --num-attention-heads '32' --micro-batch-size '1' --global-batch-size '24' --seq-length '20\n48' --max-position-embeddings '2048' --train-iters '250000' --save '/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1'\n--load '/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/checkpoints/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1' --data-path --data-impl 'mmap' --tokenizer-type 'GPTSentence\nPieceTokenizer' --tokenizer-model './tmp/tokenizer.model' --split '949,50,1' --distributed-backend 'ccl' --lr '3e-4' --lr-decay-style 'cosine' --min-lr '3e-5' --weight-decay '0.1' --clip-grad '1' --lr-warmup-iters '2000' --optimizer 'adam\n' --adam-beta1 '0.9' --adam-beta2 '0.95' --log-interval '1' --save-interval '10000' --eval-interval '1000' --eval-iters '10' --bf16 --no-query-key-layer-scaling --attention-dropout '0' --hidden-dropout '0' --use-rotary-position-embeddings\n --untie-embeddings-and-output-weights --swiglu --normalization 'rmsnorm' --disable-bias-linear --num-key-value-heads '4' --tensorboard-dir '/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/ou\ntputs/LLAMA_7B_LLAMA_7B_z3_seqlen_mp1_pp1_sp24_nl32_hs4096_gb24_mb1/tensorboard' --log-timers-to-tensorboard --tensorboard-log-interval '1' --data-path '/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-\nDeepSpeed/dataset/BookCorpusDataset_text_document' --vocab-file '/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-vocab.json' --merge-file '/lus/gecko/projects/Aurora_deployment/f\noremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/dataset/gpt2-merges.txt' --zero-stage=3 --deepspeed_config=/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/deepspeed.json --deepspeed\nx4502c1s3b0n0: Warning: Permanently added 'x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov,10.115.53.138' (ECDSA) to the list of known hosts.\n\nx4502c1s0b0n0: /home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io\n`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\nx4502c1s0b0n0:   warn(\nx4502c1s3b0n0: /home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\nx4502c1s3b0n0:   warn(\nx4502c1s0b0n0: [2024-01-23 06:10:07,853] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\nx4502c1s0b0n0: [2024-01-23 06:10:08,419] [INFO] [launch.py:145:main] WORLD INFO DICT: {'x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}\nx4502c1s0b0n0: [2024-01-23 06:10:08,419] [INFO] [launch.py:151:main] nnodes=2, num_local_procs=12, node_rank=0\nx4502c1s0b0n0: [2024-01-23 06:10:08,419] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(&lt;class 'list'&gt;, {'x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]})\nx4502c1s0b0n0: [2024-01-23 06:10:08,419] [INFO] [launch.py:163:main] dist_world_size=24\nx4502c1s0b0n0: [2024-01-23 06:10:08,419] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7,8,9,10,11\nx4502c1s3b0n0: [2024-01-23 06:10:08,885] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\nx4502c1s3b0n0: [2024-01-23 06:10:09,452] [INFO] [launch.py:145:main] WORLD INFO DICT: {'x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}\nx4502c1s3b0n0: [2024-01-23 06:10:09,452] [INFO] [launch.py:151:main] nnodes=2, num_local_procs=12, node_rank=1\nx4502c1s3b0n0: [2024-01-23 06:10:09,452] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(&lt;class 'list'&gt;, {'x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], 'x4502c1s3b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]})\nx4502c1s3b0n0: [2024-01-23 06:10:09,452] [INFO] [launch.py:163:main] dist_world_size=24\nx4502c1s3b0n0: [2024-01-23 06:10:09,452] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7,8,9,10,11\nx4502c1s0b0n0: My guessed rank = 4\nx4502c1s0b0n0: My guessed rank = 9\nx4502c1s0b0n0: My guessed rank = 8\nx4502c1s0b0n0: My guessed rank = 0\nx4502c1s0b0n0: My guessed rank = 6\nx4502c1s0b0n0: My guessed rank = 7\nx4502c1s0b0n0: My guessed rank = 11\nx4502c1s0b0n0: My guessed rank = 5\nx4502c1s0b0n0: My guessed rank = 10\nx4502c1s0b0n0: My guessed rank = 3\nx4502c1s0b0n0: My guessed rank = 2\nx4502c1s0b0n0: My guessed rank = 1\nx4502c1s3b0n0: My guessed rank = 21\nx4502c1s3b0n0: My guessed rank = 18\nx4502c1s3b0n0: My guessed rank = 22\nx4502c1s3b0n0: My guessed rank = 20\nx4502c1s3b0n0: My guessed rank = 14\nx4502c1s3b0n0: My guessed rank = 12\nx4502c1s3b0n0: My guessed rank = 23\nx4502c1s3b0n0: My guessed rank = 16\nx4502c1s3b0n0: My guessed rank = 17\nx4502c1s3b0n0: My guessed rank = 19\nx4502c1s3b0n0: My guessed rank = 15\nx4502c1s3b0n0: My guessed rank = 13\nx4502c1s0b0n0: [2024-01-23 06:10:14,751] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\nx4502c1s0b0n0: [2024-01-23 06:10:19,225] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\nx4502c1s0b0n0: [2024-01-23 06:10:19,225] [INFO] [comm.py:637:init_distributed] cdb=None\nx4502c1s0b0n0: [2024-01-23 06:10:20,891] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl\nx4502c1s0b0n0: [2024-01-23 06:10:21][INFO][dist:257] - DistInfo={\nx4502c1s0b0n0:     \"DEVICE\": \"xpu\",\nx4502c1s0b0n0:     \"DEVICE_ID\": \"xpu:0\",\nx4502c1s0b0n0:     \"DISTRIBUTED_BACKEND\": \"gloo\",\nx4502c1s0b0n0:     \"GPUS_PER_NODE\": 12,\nx4502c1s0b0n0:     \"HOSTFILE\": \"/var/spool/pbs/aux/604213.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\",\nx4502c1s0b0n0:     \"HOSTNAME\": \"x4502c1s0b0n0.hostmgmt2502.cm.aurora.alcf.anl.gov\",\nx4502c1s0b0n0:     \"HOSTS\": \"['x4502c1s0b0n0', 'x4502c1s3b0n0']\",\nx4502c1s0b0n0:     \"LOCAL_RANK\": 0,\nx4502c1s0b0n0:     \"MACHINE\": \"Aurora\",\nx4502c1s0b0n0:     \"NGPUS\": 24,\nx4502c1s0b0n0:     \"NODE_ID\": 0,\nx4502c1s0b0n0:     \"NUM_NODES\": 2,\nx4502c1s0b0n0:     \"RANK\": 0,\nx4502c1s0b0n0:     \"SCHEDULER\": \"PBS\",\nx4502c1s0b0n0:     \"WORLD_SIZE_IN_USE\": 1,\nx4502c1s0b0n0:     \"WORLD_SIZE_TOTAL\": 24\nx4502c1s0b0n0: }\nx4502c1s0b0n0: [2024-01-23 06:10:21,533] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to xpu (auto detect)\nx4502c1s0b0n0: --------------------------------------------------\nx4502c1s0b0n0: DeepSpeed C++/CUDA extension op report\nx4502c1s0b0n0: --------------------------------------------------\nx4502c1s0b0n0: NOTE: Ops not installed will be just-in-time (JIT) compiled at\nx4502c1s0b0n0:       runtime if needed. Op compatibility means that your system\nx4502c1s0b0n0:       meet the required dependencies to JIT install the op.\nx4502c1s0b0n0: --------------------------------------------------\nx4502c1s0b0n0: JIT compiled ops requires ninja\nx4502c1s0b0n0: ninja .................. [OKAY]\nx4502c1s0b0n0: --------------------------------------------------\nx4502c1s0b0n0: op name ................ installed .. compatible\nx4502c1s0b0n0: --------------------------------------------------\nx4502c1s0b0n0: [2024-01-23 06:10:21][INFO][spawn:38] - gcc -pthread -B /home/foremans/miniconda3/envs/anl_release_q4/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/foremans/miniconda3/envs/anl_release_q4/include -fPIC -O2 -isystem /home/foremans/miniconda3/envs/anl_release_q4/include -fPIC -c /tmp/tmptqyph55g/test.c -o /tmp/tmptqyph55g/test.o\nx4502c1s3b0n0: [2024-01-23 06:10:21,671] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\nx4502c1s3b0n0: [2024-01-23 06:10:21,672] [INFO] [comm.py:637:init_distributed] cdb=None\n\n[...]\nx4502c1s0b0n0: &gt;fused kernel is only supported in cuda, skip loading fused kernel\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153241) |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153241) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153241) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nx4502c1s0b0n0: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153242) |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153242) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153242) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nx4502c1s0b0n0: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\nx4502c1s3b0n0:  &gt; padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153237) |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153237) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\nx4502c1s0b0n0: 2024:01:23-06:12:16:(153237) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nx4502c1s0b0n0: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\nx4502c1s0b0n0:  &gt; padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\nx4502c1s0b0n0:  &gt; padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\nx4502c1s3b0n0: 2024:01:23-06:12:16:(129554) |CCL_WARN| could not get local_idx/count from environment variables, trying to get them from ATL\nx4502c1s3b0n0: 2024:01:23-06:12:16:(129554) |CCL_ERROR| global.cpp:150 getenv_local_coord: condition global_data::env().ze_ipc_exchange == ccl::ze::ipc_exchange_mode::sockets failed\nx4502c1s3b0n0: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\nx4502c1s3b0n0: RuntimeError: oneCCL: global.cpp:150 getenv_local_coord: EXCEPTION: to get local_idx/count from ATL, set CCL_ZE_IPC_EXCHANGE=sockets explicitly\nx4502c1s3b0n0: Traceback (most recent call last):\nx4502c1s3b0n0:   File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/pretrain_llama.py\", line 583, in &lt;module&gt;\nx4502c1s3b0n0:     model = main()\nx4502c1s3b0n0:   File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/pretrain_llama.py\", line 561, in main\nx4502c1s3b0n0:     model = pretrain(\nx4502c1s3b0n0:   File \"/lus/gecko/projects/Aurora_deployment/foremans/anl_24_release_q4/llm.devkit/Megatron-DeepSpeed/megatron/training.py\", line 136, in pretrain\nx4502c1s3b0n0:     torch.distributed.all_reduce(start_time_tensor,\nx4502c1s3b0n0:   File \"/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torch/distributed/c10d_logger.py\", line 47, in wrapper\nx4502c1s3b0n0:     return func(*args, **kwargs)\nx4502c1s3b0n0:   File \"/home/foremans/miniconda3/envs/anl_release_q4/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 2050, in all_reduce\nx4502c1s3b0n0:     work = group.allreduce([tensor], opts)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèéÔ∏è Megatron-DeepSpeed on Intel XPU"
    ]
  },
  {
    "objectID": "posts/2025/06/index.html",
    "href": "posts/2025/06/index.html",
    "title": "06",
    "section": "",
    "text": "What\n\n\n\nWhen\n\n\n\n\n\n\n\n\nüèóÔ∏è Building PyTorch 2.8 from Source on Aurora\n\n\n2025-06-14\n\n\n\n\n\n\nüßú‚Äç‚ôÄÔ∏è Mermaid\n\n\n2025-06-02\n\n\n\n\n\n\nüì∞ Nice Headings\n\n\n2025-06-01\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2025,\n  author = {Foreman, Sam},\n  title = {06},\n  date = {2025-06-01},\n  url = {https://samforeman.me/posts/2025/06/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2025. ‚Äú06.‚Äù June 1, 2025. https://samforeman.me/posts/2025/06/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06"
    ]
  },
  {
    "objectID": "posts/2025/06/02/index.html",
    "href": "posts/2025/06/02/index.html",
    "title": "üßú‚Äç‚ôÄÔ∏è Mermaid",
    "section": "",
    "text": "flowchart LR\n    subgraph D[\"`Data`\"]\n        direction TB\n        x(\"`x‚ÇÄ`\")\n        x1(\"`x‚ÇÅ`\")\n        x2(\"`x‚ÇÇ`\")\n    end\n    direction LR\n    subgraph G0[\"`GPU0`\"]\n        direction LR\n        subgraph N0[\"`NN`\"]\n        end\n        L0[\"`L0`\"]\n    end\n    subgraph G1[\"`GPU1`\"]\n        direction LR\n        subgraph N1[\"`NN`\"]\n        end\n        L1[\"`L1`\"]\n    end\n    subgraph G2[\"`GPU2`\"]\n        direction LR\n        subgraph N2[\"`NN`\"]\n        end\n        L2[\"`L2`\"]\n    end\n    %%subgraph AR[\"`Average Grads`\"]\n    %%    direction LR\n    %%    ar(\"`(1/N) ‚àë g‚Çô`\")\n    %%    %%ar --&gt; bc\n    %%end\n    subgraph AR[\"`&nbsp;`\"]\n        direction TB\n        ar(\"`Avg Grads&lt;br&gt;(1/N) ‚àë g‚Çô`\")\n        %% bc(\"`Update Weights`\")\n    end\n    %%subgraph UW[\"Update Weights\"]\n    %%    bc(\"`Update Weights`\")\n    %%end\n    x --&gt; G0\n    x1 --&gt; G1\n    x2 --&gt; G2\n    N0 --&gt; L0\n    N1 --&gt; L1\n    N2 --&gt; L2\n    L0 -.-&gt; ar\n    L1 -.-&gt; ar\n    L2 -.-&gt; ar\n    %% ar -.-&gt; bc\n    %% bc -.-&gt; \n    %%bc -.-&gt; G1\n    %%bc -.-&gt; G2\n    %%G0 -.-&gt; ar\n    %%G1 -.-&gt; ar\n    %%G2 -.-&gt; ar\n    %%G0 &lt;-.- bc\n    %%bc -.-&gt; G0\n    %%bc -.-&gt; G1\n    %%bc -.-&gt; G2\n    %%G2 -.-&gt; ar\n    %%X1 --&gt;|\"`x‚ÇÄ W‚ÇÄ &lt;br&gt;+ x‚ÇÅ W‚ÇÅ`\"|X2\n\nclassDef block fill:#CCCCCC02,stroke:#838383,stroke-width:1px,color:#838383\nclassDef grey fill:#cccccc,stroke:#333,stroke-width:1px,color:#000\nclassDef red fill:#ff8181,stroke:#333,stroke-width:1px,color:#000\nclassDef orange fill:#FFC47F,stroke:#333,stroke-width:1px,color:#000\nclassDef yellow fill:#FFFF7F,stroke:#333,stroke-width:1px,color:#000\nclassDef green fill:#98E6A5,stroke:#333,stroke-width:1px,color:#000\nclassDef blue fill:#7DCAFF,stroke:#333,stroke-width:1px,color:#000\nclassDef purple fill:#FFCBE6,stroke:#333,stroke-width:1px,color:#000\nclassDef text fill:#CCCCCC02,stroke:#838383,stroke-width:0px,color:#838383\nclass x,y0,L0 red\nclass x1,L1 green\nclass x2,L2 blue\nclass x3,ar grey\nclass D,N0,N1,N2,G0,G1,G2,GU block\nclass AR block\nclass bc text\n\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2025,\n  author = {Foreman, Sam},\n  title = {üßú‚Äç‚ôÄÔ∏è {Mermaid}},\n  date = {2025-06-02},\n  url = {https://samforeman.me/posts/2025/06/02/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2025. ‚Äúüßú‚Äç‚ôÄÔ∏è Mermaid.‚Äù June 2, 2025. https://samforeman.me/posts/2025/06/02/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üßú‚Äç‚ôÄÔ∏è Mermaid"
    ]
  },
  {
    "objectID": "posts/2025/05/03/index.html",
    "href": "posts/2025/05/03/index.html",
    "title": "üöß Frameworks Issue with numpy > 2",
    "section": "",
    "text": "Something I just learned\nThe TensorFlow that is included in the new frameworks module (aurora_nre_models_frameworks-2025.0.0) was built with numpy==1.26.4 (&lt; 2).\nUnfortunately, if you then (for whatever reason) then tries to install / upgrade a package1 that has numpy in its dependencies, e.g.:\nThis will pull in numpy &gt; 2, effectively breaking the frameworks module.\nIn particular, any application that uses intel/extension_for_pytorch:\nWill crash with:\nFollowing through the stack trace, I see that the error is actually coming from huggingface/transformers/image_transforms.py#L47.\nDigging around a bit more I found there is a flag in transformers that allows you to bypass the entire import tensorflow as tf logic:\nwhich not only prevents things from crashing with numpy &gt; 2, but is also noticeably quicker.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "05",
      "üöß Frameworks Issue with <code>numpy > 2</code>"
    ]
  },
  {
    "objectID": "posts/2025/05/03/index.html#reinstall-modules-built-with-numpy-2",
    "href": "posts/2025/05/03/index.html#reinstall-modules-built-with-numpy-2",
    "title": "üöß Frameworks Issue with numpy > 2",
    "section": "Reinstall Modules built with numpy < 2",
    "text": "Reinstall Modules built with numpy &lt; 2\nIn addition to tensorflow, it seems that: { jax, jaxlib, ml-dtypes, opt-einsum, scipy } were all built with numpy &lt; 2, and so need to be rebuilt after upgrading numpy.\nTo do so:\npython3 -m pip install --upgrade  numpy jax jaxlib ml-dtypes opt-einsum scipy transformers\n‚úÖ Now, we‚Äôre able to successfully:\n#[üêç aurora_nre_models_frameworks-2025.0.0](üëª aurora_nre_models_frameworks-2025.0.0)\n#[05/03/25 @ 12:12:29][x4515c7s4b0n0][/f/d/f/p/s/ezpz][üå± update-utils][üì¶ü§∑‚úì] [‚è±Ô∏è 25s]\n; USE_TORCH=1 python3 -c 'import numpy as np; print(np.__version__) ; import ezpz '\n2.2.5\n[W503 12:12:34.201673197 OperatorEntry.cpp:155] Warning: Warning only once for all operators,  other operators may also be overridden.\n  Overriding a previously registered kernel for the same operator and the same dispatch key\n  operator: aten::_cummax_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -&gt; ()\n    registered at /build/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n  dispatch key: XPU\n  previous kernel: registered at /build/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30476\n       new kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:2971 (function operator())\n[2025-05-03 12:13:18][W][utils/_logger:68:ezpz] Unable to import deepspeed. Please install it to use DeepSpeed features.\ntook: 0h:00m:48s",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "05",
      "üöß Frameworks Issue with <code>numpy > 2</code>"
    ]
  },
  {
    "objectID": "posts/2025/05/03/index.html#profiles-and-timing-comparisons",
    "href": "posts/2025/05/03/index.html#profiles-and-timing-comparisons",
    "title": "üöß Frameworks Issue with numpy > 2",
    "section": "Profiles and Timing Comparisons",
    "text": "Profiles and Timing Comparisons\nBelow we present timing profiles obtained from\n\nhyperfine: A command-line benchmarking tool\npyinstrument: A call stack profiler for Python\n\nBelow we present the profiles obtained by the usual mechanism, i.e.\nmodule load frameworks\npython3 -m venv --system-site-packages \"venvs/$(basename ${CONDA_PREFIX})\"\nsource venvs/$(basename ${CONDA_PREFIX})/bin/activate\npython3 -m pip install -e \"git+https://github.com/saforem2/ezpz\"\n\nDEFAULT BEHAVIOR\n\nBash Profile (hyperfine)\n$ hyperfine --max-runs=10 --shell=zsh --show-output 'ezpz_init() { $(which python3) -c \"import ezpz\" }; ezpz_init'\n# ...[clipped]...\nTime (mean ¬± œÉ):     10.754 s ¬±  0.122 s    [User: 14.574 s, System: 12.795 s]\nRange (min ‚Ä¶ max):   10.467 s ‚Ä¶ 10.910 s    10 runs\n\n\nPython Profile (pyinstrument)\n$ pyinstrument -c 'import ezpz'\n# ...[clipped]...\n12.021 &lt;module&gt;  ezpz/__init__.py:1\n‚îú‚îÄ 8.624 &lt;module&gt;  ezpz/dist.py:1\n‚îÇ  ‚îî‚îÄ 8.542 &lt;module&gt;  intel_extension_for_pytorch/__init__.py:1\n‚îÇ        [206 frames hidden]  intel_extension_for_pytorch, transfor...\n‚îÇ           0.247 &lt;module&gt;  torch/utils/_sympy/functions.py:1\n‚îÇ           ‚îî‚îÄ 0.241 &lt;module&gt;  sympy/__init__.py:1\n‚îÇ              ‚îî‚îÄ 0.126 &lt;module&gt;  sympy/polys/__init__.py:1\n\n\n\nWITH USE_TORCH=1 and numpy==2.2.5\nBelow we present the profiles and timing measurements obtained:\n\nAfter upgrading numpy==2.25\nSkipping the import tensorflow as tf logic in transformers by specifying USE_TORCH=1, explicitly.\n\n\nBash Profile (hyperfine)\n$ hyperfine --max-runs=10 --shell=zsh --show-output 'ezpz_init() { USE_TORCH=1 $(which python3) -c \"import ezpz\" }; ezpz_init'\n# ...[clipped]...\nTime (mean ¬± œÉ):      7.491 s ¬±  0.162 s    [User: 12.130 s, System: 11.940 s]\nRange (min ‚Ä¶ max):    7.311 s ‚Ä¶  7.883 s    10 runs\n\n\nPython Profile (pyinstrument)\n$ USE_TORCH=1 pyinstrument -c 'import ezpz'\n# ...[clipped]...\n8.478 &lt;module&gt;  ezpz/__init__.py:1\n‚îú‚îÄ 5.109 &lt;module&gt;  ezpz/dist.py:1\n‚îÇ  ‚îî‚îÄ 5.016 &lt;module&gt;  intel_extension_for_pytorch/__init__.py:1\n‚îÇ        [174 frames hidden]  intel_extension_for_pytorch, transfor...\n‚îÇ           0.249 &lt;module&gt;  torch/utils/_sympy/functions.py:1\n‚îÇ           ‚îî‚îÄ 0.241 &lt;module&gt;  sympy/__init__.py:1\n‚îÇ              ‚îî‚îÄ 0.124 &lt;module&gt;  sympy/polys/__init__.py:1",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "05",
      "üöß Frameworks Issue with <code>numpy > 2</code>"
    ]
  },
  {
    "objectID": "posts/2025/05/03/index.html#stack-trace-from-numpy-2-issue",
    "href": "posts/2025/05/03/index.html#stack-trace-from-numpy-2-issue",
    "title": "üöß Frameworks Issue with numpy > 2",
    "section": "Stack Trace from numpy > 2 issue",
    "text": "Stack Trace from numpy &gt; 2 issue\n\n\nStack Trace\n\n#[üêç aurora_nre_models_frameworks-2025.0.0](üëª aurora_nre_models_frameworks-2025.0.0)\n#[05/02/25 @ 15:46:43][x4005c2s6b0n0][/f/d/f/p/s/t/2/ezpz][üå± update-utils][‚úì] [‚è±Ô∏è 19s]\n; ezpz-test --profile --tp 2 --pp 4\n[W502 16:00:18.739960487 OperatorEntry.cpp:155] Warning: Warning only once for all operators,  other operators may also be overridden.\n  Overriding a previously registered kernel for the same operator and the same dispatch key\n  operator: aten::_cummax_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -&gt; ()\n    registered at /build/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n  dispatch key: XPU\n  previous kernel: registered at /build/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30476\n       new kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:2971 (function operator())\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11&gt;=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy&lt;2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/venvs/aurora_nre_models_frameworks-2025.0.0/bin/ezpz-test\", line 6, in &lt;module&gt;\n    from ezpz.test import main\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/src/ezpz/__init__.py\", line 102, in &lt;module&gt;\n    from ezpz.dist import (\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/src/ezpz/dist.py\", line 42, in &lt;module&gt;\n    import intel_extension_for_pytorch as ipex  # type:ignore[missingTypeStubs]\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/__init__.py\", line 128, in &lt;module&gt;\n    from . import xpu\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/xpu/__init__.py\", line 20, in &lt;module&gt;\n    from .utils import *\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/xpu/utils.py\", line 7, in &lt;module&gt;\n    from .. import frontend\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py\", line 9, in &lt;module&gt;\n    from .nn import utils\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/__init__.py\", line 6, in &lt;module&gt;\n    from .modules import FrozenBatchNorm2d\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/modules/__init__.py\", line 11, in &lt;module&gt;\n    from ...cpu.nn.linear_fuse_eltwise import IPEXLinearEltwise\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/cpu/nn/linear_fuse_eltwise.py\", line 3, in &lt;module&gt;\n    from intel_extension_for_pytorch.nn.utils._weight_prepack import (\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/utils/__init__.py\", line 1, in &lt;module&gt;\n    from intel_extension_for_pytorch.nn.utils import _weight_prepack\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/utils/_weight_prepack.py\", line 8, in &lt;module&gt;\n    from intel_extension_for_pytorch.cpu.tpp.utils.blocked_layout import (\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/cpu/tpp/__init__.py\", line 2, in &lt;module&gt;\n    from . import fused_bert\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/intel_extension_for_pytorch/cpu/tpp/fused_bert.py\", line 16, in &lt;module&gt;\n    from transformers.modeling_utils import apply_chunking_to_forward\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/venvs/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 69, in &lt;module&gt;\n    from .loss.loss_utils import LOSS_MAPPING\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/venvs/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/transformers/loss/loss_utils.py\", line 21, in &lt;module&gt;\n    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/venvs/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/transformers/loss/loss_deformable_detr.py\", line 4, in &lt;module&gt;\n    from ..image_transforms import center_to_corners_format\n  File \"/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-05-02-150121/ezpz/venvs/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/transformers/image_transforms.py\", line 47, in &lt;module&gt;\n    import tensorflow as tf\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/__init__.py\", line 48, in &lt;module&gt;\n    from tensorflow._api.v2 import __internal__\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in &lt;module&gt;\n    from tensorflow._api.v2.__internal__ import autograph\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in &lt;module&gt;\n    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in &lt;module&gt;\n    from tensorflow.python.autograph.utils import ag_logging\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in &lt;module&gt;\n    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in &lt;module&gt;\n    from tensorflow.python.framework import ops\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 41, in &lt;module&gt;\n    from tensorflow.python import pywrap_tfe\n  File \"/opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0/lib/python3.10/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in &lt;module&gt;\n    from tensorflow.python._pywrap_tfe import *\nAttributeError: _ARRAY_API not found\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n\n# ...[clipped]...",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "05",
      "üöß Frameworks Issue with <code>numpy > 2</code>"
    ]
  },
  {
    "objectID": "posts/2025/05/03/index.html#footnotes",
    "href": "posts/2025/05/03/index.html#footnotes",
    "title": "üöß Frameworks Issue with numpy > 2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a lot of packages, including: { torch, jax, tensorflow, scipy, jaxlib, numpy, ml-dtypes, opt-einsum, ‚Ä¶, }.‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "05",
      "üöß Frameworks Issue with <code>numpy > 2</code>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nTipüìì References\n\n\n\n\n\n\nReferences:\n\n(Yan et al. 2025)\n(Gokdemir et al. 2025)\n(Dharuman et al. 2024)\n(Parete-Koon et al. 2024)\n(Cheng et al. 2024)\n(Zvyagin et al. 2023)\n(Dharuman et al. 2023)\n(Emani et al. 2023)\n(Song et al. 2023)\n(Sam Foreman, Jin, and Osborn)\n(Boyda et al. 2022)\n(Kronfeld et al. 2022)\n(Shanahan, Terao, and Whiteson 2022)\n(S. Foreman, Jin, and Osborn 2022)\n(Sam Foreman et al. 2021)\n(Sam Foreman, Jin, and Osborn 2020)\n(S. A. Foreman 2019)\n(Sam Foreman et al. 2018)\n(Hubler et al. 2018)\n(Samuel Foreman et al. 2018)\n(Liu et al. 2017)\n(Deamont and Foreman 2014)\n\n\n\n\nBoyda, Denis, Salvatore Calƒ±ÃÄ, Sam Foreman, Lena Funcke, Daniel C Hackett, Yin Lin, Gert Aarts, et al. 2022. ‚ÄúApplications of Machine Learning to Lattice Quantum Field Theory.‚Äù arXiv Preprint arXiv:2202.05838. https://arxiv.org/abs/2202.05838.\n\n\nCheng, Scott, Jun-Liang Lin, Murali Emani, Siddhisanket Raskar, Sam Foreman, Zhen Xie, Venkatram Vishwanath, and Mahmut Taylan Kandemir. 2024. ‚ÄúThorough Characterization and Analysis of Large Transformer Model Training at-Scale.‚Äù Proceedings of the ACM on Measurement and Analysis of Computing Systems 8 (1): 1‚Äì25.\n\n\nDeamont, George, and Sam Foreman. 2014. ‚ÄúSuperconductivity of in and Sn Samples.‚Äù\n\n\nDharuman, Gautham, Kyle Hippe, Alexander Brace, Sam Foreman, V√§in√§ Hatanp√§√§, Varuni K Sastry, Huihuo Zheng, et al. 2024. ‚ÄúMProt-DPO: Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows with Direct Preference Optimization.‚Äù In 2024 SC24: International Conference for High Performance Computing, Networking, Storage and Analysis SC, 74‚Äì86. IEEE Computer Society.\n\n\nDharuman, Gautham, Logan Ward, Heng Ma, Priyanka V Setty, Ozan Gokdemir, Sam Foreman, Murali Emani, et al. 2023. ‚ÄúProtein Generation via Genome-Scale Language Models with Bio-Physical Scoring.‚Äù In Proceedings of the SC‚Äô23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis, 95‚Äì101.\n\n\nEmani, Murali, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, and Michael E Papka. 2023. ‚ÄúA Comprehensive Performance Study of Large Language Models on Novel AI Accelerators.‚Äù arXiv Preprint arXiv:2310.04607. https://arxiv.org/abs/2310.04607.\n\n\nForeman, Sam, Joel Giedt, Yannick Meurice, and Judah Unmuth-Yockey. 2018. ‚ÄúRG-Inspired Machine Learning for Lattice Field Theory.‚Äù In EPJ Web of Conferences, 175:11025. EDP Sciences.\n\n\nForeman, Sam, Taku Izubuchi, Luchang Jin, Xiao-Yong Jin, James C Osborn, and Akio Tomiya. 2021. ‚ÄúHMC with Normalizing Flows.‚Äù arXiv Preprint arXiv:2112.01586. https://arxiv.org/abs/2112.01586.\n\n\nForeman, Sam, Xiao-Yong Jin, and James Osborn. ‚ÄúMLMC: Machine Learning Monte Carlo for Lattice Gauge Theory.‚Äù In 40th International Symposium on Lattice Field Theory (Lattice 2023) (Batavia, IL, United States, 07/31/2023 - 08/04/2023).\n\n\nForeman, Sam, Xiao-Yong Jin, and James C Osborn. 2020. ‚ÄúMachine Learning and Neural Networks for Field Theory.‚Äù\n\n\nForeman, Samuel Alfred. 2019. ‚ÄúLearning Better Physics: A Machine Learning Approach to Lattice Gauge Theory.‚Äù PhD thesis, University of Iowa.\n\n\nForeman, Samuel, Joel Giedt, Yannick Meurice, and Judah Unmuth-Yockey. 2018. ‚ÄúExamples of Renormalization Group Transformations for Image Sets.‚Äù Physical Review E 98 (5): 052129.\n\n\nForeman, S., X. y. Jin, and J. Osborn. 2022. ‚ÄúLeapfrogLayers: A Trainable Framework for Effective Topological Sampling.‚Äù In The 38th International Symposium on Lattice Field Theory, 508. https://doi.org/10.22323/1.396.0508.\n\n\nGokdemir, Ozan, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, et al. 2025. ‚ÄúHiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights.‚Äù https://arxiv.org/abs/2505.04846.\n\n\nHubler, A, S Foreman, J Liu, and L Wortsmann. 2018. ‚ÄúLarge Energy Density in Three-Plate Nanocapacitors Due to Coulomb Blockade.‚Äù Journal of Applied Physics 123 (10).\n\n\nKronfeld, Andreas S, Tanmoy Bhattacharya, Thomas Blum, Norman H Christ, Carleton DeTar, William Detmold, Robert Edwards, et al. 2022. ‚ÄúLattice QCD and Particle Physics.‚Äù arXiv Preprint arXiv:2207.07641. https://arxiv.org/abs/2207.07641.\n\n\nLiu, Jiaqi, Alfred W Hubler, Samuel Alfred Foreman, and Katharina Ott. 2017. ‚ÄúEnergy Storage in Quantum Resonators.‚Äù\n\n\nParete-Koon, Suzanne, Michael Sandoval, Kellen Leland, Subil Abraham, Mary Ann Leung, Rebecca Hartman-Baker, Paige Kinsley, et al. 2024. ‚ÄúIntro to HPC Bootcamp: Engaging New Communities Through Energy Justice Projects.‚Äù Journal of Computational Science Education 15 (1).\n\n\nShanahan, Phiala, Kazuhiro Terao, and Daniel Whiteson. 2022. ‚ÄúSnowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning.‚Äù arXiv Preprint arXiv:2209.07559. https://arxiv.org/abs/2209.07559.\n\n\nSong, Shuaiwen Leon, Bonnie Kruft, Minjia Zhang, Conglong Li, Shiyang Chen, Chengming Zhang, Masahiro Tanaka, et al. 2023. ‚ÄúDeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery Through Sophisticated AI System Technologies.‚Äù arXiv Preprint arXiv:2310.04610. https://arxiv.org/abs/2310.04610.\n\n\nYan, Xiaoli, Nathaniel Hudson, Hyun Park, Daniel Grzenda, J. Gregory Pauloski, Marcus Schwarting, Haochen Pan, et al. 2025. ‚ÄúMOFA: Discovering Materials for Carbon Capture with a GenAI- and Simulation-Based Workflow.‚Äù https://arxiv.org/abs/2501.10651.\n\n\nZvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang, Cindy Orozco Bohorquez, Austin Clyde, et al. 2023. ‚ÄúGenSLMs: Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics.‚Äù The International Journal of High Performance Computing Applications 37 (6): 683‚Äì705."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "",
    "section": "üìÜ 2025",
    "text": "üìÜ 2025\n\n\n\n\n\n\nTipLLMs on Aurora: üåå AuroraGPT @ 2025 ALCF INCITE GPU Hackathon [05/2025]\n\n\n\n\n\n\nüé• video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipLLMs on Aurora: üçã ezpz @ 2025 ALCF INCITE GPU Hackathon [05/2025]\n\n\n\n\n\n\nüé• video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipAuroraGPT: Foundation Models for Science @ Foundation Models for the Electric Grid [02/2025]"
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "",
    "section": "üìÜ 2024",
    "text": "üìÜ 2024\n\n\n\n\n\n\nTipParallel Training Methods @ AI-for-Science on Supercomputers [11/2024]\n\n\n\n\n\n\nüé• video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipAuroraGPT @ 2024 ALCF Hands-On HPC Workshop [10/2024]\n\n\n\n\n\n\nüé• video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipMachine Learning and Foundation Models at Scale @ 2024 ALCF Hands-On HPC Workshop [10/2024]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipAuroraGPT @ HPC User Forum, 2024 [09/2024]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipTraining LLMs at Scale @ ATPESC, 2024 [08/2024]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipLLMs on Polaris @ Center for Scientific Foundation Models, Summer School 24‚Äô [07/2024]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipParallel Training Techniques @ AI-4-Science Training Series [03/2024]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipLLMs from Scratch @ LLM Tutorial Workshop [02/2024]"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "",
    "section": "üìÜ 2023",
    "text": "üìÜ 2023\n\n\n\n\n\n\nTipCreating Small(-ish) LLMs @ LLM Tutorial Workshop (1) [11/2023]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipExascale Science on Aurora @ Intel oneAPI Workshop @ UIC [10/2023]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipLLM Lunch Talk @ ALCF Hands On HPC Workshop [10/2023]\n\n\n\n\n\n\nüé• video\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipScaling LLMs for Science @ Data-Intensive Computing + AI/ML at Scale [08/2023]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipMLMC: Machine Learning Monte Carlo @ Lattice 2023 [07/2023]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipGenerative Modeling and Efficient Sampling @ PASC23 [07/2023]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipEfficient Sampling for LGT @ Deep Fridays @ U. Bologna [04/2023]"
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "",
    "section": "üìÜ 2022",
    "text": "üìÜ 2022\n\n\n\n\n\n\nTipLarge Scale Training @ AI4Science on Supercomputers (ALCF) [11/2022]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipHyperparameter Management @ ALCF SDL Workshop [10/2022]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipStatistical Learning @ ATPESC 2022 [08/2022]\n\n\n\n\n\n\nüìï accompanying notebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipScientific Data Science: An Emerging Symbiosis @ ANL (05/2022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipMachine Learning in HEP @ UNC Greensboro [03/2022]\n\n\n\n\n\n\nMachine Learning in HEP, at UNC Greensboro, March 2022"
  },
  {
    "objectID": "index.html#section-4",
    "href": "index.html#section-4",
    "title": "",
    "section": "üìÜ 2021",
    "text": "üìÜ 2021\n\n\n\n\n\n\nTipAccelerated Sampling Methods for LGT, @ DWQ @ 25 [BNL] [12/2021]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipTraining Topological Samplers for LGT @ ML4HEP, ECT* Trento [09/2021]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipl2hmc-qcd @ MIT Lattice Group Seminar [2021]\n\n\n\n\n\nl2hmc-qcd at the MIT Lattice Group Seminar, 2021\n\n\n\n\n\n\n\n\n\nTipDeep Learning HMC for Improved Gauge Generation @ ML in LQCD Workshop [2021]"
  },
  {
    "objectID": "index.html#section-5",
    "href": "index.html#section-5",
    "title": "",
    "section": "üìÜ 2020",
    "text": "üìÜ 2020\n\n\n\n\n\n\nTipMachine Learning for Lattice QCD @ U. Iowa [2020]"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee full list on Google Scholar‚Ü©Ô∏é\nSee full list at: samforeman.me/talks‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2025/04/28/index.html#pytorch-2.6-on-aurora",
    "href": "posts/2025/04/28/index.html#pytorch-2.6-on-aurora",
    "title": "üî• Building PyTorch 2.6 from Source on Aurora",
    "section": "PyTorch 2.6 on Aurora",
    "text": "PyTorch 2.6 on Aurora\n; source &lt;(curl -L https://bit.ly/ezpz-utils) && ezpz_setup_env\n; export CXX=$(which g++)\n; export CC=$(which gcc)\n; export REL_WITH_DEB_INFO=1\n; export USE_CUDA=0\n; export USE_ROCM=0\n; export USE_MKLDNN=1\n; export USE_MKL=1\n; export USE_ROCM=0\n; export USE_CUDNN=0\n; export USE_FBGEMM=0\n; export USE_NNPACK=0\n; export USE_QNNPACK=0\n; export USE_NCCL=0\n; export USE_CUDA=0\n; export BUILD_CAFFE2_OPS=0\n; export BUILD_TEST=0\n; export USE_DISTRIBUTED=1\n; export USE_NUMA=0\n; export USE_MPI=1\n; export USE_XPU=1\n; export USE_XCCL=1\n; export INTEL_MKL_DIR=$MKLROOT\n; export USE_AOT_DEVLIST='pvc'\n; export TORCH_XPU_ARCH_LIST='pvc'\n; export OCLOC_VERSION=24.39.1\n; which -a gcc\n# /opt/aurora/24.347.0/spack/unified/0.9.1/install/linux-sles15-x86_64/gcc-13.3.0/gcc-13.3.0-4enwbrb/bin/gcc\n#/usr/bin/gcc\n; which -a g++\n#/opt/aurora/24.347.0/spack/unified/0.9.1/install/linux-sles15-x86_64/gcc-13.3.0/gcc-13.3.0-4enwbrb/bin/g++\n#/usr/bin/g++\n; git clone https://github.com/pytorch/pytorch.git\n; cd pytorch\n; git checkout v2.6.0\n; git submodule update --init --recursive --force\n; make triton\n; USE_XCCL=1 DEBUG=1 REL_WITH_DEB_INFO=1 USE_CUDA=0 CC=$(which gcc) CXX=$(which g++) python3 setup.py bdist_wheel --verbose 2&gt;&1 | tee \"build_whl-${NOW}.log\"\n; python3 -m pip install dist/torch-2.6.0a0+git1eba9b3-cp310-cp310-linux_x86_64.whl --force-reinstall\n; python -m pip install intel-extension-for-pytorch==2.6.10+xpu oneccl_bind_pt==2.6.0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "04",
      "üî• Building PyTorch 2.6 from Source on Aurora"
    ]
  },
  {
    "objectID": "posts/2025/06/01/index.html",
    "href": "posts/2025/06/01/index.html",
    "title": "üì∞ Nice Headings",
    "section": "",
    "text": "I like headings. They help organize content and make it easier to read.\nInspired by my neovim config, I wanted to recreate a similar style for headings in my website.\nI think they turned out pretty well!",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üì∞ Nice Headings"
    ]
  },
  {
    "objectID": "posts/2025/06/01/index.html#heading-2",
    "href": "posts/2025/06/01/index.html#heading-2",
    "title": "üì∞ Nice Headings",
    "section": "Heading 2",
    "text": "Heading 2\n\nHeading 3\n\nHeading 4\n\nHeading 5\n\nHeading 6",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üì∞ Nice Headings"
    ]
  },
  {
    "objectID": "posts/2025/06/14/index.html#shell-environment",
    "href": "posts/2025/06/14/index.html#shell-environment",
    "title": "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora",
    "section": "üèñÔ∏è Shell Environment",
    "text": "üèñÔ∏è Shell Environment\n\nHelper function to get timestamp:\ntstamp() {\n     date +\"%Y-%m-%d-%H%M%S\"\n}\nLoad frameworks module:\nmodule load frameworks\nDeactivate conda environment:\nconda deactivate\nCreate new conda environment:\nENV_PATH=\"/flare/datascience/foremans/miniconda/2025-06-15\"\nconda create --prefix \"${ENV_PATH}\" --y --solver=libmamba --verbose python=3.12\nconda activate \"${ENV_PATH}\"",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora"
    ]
  },
  {
    "objectID": "posts/2025/06/14/index.html#build-libraries",
    "href": "posts/2025/06/14/index.html#build-libraries",
    "title": "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora",
    "section": "üî® Build Libraries",
    "text": "üî® Build Libraries\n\nPyTorch\n\nClone pytorch/pytorch\ngit clone https://github.com/pytorch/pytorch\ncd pytorch\ngit submodule sync\ngit submodule update --init --recursive\nInstall dependencies:\npython3 -m pip install cmake ninja\npython3 -m pip install -r requirements.txt\npython3 -m pip install mkl-static mkl-include\nMake triton:\nexport USE_XPU=1  # for Intel GPU support\nmake triton\nSet environment variables for PyTorch build:\nCC=$(which gcc); export CC\nCXX=$(which g++); export CXX\nexport REL_WITH_DEB_INFO=1\nexport USE_CUDA=0\nexport USE_ROCM=0\nexport USE_MKLDNN=1\nexport USE_MKL=1\nexport USE_ROCM=0\nexport USE_CUDNN=0\nexport USE_FBGEMM=1\nexport USE_NNPACK=1\nexport USE_QNNPACK=1\nexport USE_NCCL=0\nexport USE_CUDA=0\nexport BUILD_CAFFE2_OPS=0\nexport BUILD_TEST=0\nexport USE_DISTRIBUTED=1\nexport USE_NUMA=0\nexport USE_MPI=1\nexport USE_XPU=1\nexport USE_XCCL=1\nexport INTEL_MKL_DIR=$MKLROOT\nexport USE_AOT_DEVLIST='pvc'\nexport TORCH_XPU_ARCH_LIST='pvc'\nexport OCLOC_VERSION=24.39.1\nwhich -a gcc\nwhich -a g++\nBuild PyTorch (takes ~ 30 mins):\npython3 setup.py bdist_wheel 2&gt;&1 | tee \"torch-build-whl-$(tstamp).log\"\npython3 -m pip install dist/*.whl\ncd ..\n[Optional] Install {torchvision, torchaudio, torchdata} with no dependencies:\npython3 -m pip install torchvision torchaudio --no-deps --index-url https://download.pytorch.org/whl/xpu\npython3 -m pip install torchdata --no-deps\n\n\n\nIntel Libraries\n\nintel/intel-extension-for-pytorch\ngit clone https://github.com/intel/intel-extension-for-pytorch\ncd intel-extension-for-pytorch\ngit checkout xpu-main\ngit submodule sync\ngit submodule update --init --recursive\npython3 -m pip install -r requirements.txt\npython3 -m pip install --upgrade pip setuptools wheel build black flake8\nMAX_JOBS=48 CC=$(which gcc) CXX=$(which g++) INTELONEAPIROOT=\"${ONEAPI_ROOT}\" python3 setup.py bdist_wheel 2&gt;&1 | tee \"ipex-build-whl-$(tstamp).log\"\npython3 -m pip install dist/*.whl\ncd ..\nintel/torch-ccl\ngit clone https://github.com/intel/torch-ccl\ncd torch-ccl\ngit checkout c27ded5\ngit submodule sync\ngit submodule update --init --recursive\npython3 -m pip install -r requirements.txt\n# see:\n# https://github.com/intel/torch-ccl/blob/c27ded5190a6b115ec68c7a8c28f40cfe7f0a32a/version.txt\nONECCL_BINDINGS_FOR_PYTORCH_BACKEND=xpu INTELONEAPIROOT=\"${ONEAPI_ROOT}\" USE_SYSTEM_ONECCL=ON COMPUTE_BACKEND=dpcpp python3 setup.py bdist_wheel 2&gt;&1 | tee \"torch-ccl-build-whl-$(tstamp).log\"\n\npython3 -m pip install dist/*.whl\ncd ..\n\n\n\nmpi4py\ngit clone https://github.com/mpi4py/mpi4py\ncd mpi4py\nCC=mpicc CXX=mpicxx python3 setup.py build |& tee build.log\nCC=mpicc CXX=mpicxx python3 setup.py install |& tee install.log\ncd ..",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora"
    ]
  },
  {
    "objectID": "posts/2025/06/14/index.html#verify-installation",
    "href": "posts/2025/06/14/index.html#verify-installation",
    "title": "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora",
    "section": "‚úÖ Verify Installation",
    "text": "‚úÖ Verify Installation\n\nCommand:\npython3 -c 'import torch; print(torch.__file__); print(*torch.__config__.show().split(\"\\n\"), sep=\"\\n\") ; print(f\"{torch.__version__=}\"); print(f\"{torch.xpu.is_available()=}\"); print(f\"{torch.xpu.device_count()=}\") ; import torch.distributed; print(f\"{torch.distributed.is_xccl_available()=}\"); import torch; import intel_extension_for_pytorch as ipex; print(f\"{torch.__version__=}\"); print(f\"{ipex.__version__=}\"); import oneccl_bindings_for_pytorch as oneccl_bpt; print(f\"{oneccl_bpt.__version__=}\") ; [print(f\"[{i}]: {torch.xpu.get_device_properties(i)}\") for i in range(torch.xpu.device_count())]'\nOutput:\n$ python3 -c 'import torch; print(torch.__file__); print(*torch.__config__.show().split(\"\\n\"), sep=\"\\n\") ; print(f\"{torch.__version__=}\"); print(f\"{torch.xpu.is_available()=}\"); print(f\"{torch.xpu.device_count()=}\") ; import torch.distributed; print(f\"{torch.distributed.is_xccl_available()=}\"); import torch; import intel_extension_for_pytorch as ipex; print(f\"{torch.__version__=}\"); print(f\"{ipex.__version__=}\"); import oneccl_bindings_for_pytorch as oneccl_bpt; print(f\"{oneccl_bpt.__version__=}\") ; [print(f\"[{i}]: {torch.xpu.get_device_properties(i)}\") for i in range(torch.xpu.device_count())]'\n/flare/datascience/foremans/miniconda/2025-06-15/lib/python3.12/site-packages/torch/__init__.py\nPyTorch built with:\n  - GCC 13.3\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2025.0.1-Product Build 20241031 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v3.7.1 (Git Hash 8d263e693366ef8db40acc569cc7d8edf644556d)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX512\nXPU backend  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Debug, COMMIT_SHA=655b3b14ffba4ae73e26a63b4289329e8d160a6f, CXX_COMPILER=/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/gcc-13.3.0-4enwbrb/bin/g++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=OFF -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -DC10_NODEPRECATED -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-dangling-reference -Wno-error=dangling-reference -DUSE_XPU -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.8.0, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=1, USE_MPI=1, USE_NCCL=OFF, USE_NNPACK=1,USE_OPENMP=ON, USE_ROCM=0, USE_ROCM_KERNEL_ASSERT=OFF, USE_XCCL=1, USE_XPU=1,\n\ntorch.__version__='2.8.0a0+git655b3b1'\ntorch.xpu.is_available()=True\ntorch.xpu.device_count()=12\ntorch.distributed.is_xccl_available()=True\n[W615 14:52:10.420018164 OperatorEntry.cpp:217] Warning: Warning only once for all operators,  other operators may also be overridden.\n  Overriding a previously registered kernel for the same operator and the same dispatch key\n  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -&gt; Tensor(a!)\n    registered at /lus/flare/projects/datascience/foremans/AuroraBuilds/2025-06-15/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n  dispatch key: XPU\n  previous kernel: registered at /lus/flare/projects/datascience/foremans/AuroraBuilds/2025-06-15/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:37\n       new kernel: registered at /lus/flare/projects/datascience/foremans/AuroraBuilds/2025-06-15/intel-extension-for-pytorch/build/Release/csrc/gpu/csrc/gpu/xpu/ATen/RegisterXPU_0.cpp:186 (function operator())\ntorch.__version__='2.8.0a0+git655b3b1'\nipex.__version__='2.8.10+git57bb68a'\noneccl_bpt.__version__='2.8.0+xpu'\n[0]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[1]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[2]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[3]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[4]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[5]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[6]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[7]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[8]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[9]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[10]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n[11]: _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) oneAPI Unified Runtime over Level-Zero', type='gpu', driver_version='1.6.32567+18', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, gpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\ntook: 0h:00m:21s",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025",
      "06",
      "üèóÔ∏è Building PyTorch 2.8 from Source on Aurora"
    ]
  },
  {
    "objectID": "posts/2025/index.html",
    "href": "posts/2025/index.html",
    "title": "üìÜ 2025",
    "section": "",
    "text": "What\n\n\n\nWhen\n\n\n\n\n\n\n\n\nüèóÔ∏è Building PyTorch 2.8 from Source on Aurora\n\n\n2025-06-14\n\n\n\n\n\n\nüßú‚Äç‚ôÄÔ∏è Mermaid\n\n\n2025-06-02\n\n\n\n\n\n\nüì∞ Nice Headings\n\n\n2025-06-01\n\n\n\n\n\n\nüöß Frameworks Issue with numpy &gt; 2\n\n\n2025-05-03\n\n\n\n\n\n\nüî• Building PyTorch 2.6 from Source on Aurora\n\n\n2025-04-28\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2025,\n  author = {Foreman, Sam},\n  title = {üìÜ 2025},\n  date = {2025-06-14},\n  url = {https://samforeman.me/posts/2025/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2025. ‚ÄúüìÜ 2025.‚Äù June 14, 2025. https://samforeman.me/posts/2025/.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìÜ 2025"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/checkpoints/index.html#mds-hf",
    "href": "posts/AuroraGPT/checkpoints/index.html#mds-hf",
    "title": "üíæ Converting Checkpoints",
    "section": "MDS ‚Äì> HF",
    "text": "MDS ‚Äì&gt; HF\nconvert_mds_to_hf() {\n # GLOBAL_STEP=$1\n CKPT_ROOT=$2\n\n CKPT_ROOT=\"/flare/Aurora_deployment/AuroraGPT-Testing/foremans/rollback-41k8/Megatron-DeepSpeed-41800/checkpoints/ws768_ds_stage1_nl32_hs4096_mb4_seq4096_gb3072_sp1_pp1_tp1_bf16_optadamw_lr0.00020_lwf0.05/\";\n SRC=\"${CKPT_ROOT}/global_step${GLOBAL_STEP}\"\n if [[ -d \"${SRC}\" ]]; then\n        echo \"Converting checkpoint @ global step ${GLOBAL_STEP}\"\n        echo \"\\tsrc=${SRC}\"\n        DST=\"/flare/Aurora_deployment/AuroraGPT-Checkpoints/Megatron-DeepSpeed/checkpoints-to-convert/ws768_ds_stage1_nl32_hs4096_mb4_seq4096_gb3072_sp1_pp1_tp1_bf16_optadamw_lr0.00020_lwf0.05/global_step${GLOBAL_STEP}_hf\"\n        echo \"\\tdst=${DST}\"\n        python3 mds_to_hf.py --mds_checkpoint \"${SRC}/mp_rank_00_model_states.pt\" --output_dir \"${DST}\" --cache_dir \"./.cache\"\n else\n        echo \"Unable to locate directory ${SRC}. Exiting\"\n        exit 1\n fi\n}",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üíæ Converting Checkpoints"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/checkpoints/index.html#section",
    "href": "posts/AuroraGPT/checkpoints/index.html#section",
    "title": "üíæ Converting Checkpoints",
    "section": "2024-10-17",
    "text": "2024-10-17\nimport os\nimport ezpz as ez\nimport torch\nimport deepspeed\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\nfrom transformers.integrations import HfDeepSpeedConfig\n# distributed setup\n\nos.environ['WORLD_SIZE'] = '12'\nrank = ez.setup_torch(backend='deepspeed')\ndeepspeed.init_distributed()\nmodel_name = \"meta-llama/Llama-3.2-1B\"\nconfig = AutoConfig.from_pretrained(model_name)\nds_config = {\n    \"steps_per_print\": 1,\n    \"train_batch_size\": 1,\n    \"train_micro_batch_size_per_gpu\": 1,\n    \"bf16\": {\n        \"enabled\": True\n    },\n    \"optimizer\": {\n        \"type\": \"Adam\",\n    },\n    \"zero_optimization\": {\n        \"stage\": 3,\n    },\n}\n\ndschf = HfDeepSpeedConfig(ds_config)  # keep this object alive\n# now a model can be loaded.\nmodel = AutoModelForCausalLM.from_pretrained(model_name).to(ez.get_torch_device()).to(torch.bfloat16)\n# initialise Deepspeed ZeRO and store only the engine object\nds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\n\ndataset = load_dataset(\"yelp_review_full\")\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\nfrom transformers import Trainer\ntraining_args = TrainingArguments(output_dir=\"llama-3.2-1B\", deepspeed=ds_config)\ntrainer = Trainer(model, training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset, tokenizer=tokenizer)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üíæ Converting Checkpoints"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/checkpoints/index.html#older",
    "href": "posts/AuroraGPT/checkpoints/index.html#older",
    "title": "üíæ Converting Checkpoints",
    "section": "Older",
    "text": "Older\nCurrent status:\n#[üêç aurora_nre_models_frameworks-2024.2.1_u1][üëª aurora_nre_models_frameworks-2024.2.1_u1]\n#[üåå][03:39:06 PM][foremans]@[x4407c6s7b0n0][/f/A/f/p/a/Megatron-DeepSpeed][üå±hzheng-data-fix][üìùü§∑üèéüí®]\n$ _conversion_args=(\"--hf-ckpt-num-shards 1\"\n \"--hf-ckpt-dir /flare/Aurora_deployment/foremans/Meta-Llama-3.1-8B-128512\"\n \"--load-mode auto\"\n \"--save ckpt-mds-llama-3/\"\n \"--tensor-model-parallel-size 1\"\n \"--pipeline-model-parallel-size 1\"\n \"--lr-warmup-iters 2000\"\n \"--weight-decay 0.1\"\n \"--clip-grad 1\"\n \"--num-layers 32\"\n \"--hidden-size 4096\"\n \"--num-attention-heads 32\"\n \"--ffn-hidden-size 14336\"\n \"--attention-dropout 0\"\n \"--hidden-dropout 0\"\n \"--no-query-key-layer-scaling\"\n \"--num-key-value-heads 8\"\n \"--disable-bias-linear\"\n \"--normalization rmsnorm\"\n \"--use-rotary-position-embeddings\"\n \"--untie-embeddings-and-output-weights\"\n \"--swiglu\"\n \"--seq-length 2048\"\n \"--max-position-embeddings 2048\"\n \"--micro-batch-size 1\"\n \"--global-batch-size 24\"\n \"--train-iters 3500\"\n \"--lr 2e-5\"\n \"--tensorboard-dir tensorboard_output\"\n \"--lr-decay-iters 320000\"\n \"--lr-decay-style cosine\"\n \"--log-interval 1\"\n \"--eval-iters 100\"\n \"--eval-interval 100\"\n \"--data-path /lus/flare/projects/candle_aesp_CNDA/azton/data/v2/megatron/dataset_v2_wtextbooks_text_document\"\n \"--save-interval 1500\"\n \"--split 100,0,0\"\n \"--bf16\"\n \"--tokenizer-type HFTokenizer\"\n \"--tokenizer-model ALCF/custom_tokenizer.model\"\n \"--deepspeed_config ./examples_deepspeed/finetune_hf_llama/ds_config.json\"\n \"--deepspeed\"\n \"--distributed-backend ccl\"\n \"--no-masked-softmax-fusion\"\n \"--no-bias-gelu-fusion\"\n \"--no-bias-dropout-fusion\"\n \"--no-gradient-accumulation-fusion\"\n \"--repeated-dataloader\"\n \"--data-cache-path ./.cache\"\n \"--make-vocab-size-divisible-by 128512\"\n \"--vocab-size 128512\"\n)\n\nconversion_flags=($(printf '%s\\n' \"${_conversion_args[@]}\" | sort))\necho \"${conversion_flags[@]}\"\n--attention-dropout 0 --bf16 --clip-grad 1 --data-cache-path ./.cache --data-path /lus/flare/projects/candle_aesp_CNDA/azton/data/v2/megatron/dataset_v2_wtextbooks_text_document --deepspeed --deepspeed_config ./examples_deepspeed/finetune_hf_llama/ds_config.json --disable-bias-linear --distributed-backend ccl --eval-interval 100 --eval-iters 100 --ffn-hidden-size 14336 --global-batch-size 24 --hf-ckpt-dir /flare/Aurora_deployment/foremans/Meta-Llama-3.1-8B-128512 --hf-ckpt-num-shards 1 --hidden-dropout 0 --hidden-size 4096 --load-mode auto --log-interval 1 --lr 2e-5 --lr-decay-iters 320000 --lr-decay-style cosine --lr-warmup-iters 2000 --make-vocab-size-divisible-by 128512 --max-position-embeddings 2048 --micro-batch-size 1 --no-bias-dropout-fusion --no-bias-gelu-fusion --no-gradient-accumulation-fusion --no-masked-softmax-fusion --no-query-key-layer-scaling --normalization rmsnorm --num-attention-heads 32 --num-key-value-heads 8 --num-layers 32 --pipeline-model-parallel-size 1 --repeated-dataloader --save ckpt-mds-llama-3/ --save-interval 1500 --seq-length 2048 --split 100,0,0 --swiglu --tensorboard-dir tensorboard_output --tensor-model-parallel-size 1 --tokenizer-model ALCF/custom_tokenizer.model --tokenizer-type HFTokenizer --train-iters 3500 --untie-embeddings-and-output-weights --use-rotary-position-embeddings --vocab-size 128512 --weight-decay 0.1\n#[üêç aurora_nre_models_frameworks-2024.2.1_u1][üëª aurora_nre_models_frameworks-2024.2.1_u1]\n#[üåå][03:39:18 PM][foremans]@[x4407c6s7b0n0][/f/A/f/p/a/Megatron-DeepSpeed][üå±hzheng-data-fix][üìùü§∑üèéüí®]\n$ launch python3 tools/hf2megads_weight_converter.py \"${conversion_flags[@]}\"\n\n\noutput:\n\nDisabling local launch: multi-node application\nConnected to tcp://x4407c6s7b0n0.hostmgmt2407.cm.aurora.alcf.anl.gov:7919\nFound executable /flare/Aurora_deployment/foremans/projects/argonne-lcf/Megatron-DeepSpeed/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\nLaunching application bdbd987f-b27b-4922-928b-5d1a166e800b\n[2024-10-16 15:39:30,424] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,456] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,456] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,456] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,457] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,568] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,571] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,575] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,578] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,584] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,608] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,613] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,613] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,614] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,615] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,630] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,686] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,698] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,711] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,715] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,716] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,723] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,724] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,726] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,731] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,737] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,755] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,766] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,768] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,780] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,798] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,840] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,870] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,870] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,872] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,873] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,877] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,888] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,896] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,902] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,932] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,934] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,957] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:30,984] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:31,028] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:31,029] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:31,062] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:31,150] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2024-10-16 15:39:33,079] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:33,079] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:33,079] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:33,481] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:33,481] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:33,481] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:33,982] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:33,982] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:33,982] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:33,983] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:33,983] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:33,983] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:33,984] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:33,984] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:33,984] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,133] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,133] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,133] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,165] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,165] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,165] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,207] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,207] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,207] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,210] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,210] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,210] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,216] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,216] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,216] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,218] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,218] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,219] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,271] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,271] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,271] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,768] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,768] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,768] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,772] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,772] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,772] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,784] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,784] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,784] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:34,795] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:34,795] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:34,795] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,038] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,038] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,038] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,048] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,048] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,048] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,062] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,062] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,062] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,070] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,070] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,070] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,073] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,073] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,073] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,077] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,078] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,078] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,103] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,104] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,104] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,106] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend\n[2024-10-16 15:39:35,107] [INFO] [comm.py:652:init_distributed] cdb=None\n[2024-10-16 15:39:35,107] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=4, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=5, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=6, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=7, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=8, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=9, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=10, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=11, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=4, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=5, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=6, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=7, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=8, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=9, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=10, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35,107] [INFO] [comm.py:718:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=11, world_size=24, master_addr=10.115.45.184, master_port=29500\n[2024-10-16 15:39:35.116490][INFO][dist.py:348] - [device='xpu'][rank=15/23][local_rank=3/11][node=1/1]\n[2024-10-16 15:39:35.117455][INFO][dist.py:348] - [device='xpu'][rank=1/23][local_rank=1/11][node=1/1]\n2024:10:16-15:39:35:(34466) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169066) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.120281][INFO][dist.py:348] - [device='xpu'][rank=10/23][local_rank=10/11][node=0/1]\n[2024-10-16 15:39:35.120280][INFO][dist.py:348] - [device='xpu'][rank=11/23][local_rank=11/11][node=1/1]\n2024:10:16-15:39:35:(169075) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169076) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.124730][INFO][dist.py:348] - [device='xpu'][rank=4/23][local_rank=4/11][node=0/1]\n[2024-10-16 15:39:35.125260][INFO][dist.py:348] - [device='xpu'][rank=6/23][local_rank=6/11][node=0/1]\n[2024-10-16 15:39:35.125427][INFO][dist.py:348] - [device='xpu'][rank=3/23][local_rank=3/11][node=1/1]\n2024:10:16-15:39:35:(169069) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169068) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169071) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.127167][INFO][dist.py:348] - [device='xpu'][rank=8/23][local_rank=8/11][node=0/1]\n[2024-10-16 15:39:35.127199][INFO][dist.py:348] - [device='xpu'][rank=21/23][local_rank=9/11][node=1/1]\n2024:10:16-15:39:35:(169073) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34472) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.129097][INFO][dist.py:348] - [device='xpu'][rank=14/23][local_rank=2/11][node=0/1]\n[2024-10-16 15:39:35.129281][INFO][dist.py:348] - [device='xpu'][rank=9/23][local_rank=9/11][node=1/1]\n[2024-10-16 15:39:35.129345][INFO][dist.py:348] - [device='xpu'][rank=22/23][local_rank=10/11][node=0/1]\n[2024-10-16 15:39:35.129461][INFO][dist.py:348] - [device='xpu'][rank=20/23][local_rank=8/11][node=0/1]\n2024:10:16-15:39:35:(34465) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.130518][INFO][dist.py:348] - [device='xpu'][rank=13/23][local_rank=1/11][node=1/1]\n2024:10:16-15:39:35:(34473) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169074) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34471) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34464) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.131822][INFO][dist.py:348] - [device='xpu'][rank=18/23][local_rank=6/11][node=0/1]\n[2024-10-16 15:39:35.131816][INFO][dist.py:348] - [device='xpu'][rank=19/23][local_rank=7/11][node=1/1]\n2024:10:16-15:39:35:(34469) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.133183][INFO][dist.py:348] - [device='xpu'][rank=7/23][local_rank=7/11][node=1/1]\n2024:10:16-15:39:35:(34470) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(169072) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.192746][INFO][dist.py:348] - [device='xpu'][rank=2/23][local_rank=2/11][node=0/1]\n[2024-10-16 15:39:35.192682][INFO][dist.py:348] - [device='xpu'][rank=5/23][local_rank=5/11][node=1/1]\n[2024-10-16 15:39:35.193446][INFO][dist.py:348] - [device='xpu'][rank=17/23][local_rank=5/11][node=1/1]\n2024:10:16-15:39:35:(169067) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.193506][INFO][dist.py:348] - [device='xpu'][rank=12/23][local_rank=0/11][node=0/1]\n2024:10:16-15:39:35:(169070) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.194435][INFO][dist.py:348] - [device='xpu'][rank=23/23][local_rank=11/11][node=1/1]\n[2024-10-16 15:39:35.194529][INFO][dist.py:348] - [device='xpu'][rank=16/23][local_rank=4/11][node=0/1]\n2024:10:16-15:39:35:(34468) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34463) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34467) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n2024:10:16-15:39:35:(34474) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\n[2024-10-16 15:39:35.198383][INFO][dist.py:92] -\n\n[dist_info]:\n  ‚Ä¢ DEVICE=xpu\n  ‚Ä¢ DEVICE_ID=xpu:0\n  ‚Ä¢ DISTRIBUTED_BACKEND=ccl\n  ‚Ä¢ GPUS_PER_NODE=12\n  ‚Ä¢ HOSTS=['x4407c6s7b0n0.hostmgmt2407.cm.aurora.alcf.anl.gov', 'x4308c2s5b0n0.hostmgmt2308.cm.aurora.alcf.anl.gov']\n  ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/886439.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n  ‚Ä¢ HOSTNAME=x4407c6s7b0n0.hostmgmt2407.cm.aurora.alcf.anl.gov\n  ‚Ä¢ LOCAL_RANK=0\n  ‚Ä¢ MACHINE=Aurora\n  ‚Ä¢ NUM_NODES=2\n  ‚Ä¢ NGPUS=24\n  ‚Ä¢ NGPUS_AVAILABLE=24\n  ‚Ä¢ NODE_ID=0\n  ‚Ä¢ RANK=0\n  ‚Ä¢ SCHEDULER=PBS\n  ‚Ä¢ WORLD_SIZE_TOTAL=24\n  ‚Ä¢ WORLD_SIZE_IN_USE=24\n  ‚Ä¢ LAUNCH_CMD=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/886439.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n\n\n--------------------------------------------------\nDeepSpeed C++/CUDA extension op report\n--------------------------------------------------\nNOTE: Ops not installed will be just-in-time (JIT) compiled at\n      runtime if needed. Op compatibility means that your system\n      meet the required dependencies to JIT install the op.\n--------------------------------------------------\nJIT compiled ops requires ninja\nninja .................. [OKAY]\n--------------------------------------------------\nop name ................ installed .. compatible\n--------------------------------------------------\ndeepspeed_not_implemented  [NO] ....... [OKAY]\n [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.\n [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\nasync_io ............... [NO] ....... [NO]\ncpu_adagrad ............ [NO] ....... [OKAY]\ncpu_adam ............... [NO] ....... [OKAY]\nflash_attn ............. [NO] ....... [OKAY]\nfused_adam ............. [NO] ....... [OKAY]\ntransformer_inference .. [NO] ....... [OKAY]\npack_bits .............. [NO] ....... [OKAY]\n--------------------------------------------------\nDeepSpeed general environment info:\ntorch install path ............... ['/opt/aurora/24.180.0/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch']\ntorch version .................... 2.3.1+cxx11.abi\ndeepspeed install path ........... ['/lus/flare/projects/Aurora_deployment/foremans/projects/argonne-lcf/Megatron-DeepSpeed/deps/DeepSpeed/deepspeed']\ndeepspeed info ................... 0.15.3+unknown, unknown, unknown\ndeepspeed wheel compiled w. ...... torch 2.3\nshared memory (/dev/shm) size .... 503.18 GB\n[2024-10-16 15:39:35.319255][INFO][configs.py:272] - **** Git info for DeepSpeed: git_hash=7ef26bf git_branch=hzheng-data-fix ****\n[2024-10-16 15:39:35.319927][INFO][dist.py:725] - Using oneccl_bindings from: /opt/aurora/24.180.0/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/oneccl_bindings_for_pytorch/__init__.py\n[2024-10-16 15:39:35.320347][INFO][dist.py:727] - Using ipex from: /opt/aurora/24.180.0/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/intel_extension_for_pytorch/__init__.py\n[2024-10-16 15:39:35.320734][INFO][dist.py:728] - [0/24] Using device='xpu' with backend='deepspeed' + 'ccl' for distributed training.\n[2024-10-16 15:39:35.325748][INFO][dist.py:348] - [device='xpu'][rank=0/23][local_rank=0/11][node=0/1]\n[2024-10-16 15:39:35.326291][WARNING][_logger.py:68] - Using [24 / 24] available \"xpu\" devices !!\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_KVS_MODE changed to be mpi (default:pmi)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_KVS_CONNECTION_TIMEOUT changed to be 3600 (default:120)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_BCAST changed to be double_tree (default:)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_ENABLE_SYCL_KERNELS changed to be 1 (default:0)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_SYCL_ESIMD changed to be 1 (default:0)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be pmix (default:hydra)\n2024:10:16-15:39:35:(169065) |CCL_WARN| value of CCL_ZE_CACHE_OPEN_IPC_HANDLES_THRESHOLD changed to be 32768 (default:1000)\n2024:10:16-15:39:35:(169065) |CCL_WARN| CCL_ALLGATHERV_MEDIUM_SIZE_THRESHOLD=0 is unknown to and unused by oneCCL code but is present in the environment, check if it is not mistyped.\n2024:10:16-15:39:35:(169065) |CCL_WARN| CCL_SKIP_SCHEDULER=1 is unknown to and unused by oneCCL code but is present in the environment, check if it is not mistyped.\n2024:10:16-15:39:35:(169065) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored\nusing world size: 24, data-parallel-size: 24, sequence-parallel size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1\naccumulate and all-reduce gradients in fp32 for bfloat16 data type.\nusing torch.bfloat16 for parameters ...\n------------------------ arguments ------------------------\n  accumulate_allreduce_grads_in_fp32 .............. True\n  adam_beta1 ...................................... 0.9\n  adam_beta2 ...................................... 0.999\n  adam_eps ........................................ 1e-08\n  add_bias_linear ................................. False\n  add_position_embedding .......................... False\n  adlr_autoresume ................................. False\n  adlr_autoresume_interval ........................ 1000\n  aml_data_download_path .......................... None\n  apply_layernorm_1p .............................. False\n  apply_query_key_layer_scaling ................... False\n  apply_residual_connection_post_layernorm ........ False\n  async_tensor_model_parallel_allreduce ........... False\n  attention_dropout ............................... 0.0\n  attention_softmax_in_fp32 ....................... False\n  barrier_with_L1_time ............................ True\n  bert_binary_head ................................ True\n  bert_embedder_type .............................. megatron\n  bert_load ....................................... None\n  bf16 ............................................ True\n  bias_dropout_fusion ............................. False\n  bias_gelu_fusion ................................ False\n  biencoder_projection_dim ........................ 0\n  biencoder_shared_query_context_model ............ False\n  block_data_path ................................. None\n  checkpoint_activations .......................... False\n  checkpoint_in_cpu ............................... False\n  checkpoint_num_layers ........................... 1\n  classes_fraction ................................ 1.0\n  clip_grad ....................................... 1.0\n  compression_training ............................ False\n  consumed_train_samples .......................... 0\n  consumed_train_tokens ........................... 0\n  consumed_valid_samples .......................... 0\n  contigious_checkpointing ........................ False\n  cpu_optimizer ................................... False\n  cpu_torch_adam .................................. False\n  create_moe_param_group .......................... False\n  curriculum_learning_legacy ...................... False\n  data_cache_path ................................. ./.cache\n  data_efficiency_curriculum_learning ............. False\n  data_file_list .................................. None\n  data_impl ....................................... infer\n  data_parallel_random_init ....................... False\n  data_parallel_size .............................. 24\n  data_path ....................................... ['/lus/flare/projects/candle_aesp_CNDA/azton/data/v2/megatron/dataset_v2_wtextbooks_text_document']\n  data_per_class_fraction ......................... 1.0\n  data_sharding ................................... True\n  dataloader_type ................................. single\n  DDP_impl ........................................ local\n  decoder_num_layers .............................. None\n  decoder_seq_length .............................. None\n  deepscale ....................................... False\n  deepscale_config ................................ None\n  deepspeed ....................................... True\n  deepspeed_activation_checkpointing .............. False\n  deepspeed_config ................................ ./examples_deepspeed/finetune_hf_llama/ds_config.json\n  dino_bottleneck_size ............................ 256\n  dino_freeze_last_layer .......................... 1\n  dino_head_hidden_size ........................... 2048\n  dino_local_crops_number ......................... 10\n  dino_local_img_size ............................. 96\n  dino_norm_last_layer ............................ False\n  dino_teacher_temp ............................... 0.07\n  dino_warmup_teacher_temp ........................ 0.04\n  dino_warmup_teacher_temp_epochs ................. 30\n  distribute_checkpointed_activations ............. False\n  distribute_saved_activations .................... False\n  distributed_backend ............................. ccl\n  distributed_timeout_minutes ..................... 10\n  ds_fused_adam ................................... False\n  ds_inference .................................... False\n  ds_pipeline_enabled ............................. True\n  ds_sequence_parallel_size ....................... 1\n  embedding_path .................................. None\n  embedding_weights_in_fp32 ....................... False\n  empty_unused_memory_level ....................... 0\n  enable_expert_tensor_parallelism ................ False\n  enable_zbh1_exact_semantics ..................... False\n  enable_zbh1_pipeline ............................ False\n  encoder_num_layers .............................. 32\n  encoder_seq_length .............................. 2048\n  end_weight_decay ................................ 0.1\n  eod_mask_loss ................................... False\n  eval_interval ................................... 100\n  eval_iters ...................................... 100\n  evidence_data_path .............................. None\n  exit_duration_in_mins ........................... None\n  exit_interval ................................... None\n  exit_on_missing_checkpoint ...................... False\n  exit_signal_handler ............................. False\n  expert_interval ................................. 2\n  ffn_hidden_size ................................. 14336\n  finetune ........................................ False\n  force_ds_sequence_parallel ...................... False\n  fp16 ............................................ False\n  fp16_lm_cross_entropy ........................... False\n  fp32_residual_connection ........................ False\n  fp8_amax_compute_algo ........................... most_recent\n  fp8_amax_history_len ............................ 1\n  fp8_e4m3 ........................................ False\n  fp8_hybrid ...................................... False\n  fp8_interval .................................... 1\n  fp8_margin ...................................... 0\n  fp8_wgrad ....................................... True\n  global_batch_size ............................... 24\n  gradient_accumulation_fusion .................... False\n  head_lr_mult .................................... 1.0\n  hf_ckpt_dir ..................................... /flare/Aurora_deployment/foremans/Meta-Llama-3.1-8B-128512\n  hf_ckpt_num_shards .............................. 1\n  hidden_dropout .................................. 0.0\n  hidden_size ..................................... 4096\n  hidden_size_teacher ............................. None\n  hysteresis ...................................... 2\n  ict_head_size ................................... None\n  ict_load ........................................ None\n  img_h ........................................... 224\n  img_w ........................................... 224\n  indexer_batch_size .............................. 128\n  indexer_log_interval ............................ 1000\n  inference ....................................... False\n  inference_batch_times_seqlen_threshold .......... 512\n  init_method_std ................................. 0.02\n  init_method_xavier_uniform ...................... False\n  initial_loss_scale .............................. 4294967296\n  iter_per_epoch .................................. 1250\n  kd .............................................. False\n  kd_alpha_ce ..................................... 1\n  kd_beta_ce ...................................... 1\n  kd_temp ......................................... 1.0\n  kill_switch_file ................................ None\n  kv_channels ..................................... 128\n  layernorm_epsilon ............................... 1e-05\n  lazy_mpu_init ................................... None\n  load ............................................ None\n  load_mode ....................................... auto\n  load_tag ........................................ None\n  load_teacher .................................... None\n  local_rank ...................................... None\n  log_batch_size_to_tensorboard ................... False\n  log_interval .................................... 1\n  log_learning_rate_to_tensorboard ................ True\n  log_loss_scale_to_tensorboard ................... True\n  log_memory_to_tensorboard ....................... False\n  log_num_zeros_in_grad ........................... False\n  log_optimizer_states_to_tensorboard ............. False\n  log_params_norm ................................. False\n  log_timers_to_tensorboard ....................... False\n  log_validation_ppl_to_tensorboard ............... False\n  log_world_size_to_tensorboard ................... False\n  loss_scale ...................................... None\n  loss_scale_window ............................... 1000\n  lr .............................................. 2e-05\n  lr_decay_iters .................................. 320000\n  lr_decay_samples ................................ None\n  lr_decay_style .................................. cosine\n  lr_decay_tokens ................................. None\n  lr_warmup_fraction .............................. None\n  lr_warmup_iters ................................. 2000\n  lr_warmup_samples ............................... 0\n  lr_warmup_tokens ................................ None\n  make_vocab_size_divisible_by .................... 128512\n  mask_factor ..................................... 1.0\n  mask_prob ....................................... 0.15\n  mask_type ....................................... random\n  masked_softmax_fusion ........................... False\n  max_position_embeddings ......................... 2048\n  max_tokens_to_oom ............................... 12000\n  mem_efficient_ln ................................ True\n  memory_centric_tiled_linear ..................... False\n  merge_file ...................................... None\n  micro_batch_size ................................ 1\n  min_loss_scale .................................. 1.0\n  min_lr .......................................... 0.0\n  mlp_type ........................................ standard\n  mmap_warmup ..................................... False\n  moe_eval_capacity_factor ........................ 1.0\n  moe_expert_parallel_size ........................ 1\n  moe_loss_coeff .................................. 0.1\n  moe_min_capacity ................................ 4\n  moe_token_dropping .............................. True\n  moe_top2_2nd_expert_sampling .................... True\n  moe_train_capacity_factor ....................... 1.0\n  mos ............................................. False\n  multiprocessing_context ......................... fork\n  no_load_lr_state ................................ False\n  no_load_optim ................................... None\n  no_load_rng ..................................... None\n  no_persist_layer_norm ........................... False\n  no_pipeline_parallel ............................ False\n  no_save_optim ................................... None\n  no_save_rng ..................................... None\n  normalization ................................... rmsnorm\n  num_attention_heads ............................. 32\n  num_attention_heads_teacher ..................... None\n  num_channels .................................... 3\n  num_classes ..................................... 1000\n  num_experts ..................................... [1]\n  num_experts_switch .............................. None\n  num_experts_teacher ............................. [1]\n  num_key_value_heads ............................. 8\n  num_layers ...................................... 32\n  num_layers_per_virtual_pipeline_stage ........... None\n  num_layers_teacher .............................. None\n  num_workers ..................................... 2\n  onnx_safe ....................................... None\n  openai_gelu ..................................... False\n  optimizer ....................................... adam\n  output_bert_embeddings .......................... False\n  overlap_p2p_comm ................................ False\n  override_opt_param_scheduler .................... False\n  params_dtype .................................... torch.bfloat16\n  partition_activations ........................... False\n  patch_dim ....................................... 16\n  perform_initialization .......................... True\n  pipeline_model_parallel_size .................... 1\n  pipeline_model_parallel_split_rank .............. None\n  profile ......................................... None\n  profile_backward ................................ False\n  profile_ranks ................................... None\n  profile_steps ................................... 2,3\n  query_in_block_prob ............................. 0.1\n  rampup_batch_size ............................... None\n  random_ltd ...................................... False\n  rank ............................................ 0\n  recompute_granularity ........................... None\n  recompute_method ................................ None\n  recompute_num_layers ............................ 1\n  remote_device ................................... none\n  repeated_dataloader ............................. True\n  reset_attention_mask ............................ False\n  reset_iteration ................................. False\n  reset_position_ids .............................. False\n  retriever_report_topk_accuracies ................ []\n  retriever_score_scaling ......................... False\n  retriever_seq_length ............................ 256\n  retro_add_retriever ............................. False\n  retro_cyclic_train_iters ........................ None\n  retro_encoder_attention_dropout ................. 0.1\n  retro_encoder_hidden_dropout .................... 0.1\n  retro_encoder_layers ............................ 2\n  retro_num_neighbors ............................. 2\n  retro_num_retrieved_chunks ...................... 2\n  retro_return_doc_ids ............................ False\n  retro_workdir ................................... None\n  return_data_index ............................... False\n  rope_theta ...................................... 10000\n  rotary_percent .................................. 1.0\n  sample_rate ..................................... 1.0\n  save ............................................ ckpt-mds-llama-3/\n  save_interval ................................... 1500\n  scatter_gather_tensors_in_pipeline .............. True\n  scattered_embeddings ............................ False\n  schedulefree_for_each ........................... False\n  seed ............................................ 1234\n  seq_length ...................................... 2048\n  sequence_parallel ............................... False\n  sgd_momentum .................................... 0.9\n  short_seq_prob .................................. 0.1\n  shuffle_sample .................................. False\n  skip_train ...................................... False\n  sophiag_beta1 ................................... 0.9\n  sophiag_beta2 ................................... 0.95\n  sophiag_rho ..................................... 0.01\n  split ........................................... 100,0,0\n  split_transformers .............................. False\n  squared_relu .................................... False\n  standalone_embedding_stage ...................... False\n  start_weight_decay .............................. 0.1\n  swiglu .......................................... True\n  swin_backbone_type .............................. tiny\n  synchronize_each_layer .......................... False\n  tensor_model_parallel_size ...................... 1\n  tensorboard_dir ................................. tensorboard_output\n  tensorboard_log_interval ........................ 1\n  tensorboard_queue_size .......................... 1000\n  test_data_path .................................. None\n  tile_factor ..................................... 1\n  timing_log_level ................................ 0\n  timing_log_option ............................... minmax\n  titles_data_path ................................ None\n  to_hf_ckpt ...................................... False\n  tokenizer_model ................................. ALCF/custom_tokenizer.model\n  tokenizer_type .................................. HFTokenizer\n  topk ............................................ 1\n  trace_dir ....................................... ./trace/\n  train_data_exact_num_epochs ..................... None\n  train_data_path ................................. None\n  train_desc_path ................................. None\n  train_doc_idx_path .............................. None\n  train_idx_path .................................. None\n  train_iters ..................................... 3500\n  train_iters_to_skip ............................. None\n  train_range_to_skip ............................. None\n  train_sample_idx_path ........................... None\n  train_samples ................................... None\n  train_shuffle_idx_path .......................... None\n  train_tokens .................................... None\n  transformer_impl ................................ local\n  transformer_pipeline_model_parallel_size ........ 1\n  trust_remote_code ............................... False\n  universal_checkpoint ............................ False\n  untie_embeddings_and_output_weights ............. True\n  use_checkpoint_args ............................. False\n  use_checkpoint_opt_param_scheduler .............. False\n  use_contiguous_buffers_in_local_ddp ............. True\n  use_cpu_initialization .......................... None\n  use_dataset_only ................................ False\n  use_distributed_optimizer ....................... False\n  use_flash_attn .................................. False\n  use_flash_attn_builder .......................... False\n  use_flash_attn_triton ........................... False\n  use_flash_attn_v1 ............................... False\n  use_flash_attn_v2 ............................... False\n  use_mics ........................................ False\n  use_one_sent_docs ............................... False\n  use_pin_memory .................................. False\n  use_ring_exchange_p2p ........................... False\n  use_rotary_position_embeddings .................. True\n  use_tutel ....................................... False\n  valid_data_path ................................. None\n  variable_seq_lengths ............................ False\n  virtual_pipeline_model_parallel_size ............ None\n  vision_backbone_type ............................ vit\n  vision_pretraining .............................. False\n  vision_pretraining_type ......................... classify\n  vocab_extra_ids ................................. 0\n  vocab_file ...................................... None\n  vocab_size ...................................... 128512\n  wandb_exp_name ..................................\n  wandb_project ...................................\n  wandb_save_dir ..................................\n  weight_decay .................................... 0.1\n  weight_decay_incr_style ......................... constant\n  world_size ...................................... 24\n  zero_allgather_bucket_size ...................... 0.0\n  zero_contigious_gradients ....................... False\n  zero_reduce_bucket_size ......................... 0.0\n  zero_reduce_scatter ............................. False\n  zero_stage ...................................... 1.0\n-------------------- end of arguments ---------------------\nsetting number of micro-batches to constant 1\n&gt; building HFTokenizer tokenizer ...\n &gt; padded vocab (size: 128000) with 512 dummy tokens (new size: 128512)\ntorch distributed is already initialized, skipping initialization ...\n&gt; initialized tensor model parallel with size 1\n&gt; initialized pipeline model parallel with size 1\n&gt; setting random seeds to 1234 ...\n&gt; initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,876] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,876] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,876] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,876] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,879] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,881] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,881] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,882] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,882] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nmake: Entering directory '/lus/flare/projects/Aurora_deployment/foremans/projects/argonne-lcf/Megatron-DeepSpeed/megatron/data'\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,884] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,922] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,929] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,930] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,931] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,935] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,937] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,939] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,939] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,940] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,941] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,946] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36,949] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nmake: Nothing to be done for 'default'.\nmake: Leaving directory '/lus/flare/projects/Aurora_deployment/foremans/projects/argonne-lcf/Megatron-DeepSpeed/megatron/data'\n&gt; compiling dataset index builder ...\n&gt;&gt;&gt; done with dataset index builder. Compilation time: 0.080 seconds\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:36.956560][INFO][hf2megads_weight_converter.py:479] - building model ...\n[2024-10-16 15:39:37,133] [INFO] [utils.py:781:see_memory_usage] Before Building Model\n[2024-10-16 15:39:37,133] [INFO] [utils.py:782:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB\n[2024-10-16 15:39:37,133] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 105.24 GB, percent = 9.3%\n[2024-10-16 15:39:37,133] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nSEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\nUsing topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=1, model=0): 1, ProcessCoord(pipe=0, data=2, model=0): 2, ProcessCoord(pipe=0, data=3, model=0): 3, ProcessCoord(pipe=0, data=4, model=0): 4, ProcessCoord(pipe=0, data=5, model=0): 5, ProcessCoord(pipe=0, data=6, model=0): 6, ProcessCoord(pipe=0, data=7, model=0): 7, ProcessCoord(pipe=0, data=8, model=0): 8, ProcessCoord(pipe=0, data=9, model=0): 9, ProcessCoord(pipe=0, data=10, model=0): 10, ProcessCoord(pipe=0, data=11, model=0): 11, ProcessCoord(pipe=0, data=12, model=0): 12, ProcessCoord(pipe=0, data=13, model=0): 13, ProcessCoord(pipe=0, data=14, model=0): 14, ProcessCoord(pipe=0, data=15, model=0): 15, ProcessCoord(pipe=0, data=16, model=0): 16, ProcessCoord(pipe=0, data=17, model=0): 17, ProcessCoord(pipe=0, data=18, model=0): 18, ProcessCoord(pipe=0, data=19, model=0): 19, ProcessCoord(pipe=0, data=20, model=0): 20, ProcessCoord(pipe=0, data=21, model=0): 21, ProcessCoord(pipe=0, data=22, model=0): 22, ProcessCoord(pipe=0, data=23, model=0): 23}\n[2024-10-16 15:39:37,139] [INFO] [module.py:396:_partition_layers] Partitioning pipeline stages with method type:transformer\n2024-10-16 15:39:37.212904: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-10-16 15:39:37.212925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-10-16 15:39:37.213970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-10-16 15:39:37.704522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nLoading checkpoint shards:   0%|          | 0/7 [00:00&lt;?, ?it/s]1 GPTModelPipe(\n  (tied_modules): ModuleDict()\n  (1): EmbeddingPipe(\n    (word_embeddings): VocabParallelEmbedding()\n    (embedding_dropout): Dropout(p=0.0, inplace=False)\n  )\n  (2): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (3): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (4): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (5): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (6): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (7): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (8): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (9): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (10): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (11): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (12): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (13): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (14): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (15): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (16): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (17): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (18): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (19): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (20): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (21): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (22): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (23): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (24): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (25): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (26): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (27): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (28): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (29): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (30): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (31): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (32): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (33): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (34): RMSNorm()\n  (35): LMHeadPipe(\n    (lm_head): ColumnParallelLinear()\n  )\nLoading checkpoint shards:   0%|          | 0/7 [00:00&lt;?, ?it/s]\nLoading checkpoint shards:   0%|          | 0/7 [00:00&lt;?, ?it/s]stage=0 layers=37\n     0: _to_float16\n     1: EmbeddingPipe\n     2: ParallelTransformerLayerPipe\n     3: ParallelTransformerLayerPipe\n     4: ParallelTransformerLayerPipe\n     5: ParallelTransformerLayerPipe\n     6: ParallelTransformerLayerPipe\n     7: ParallelTransformerLayerPipe\n     8: ParallelTransformerLayerPipe\n     9: ParallelTransformerLayerPipe\n    10: ParallelTransformerLayerPipe\n    11: ParallelTransformerLayerPipe\n    12: ParallelTransformerLayerPipe\n    13: ParallelTransformerLayerPipe\n    14: ParallelTransformerLayerPipe\n    15: ParallelTransformerLayerPipe\n    16: ParallelTransformerLayerPipe\n    17: ParallelTransformerLayerPipe\n    18: ParallelTransformerLayerPipe\n    19: ParallelTransformerLayerPipe\n    20: ParallelTransformerLayerPipe\n    21: ParallelTransformerLayerPipe\n    22: ParallelTransformerLayerPipe\n    23: ParallelTransformerLayerPipe\n    24: ParallelTransformerLayerPipe\n    25: ParallelTransformerLayerPipe\n    26: ParallelTransformerLayerPipe\n    27: ParallelTransformerLayerPipe\n    28: ParallelTransformerLayerPipe\n    29: ParallelTransformerLayerPipe\n    30: ParallelTransformerLayerPipe\n    31: ParallelTransformerLayerPipe\n    32: ParallelTransformerLayerPipe\n    33: ParallelTransformerLayerPipe\n    34: RMSNorm\n    35: LMHeadPipe\n    36: float16_to_fp32\n  loss: loss_func\n[2024-10-16 15:39:38,077] [INFO] [utils.py:781:see_memory_usage] After Building Model\n[2024-10-16 15:39:38,077] [INFO] [utils.py:782:see_memory_usage] MA 14.96 GB         Max_MA 14.96 GB         CA 14.96 GB         Max_CA 15 GB\n[2024-10-16 15:39:38,077] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 105.4 GB, percent = 9.3%\n0 GPTModelPipe(\n  (tied_modules): ModuleDict()\n  (1): EmbeddingPipe(\n    (word_embeddings): VocabParallelEmbedding()\n    (embedding_dropout): Dropout(p=0.0, inplace=False)\n  )\n  (2): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (3): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (4): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (5): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (6): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (7): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (8): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (9): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (10): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (11): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (12): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (13): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (14): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (15): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (16): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (17): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (18): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (19): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (20): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (21): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (22): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (23): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (24): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (25): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (26): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (27): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (28): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (29): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (30): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (31): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (32): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (33): ParallelTransformerLayerPipe(\n    (input_layernorm): RMSNorm()\n    (self_attention): ParallelAttention(\n      (query_key_value): ColumnParallelLinear()\n      (core_attention): CoreAttention(\n        (scale_mask_softmax): FusedScaleMaskSoftmax()\n        (attention_dropout): Dropout(p=0.0, inplace=False)\n      )\n      (dense): RowParallelLinear()\n    )\n    (post_attention_layernorm): RMSNorm()\n    (mlp): ParallelMLP(\n      (dense_h_to_4h): ColumnParallelLinear()\n      (dense_4h_to_h): RowParallelLinear()\n    )\n  )\n  (34): RMSNorm()\n  (35): LMHeadPipe(\n    (lm_head): ColumnParallelLinear()\n  )\n)\nLoading checkpoint shards:   0%|          | 0/7 [00:00&lt;?, ?it/s]2024-10-16 15:39:39.334375: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay. The old value will be erased inorder to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n2024-10-16 15:39:39.334561: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /xla/service/gpu/compiled_programs_count. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n2024-10-16 15:39:39.335711: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_executions. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.\n2024-10-16 15:39:39.335722: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_execution_time_usecs. The old value will be erased in order to register a new one. Please check if you linkthe metric more than once, or if the name is already used by other metrics.\n2024-10-16 15:39:39.587872: I itex/core/wrapper/itex_gpu_wrapper.cc:38] Intel Extension for Tensorflow* GPU backend is loaded.\n2024-10-16 15:39:39.631109: I itex/core/devices/gpu/itex_gpu_runtime.cc:130] Selected platform: Intel(R) Level-Zero\n2024-10-16 15:39:39.631594: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631598: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631600: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631602: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631604: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631607: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631609: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631611: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631613: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631615: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631617: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n2024-10-16 15:39:39.631619: I itex/core/devices/gpu/itex_gpu_runtime.cc:155] number of sub-devices is zero, expose root device.\n&gt; setting tensorboard ...\nWARNING: WANDB writing requested but no legit wandb project or experiment name provided, therefore no WANDB logs will be written according to random generated project or experiment name.\n&gt;fused kernel is only supported in cuda, skip loading fused kernel\n[2024-10-16 15:39:39,835] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [03:35&lt;00:00, 30.78s/it]\n[2024-10-16 15:43:13.654241][INFO][hf2megads_weight_converter.py:108] - ----------------------------hf weight list----------------------------\n[2024-10-16 15:43:13.705041][INFO][hf2megads_weight_converter.py:113] - model.embed_tokens.weight\n[2024-10-16 15:43:13.708051][INFO][hf2megads_weight_converter.py:113] - model.layers.0.self_attn.q_proj.weight\n[2024-10-16 15:43:13.710201][INFO][hf2megads_weight_converter.py:113] - model.layers.0.self_attn.k_proj.weight\n[2024-10-16 15:43:13.711855][INFO][hf2megads_weight_converter.py:113] - model.layers.0.self_attn.v_proj.weight\n[2024-10-16 15:43:13.714676][INFO][hf2megads_weight_converter.py:113] - model.layers.0.self_attn.o_proj.weight\n[2024-10-16 15:43:13.721608][INFO][hf2megads_weight_converter.py:113] - model.layers.0.mlp.gate_proj.weight\n[2024-10-16 15:43:13.728527][INFO][hf2megads_weight_converter.py:113] - model.layers.0.mlp.up_proj.weight\n[2024-10-16 15:43:13.735447][INFO][hf2megads_weight_converter.py:113] - model.layers.0.mlp.down_proj.weight\n[2024-10-16 15:43:13.736224][INFO][hf2megads_weight_converter.py:113] - model.layers.0.input_layernorm.weight\n[2024-10-16 15:43:13.736764][INFO][hf2megads_weight_converter.py:113] - model.layers.0.post_attention_layernorm.weight\n[2024-10-16 15:43:13.739392][INFO][hf2megads_weight_converter.py:113] - model.layers.1.self_attn.q_proj.weight\n[2024-10-16 15:43:13.741013][INFO][hf2megads_weight_converter.py:113] - model.layers.1.self_attn.k_proj.weight\n[2024-10-16 15:43:13.742600][INFO][hf2megads_weight_converter.py:113] - model.layers.1.self_attn.v_proj.weight\n[2024-10-16 15:43:13.745359][INFO][hf2megads_weight_converter.py:113] - model.layers.1.self_attn.o_proj.weight\n[2024-10-16 15:43:13.752286][INFO][hf2megads_weight_converter.py:113] - model.layers.1.mlp.gate_proj.weight\n[2024-10-16 15:43:13.759192][INFO][hf2megads_weight_converter.py:113] - model.layers.1.mlp.up_proj.weight\n[2024-10-16 15:43:13.766054][INFO][hf2megads_weight_converter.py:113] - model.layers.1.mlp.down_proj.weight\n[2024-10-16 15:43:13.766785][INFO][hf2megads_weight_converter.py:113] - model.layers.1.input_layernorm.weight\n[2024-10-16 15:43:13.767321][INFO][hf2megads_weight_converter.py:113] - model.layers.1.post_attention_layernorm.weight\n[2024-10-16 15:43:13.769938][INFO][hf2megads_weight_converter.py:113] - model.layers.2.self_attn.q_proj.weight\n[2024-10-16 15:43:13.771536][INFO][hf2megads_weight_converter.py:113] - model.layers.2.self_attn.k_proj.weight\n[2024-10-16 15:43:13.773107][INFO][hf2megads_weight_converter.py:113] - model.layers.2.self_attn.v_proj.weight\n[2024-10-16 15:43:13.775861][INFO][hf2megads_weight_converter.py:113] - model.layers.2.self_attn.o_proj.weight\n[2024-10-16 15:43:13.782733][INFO][hf2megads_weight_converter.py:113] - model.layers.2.mlp.gate_proj.weight\n[2024-10-16 15:43:13.789559][INFO][hf2megads_weight_converter.py:113] - model.layers.2.mlp.up_proj.weight\n[2024-10-16 15:43:13.796385][INFO][hf2megads_weight_converter.py:113] - model.layers.2.mlp.down_proj.weight\n[2024-10-16 15:43:13.797080][INFO][hf2megads_weight_converter.py:113] - model.layers.2.input_layernorm.weight\n[2024-10-16 15:43:13.797626][INFO][hf2megads_weight_converter.py:113] - model.layers.2.post_attention_layernorm.weight\n[2024-10-16 15:43:13.800331][INFO][hf2megads_weight_converter.py:113] - model.layers.3.self_attn.q_proj.weight\n[2024-10-16 15:43:13.801911][INFO][hf2megads_weight_converter.py:113] - model.layers.3.self_attn.k_proj.weight\n[2024-10-16 15:43:13.803453][INFO][hf2megads_weight_converter.py:113] - model.layers.3.self_attn.v_proj.weight\n[2024-10-16 15:43:13.806474][INFO][hf2megads_weight_converter.py:113] - model.layers.3.self_attn.o_proj.weight\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [03:35&lt;00:00, 30.84s/it]\n[2024-10-16 15:43:13.813328][INFO][hf2megads_weight_converter.py:113] - model.layers.3.mlp.gate_proj.weight\n[2024-10-16 15:43:13.820151][INFO][hf2megads_weight_converter.py:113] - model.layers.3.mlp.up_proj.weight\n[2024-10-16 15:43:13.826971][INFO][hf2megads_weight_converter.py:113] - model.layers.3.mlp.down_proj.weight\n[2024-10-16 15:43:13.827640][INFO][hf2megads_weight_converter.py:113] - model.layers.3.input_layernorm.weight\n[2024-10-16 15:43:13.828185][INFO][hf2megads_weight_converter.py:113] - model.layers.3.post_attention_layernorm.weight\n[2024-10-16 15:43:13.831062][INFO][hf2megads_weight_converter.py:113] - model.layers.4.self_attn.q_proj.weight\n[2024-10-16 15:43:13.832590][INFO][hf2megads_weight_converter.py:113] - model.layers.4.self_attn.k_proj.weight\n[2024-10-16 15:43:13.834171][INFO][hf2megads_weight_converter.py:113] - model.layers.4.self_attn.v_proj.weight\n[2024-10-16 15:43:13.837147][INFO][hf2megads_weight_converter.py:113] - model.layers.4.self_attn.o_proj.weight\n[2024-10-16 15:43:13.843970][INFO][hf2megads_weight_converter.py:113] - model.layers.4.mlp.gate_proj.weight\n[2024-10-16 15:43:13.850793][INFO][hf2megads_weight_converter.py:113] - model.layers.4.mlp.up_proj.weight\n[2024-10-16 15:43:13.857596][INFO][hf2megads_weight_converter.py:113] - model.layers.4.mlp.down_proj.weight\n[2024-10-16 15:43:13.858284][INFO][hf2megads_weight_converter.py:113] - model.layers.4.input_layernorm.weight\n[2024-10-16 15:43:13.858810][INFO][hf2megads_weight_converter.py:113] - model.layers.4.post_attention_layernorm.weight\n[2024-10-16 15:43:13.861661][INFO][hf2megads_weight_converter.py:113] - model.layers.5.self_attn.q_proj.weight\n[2024-10-16 15:43:13.863209][INFO][hf2megads_weight_converter.py:113] - model.layers.5.self_attn.k_proj.weight\n[2024-10-16 15:43:13.864753][INFO][hf2megads_weight_converter.py:113] - model.layers.5.self_attn.v_proj.weight\n[2024-10-16 15:43:13.867739][INFO][hf2megads_weight_converter.py:113] - model.layers.5.self_attn.o_proj.weight\n[2024-10-16 15:43:13.874537][INFO][hf2megads_weight_converter.py:113] - model.layers.5.mlp.gate_proj.weight\n[2024-10-16 15:43:13.881318][INFO][hf2megads_weight_converter.py:113] - model.layers.5.mlp.up_proj.weight\n[2024-10-16 15:43:13.888097][INFO][hf2megads_weight_converter.py:113] - model.layers.5.mlp.down_proj.weight\n[2024-10-16 15:43:13.888767][INFO][hf2megads_weight_converter.py:113] - model.layers.5.input_layernorm.weight\n[2024-10-16 15:43:13.889295][INFO][hf2megads_weight_converter.py:113] - model.layers.5.post_attention_layernorm.weight\n[2024-10-16 15:43:13.892151][INFO][hf2megads_weight_converter.py:113] - model.layers.6.self_attn.q_proj.weight\n[2024-10-16 15:43:13.893641][INFO][hf2megads_weight_converter.py:113] - model.layers.6.self_attn.k_proj.weight\n[2024-10-16 15:43:13.895211][INFO][hf2megads_weight_converter.py:113] - model.layers.6.self_attn.v_proj.weight\n[2024-10-16 15:43:13.898154][INFO][hf2megads_weight_converter.py:113] - model.layers.6.self_attn.o_proj.weight\n[2024-10-16 15:43:13.904976][INFO][hf2megads_weight_converter.py:113] - model.layers.6.mlp.gate_proj.weight\n[2024-10-16 15:43:13.911767][INFO][hf2megads_weight_converter.py:113] - model.layers.6.mlp.up_proj.weight\n[2024-10-16 15:43:13.918536][INFO][hf2megads_weight_converter.py:113] - model.layers.6.mlp.down_proj.weight\n[2024-10-16 15:43:13.919201][INFO][hf2megads_weight_converter.py:113] - model.layers.6.input_layernorm.weight\n[2024-10-16 15:43:13.919795][INFO][hf2megads_weight_converter.py:113] - model.layers.6.post_attention_layernorm.weight\n[2024-10-16 15:43:13.922646][INFO][hf2megads_weight_converter.py:113] - model.layers.7.self_attn.q_proj.weight\n[2024-10-16 15:43:13.924200][INFO][hf2megads_weight_converter.py:113] - model.layers.7.self_attn.k_proj.weight\n[2024-10-16 15:43:13.925687][INFO][hf2megads_weight_converter.py:113] - model.layers.7.self_attn.v_proj.weight\n[2024-10-16 15:43:13.928651][INFO][hf2megads_weight_converter.py:113] - model.layers.7.self_attn.o_proj.weight\n[2024-10-16 15:43:13.935432][INFO][hf2megads_weight_converter.py:113] - model.layers.7.mlp.gate_proj.weight\n[2024-10-16 15:43:13.942178][INFO][hf2megads_weight_converter.py:113] - model.layers.7.mlp.up_proj.weight\n[2024-10-16 15:43:13.948916][INFO][hf2megads_weight_converter.py:113] - model.layers.7.mlp.down_proj.weight\n[2024-10-16 15:43:13.949547][INFO][hf2megads_weight_converter.py:113] - model.layers.7.input_layernorm.weight\n[2024-10-16 15:43:13.950059][INFO][hf2megads_weight_converter.py:113] - model.layers.7.post_attention_layernorm.weight\n[2024-10-16 15:43:13.952902][INFO][hf2megads_weight_converter.py:113] - model.layers.8.self_attn.q_proj.weight\n[2024-10-16 15:43:13.954461][INFO][hf2megads_weight_converter.py:113] - model.layers.8.self_attn.k_proj.weight\n[2024-10-16 15:43:13.955985][INFO][hf2megads_weight_converter.py:113] - model.layers.8.self_attn.v_proj.weight\n[2024-10-16 15:43:13.958931][INFO][hf2megads_weight_converter.py:113] - model.layers.8.self_attn.o_proj.weight\n[2024-10-16 15:43:13.965709][INFO][hf2megads_weight_converter.py:113] - model.layers.8.mlp.gate_proj.weight\n[2024-10-16 15:43:13.972481][INFO][hf2megads_weight_converter.py:113] - model.layers.8.mlp.up_proj.weight\n[2024-10-16 15:43:13.979242][INFO][hf2megads_weight_converter.py:113] - model.layers.8.mlp.down_proj.weight\n[2024-10-16 15:43:13.979876][INFO][hf2megads_weight_converter.py:113] - model.layers.8.input_layernorm.weight\n[2024-10-16 15:43:13.980381][INFO][hf2megads_weight_converter.py:113] - model.layers.8.post_attention_layernorm.weight\n[2024-10-16 15:43:13.983353][INFO][hf2megads_weight_converter.py:113] - model.layers.9.self_attn.q_proj.weight\n[2024-10-16 15:43:13.984910][INFO][hf2megads_weight_converter.py:113] - model.layers.9.self_attn.k_proj.weight\n[2024-10-16 15:43:13.986401][INFO][hf2megads_weight_converter.py:113] - model.layers.9.self_attn.v_proj.weight\n[2024-10-16 15:43:13.989279][INFO][hf2megads_weight_converter.py:113] - model.layers.9.self_attn.o_proj.weight\n[2024-10-16 15:43:13.996056][INFO][hf2megads_weight_converter.py:113] - model.layers.9.mlp.gate_proj.weight\n[2024-10-16 15:43:14.002856][INFO][hf2megads_weight_converter.py:113] - model.layers.9.mlp.up_proj.weight\n[2024-10-16 15:43:14.009601][INFO][hf2megads_weight_converter.py:113] - model.layers.9.mlp.down_proj.weight\n[2024-10-16 15:43:14.010234][INFO][hf2megads_weight_converter.py:113] - model.layers.9.input_layernorm.weight\n[2024-10-16 15:43:14.010742][INFO][hf2megads_weight_converter.py:113] - model.layers.9.post_attention_layernorm.weight\n[2024-10-16 15:43:14.013552][INFO][hf2megads_weight_converter.py:113] - model.layers.10.self_attn.q_proj.weight\n[2024-10-16 15:43:14.015117][INFO][hf2megads_weight_converter.py:113] - model.layers.10.self_attn.k_proj.weight\n[2024-10-16 15:43:14.016607][INFO][hf2megads_weight_converter.py:113] - model.layers.10.self_attn.v_proj.weight\n[2024-10-16 15:43:14.019542][INFO][hf2megads_weight_converter.py:113] - model.layers.10.self_attn.o_proj.weight\n[2024-10-16 15:43:14.026297][INFO][hf2megads_weight_converter.py:113] - model.layers.10.mlp.gate_proj.weight\n[2024-10-16 15:43:14.033038][INFO][hf2megads_weight_converter.py:113] - model.layers.10.mlp.up_proj.weight\n[2024-10-16 15:43:14.039752][INFO][hf2megads_weight_converter.py:113] - model.layers.10.mlp.down_proj.weight\n[2024-10-16 15:43:14.040455][INFO][hf2megads_weight_converter.py:113] - model.layers.10.input_layernorm.weight\n[2024-10-16 15:43:14.040966][INFO][hf2megads_weight_converter.py:113] - model.layers.10.post_attention_layernorm.weight\n[2024-10-16 15:43:14.043760][INFO][hf2megads_weight_converter.py:113] - model.layers.11.self_attn.q_proj.weight\n[2024-10-16 15:43:14.045346][INFO][hf2megads_weight_converter.py:113] - model.layers.11.self_attn.k_proj.weight\n[2024-10-16 15:43:14.046849][INFO][hf2megads_weight_converter.py:113] - model.layers.11.self_attn.v_proj.weight\n[2024-10-16 15:43:14.049725][INFO][hf2megads_weight_converter.py:113] - model.layers.11.self_attn.o_proj.weight\n[2024-10-16 15:43:14.056435][INFO][hf2megads_weight_converter.py:113] - model.layers.11.mlp.gate_proj.weight\n[2024-10-16 15:43:14.063163][INFO][hf2megads_weight_converter.py:113] - model.layers.11.mlp.up_proj.weight\n[2024-10-16 15:43:14.069898][INFO][hf2megads_weight_converter.py:113] - model.layers.11.mlp.down_proj.weight\n[2024-10-16 15:43:14.070561][INFO][hf2megads_weight_converter.py:113] - model.layers.11.input_layernorm.weight\n[2024-10-16 15:43:14.071084][INFO][hf2megads_weight_converter.py:113] - model.layers.11.post_attention_layernorm.weight\n[2024-10-16 15:43:14.073869][INFO][hf2megads_weight_converter.py:113] - model.layers.12.self_attn.q_proj.weight\n[2024-10-16 15:43:14.075363][INFO][hf2megads_weight_converter.py:113] - model.layers.12.self_attn.k_proj.weight\n[2024-10-16 15:43:14.076918][INFO][hf2megads_weight_converter.py:113] - model.layers.12.self_attn.v_proj.weight\n[2024-10-16 15:43:14.079777][INFO][hf2megads_weight_converter.py:113] - model.layers.12.self_attn.o_proj.weight\n[2024-10-16 15:43:14.086497][INFO][hf2megads_weight_converter.py:113] - model.layers.12.mlp.gate_proj.weight\n[2024-10-16 15:43:14.093183][INFO][hf2megads_weight_converter.py:113] - model.layers.12.mlp.up_proj.weight\n[2024-10-16 15:43:14.099869][INFO][hf2megads_weight_converter.py:113] - model.layers.12.mlp.down_proj.weight\n[2024-10-16 15:43:14.100523][INFO][hf2megads_weight_converter.py:113] - model.layers.12.input_layernorm.weight\n[2024-10-16 15:43:14.101038][INFO][hf2megads_weight_converter.py:113] - model.layers.12.post_attention_layernorm.weight\n[2024-10-16 15:43:14.103823][INFO][hf2megads_weight_converter.py:113] - model.layers.13.self_attn.q_proj.weight\n[2024-10-16 15:43:14.105335][INFO][hf2megads_weight_converter.py:113] - model.layers.13.self_attn.k_proj.weight\n[2024-10-16 15:43:14.106828][INFO][hf2megads_weight_converter.py:113] - model.layers.13.self_attn.v_proj.weight\n[2024-10-16 15:43:14.109698][INFO][hf2megads_weight_converter.py:113] - model.layers.13.self_attn.o_proj.weight\n[2024-10-16 15:43:14.116395][INFO][hf2megads_weight_converter.py:113] - model.layers.13.mlp.gate_proj.weight\n[2024-10-16 15:43:14.123086][INFO][hf2megads_weight_converter.py:113] - model.layers.13.mlp.up_proj.weight\n[2024-10-16 15:43:14.129807][INFO][hf2megads_weight_converter.py:113] - model.layers.13.mlp.down_proj.weight\n[2024-10-16 15:43:14.130474][INFO][hf2megads_weight_converter.py:113] - model.layers.13.input_layernorm.weight\n[2024-10-16 15:43:14.130997][INFO][hf2megads_weight_converter.py:113] - model.layers.13.post_attention_layernorm.weight\n[2024-10-16 15:43:14.133762][INFO][hf2megads_weight_converter.py:113] - model.layers.14.self_attn.q_proj.weight\n[2024-10-16 15:43:14.135290][INFO][hf2megads_weight_converter.py:113] - model.layers.14.self_attn.k_proj.weight\n[2024-10-16 15:43:14.136791][INFO][hf2megads_weight_converter.py:113] - model.layers.14.self_attn.v_proj.weight\n[2024-10-16 15:43:14.139860][INFO][hf2megads_weight_converter.py:113] - model.layers.14.self_attn.o_proj.weight\n[2024-10-16 15:43:14.146560][INFO][hf2megads_weight_converter.py:113] - model.layers.14.mlp.gate_proj.weight\n[2024-10-16 15:43:14.153229][INFO][hf2megads_weight_converter.py:113] - model.layers.14.mlp.up_proj.weight\n[2024-10-16 15:43:14.160012][INFO][hf2megads_weight_converter.py:113] - model.layers.14.mlp.down_proj.weight\n[2024-10-16 15:43:14.160681][INFO][hf2megads_weight_converter.py:113] - model.layers.14.input_layernorm.weight\n[2024-10-16 15:43:14.161212][INFO][hf2megads_weight_converter.py:113] - model.layers.14.post_attention_layernorm.weight\n[2024-10-16 15:43:14.164011][INFO][hf2megads_weight_converter.py:113] - model.layers.15.self_attn.q_proj.weight\n[2024-10-16 15:43:14.165550][INFO][hf2megads_weight_converter.py:113] - model.layers.15.self_attn.k_proj.weight\n[2024-10-16 15:43:14.167029][INFO][hf2megads_weight_converter.py:113] - model.layers.15.self_attn.v_proj.weight\n[2024-10-16 15:43:14.169860][INFO][hf2megads_weight_converter.py:113] - model.layers.15.self_attn.o_proj.weight\n[2024-10-16 15:43:14.176522][INFO][hf2megads_weight_converter.py:113] - model.layers.15.mlp.gate_proj.weight\n[2024-10-16 15:43:14.183206][INFO][hf2megads_weight_converter.py:113] - model.layers.15.mlp.up_proj.weight\n[2024-10-16 15:43:14.189866][INFO][hf2megads_weight_converter.py:113] - model.layers.15.mlp.down_proj.weight\n[2024-10-16 15:43:14.190530][INFO][hf2megads_weight_converter.py:113] - model.layers.15.input_layernorm.weight\n[2024-10-16 15:43:14.191065][INFO][hf2megads_weight_converter.py:113] - model.layers.15.post_attention_layernorm.weight\n[2024-10-16 15:43:14.193838][INFO][hf2megads_weight_converter.py:113] - model.layers.16.self_attn.q_proj.weight\n[2024-10-16 15:43:14.195331][INFO][hf2megads_weight_converter.py:113] - model.layers.16.self_attn.k_proj.weight\n[2024-10-16 15:43:14.196892][INFO][hf2megads_weight_converter.py:113] - model.layers.16.self_attn.v_proj.weight\n[2024-10-16 15:43:14.199748][INFO][hf2megads_weight_converter.py:113] - model.layers.16.self_attn.o_proj.weight\n[2024-10-16 15:43:14.206446][INFO][hf2megads_weight_converter.py:113] - model.layers.16.mlp.gate_proj.weight\n[2024-10-16 15:43:14.213109][INFO][hf2megads_weight_converter.py:113] - model.layers.16.mlp.up_proj.weight\n[2024-10-16 15:43:14.219783][INFO][hf2megads_weight_converter.py:113] - model.layers.16.mlp.down_proj.weight\n[2024-10-16 15:43:14.220402][INFO][hf2megads_weight_converter.py:113] - model.layers.16.input_layernorm.weight\n[2024-10-16 15:43:14.220932][INFO][hf2megads_weight_converter.py:113] - model.layers.16.post_attention_layernorm.weight\n[2024-10-16 15:43:14.223676][INFO][hf2megads_weight_converter.py:113] - model.layers.17.self_attn.q_proj.weight\n[2024-10-16 15:43:14.225232][INFO][hf2megads_weight_converter.py:113] - model.layers.17.self_attn.k_proj.weight\n[2024-10-16 15:43:14.226737][INFO][hf2megads_weight_converter.py:113] - model.layers.17.self_attn.v_proj.weight\n[2024-10-16 15:43:14.229543][INFO][hf2megads_weight_converter.py:113] - model.layers.17.self_attn.o_proj.weight\n[2024-10-16 15:43:14.236240][INFO][hf2megads_weight_converter.py:113] - model.layers.17.mlp.gate_proj.weight\n[2024-10-16 15:43:14.242898][INFO][hf2megads_weight_converter.py:113] - model.layers.17.mlp.up_proj.weight\n[2024-10-16 15:43:14.249590][INFO][hf2megads_weight_converter.py:113] - model.layers.17.mlp.down_proj.weight\n[2024-10-16 15:43:14.250235][INFO][hf2megads_weight_converter.py:113] - model.layers.17.input_layernorm.weight\n[2024-10-16 15:43:14.250747][INFO][hf2megads_weight_converter.py:113] - model.layers.17.post_attention_layernorm.weight\n[2024-10-16 15:43:14.253465][INFO][hf2megads_weight_converter.py:113] - model.layers.18.self_attn.q_proj.weight\n[2024-10-16 15:43:14.255062][INFO][hf2megads_weight_converter.py:113] - model.layers.18.self_attn.k_proj.weight\n[2024-10-16 15:43:14.256546][INFO][hf2megads_weight_converter.py:113] - model.layers.18.self_attn.v_proj.weight\n[2024-10-16 15:43:14.259362][INFO][hf2megads_weight_converter.py:113] - model.layers.18.self_attn.o_proj.weight\n[2024-10-16 15:43:14.266006][INFO][hf2megads_weight_converter.py:113] - model.layers.18.mlp.gate_proj.weight\n[2024-10-16 15:43:14.272677][INFO][hf2megads_weight_converter.py:113] - model.layers.18.mlp.up_proj.weight\n[2024-10-16 15:43:14.279406][INFO][hf2megads_weight_converter.py:113] - model.layers.18.mlp.down_proj.weight\n[2024-10-16 15:43:14.280055][INFO][hf2megads_weight_converter.py:113] - model.layers.18.input_layernorm.weight\n[2024-10-16 15:43:14.280566][INFO][hf2megads_weight_converter.py:113] - model.layers.18.post_attention_layernorm.weight\n[2024-10-16 15:43:14.283295][INFO][hf2megads_weight_converter.py:113] - model.layers.19.self_attn.q_proj.weight\n[2024-10-16 15:43:14.284803][INFO][hf2megads_weight_converter.py:113] - model.layers.19.self_attn.k_proj.weight\n[2024-10-16 15:43:14.286350][INFO][hf2megads_weight_converter.py:113] - model.layers.19.self_attn.v_proj.weight\n[2024-10-16 15:43:14.289142][INFO][hf2megads_weight_converter.py:113] - model.layers.19.self_attn.o_proj.weight\n[2024-10-16 15:43:14.295818][INFO][hf2megads_weight_converter.py:113] - model.layers.19.mlp.gate_proj.weight\n[2024-10-16 15:43:14.302488][INFO][hf2megads_weight_converter.py:113] - model.layers.19.mlp.up_proj.weight\n[2024-10-16 15:43:14.309098][INFO][hf2megads_weight_converter.py:113] - model.layers.19.mlp.down_proj.weight\n[2024-10-16 15:43:14.309731][INFO][hf2megads_weight_converter.py:113] - model.layers.19.input_layernorm.weight\n[2024-10-16 15:43:14.310234][INFO][hf2megads_weight_converter.py:113] - model.layers.19.post_attention_layernorm.weight\n[2024-10-16 15:43:14.312927][INFO][hf2megads_weight_converter.py:113] - model.layers.20.self_attn.q_proj.weight\n[2024-10-16 15:43:14.314505][INFO][hf2megads_weight_converter.py:113] - model.layers.20.self_attn.k_proj.weight\n[2024-10-16 15:43:14.315992][INFO][hf2megads_weight_converter.py:113] - model.layers.20.self_attn.v_proj.weight\n[2024-10-16 15:43:14.318788][INFO][hf2megads_weight_converter.py:113] - model.layers.20.self_attn.o_proj.weight\n[2024-10-16 15:43:14.325390][INFO][hf2megads_weight_converter.py:113] - model.layers.20.mlp.gate_proj.weight\n[2024-10-16 15:43:14.332020][INFO][hf2megads_weight_converter.py:113] - model.layers.20.mlp.up_proj.weight\n[2024-10-16 15:43:14.338682][INFO][hf2megads_weight_converter.py:113] - model.layers.20.mlp.down_proj.weight\n[2024-10-16 15:43:14.339334][INFO][hf2megads_weight_converter.py:113] - model.layers.20.input_layernorm.weight\n[2024-10-16 15:43:14.339845][INFO][hf2megads_weight_converter.py:113] - model.layers.20.post_attention_layernorm.weight\n[2024-10-16 15:43:14.342562][INFO][hf2megads_weight_converter.py:113] - model.layers.21.self_attn.q_proj.weight\n[2024-10-16 15:43:14.344113][INFO][hf2megads_weight_converter.py:113] - model.layers.21.self_attn.k_proj.weight\n[2024-10-16 15:43:14.345593][INFO][hf2megads_weight_converter.py:113] - model.layers.21.self_attn.v_proj.weight\n[2024-10-16 15:43:14.348370][INFO][hf2megads_weight_converter.py:113] - model.layers.21.self_attn.o_proj.weight\n[2024-10-16 15:43:14.355167][INFO][hf2megads_weight_converter.py:113] - model.layers.21.mlp.gate_proj.weight\n[2024-10-16 15:43:14.361823][INFO][hf2megads_weight_converter.py:113] - model.layers.21.mlp.up_proj.weight\n[2024-10-16 15:43:14.368428][INFO][hf2megads_weight_converter.py:113] - model.layers.21.mlp.down_proj.weight\n[2024-10-16 15:43:14.369055][INFO][hf2megads_weight_converter.py:113] - model.layers.21.input_layernorm.weight\n[2024-10-16 15:43:14.369558][INFO][hf2megads_weight_converter.py:113] - model.layers.21.post_attention_layernorm.weight\n[2024-10-16 15:43:14.372269][INFO][hf2megads_weight_converter.py:113] - model.layers.22.self_attn.q_proj.weight\n[2024-10-16 15:43:14.373830][INFO][hf2megads_weight_converter.py:113] - model.layers.22.self_attn.k_proj.weight\n[2024-10-16 15:43:14.375316][INFO][hf2megads_weight_converter.py:113] - model.layers.22.self_attn.v_proj.weight\n[2024-10-16 15:43:14.378084][INFO][hf2megads_weight_converter.py:113] - model.layers.22.self_attn.o_proj.weight\n[2024-10-16 15:43:14.384700][INFO][hf2megads_weight_converter.py:113] - model.layers.22.mlp.gate_proj.weight\n[2024-10-16 15:43:14.391366][INFO][hf2megads_weight_converter.py:113] - model.layers.22.mlp.up_proj.weight\n[2024-10-16 15:43:14.398053][INFO][hf2megads_weight_converter.py:113] - model.layers.22.mlp.down_proj.weight\n[2024-10-16 15:43:14.398695][INFO][hf2megads_weight_converter.py:113] - model.layers.22.input_layernorm.weight\n[2024-10-16 15:43:14.399206][INFO][hf2megads_weight_converter.py:113] - model.layers.22.post_attention_layernorm.weight\n[2024-10-16 15:43:14.401929][INFO][hf2megads_weight_converter.py:113] - model.layers.23.self_attn.q_proj.weight\n[2024-10-16 15:43:14.403487][INFO][hf2megads_weight_converter.py:113] - model.layers.23.self_attn.k_proj.weight\n[2024-10-16 15:43:14.404961][INFO][hf2megads_weight_converter.py:113] - model.layers.23.self_attn.v_proj.weight\n[2024-10-16 15:43:14.407720][INFO][hf2megads_weight_converter.py:113] - model.layers.23.self_attn.o_proj.weight\n[2024-10-16 15:43:14.414356][INFO][hf2megads_weight_converter.py:113] - model.layers.23.mlp.gate_proj.weight\n[2024-10-16 15:43:14.421000][INFO][hf2megads_weight_converter.py:113] - model.layers.23.mlp.up_proj.weight\n[2024-10-16 15:43:14.427610][INFO][hf2megads_weight_converter.py:113] - model.layers.23.mlp.down_proj.weight\n[2024-10-16 15:43:14.428269][INFO][hf2megads_weight_converter.py:113] - model.layers.23.input_layernorm.weight\n[2024-10-16 15:43:14.428783][INFO][hf2megads_weight_converter.py:113] - model.layers.23.post_attention_layernorm.weight\n[2024-10-16 15:43:14.431461][INFO][hf2megads_weight_converter.py:113] - model.layers.24.self_attn.q_proj.weight\n[2024-10-16 15:43:14.432995][INFO][hf2megads_weight_converter.py:113] - model.layers.24.self_attn.k_proj.weight\n[2024-10-16 15:43:14.434507][INFO][hf2megads_weight_converter.py:113] - model.layers.24.self_attn.v_proj.weight\n[2024-10-16 15:43:14.437268][INFO][hf2megads_weight_converter.py:113] - model.layers.24.self_attn.o_proj.weight\n[2024-10-16 15:43:14.443850][INFO][hf2megads_weight_converter.py:113] - model.layers.24.mlp.gate_proj.weight\n[2024-10-16 15:43:14.450632][INFO][hf2megads_weight_converter.py:113] - model.layers.24.mlp.up_proj.weight\n[2024-10-16 15:43:14.457242][INFO][hf2megads_weight_converter.py:113] - model.layers.24.mlp.down_proj.weight\n[2024-10-16 15:43:14.457890][INFO][hf2megads_weight_converter.py:113] - model.layers.24.input_layernorm.weight\n[2024-10-16 15:43:14.458409][INFO][hf2megads_weight_converter.py:113] - model.layers.24.post_attention_layernorm.weight\n[2024-10-16 15:43:14.461063][INFO][hf2megads_weight_converter.py:113] - model.layers.25.self_attn.q_proj.weight\n[2024-10-16 15:43:14.462620][INFO][hf2megads_weight_converter.py:113] - model.layers.25.self_attn.k_proj.weight\n[2024-10-16 15:43:14.464102][INFO][hf2megads_weight_converter.py:113] - model.layers.25.self_attn.v_proj.weight\n[2024-10-16 15:43:14.466871][INFO][hf2megads_weight_converter.py:113] - model.layers.25.self_attn.o_proj.weight\n[2024-10-16 15:43:14.473435][INFO][hf2megads_weight_converter.py:113] - model.layers.25.mlp.gate_proj.weight\n[2024-10-16 15:43:14.480017][INFO][hf2megads_weight_converter.py:113] - model.layers.25.mlp.up_proj.weight\n[2024-10-16 15:43:14.486605][INFO][hf2megads_weight_converter.py:113] - model.layers.25.mlp.down_proj.weight\n[2024-10-16 15:43:14.487227][INFO][hf2megads_weight_converter.py:113] - model.layers.25.input_layernorm.weight\n[2024-10-16 15:43:14.487743][INFO][hf2megads_weight_converter.py:113] - model.layers.25.post_attention_layernorm.weight\n[2024-10-16 15:43:14.490427][INFO][hf2megads_weight_converter.py:113] - model.layers.26.self_attn.q_proj.weight\n[2024-10-16 15:43:14.491946][INFO][hf2megads_weight_converter.py:113] - model.layers.26.self_attn.k_proj.weight\n[2024-10-16 15:43:14.493433][INFO][hf2megads_weight_converter.py:113] - model.layers.26.self_attn.v_proj.weight\n[2024-10-16 15:43:14.496192][INFO][hf2megads_weight_converter.py:113] - model.layers.26.self_attn.o_proj.weight\n[2024-10-16 15:43:14.502792][INFO][hf2megads_weight_converter.py:113] - model.layers.26.mlp.gate_proj.weight\n[2024-10-16 15:43:14.509329][INFO][hf2megads_weight_converter.py:113] - model.layers.26.mlp.up_proj.weight\n[2024-10-16 15:43:14.515980][INFO][hf2megads_weight_converter.py:113] - model.layers.26.mlp.down_proj.weight\n[2024-10-16 15:43:14.516659][INFO][hf2megads_weight_converter.py:113] - model.layers.26.input_layernorm.weight\n[2024-10-16 15:43:14.517200][INFO][hf2megads_weight_converter.py:113] - model.layers.26.post_attention_layernorm.weight\n[2024-10-16 15:43:14.519874][INFO][hf2megads_weight_converter.py:113] - model.layers.27.self_attn.q_proj.weight\n[2024-10-16 15:43:14.521415][INFO][hf2megads_weight_converter.py:113] - model.layers.27.self_attn.k_proj.weight\n[2024-10-16 15:43:14.522879][INFO][hf2megads_weight_converter.py:113] - model.layers.27.self_attn.v_proj.weight\n[2024-10-16 15:43:14.525620][INFO][hf2megads_weight_converter.py:113] - model.layers.27.self_attn.o_proj.weight\n[2024-10-16 15:43:14.532202][INFO][hf2megads_weight_converter.py:113] - model.layers.27.mlp.gate_proj.weight\n[2024-10-16 15:43:14.538768][INFO][hf2megads_weight_converter.py:113] - model.layers.27.mlp.up_proj.weight\n[2024-10-16 15:43:14.545303][INFO][hf2megads_weight_converter.py:113] - model.layers.27.mlp.down_proj.weight\n[2024-10-16 15:43:14.545921][INFO][hf2megads_weight_converter.py:113] - model.layers.27.input_layernorm.weight\n[2024-10-16 15:43:14.546440][INFO][hf2megads_weight_converter.py:113] - model.layers.27.post_attention_layernorm.weight\n[2024-10-16 15:43:14.549101][INFO][hf2megads_weight_converter.py:113] - model.layers.28.self_attn.q_proj.weight\n[2024-10-16 15:43:14.550596][INFO][hf2megads_weight_converter.py:113] - model.layers.28.self_attn.k_proj.weight\n[2024-10-16 15:43:14.552114][INFO][hf2megads_weight_converter.py:113] - model.layers.28.self_attn.v_proj.weight\n[2024-10-16 15:43:14.554821][INFO][hf2megads_weight_converter.py:113] - model.layers.28.self_attn.o_proj.weight\n[2024-10-16 15:43:14.561373][INFO][hf2megads_weight_converter.py:113] - model.layers.28.mlp.gate_proj.weight\n[2024-10-16 15:43:14.567945][INFO][hf2megads_weight_converter.py:113] - model.layers.28.mlp.up_proj.weight\n[2024-10-16 15:43:14.574713][INFO][hf2megads_weight_converter.py:113] - model.layers.28.mlp.down_proj.weight\n[2024-10-16 15:43:14.575333][INFO][hf2megads_weight_converter.py:113] - model.layers.28.input_layernorm.weight\n[2024-10-16 15:43:14.575833][INFO][hf2megads_weight_converter.py:113] - model.layers.28.post_attention_layernorm.weight\n[2024-10-16 15:43:14.578469][INFO][hf2megads_weight_converter.py:113] - model.layers.29.self_attn.q_proj.weight\n[2024-10-16 15:43:14.580020][INFO][hf2megads_weight_converter.py:113] - model.layers.29.self_attn.k_proj.weight\n[2024-10-16 15:43:14.581498][INFO][hf2megads_weight_converter.py:113] - model.layers.29.self_attn.v_proj.weight\n[2024-10-16 15:43:14.584217][INFO][hf2megads_weight_converter.py:113] - model.layers.29.self_attn.o_proj.weight\n[2024-10-16 15:43:14.590850][INFO][hf2megads_weight_converter.py:113] - model.layers.29.mlp.gate_proj.weight\n[2024-10-16 15:43:14.597375][INFO][hf2megads_weight_converter.py:113] - model.layers.29.mlp.up_proj.weight\n[2024-10-16 15:43:14.603899][INFO][hf2megads_weight_converter.py:113] - model.layers.29.mlp.down_proj.weight\n[2024-10-16 15:43:14.604548][INFO][hf2megads_weight_converter.py:113] - model.layers.29.input_layernorm.weight\n[2024-10-16 15:43:14.605067][INFO][hf2megads_weight_converter.py:113] - model.layers.29.post_attention_layernorm.weight\n[2024-10-16 15:43:14.607694][INFO][hf2megads_weight_converter.py:113] - model.layers.30.self_attn.q_proj.weight\n[2024-10-16 15:43:14.609232][INFO][hf2megads_weight_converter.py:113] - model.layers.30.self_attn.k_proj.weight\n[2024-10-16 15:43:14.610733][INFO][hf2megads_weight_converter.py:113] - model.layers.30.self_attn.v_proj.weight\n[2024-10-16 15:43:14.613448][INFO][hf2megads_weight_converter.py:113] - model.layers.30.self_attn.o_proj.weight\n[2024-10-16 15:43:14.619991][INFO][hf2megads_weight_converter.py:113] - model.layers.30.mlp.gate_proj.weight\n[2024-10-16 15:43:14.626559][INFO][hf2megads_weight_converter.py:113] - model.layers.30.mlp.up_proj.weight\n[2024-10-16 15:43:14.633070][INFO][hf2megads_weight_converter.py:113] - model.layers.30.mlp.down_proj.weight\n[2024-10-16 15:43:14.633733][INFO][hf2megads_weight_converter.py:113] - model.layers.30.input_layernorm.weight\n[2024-10-16 15:43:14.634259][INFO][hf2megads_weight_converter.py:113] - model.layers.30.post_attention_layernorm.weight\n[2024-10-16 15:43:14.636877][INFO][hf2megads_weight_converter.py:113] - model.layers.31.self_attn.q_proj.weight\n[2024-10-16 15:43:14.638487][INFO][hf2megads_weight_converter.py:113] - model.layers.31.self_attn.k_proj.weight\n[2024-10-16 15:43:14.639954][INFO][hf2megads_weight_converter.py:113] - model.layers.31.self_attn.v_proj.weight\n[2024-10-16 15:43:14.642672][INFO][hf2megads_weight_converter.py:113] - model.layers.31.self_attn.o_proj.weight\n[2024-10-16 15:43:14.649190][INFO][hf2megads_weight_converter.py:113] - model.layers.31.mlp.gate_proj.weight\n[2024-10-16 15:43:14.655715][INFO][hf2megads_weight_converter.py:113] - model.layers.31.mlp.up_proj.weight\n[2024-10-16 15:43:14.662234][INFO][hf2megads_weight_converter.py:113] - model.layers.31.mlp.down_proj.weight\n[2024-10-16 15:43:14.662858][INFO][hf2megads_weight_converter.py:113] - model.layers.31.input_layernorm.weight\n[2024-10-16 15:43:14.663389][INFO][hf2megads_weight_converter.py:113] - model.layers.31.post_attention_layernorm.weight\n[2024-10-16 15:43:14.663915][INFO][hf2megads_weight_converter.py:113] - model.norm.weight\n[2024-10-16 15:43:14,693] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:14.713565][INFO][hf2megads_weight_converter.py:113] - lm_head.weight\n[2024-10-16 15:43:14.714574][INFO][hf2megads_weight_converter.py:504] - before deepspeed init\n[2024-10-16 15:43:14,715] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed info: version=0.15.3+unknown, git-hash=unknown, git-branch=unknown\n[2024-10-16 15:43:14,715] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [03:57&lt;00:00, 33.97s/it]\n[2024-10-16 15:43:36,676] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.36s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.38s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.40s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.39s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.41s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.43s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.40s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.41s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:00&lt;00:00, 34.41s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.44s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.44s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.46s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.44s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.43s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.47s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.44s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.47s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.44s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [03:58&lt;00:00, 34.12s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.47s/it]\nLoading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [04:01&lt;00:00, 34.51s/it]\n[2024-10-16 15:43:39,455] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,666] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,739] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,801] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,842] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,860] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,862] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,881] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:39,920] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,138] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,153] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,174] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,175] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,205] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,212] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,224] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,251] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,255] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,256] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,417] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:40,538] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 24\n[2024-10-16 15:43:56,920] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n[2024-10-16 15:43:56,921] [INFO] [logging.py:129:log_dist] [Rank 0] Creating BF16 optimizer\n[2024-10-16 15:43:57,118] [INFO] [utils.py:781:see_memory_usage] begin bf16_optimizer\n[2024-10-16 15:43:57,118] [INFO] [utils.py:782:see_memory_usage] MA 14.96 GB         Max_MA 14.96 GB         CA 14.96 GB         Max_CA 15 GB\n[2024-10-16 15:43:57,118] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 490.74 GB, percent = 43.3%\n[2024-10-16 15:43:57,290] [INFO] [utils.py:781:see_memory_usage] end bf16_ optimizer\n[2024-10-16 15:43:57,291] [INFO] [utils.py:782:see_memory_usage] MA 14.96 GB         Max_MA 14.96 GB         CA 14.96 GB         Max_CA 15 GB\n[2024-10-16 15:43:57,291] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 490.74 GB, percent = 43.3%\n[2024-10-16 15:43:57,291] [INFO] [config.py:999:print] DeepSpeedEngine configuration:\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   activation_checkpointing_config  {\n    \"partition_activations\": false,\n    \"contiguous_memory_optimization\": false,\n    \"cpu_checkpointing\": false,\n    \"number_checkpoints\": null,\n    \"synchronize_checkpoint_boundary\": false,\n    \"profile\": false\n}\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   amp_enabled .................. False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   amp_params ................... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   autotuning_config ............ {\n    \"enabled\": false,\n    \"start_step\": null,\n    \"end_step\": null,\n    \"metric_path\": null,\n    \"arg_mappings\": null,\n    \"metric\": \"throughput\",\n    \"model_info\": null,\n    \"results_dir\": \"autotuning_results\",\n    \"exps_dir\": \"autotuning_exps\",\n    \"overwrite\": true,\n    \"fast\": true,\n    \"start_profile_step\": 3,\n    \"end_profile_step\": 5,\n    \"tuner_type\": \"gridsearch\",\n    \"tuner_early_stopping\": 5,\n    \"tuner_num_trials\": 50,\n    \"model_info_path\": null,\n    \"mp_size\": 1,\n    \"max_train_batch_size\": null,\n    \"min_train_batch_size\": 1,\n    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03,\n    \"min_train_micro_batch_size_per_gpu\": 1,\n    \"num_tuning_micro_batch_sizes\": 3\n}\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   comms_config ................. &lt;deepspeed.comm.config.DeepSpeedCommsConfig object at 0x145ea0815900&gt;\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   communication_data_type ...... None\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   disable_allgather ............ False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   dump_state ................... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06\n[2024-10-16 15:43:57,292] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   elasticity_enabled ........... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   flops_profiler_config ........ {\n    \"enabled\": false,\n    \"recompute_fwd_factor\": 0.0,\n    \"profile_step\": 1,\n    \"module_depth\": -1,\n    \"top_modules\": 1,\n    \"detailed\": true,\n    \"output_file\": null\n}\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   fp16_enabled ................. False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   global_rank .................. 0\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.0\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   graph_harvesting ............. False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   loss_scale ................... 1.0\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   memory_breakdown ............. False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   mics_shard_size .............. -1\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   nebula_config ................ {\n    \"enabled\": false,\n    \"persistent_storage_path\": null,\n    \"persistent_time_interval\": 100,\n    \"num_of_version_in_retention\": 2,\n    \"enable_nebula_load\": true,\n    \"load_path\": null\n}\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   optimizer_name ............... None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   optimizer_params ............. None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   pld_enabled .................. False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   pld_params ................... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   prescale_gradients ........... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   scheduler_name ............... None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   scheduler_params ............. None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   sparse_attention ............. None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   steps_per_print .............. 100\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   train_batch_size ............. 24\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   use_node_local_storage ....... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   weight_quantization_config ... None\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   world_size ................... 24\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   zero_enabled ................. False\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True\n[2024-10-16 15:43:57,293] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 0\n[2024-10-16 15:43:57,293] [INFO] [config.py:989:print_user_config]   json = {\n    \"train_batch_size\": 24,\n    \"train_micro_batch_size_per_gpu\": 1,\n    \"steps_per_print\": 100,\n    \"zero_optimization\": {\n        \"stage\": 0\n    },\n    \"bf16\": {\n        \"enabled\": true\n    }\n}\n[2024-10-16 15:43:57,293] [INFO] [engine.py:105:__init__] CONFIG: micro_batches=1 micro_batch_size=1\n[2024-10-16 15:43:57,294] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,298] [INFO] [engine.py:165:__init__] RANK=0 STAGE=0 LAYERS=37 [0, 37) STAGE_PARAMS=8032358400 (8032.358M) TOTAL_PARAMS=8032358400 (8032.358M) UNIQUE_PARAMS=8032358400 (8032.358M)\n[2024-10-16 15:43:57.298751][INFO][hf2megads_weight_converter.py:511] - after deepspeed init\n[2024-10-16 15:43:57.299527][INFO][hf2megads_weight_converter.py:162] - hf_w.shape[0]=128512\n[2024-10-16 15:43:57.299951][INFO][hf2megads_weight_converter.py:163] - self.token_vocab=128000\n[2024-10-16 15:43:57,373] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,410] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,525] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n                                     [--hidden-size HIDDEN_SIZE]\n!!! ATTENTION !!!\n                                     [--num-attention-heads NUM_ATTENTION_HEADS]\nType 'up' to get to the frame that called dist.breakpoint(rank=0)\n                                     [--kv-channels KV_CHANNELS]\n&gt; /opt/aurora/24.180.0/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/__init__.py(89)breakpoint()\n-&gt; barrier()\n(Pdb) [2024-10-16 15:43:57,531] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,539] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,613] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,677] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,689] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,689] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,694] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,694] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,733] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,768] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,769] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,823] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,857] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,869] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,876] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:57,876] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:58,057] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:58,058] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:58,102] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n[2024-10-16 15:43:58,102] [INFO] [engine.py:146:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n                                     [--ffn-hidden-size FFN_HIDDEN_SIZE]\n(Pdb) l\n 84                pdb.message(\n 85                    \"\\n!!! ATTENTION !!!\\n\\n\"\n 86                    f\"Type 'up' to get to the frame that called dist.breakpoint(rank={rank})\\n\"\n 87                )\n 88                pdb.set_trace()\n 89  -&gt;        barrier()\n 90     \n 91        if sys.platform != \"win32\":\n 92            from torch._C._distributed_c10d import (\n 93                HashStore,\n 94                _round_robin_process_groups,\n(Pdb) ll\n 74        def breakpoint(rank: int = 0):\n 75            \"\"\"\n 76            Set a breakpoint, but only on a single rank.  All other ranks will wait for you to be\n 77            done with the breakpoint before continuing.\n 78     \n 79            Args:\n 80                rank (int): Which rank to break on.  Default: ``0``\n 81            \"\"\"\n 82            if get_rank() == rank:\n 83                pdb = _DistributedPdb()\n 84                pdb.message(\n 85                    \"\\n!!! ATTENTION !!!\\n\\n\"\n 86                    f\"Type 'up' to get to the frame that called dist.breakpoint(rank={rank})\\n\"\n 87                )\n 88                pdb.set_trace()\n 89  -&gt;        barrier()\n(Pdb) up\n&gt; /lus/flare/projects/Aurora_deployment/foremans/projects/argonne-lcf/Megatron-DeepSpeed/tools/hf2megads_weight_converter.py(224)_qkv_refactor()\n-&gt; torch.distributed.breakpoint(0)\n(Pdb) ll\n194        def _qkv_refactor(self, pname, p, hf_layer):\n195            hf_wq_name = f\"model.layers.{hf_layer}.self_attn.q_proj.weight\"\n196            hf_wk_name = f\"model.layers.{hf_layer}.self_attn.k_proj.weight\"\n197            hf_wv_name = f\"model.layers.{hf_layer}.self_attn.v_proj.weight\"\n198            wq = self.hf_model[hf_wq_name]\n199            wk = self.hf_model[hf_wk_name]\n200            wv = self.hf_model[hf_wv_name]\n201     \n202            hidden_size = wq.shape[0]\n203            per_partition_size, start_index, end_index = compute_partition_range(\n204                hidden_size, self.tp_rank, self.tp_size)\n205            hidden_size_per_attention_head = divide(hidden_size,\n206                                                    self.config.num_attention_heads)\n207            num_attention_heads_per_partition = divide(self.config.num_attention_heads,\n208                                                       self.tp_size)\n209     \n210            new_w = torch.zeros((per_partition_size * 3, wq.shape[1]), dtype=wq.dtype)\n211     \n212            for i in range(num_attention_heads_per_partition):\n213                try:\n214                    current_index = start_index + i * hidden_size_per_attention_head\n215                    next_index = current_index + hidden_size_per_attention_head\n216                    new_w_index = i * (3 * hidden_size_per_attention_head)\n217                    new_w[new_w_index: new_w_index + (3 * hidden_size_per_attention_head), :] = \\\n218                        torch.cat([\n219                            wq[current_index: next_index, :],\n220                            wk[current_index: next_index, :],\n221                            wv[current_index: next_index, :]\n222                        ], dim=0)\n223                except Exception:\n224  -&gt;                torch.distributed.breakpoint(0)\n225            self.record_mapping_info(\n226                f\"mega-ds:{pname,p.data.shape}&lt;--hf{hf_wq_name,hf_wk_name,hf_wv_name,}  cat q,k,v [{current_index}:{next_index},:]  of q,k,v{wq.shape}\"\n227            )\n228            return new_w\n(Pdb) current_index\n1024\n(Pdb) next_index\n1152\n(Pdb) new_w_index\n3072\n(Pdb) new_w.shape\ntorch.Size([12288, 4096])\n(Pdb) wq\ntensor([[ 0.0053, -0.0291, -0.0058,  ...,  0.0095, -0.0420, -0.0272],\n        [-0.0142, -0.0679, -0.0049,  ..., -0.0142, -0.0498,  0.0192],\n        [-0.0162, -0.0393, -0.0026,  ...,  0.0115, -0.0126,  0.0071],\n        ...,\n        [-0.0039, -0.0393,  0.0806,  ...,  0.0061, -0.0013,  0.0023],\n        [-0.0035, -0.0101,  0.0459,  ...,  0.0049, -0.0011,  0.0011],\n        [-0.0018, -0.0153,  0.0347,  ...,  0.0110,  0.0004,  0.0044]],\n       dtype=torch.bfloat16, grad_fn=&lt;CloneBackward0&gt;)\n(Pdb) wq.shape\ntorch.Size([4096, 4096])\n(Pdb) wk.shape\ntorch.Size([1024, 4096])\n(Pdb) wv.shape\ntorch.Size([1024, 4096])\n(Pdb) hidden_size\n4096\n(Pdb) per_partition_size\n4096\n(Pdb) num_attention_heads_per_partition\n32\n(Pdb) new_w.shape\ntorch.Size([12288, 4096])\n(Pdb) new_w.shape\ntorch.Size([12288, 4096])\n(Pdb)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üíæ Converting Checkpoints"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#update-2024-06-16",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#update-2024-06-16",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "Update: 2024-06-16",
    "text": "Update: 2024-06-16\nAfter an interactive debug session with Intel, the root behavior of the apparent discrepancy was identified.\nIn particular, we found that the ALCF/Megatron-DeepSpeed repo was NOT explicitly setting the dropout values to 0.0 (and so, was using the default values of 0.1) for both --attention-dropout and --hidden-dropout.\nAfter making this change, the losses were observed to agree, as can be seen below in\n\n\n\n\n\n\nFigure¬†1: After correctly setting the dropout values, the loss curves were observed to agree.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#impact-on-loss-bug",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#impact-on-loss-bug",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "üêõ Impact on Loss [Bug?]",
    "text": "üêõ Impact on Loss [Bug?]\nIn the q4-drop, it was observed that toggling flash-attn on / off seemed to produce different loss curves (with otherwise identical configs)\n\n\nshared-config.yaml\n\nTP: 1\nPP: 1\nGAS: 1\nOPT: adamw\ndtype: bf16\nNLAYERS: 10\nMICRO_BATCH: 2\nWORLD_SIZE: 24\n\nThis can be seen clearly in the figure below:\n\nThis was identified, and to be addressed in upcoming release.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#llm-framework-release",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#llm-framework-release",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "üì¶ LLM Framework Release",
    "text": "üì¶ LLM Framework Release\nOn 05/14/2024, Intel dropped their new LLM frameworks release:\n\n\nüéÅ frameworks_2024_5_v2 Announcement:\n\nHi Venkat,\nWe have shared the official Q2 release in two different forms :\nManual Setup: /gila/Aurora_deployment/anl_24_q2_release.tar.gz\nand\nModule:\nmodule use -a /home/jmitche1/anl_release/2024/q2\nmodule load frameworks_2024_5_v2\n¬†Instructions on how to use modules with Q2 build are anl_24_q2_release/README\n\nThe release includes :\n\nMegatron-DeepSpeed 0.14.2 (with patch)\nIntel¬Æ Extension for PyTorch* v2.1.30+xpu\nTorchCCL 2.1.300\nONEAPI 2024.1.0.596.PUBLIC_IDP_2024.1.0_723\nAgama driver: 803.29\n\nThe release provides following key features:\n\nScaleup Performance improvement from the TorchCCl prototype feature enabled by TORCH_LLM_ALLREDUCE=1 ¬†details\nAuto TP inference support for more workloads\nFlash Attention V2 improvement for 256 head dimension support; MiCS support.\nLatest Features and Optimizations from DeepSpeed¬†0.14.2¬†and Intel¬Æ Extension for PyTorch*¬†2.1.30.\n\n\nThanks,¬†\nJerome\n\n\nüì∏ flash ü§ù üì∑ no-flash\nWith this new release, Intel observed that the loss curves agreed exactly for flash / no-flash, using the learning rate settings below:\nlr: 0.00015\nlr_warmup_frac: 0.01\nlr_decay_iters: 320000\nTesting with Jerome‚Äôs new release:\nmodule use -a /home/jmitche1/anl_release/2024/q2\nmodule load frameworks_2024_5_v2\nI was able to independently confirm these results, shown in üì∏ flash ü§ù üì∑ no-flash below.\n\n\nüîó wandb links:\n\n\n[üì∏ flash] W&B Run: youthful-river-1832\n[üì∑ no-flash] W&B Run: earthy-wave-1830\n\n\n\n\nüì∏ flash vs.¬†üì∑ no-flash\n\n\n\n\nflash üì∏ ü§ù üì∑ no-flash\n\n\n\n\n\nüöß Broken MPI1\nFor whatever reason, things seemed to have spontaneously broken on the night of 2024-04-14 ??\nWhen trying to run experiments the following day (05/15/2024) I was met with this2:\nAbort(15): Fatal error in internal_Init_thread: Other MPI error\nwhich was discussed further in this thread on slack.\nIt seems Subrata also encountered a similar issue [see: slack thread]\n\n\n‚úÖ mpi4py fix\n\nTo resolve this\nAbort(15): Fatal error in internal_Init_thread: Other MPI error\nissue we can simply load the correct modules:\nmodule use -a /home/jmitche1/anl_release/2024/q2\nmodule load frameworks_2024_5_v2\nmodule use /home/ftartagl/graphics-compute-runtime/modulefiles\nmodule load graphics-compute-runtime/agama-ci-devel-803.29 \nmodule load spack-pe-gcc/0.6.1-23.275.2 gcc/12.2.0\nmodule use /soft/preview-modulefiles/24.086.0\nmodule load oneapi/release/2024.04.15.001\nFor full details see mpi4py-reproducer, and this [slack thread].",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#framework-comparison",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#framework-comparison",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "üïµüèª‚Äç Framework Comparison",
    "text": "üïµüèª‚Äç Framework Comparison\nAs I was re-building MPI, and after talking to Jerome, I realized that most of the dependencies are already present in the provided frameworks/ modules on Sunspot.\nAs a simple test, I tried building a new environment built on the base conda environment3 provided by theframeworks/2023.12.15.001 module, which worked without modification and had ) most of what I needed already installed:\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; torch.__version__\n'2.1.0a0+cxx11.abi'\n&gt;&gt;&gt; import intel_extension_for_pytorch as ipex\n&gt;&gt;&gt; ipex.__version__\n'2.1.10+xpu'\n&gt;&gt;&gt; from mpi4py import MPI\nThe remaining dependencies were installed according to the instructions from the new release frameworks_2024_5_v2.\nDetails included below.\n\n\nüì¶ pip Install Dependencies\n\nUnfortunately, the frameworks/** don‚Äôt appear to provide DeepSpeed.\nWe can create a virtual environment on top of the base conda by\n$ module use frameworks/2023.12.15.001\n$ export PBS_O_WORKDIR=$(pwd) ; source ALCF/helpers.sh && setup_venv_from_conda\nOnce the venv has been created and activated, we can install the remaining dependencies:\nTo build / install DeepSpeed, along with its required dependencies:\n\nintel-extension-for-deepspeed:\npython3 -m pip install intel_extension_for_pytorch_deepspeed\\=\\=2.1.30 -f \"https://pytorch-extension.intel.com/release-whl/stable/xpu/us/intel-extension-for-pytorch-deepspeed/\"\nDeepSpeed:\necho \"build deepspeed\"\ngit clone https://github.com/microsoft/DeepSpeed.git\ncd DeepSpeed\ngit remote add yizhou_ds https://github.com/YizhouZ/DeepSpeed.git\ngit fetch yizhou_ds\ngit checkout yizhou/kernel_path\npip install -r requirements/requirements.txt\npython setup.py develop |& tee build.log\nExtras:\npython3 -m pip install transformers datasets python-etcd tensorboardX packaging sentencepiece bitsandbytes tiktoken neural-speed einops intel-extension-for-transformers\n\n\nLooking around the available modules a bit, I noticed a newer frameworks release (frameworks/2024.04.15.002) that had a newer version of both torch and ipex:\nmodule use /soft/preview-modulefiles/24.086.0\nmodule load frameworks/2024.04.15.002.lua\npython3 -c 'from mpi4py import MPI; print(MPI.__file__)'\n# /soft/datascience/aurora_nre_models_frameworks-2024.1_preview_u1/lib/python3.9/site-packages/mpi4py/MPI.cpython-39-x86_64-linux-gnu.so\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; torch.__version__\n'2.1.0.post2+cxx11.abi'\n&gt;&gt;&gt; import intel_extension_for_pytorch as ipex\n&gt;&gt;&gt; ipex.__version__\n'2.1.30+xpu'\n&gt;&gt;&gt; from mpi4py import MPI; print(MPI.__file__)\n/soft/datascience/aurora_nre_models_frameworks-2024.1_preview_u1/lib/python3.9/site-packages/mpi4py/MPI.cpython-39-x86_64-linux-gnu.so\nThe remaining dependencies were installed identically to what was just done previously for the frameworks/2023.12.15.001 module.\nNOTE: In the figures below, we denote these two environments as:\n\n2024.0:\n\nmodule load frameworks/2023.12.15.001\n\n2024.1:\n\nmodule use /soft/preview-modulefiles/24.086.0\nmodule load frameworks/2024.04.15.002.lua\n\nanl_24_q2_release:\n\neval \"$(~/miniconda3/bin/conda shell.zsh hook)\"\nconda activate anl_24_q2_release\n\n\n\nü•∏ Fix in Disguise\nArmed now with functional environment(s) for argonne-lcf/Megatron-DeepSpeed, I was able to resume my previous experiments.\nFrom the discussion with Intel, it was hard to understand / reason about why the flash-attn fix would have any dependence on the learning rate schedule (warmup + decay).\nIf the flash-attn fix works for a particular learning rate schedule, you would reasonably expect that it should work for any learning rate schedule.\nAn additional source of confusion for me was that the discrepancy in the loss curves (seemingly) disappeared when using the learning rate settings provided by Intel4, but not when using the ALCF defaults5.\nAfter thinking about it for a bit and trying to reason about possible causes, I wondered if it might not be a mix of multiple different factors:\n\nSmall learning rate\nVery long decay\n[maybe ?] somehow dependent on the learning rate warmup fraction\n\npreliminary experiments seemed to suggest this was not the case\n\n\nSo, I was curious what would happen if I used the (larger) learning rate value from the ALCF defaults (lr=0.003) with the very long lr-decay-iters: 320000 from Intel.\nThese results are shown below.\nIn particular, for all three experiments the following learning rate settings were used:\nlr: 0.0003\nlr-warmup-frac: 0.05\nlr-decay-iters: 320000\n Looking at this figure ^, it appears that up until the very very end, all three loss curves agree identically.\nHowever, if we look closely at the very end, it looks like there might be a slight difference beginning to appear between the 2024.0 (brown line) and {anl_24_q2_release, 2024.1} ({dark, light} blue lines, respectively).\nThinking that I might be onto something, I then tried again with a smaller lr-decay-iters: 5000.\nThis result is shown below:\n In particular, we can now more clearly see the difference beginning to appear between the 2024.0 and 2024.1 loss curves.\nContinuing on, we see this effect become increasingly dramatic with even smaller values of lr-decay-iters:\n \n In each of these experiments, it appears that:\n\n2024.0:\n\nNot impacted by this lr-decay-iters dependence\nContinue to decrease for the duration of training\n\n2024.1:\n\nImpacted by the lr-decay-iters dependence\nPlateaus towards the end of training\n\n\n\n\nOlder Figs\n\n \n\n\n\n‚úÖ 2024.0 Fix\nEverything seems to work with\nmodule load frameworks/2023.12.15.001\n \n\n\nüìä lr-decay-iters Comparison\n\n2024.0:\n\n\n\n2024.1:",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#lr-decay-iters-dependence",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#lr-decay-iters-dependence",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "üìà lr-decay-iters dependence",
    "text": "üìà lr-decay-iters dependence",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#performance-improvement-in-2024.1",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#performance-improvement-in-2024.1",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "üèéÔ∏è Performance Improvement in 2024.1",
    "text": "üèéÔ∏è Performance Improvement in 2024.1\n\n\nlr: 0.0003\nlr-warmup-frac: 0.05\nlr-decay-iters: null",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/flash-attn-sunspot/index.html#footnotes",
    "href": "posts/AuroraGPT/flash-attn-sunspot/index.html#footnotes",
    "title": "üì∏ flash-attn on Sunspot",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGremlins, likely‚Ü©Ô∏é\nhttps://github.com/pmodels/mpich/pull/7001‚Ü©Ô∏é\nExplicitly, aurora_nre_models_frameworks-2024.0, abbreviated as 2024.0‚Ü©Ô∏é\nIntel used the following learning rate schedule in their experiments yml   lr: 0.00015   lr-warmup-frac: 0.01   lr-decay-iters: 320000‚Ü©Ô∏é\nALCF used the following learning rate schedule in their experiments‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üì∏ `flash-attn` on Sunspot"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html",
    "href": "posts/AuroraGPT/long-sequences/index.html",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "",
    "text": "The new Megatron-DeepSpeed release contains a variety of improvements / optimizations to enable pre-training Transformer based architectures with significantly longer sequences than was previously possible.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html#deepspeed4science-092023",
    "href": "posts/AuroraGPT/long-sequences/index.html#deepspeed4science-092023",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "DeepSpeed4Science (09/2023)",
    "text": "DeepSpeed4Science (09/2023)\n\nNew Features\n\nEnabled Megatron-LM‚Äôs sequence parallel.\nEnabled rotary positional embedding.\nEnabled FlashAttention v1 and v2.\nEnabled new fused kernels from NVIDIA.\n\n\n\nNew optimizations\n\nEnabled attention map memory optimization, where we first generated attention mask on CPU memory and then moved it into GPU memory to avoid out-of-memory errors when training with very large sequence lengths.\nPosition embedding partitioning, where we split weights of position encoding across all GPUs when enabling sequence parallel to further reduce the memory footprint.\n\n\n\nInitial Results\n\n\n\nTable¬†1: Long sequence length support1 from microsoft/Megatron-DeepSpeed\n\n\n\n\n\n\n\n\n\n\nSequence Length\nOld Megatron-DeepSpeed (TFLOPS)\nNew Megatron-DeepSpeed (TFLOPS)\n\n\n\n\n2k\n25\n68\n\n\n4k\n28\n80\n\n\n8k\nOOM\n86\n\n\n16k\nOOM\n92\n\n\n32k\nOOM\n100\n\n\n64k\nOOM\n106\n\n\n128k\nOOM\n119\n\n\n256k\nOOM\n94\n\n\n\n\n\n\n\n\nData\ngpus = ('32', '64', '128')\n\ncolors = {\n    'Old Megatron-DS': '#FF5252',\n    'Megatron-LM': '#76b900',\n    'New Megatron-DS':  '#1A8FFF',\n}\n\ndata = {\n    '25B': {\n        'Old Megatron-DS': np.array([36, 42, 42]),\n        'Megatron-LM': np.array([26, 48, 52]),\n        'New Megatron-DS': np.array([192, 448, 512]),\n    },\n    '33B': {\n        'Old Megatron-DS': np.array([28, 32, 32]),\n        'Megatron-LM': np.array([14, 46, 52]),\n        'New Megatron-DS': np.array([128, 384, 448]),\n    },\n}\n\n\n\nMake the plots\nx = np.arange(len(gpus))\nwidth = 0.25\nmultiplier = 0\n\noutdir = Path(os.getcwd()).joinpath('assets')\noutdir.mkdir(exist_ok=True, parents=True)\n\nimprovement = {}\nfor idx, (model_size, d) in enumerate(data.items()):\n    multiplier = 0\n    figure, axes = plt.subplots(figsize=(7.5, 4))\n    fig = plt.gcf()\n    ax = plt.gca()\n    for label, value in d.items():\n        offset = width * multiplier\n        rects = ax.barh(\n          x + offset,\n          value,\n          width,\n          label=label,\n          color=colors[label],\n          alpha=0.8\n        )\n        ax.bar_label(\n          rects,\n          padding=3,\n          color=colors[label],\n          family='monospace',\n          weight='bold'\n        )\n        multiplier += 1\n    ax.set_ylabel(\n        'GPUs',\n        fontsize=18,\n        family='sans-serif',\n        loc='center',\n    )\n    ax.set_yticks(x + width, gpus)\n    plt.figtext(\n        0.005, 0.93, f\"{model_size}\", fontsize=24, fontweight='bold', ha='left'\n    )\n    ax.set_xlabel(\n        'Sequence Length (k)', fontsize=18, loc='center'\n    )\n    ax.legend(\n        bbox_to_anchor=(0.005, 1.04, 0.99, .098),\n        alignment='center',\n        edgecolor=\"#83838320\",\n        frameon=True,\n        ncols=3,\n        fontsize=13,\n        mode=\"expand\",\n        borderaxespad=0.01\n    )\n    save_figure(fname=f'{model_size}', outdir=outdir)\n    _ = plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-25B Model\n\n\n\n\n\n\n\nGPT-33B Model\n\n\n\n\n\n\n\nFigure¬†2: Pre-training with long sequence support across different model sizes and numbers of GPUs. In each case, the new (current) implementation significantly outperforms both NVIDIA/Megatron-LM as well as our previous implementation.",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html#installation",
    "href": "posts/AuroraGPT/long-sequences/index.html#installation",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "Installation",
    "text": "Installation\n\nUsing install.sh\n\n\n\n\n\n\nTipInstallation\n\n\n\n\n\nImportant To install, simply:\ngit clone https://github.com/ramanthanlab/GenSLM/\ncd GenSLM/examples/long-sequences/\n./install.sh\nExplicitly, ./install.sh will:\n\nAutomatically create a virtual environment on top of the latest conda module\nInstall (+ update2) / build all the required dependencies into this virtual environment\n\n\n\n\n\n\nStep-by-Step\nFor completeness, we describe below the steps for installing and building each of the dependencies.\n\nClone GitHub repo:\ngit clone https://github.com/ramanthanlab/GenSLM\nLoad conda module:\n\nThetaGPU:\n# ThetaGPU:\nif [[ \"$(hostname)==theta*\" ]]; then\n    export MACHINE=\"ThetaGPU\"\n    export CONDA_DATE=\"2023-01-10\"\n    module load conda/2023-01-11\n    conda activate base\nfi\nPolaris:\n# Polaris:\nif [[ \"$(hostname)==x3*\" ]]; then\n    export MACHINE=\"Polaris\"\n    export CONDA_DATE=\"2023-01-10\"\n    module load conda/2023-01-10-unstable\n    conda activate base\nfi\n\nSetup Virtual Environment3:\ncd ./genslm/examples/long-sequences\n# create a new virtual environment\nmkdir -p \"venvs/${MACHINE}/${CONDA_DATE}\"\npython3 -m venv \"venvs/${MACHINE}/${CONDA_DATE}\" --system-site-packages\nsource \"venvs/${MACHINE}/${CONDA_DATE}/bin/activate\"\nCreate a new folder (genslm/examples/long-sequences/deps/${MACHINE}) where we‚Äôll installing dependencies locally:\nmkdir -p \"deps/${MACHINE}\"\ncd \"deps/${MACHINE}\"\n\n\nDependencies\nWe provide below the details needed to install each of the required dependencies.\n\n\n saforem2/ezpz\n\n\n saforem2/ezpz\npip install -e \"git+https://github.com/saforem2/ezpz.git#egg=ezpz\"\n\n\n\n\n Microsoft/DeepSpeed\n\n\n Microsoft/DeepSpeed\ngit clone https://github.com/microsoft/DeepSpeed.git\ncd DeepSpeed\npython3 -m pip install -e .\n\n\n\n\n Microsoft/Megatron-DeepSpeed\n\n\n Microsoft/Megatron-DeepSpeed:\ngit clone https://github.com/microsoft/Megatron-DeepSpeed.git\n\n\n\n\n NVIDIA/apex\n\n\n NVIDIA/apex\ngit clone https://github.com/NVIDIA/apex\ncd ../apex/\npip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" -e ./\n\n\n\n\n pybind/PyBind11\n\n\n pybind/PyBind11\npip install pybind11\n\n\n\n\n Dao-AILab/flash-attention\n\n\n Dao-AILab/flash-attention:\n\n\n\n\n\n\nCautionFlash Attention\n\n\n\n\n\n\nThe new release supports three different implementations of FlashAttention: (v1.0.4, v2.x, triton)\nFlashAttention v2.x may have numerical instability issues. For the best performance, we recommend using FlashAttention + Triton\n\n\n\n\n\nv1.0.4:\npython3 -m pip install flash-attn==1.0.4\nv2.x:\ngit clone https://github.com/Dao-AILab/flash-attention\ncd flash-attention\npython3 setup.py install\nopenai/triton:\ngit clone -b legacy-backend https://github.com/openai/triton\ncd triton/python\npython3 -m pip install cmake\npython3 -m pip install .",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html#running",
    "href": "posts/AuroraGPT/long-sequences/index.html#running",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "Running",
    "text": "Running\nThe ALCF/ directory contains shell scripts for setting up the environment and specifying the options to be used when launching.\nVarious options can be specified dynamically at runtime by setting them in your environment, e.g.:\nMODEL_SIZE_KEY=\"GPT25B\" SEQ_LEN=128000 USE_FLASH_ATTN=1 MICRO_BATCH=1 GAS=1 SP_TYPE=\"megatron\" ZERO_STAGE=1 ./ALCF/train-gpt3.sh\nExplicitly:\n\nALCF/train-gpt3.sh: Main entry point for training\n\nThis script will automatically source the rest of the required ALCF/*.sh scripts below\n\nALCF/models.sh: Contains some example model architectures for GPT3-style models\nALCF/args.sh: Logic for parsing / setting up runtime options for Megatron and DeepSpeed\nALCF/setup.sh: Locate and activate virtual environment to be used, ensure MPI variables are set properly\nALCF/launch.sh: Identify available resources and build the command to be executed\n\ni.e.¬†figure out how many: {nodes, GPUs per node, GPUs total}, to pass to mpi{run,exec}\nthen, use this to build mpiexec &lt;mpiexec-args&gt; python3 pretrain_gpt.py",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html#zero-offloading",
    "href": "posts/AuroraGPT/long-sequences/index.html#zero-offloading",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "ZeRO Offloading",
    "text": "ZeRO Offloading\nüöÄ W&B Report: Looooooooong Sequences\nThese newly introduced optimizations, in combination with ZeRO-Offload allows us to go even further.\nBy employing ZeRO-Offloading, we are able to free up additional memory which can be used for even longer sequences.\nThough work is still ongoing, this is a promising direction that will allow us to consider significantly larger genomes than previously possible.\nWe use Weights & Biases to track these experiments, and have aggregated our initial results in the W&B Report below.\nWe can evaluate the performance of our model by looking at two different metrics for throughput: samples_per_sec and TFLOPS.\nExplicitly, we see that we are able to scale up to significantly longer sequences (420k / 128k ~ 3.3x) with only a minimal impact on throughput performance (81 / 105 ~ 77\\%)4.\n\n\n\nTable¬†2: Impact on TFLOPS as a function of increasing sequence length. Table from: throughput/TFLOPS\n\n\n\n\n\n\n\n\n\n\n\n\nName\nSequence Length (k)\n(seq_len / min_seq_len)\nTFLOPS\nTFLOPS (% of peak)\n\n\n\n\nGPT25B\n420\n3.28125\n81.77225\n77.867\n\n\nGPT25B\n400\n3.125\n90.62\n86.297\n\n\nGPT25B\n360\n2.8125\n81.6325\n77.7348\n\n\nGPT25B\n360\n2.8125\n82.6824\n78.7346\n\n\nGPT25B\n192\n1.5\n115.8228\n110.2927\n\n\nGPT25B\n128\n1\n106.672\n101.5788\n\n\nGPT25B\n128\n1\n105.014\n100.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Weights & Biases Report",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/long-sequences/index.html#footnotes",
    "href": "posts/AuroraGPT/long-sequences/index.html#footnotes",
    "title": "üöÇ Loooooooong Sequence Lengths",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe described experiments were performed on 4 NVIDIA DGX A100-40GB nodes, all using TPSIZE=32[^tpsize], connected through 8 HDR InfiniBand (200Gb/s per HDR).‚Ü©Ô∏é\n\n\ndeepspeed-0.10.3\npytorch==2.0.0+cu118\n\n‚Ü©Ô∏é\nWhere \"${MACHINE}\" \\in {\"ThetaGPU\", \"Polaris\"} and \"${CONDA_DATE}\" \\in {\"2023-01-10\", \"2023-01-11\"}‚Ü©Ô∏é\nthroughput/TFLOPS‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üöÇ Loooooooong Sequence Lengths"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/spike-skipper/index.html#example",
    "href": "posts/AuroraGPT/spike-skipper/index.html#example",
    "title": "üèîÔ∏è Spike Skipper",
    "section": "üìù Example",
    "text": "üìù Example\nSuppose we observe a large spike in our loss curve, as shown below:\n\n\n\nspike-skipper\n\n\nSeemingly, this spike is being caused by a batch of ‚Äúbad data‚Äù. In order to prevent this ‚Äúbad data‚Äù sample from corrupting our training, we would like to ‚Äúskip‚Äù that particular training step.\nThis can be accomplished by passing the keyword argument --train-range-to-skip and specifying the endpoints of the ranges to be skipped.\ne.g., if you would like to skip all steps from [10, 20] and from [25, 30], we would specify:\nPBS_O_WORKDIR=$(pwd) bash train_aGPT_7B.sh \\\n    --train-range-to-skip 10 20 25 30",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèîÔ∏è Spike Skipper"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/spike-skipper/index.html#implementation",
    "href": "posts/AuroraGPT/spike-skipper/index.html#implementation",
    "title": "üèîÔ∏è Spike Skipper",
    "section": "üß™ Implementation",
    "text": "üß™ Implementation\nWe discuss below the details of the implementation, and provide some simple results to confirm things are behaving how we expect.\n\nCheck if args.train_range_to_skip is not None [here]\n\nAssert len(args.train_range_to_skip) % 2 == 0 [here]\n\nZip these up into pairs [here]:\nranges_to_skip = list(\n    zip(\n        args.train_range_to_skip[::2],\n        args.train_range_to_skip[1::2]\n    )\n)\n\nIf current iteration is in any of these pairs [here]\n\nFor each micro_step in range(gradient_accumulation_steps), explicitly:\n\ndraw a new batch of data [here] from our train_data_iterator\nimmediately discard it (instead of propagating it through the network)\n\nIncrement [here]:\n\nDeepSpeedEngine.skipped_steps\nDeepSpeedEngine.global_steps\nDeepSpeedEngine.micro_steps\nDeepSpeedEngine.global_samples\nlr_scheduler\n\n\n\n\nMust be even since we‚Äôre specifying the endpoints of intervals to skip",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèîÔ∏è Spike Skipper"
    ]
  },
  {
    "objectID": "posts/AuroraGPT/spike-skipper/index.html#sanity-check",
    "href": "posts/AuroraGPT/spike-skipper/index.html#sanity-check",
    "title": "üèîÔ∏è Spike Skipper",
    "section": "‚úÖ Sanity Check",
    "text": "‚úÖ Sanity Check\nIn order to confirm things are behaving as expected, we can explicitly look at the tokens drawn for each step, and ensure that they are the same regardless of whether or not that iteration was skipped.\n\nIn particular, we see that:\n\ntest 1:\n# [2024-09-16 23:09:09.059118][INFO][training:1083] - iteration=2 [0/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor(\n    [[ 1858,  3851, 29889,  ...,   500,    13,    13],\n     [  349,  6156,  1650,  ...,  5806, 28557,  3519],\n     [16554,   304,  1653,  ...,   322,  6934, 14722],\n     [ 4955,   310, 10465,  ...,  1438,  3841, 29892]]\n)\n# [2024-09-16 23:09:09.061999][INFO][training:1083] - iteration=2 [1/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor(\n    [[  363,  1302, 16453,  ...,  7967, 29891,   484],\n     [  367,   766,  4752,  ...,     1, 29871, 30143],\n     [29899,   855,  1503,  ...,  3786, 29892,  5100],\n     [  465,  1974,   289,  ..., 21588,   533,   304]]\n)\ntest 2:\n# [2024-09-16 22:59:27.752277][INFO][pretrain_gpt_alcf:198] - args.iteration=2:\ndata['text'][:10]=tensor(\n    [[ 1858,  3851, 29889,  ...,   500,    13,    13],\n     [  349,  6156,  1650,  ...,  5806, 28557,  3519],\n     [16554,   304,  1653,  ...,   322,  6934, 14722],\n     [ 4955,   310, 10465,  ...,  1438,  3841, 29892]]\n)\n# [2024-09-16 22:59:27,755] [INFO] [profiler.py:81:start_profile] Flops profiler started\n# [2024-09-16 22:59:28.568805][INFO][pretrain_gpt_alcf:198] - args.iteration=2:\ndata['text'][:10]=tensor(\n    [[363,  1302, 16453,  ...,  7967, 29891,   484],\n     [  367,   766,  4752,  ...,     1, 29871, 30143],\n     [29899,   855,  1503,  ...,  3786, 29892,  5100],\n     [  465,  1974,   289,  ..., 21588,   533,   304]]\n)\n\nas expected.\n\n\nüîç Details\n\nFirst 4 steps:\n\n\ntokens:\n\n\nIteration 0:\n[2024-09-16 22:58:50.168667][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  304,  7344,  5146,  ...,  9776, 29914, 26419],\n        [29889,    13,  4706,  ...,  9280, 30004,    13],\n        [29943, 20774, 29908,  ...,   304, 27391,   322],\n        [ 2645,   445, 29871,  ..., 16888,  4656, 10070]])\n[2024-09-16 22:58:58.866409][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[ 2768,   596,  1788,  ..., 27274,   393, 30010],\n        [  278,  5613,  4192,  ...,   362,   310,  1950],\n        [28038, 29892,  2022,  ...,  3160,   278,  2087],\n        [ 4149,   907, 29888,  ..., 29896, 29892, 29896]])\n[2024-09-16 22:59:02.043059][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  424,   322, 16232,  ...,   366,   748,   467],\n        [   13,   462,  1678,  ...,  2084, 29892,  3497],\n        [ 7562,   310, 19320,  ...,  8973, 22684,   358],\n        [ 2089,  3633,   292,  ..., 13774,   269,  2375]])\n[2024-09-16 22:59:03.456919][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[21411,   322,  3896,  ...,  2610, 29889,   319],\n        [ 8003, 29898, 29900,  ...,    12,  6658,   529],\n        [  278,  4148,   310,  ...,   263, 12212,   282],\n        [ 5977, 29871, 29906,  ..., 15332,   310,  1749]])\n[2024-09-16 22:59:04.596630][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  278,  1473, 24987,  ...,   263,  2217,  3804],\n        [ 2973,   263, 18778,  ...,   263,  4642,  6673],\n        [  309,   323,   804,  ...,  1063, 15296,   327],\n        [  278,  5864,   322,  ...,  9409, 29889,  2178]])\n[2024-09-16 22:59:05.486913][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[29892, 13731,  6617,  ..., 29871, 29896, 29946],\n        [ 2892,  1012,  1266,  ...,  4036,  7512,  2068],\n        [ 1473,  1556,  3619,  ...,  3762,   338,   263],\n        [23353, 29918,  2177,  ...,   501,   567,   814]])\n[2024-09-16 22:59:06.361333][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[ 5400, 14378,  4768,  ...,  2107, 18677, 29889],\n        [ 9200, 29887, 29914,  ...,   293, 24235,   322],\n        [30143,  4746,  2184,  ..., 11891, 29974, 25760],\n        [19263, 29914,   303,  ...,   358, 29889,    13]])\n[2024-09-16 22:59:07.230671][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  309,  1306,   681,  ...,   310, 23186, 21809],\n        [29896, 29929,    13,  ..., 29871, 29900,    13],\n        [ 9558,   964,   263,  ...,   322,   282,   682],\n        [  278, 23904, 21767,  ...,   313, 29929, 29889]])\nIteration 1:\n[2024-09-16 22:59:19.287338][INFO][training_log:661] -  iteration=       1/  635782 | consumed_samples=         768 | consumed_tokens=     3145728 | elapsed_time_per_iteration_ms=29570.0 | learning_rate=9.4372e-09 | global_batch_size=768 | lm loss=11.167250 | loss_scale=1.0 | grad_norm=6.363 | actual_seqlen= 4096 | number_of_skipped_iterations=  0 | number_of_nan_iterations=  0 | samples_per_second=25.972 | tokens_per_gpu_per_second_tgs=4432.597 | [LM]TFLOPs=20.30 | [DS]TFLOPs=26.18 |\n[2024-09-16 22:59:19.289582][INFO][utils:207] - [Rank 0] (after 1 iterations) memory (MB) | allocated: 1894.57666015625 | max allocated: 9752.35498046875 | reserved: 11342.0 | max reserved: 11342.0\n(min, max) time across ranks (ms):\n  forward-backward ...............................: (26094.39, 26095.09)\n  optimizer ......................................: (3407.56, 3409.92)\n[2024-09-16 22:59:19.297183][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[ 1472, 29892,   408,  ..., 29892,  1584,   363],\n      [  967, 19475,  6593,  ...,  8093, 29899, 11249],\n      [ 1006,  2218, 13326,  ...,  2355,  1304,   304],\n      [29900, 29916, 29947,  ...,   353,  1870, 29936]])\n[2024-09-16 22:59:20.104352][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[ 2354,   274,  1041,  ..., 29892, 13049,  9098],\n      [ 8798,  9547, 10353,  ...,   303,  3143, 29889],\n      [ 1373,  4056,  7236,  ...,  3186,   297,  5837],\n      [ 1738, 29920,  7355,  ...,    13, 29871,  3776]])\n[2024-09-16 22:59:20.977036][INFO][utils:326] -  &gt;&gt; building dataset for /flare/Aurora_deployment/AuroraGPT/datasets/dolma/data_v1.7_Llama2Tokenizer/c4-0000_text_document\n[2024-09-16 22:59:20.977877][INFO][utils:326] -  &gt; building dataset index ...\n[2024-09-16 22:59:20.977147][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[ 2020,   306,  1016,  ...,   322,   920,   372],\n      [ 5921,  1749,  7306,  ..., 19252,   297,  5664],\n      [  970,   770, 28547,  ...,   970,   894,  2577],\n      [ 1907,   363, 14188,  ...,   756,  3646,   287]])\n[2024-09-16 22:59:21.851620][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[  715, 25392,  3104,  ...,   289,  5761,   616],\n      [  426,    13,  9651,  ...,  9651,  1815, 22603],\n      [ 7714,  1213,    13,  ...,    13, 29876,   457],\n      [29889, 28663,  1230,  ...,  1546,   278,  6586]])\n[2024-09-16 22:59:22.720945][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[29929,    13,    13,  ..., 10739,  4770, 11277],\n      [ 4528,   304,  2367,  ...,  2501,   385,  4203],\n      [  869,   319,   794,  ...,  3158, 29889,  3115],\n      [  592,   260,  4125,  ...,   284,  1135, 18655]])\n[2024-09-16 22:59:23.590149][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[14338, 25323,  3321,  ...,  5607,  1806,  1164],\n      [  322,   278, 15352,  ...,  6462,   313,  1552],\n      [25738,   714, 29889,  ..., 29915, 29879, 24842],\n      [ 5122,   399, 29889,  ..., 29947,  7284,  2305]])\n[2024-09-16 22:59:24.457646][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[  367, 19310,  1891,  ...,  2408,   292,   263],\n      [  470,  3307,  5713,  ...,   568,  2594, 19385],\n      [29953, 29905,  1631,  ...,  1118,   343, 29897],\n      [10261,   373,  5490,  ...,   511,   297,  1760]])\n[2024-09-16 22:59:25.326699][INFO][pretrain_gpt_alcf:198] - args.iteration=1: data['text'][:10]=tensor([[ 1006,   326, 29901,  ..., 14834,  6694,  9595],\n      [12058,  5446, 29892,  ..., 29889,  8246,  3310],\n      [ 7483,   310,   278,  ...,   402,  9851,  4423],\n      [ 8041,   813,   322,  ...,  3303,  3900,   393]])\nIteration 2:\n[2024-09-16 22:59:27.744603][INFO][training_log:661] -  iteration=       2/  635782 | consumed_samples=        1536 | consumed_tokens=     6291456 | elapsed_time_per_iteration_ms=8457.2 | learning_rate=1.88744e-08 | global_batch_size=768 | lm loss=11.164009 | loss_scale=1.0 | grad_norm=6.271 | actual_seqlen= 4096 | number_of_skipped_iterations=  0 | number_of_nan_iterations=  0 | samples_per_second=90.810 | tokens_per_gpu_per_second_tgs=15498.234 | [LM]TFLOPs=70.98| [DS]TFLOPs=91.53 |\n(min, max) time across ranks (ms):\n  forward-backward ...............................: (8384.83, 8385.57)\n  optimizer ......................................: (55.03, 55.61)\n[2024-09-16 22:59:27.752277][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[ 1858,  3851, 29889,  ...,   500,    13,    13],\n      [  349,  6156,  1650,  ...,  5806, 28557,  3519],\n      [16554,   304,  1653,  ...,   322,  6934, 14722],\n      [ 4955,   310, 10465,  ...,  1438,  3841, 29892]])\n[2024-09-16 22:59:27,755] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:28.568805][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[  363,  1302, 16453,  ...,  7967, 29891,   484],\n      [  367,   766,  4752,  ...,     1, 29871, 30143],\n      [29899,   855,  1503,  ...,  3786, 29892,  5100],\n      [  465,  1974,   289,  ..., 21588,   533,   304]])\n[2024-09-16 22:59:28,571] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:29.440843][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[29889,    13,  4806,  ...,  3086, 26040,  9220],\n      [  293,  7207,   355,  ..., 18131,   520,  1247],\n      [ 8619, 29889, 29871,  ...,   304, 10029,   266],\n      [  363, 15202, 29892,  ...,   482, 17162, 19104]])\n[2024-09-16 22:59:29,443] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:30.313403][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[25561,   411,   278,  ...,   297,  2898, 26163],\n      [22574,  2607, 18134,  ...,    13,  4706,   500],\n      [20190, 24820,  1623,  ...,   310,   901, 29892],\n      [29892,  1951,  4486,  ...,   869,   887, 30010]])\n[2024-09-16 22:59:30,316] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:31.185339][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[ 5371, 22417, 29892,  ...,    13,  6716,   901],\n      [  353,  1565, 29936,  ..., 29878,  3567,  7196],\n      [17296,   338,  1985,  ...,  3741,  9089,   422],\n      [  694, 13331,   310,  ..., 21180, 29892,   607]])\n[2024-09-16 22:59:31,188] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:32.057207][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[  292,  8818,   267,  ..., 29892, 11275,  7407],\n      [ 1870, 29897,    13,  ...,  2697, 29901,    13],\n      [29913,   338,   263,  ..., 29892,   591,  3394],\n      [ 2253,   472,  1554,  ...,   982,   304,   376]])\n[2024-09-16 22:59:32,060] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:32.930293][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[  391,  2598, 29883,  ..., 22629,   346,   440],\n      [29871, 29896, 29906,  ...,   407,   583,  2833],\n      [ 4262,  1836,    13,  ...,   310,   263, 10608],\n      [ 1199,   411, 24770,  ...,   272,  2153, 29889]])\n[2024-09-16 22:59:32,932] [INFO] [profiler.py:81:start_profile] Flops profiler started\n[2024-09-16 22:59:33.803567][INFO][pretrain_gpt_alcf:198] - args.iteration=2: data['text'][:10]=tensor([[  620, 20503,   428,  ...,   297,  1009,  9443],\n      [  950, 25078,   892,  ...,   408, 10636,   284],\n      [ 1012,  2003,   364,  ...,  7313, 29912, 19303],\n      [29906, 29892, 29945,  ...,   967, 26414,   472]])\nIteration 3:\n[2024-09-16 22:59:34.881265][INFO][training_log:661] -  iteration=       3/  635782 | consumed_samples=        2304 | consumed_tokens=     9437184 | elapsed_time_per_iteration_ms=7136.5 | learning_rate=2.83116e-08 | global_batch_size=768 | lm loss=11.164038 | loss_scale=1.0 | grad_norm=6.279 | actual_seqlen= 4096 | number_of_skipped_iterations=  0 | number_of_nan_iterations=  0 | samples_per_second=107.615 | tokens_per_gpu_per_second_tgs=18366.372 | [LM]TFLOPs=84.12 | [DS]TFLOPs=108.46 |\n(min, max) time across ranks (ms):\n  forward-backward ...............................: (7078.48, 7079.28)\n  optimizer ......................................: (38.62, 43.08)\n[2024-09-16 22:59:34.888870][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[  496,   313, 29941,  ...,  1316,   408,  4857],\n      [29899,  3204, 29889,  ...,  1074,   330,  2547],\n      [29916, 29900, 29946,  ..., 18455, 29889,  4002],\n      [26406,   338,  1641,  ...,   670,  1914,  6900]])\n[2024-09-16 22:59:35.719630][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[29945, 29900,   867,  ...,  7601, 12091,   310],\n      [  975, 29871, 29896,  ...,  3573,   825,   306],\n      [29906, 29900,  4638,  ..., 29227, 23145, 29892],\n      [  278, 14368,   322,  ..., 14909, 29936, 25913]])\n[2024-09-16 22:59:36.591343][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[  988,   306,  1033,  ...,   437,   408,  1532],\n      [  450, 10317,   310,  ...,   322,   752, 13036],\n      [11405,  8020, 29889,  ...,   471, 18096,   287],\n      [  288,  3594, 19284,  ...,   910,   338,   385]])\n[2024-09-16 22:59:37.463941][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[  322, 15151, 29946,  ..., 11648,  1497, 29889],\n      [24233,   362,   467,  ...,  4513,  1353,   322],\n      [ 3311, 13605, 29912,  ...,   945, 29899,  4181],\n      [ 1951,   366,   508,  ...,  6589,   491,   777]])\n[2024-09-16 22:59:38.343307][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[29889, 29900,    13,  ...,  6017,   424,  1711],\n      [  297,  5500,  1489,  ...,   310,  3802,  7875],\n      [ 8078,  5314,   515,  ...,   373,   278,  6991],\n      [13763,  6204,  6359,  ...,  4706,  2024,  1347]])\n[2024-09-16 22:59:39.214871][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[   13,  4806,  3512,  ...,   278,  7824,  6438],\n      [ 2294,   938,   903,  ...,  4537,  3047,   449],\n      [ 1230,  4123,   767,  ...,   310,   963, 21003],\n      [ 1152,  2319, 10365,  ...,   367, 14040,   363]])\n[2024-09-16 22:59:40.085368][INFO][utils:326] -  &gt;&gt; building dataset for /flare/Aurora_deployment/AuroraGPT/datasets/dolma/data_v1.7_Llama2Tokenizer/tulu_flan-0000_text_document\n[2024-09-16 22:59:40.086224][INFO][utils:326] -  &gt; building dataset index ...\n[2024-09-16 22:59:40.085475][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[27297, 29924,   801,  ..., 28947, 29892,   470],\n      [12542,  5568,   703,  ...,   426,    13,  4706],\n      [ 6907,   800,   322,  ..., 29892,  1661, 30304],\n      [29900, 13630,   293,  ..., 26552,   363,   975]])\n[2024-09-16 22:59:40.958071][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[   13, 29946, 29953,  ..., 29953, 29945, 29871],\n      [ 1283, 16578,  1156,  ...,   408,  2215,   408],\n      [29906,  4229,  7671,  ...,    13,  1576,  1014],\n      [  526,  2898,   304,  ...,   471,  4802, 29991]])\nIteration 4:\n[2024-09-16 22:59:42.028460][INFO][training_log:661] -  iteration=       4/  635782 | consumed_samples=        3072 | consumed_tokens=    12582912 | elapsed_time_per_iteration_ms=7147.0 | learning_rate=3.77488e-08 | global_batch_size=768 | lm loss=11.171233 | loss_scale=1.0 | grad_norm=6.272 | actual_seqlen= 4096 | number_of_skipped_iterations=  0 | number_of_nan_iterations=  0 | samples_per_second=107.458 | tokens_per_gpu_per_second_tgs=18339.524 | [LM]TFLOPs=84.00 | [DS]TFLOPs=108.31 |\n(min, max) time across ranks (ms):\n  forward-backward ...............................: (7091.77, 7092.56)\n  optimizer ......................................: (39.21, 40.11)\n[2024-09-16 22:59:42.035716][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[  443,   666, 10170,  ...,   278,   619,  7323],\n      [   13, 11008,   338,  ...,  2472,   363, 22049],\n      [29871,    13, 29938,  ..., 29962,  8521, 29896],\n      [ 1165,  2280,   304,  ...,   306,   471,  2086]])\n[2024-09-16 22:59:42.860756][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[  304,   679,   304,  ...,  1475, 29889,  1570],\n      [ 2184, 29936,    13,  ...,  4706,   970,  1780],\n      [29872,   352, 29901,  ..., 29905,  4915, 29912],\n      [16809,   304,  1438,  ..., 13457, 29889,    13]])\n[2024-09-16 22:59:43.731208][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[12015, 29901, 20549,  ...,   322, 10752, 17906],\n      [  372, 30010, 29879,  ..., 29892, 14595,   653],\n      [18280, 29958,    13,  ..., 18884,   736,  6251],\n      [29889,    13,    13,  ...,   599,   373, 17097]])\n[2024-09-16 22:59:44.605047][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[ 3367,   567,   964,  ...,  3353, 24870,  2181],\n      [ 1262,  2609,   367,  ..., 29974, 29896,  7570],\n      [29871, 29941, 29900,  ...,   341,   555,   265],\n      [ 4225,   526,  6041,  ...,  1925,  1623,  2748]])\n[2024-09-16 22:59:45.479433][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[ 2283, 10162,  1496,  ..., 30656, 30317, 30605],\n      [29879,  9228,   292,  ...,  7968, 29899,  7052],\n      [  884,   599,   367,  ..., 29892,   278,  6054],\n      [29879,   411,   278,  ...,   367,  5019,  1183]])\n[2024-09-16 22:59:46.351707][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[ 3867,   281,   761,  ..., 11949,   338,  4922],\n      [  297,  1432,  2586,  ...,  5414,   278, 29811],\n      [29892,   278, 15562,  ..., 10296,   310,   394],\n      [ 1451,  2960,  3505,  ...,   657, 14346,  8003]])\n[2024-09-16 22:59:47.222016][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[ 6601,  2874,   414,  ...,   302,   317,  7390],\n      [16415,   297,  5146,  ...,   763,   372,   471],\n      [29941, 29906,  1118,  ..., 29900, 29889, 29953],\n      [ 4893,   304,  4808,  ...,  2284,  2164, 18690]])\n[2024-09-16 22:59:48.094752][INFO][pretrain_gpt_alcf:198] - args.iteration=4: data['text'][:10]=tensor([[  901,   310,  2994,  ..., 29873,  1641,   766],\n      [  304,  1716,  2562,  ...,  3489,   304,   367],\n      [ 1949,  6736, 29871,  ..., 29965, 29909,   353],\n      [   13,    13, 29930,  ..., 16497,   316,   474]])\n\n\nSkipping steps [2, 3]:\n\n\ntokens:\n\n\nIteration 0:\n[2024-09-16 23:08:47.749839][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  304,  7344,  5146,  ...,  9776, 29914, 26419],\n  [29889,    13,  4706,  ...,  9280, 30004,    13],\n  [29943, 20774, 29908,  ...,   304, 27391,   322],\n  [ 2645,   445, 29871,  ..., 16888,  4656, 10070]])\n[2024-09-16 23:08:51.451183][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[ 2768,   596,  1788,  ..., 27274,   393, 30010],\n  [  278,  5613,  4192,  ...,   362,   310,  1950],\n  [28038, 29892,  2022,  ...,  3160,   278,  2087],\n  [ 4149,   907, 29888,  ..., 29896, 29892, 29896]])\n[2024-09-16 23:08:54.073597][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  424,   322, 16232,  ...,   366,   748,   467],\n  [   13,   462,  1678,  ...,  2084, 29892,  3497],\n  [ 7562,   310, 19320,  ...,  8973, 22684,   358],\n  [ 2089,  3633,   292,  ..., 13774,   269,  2375]])\n[2024-09-16 23:08:56.212476][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[21411,   322,  3896,  ...,  2610, 29889,   319],\n  [ 8003, 29898, 29900,  ...,    12,  6658,   529],\n  [  278,  4148,   310,  ...,   263, 12212,   282],\n  [ 5977, 29871, 29906,  ..., 15332,   310,  1749]])\n[2024-09-16 23:08:57.207940][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  278,  1473, 24987,  ...,   263,  2217,  3804],\n  [ 2973,   263, 18778,  ...,   263,  4642,  6673],\n  [  309,   323,   804,  ...,  1063, 15296,   327],\n  [  278,  5864,   322,  ...,  9409, 29889,  2178]])\n[2024-09-16 23:08:58.083935][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[29892, 13731,  6617,  ..., 29871, 29896, 29946],\n  [ 2892,  1012,  1266,  ...,  4036,  7512,  2068],\n  [ 1473,  1556,  3619,  ...,  3762,   338,   263],\n  [23353, 29918,  2177,  ...,   501,   567,   814]])\n[2024-09-16 23:08:58.951793][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[ 5400, 14378,  4768,  ...,  2107, 18677, 29889],\n  [ 9200, 29887, 29914,  ...,   293, 24235,   322],\n  [30143,  4746,  2184,  ..., 11891, 29974, 25760],\n  [19263, 29914,   303,  ...,   358, 29889,    13]])\n[2024-09-16 23:08:59.820234][INFO][pretrain_gpt_alcf:198] - args.iteration=0: data['text'][:10]=tensor([[  309,  1306,   681,  ...,   310, 23186, 21809],\n  [29896, 29929,    13,  ..., 29871, 29900,    13],\n  [ 9558,   964,   263,  ...,   322,   282,   682],\n  [  278, 23904, 21767,  ...,   313, 29929, 29889]])\nIteration 1:\n[2024-09-16 23:09:08.943867][INFO][training_log:661] -  iteration=       1/  635782 | consumed_samples=         768 | consumed_tokens=     3145728 | elapsed_time_per_iteration_ms=21224.4 | learning_rate=9.4372e-09 | global_batch_size=768 | lm loss=11.167250 | loss_scale=1.0 | grad_norm=6.363 | actual_seqlen= 4096 | number_of_skipped_iterations=  0 | number_of_nan_iterations=  0 | samples_per_second=36.185 | tokens_per_gpu_per_second_tgs=6175.523 | [LM]TFLOPs=28.29 | [DS]TFLOPs=36.47 |\n[2024-09-16 23:09:08.953432][INFO][training:1083] - iteration=1 [0/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 1472, 29892,   408,  ..., 29892,  1584,   363],\n  [  967, 19475,  6593,  ...,  8093, 29899, 11249],\n  [ 1006,  2218, 13326,  ...,  2355,  1304,   304],\n  [29900, 29916, 29947,  ...,   353,  1870, 29936]])\n[2024-09-16 23:09:08.957524][INFO][training:1083] - iteration=1 [1/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 2354,   274,  1041,  ..., 29892, 13049,  9098],\n  [ 8798,  9547, 10353,  ...,   303,  3143, 29889],\n  [ 1373,  4056,  7236,  ...,  3186,   297,  5837],\n  [ 1738, 29920,  7355,  ...,    13, 29871,  3776]])\n[2024-09-16 23:09:08.966648][INFO][training:1083] - iteration=1 [2/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 2020,   306,  1016,  ...,   322,   920,   372],\n  [ 5921,  1749,  7306,  ..., 19252,   297,  5664],\n  [  970,   770, 28547,  ...,   970,   894,  2577],\n  [ 1907,   363, 14188,  ...,   756,  3646,   287]])\n[2024-09-16 23:09:08.969989][INFO][training:1083] - iteration=1 [3/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  715, 25392,  3104,  ...,   289,  5761,   616],\n  [  426,    13,  9651,  ...,  9651,  1815, 22603],\n  [ 7714,  1213,    13,  ...,    13, 29876,   457],\n  [29889, 28663,  1230,  ...,  1546,   278,  6586]])\n[2024-09-16 23:09:08.990736][INFO][training:1083] - iteration=1 [4/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[29929,    13,    13,  ..., 10739,  4770, 11277],\n  [ 4528,   304,  2367,  ...,  2501,   385,  4203],\n  [  869,   319,   794,  ...,  3158, 29889,  3115],\n  [  592,   260,  4125,  ...,   284,  1135, 18655]])\n[2024-09-16 23:09:08.993101][INFO][training:1083] - iteration=1 [5/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[14338, 25323,  3321,  ...,  5607,  1806,  1164],\n  [  322,   278, 15352,  ...,  6462,   313,  1552],\n  [25738,   714, 29889,  ..., 29915, 29879, 24842],\n  [ 5122,   399, 29889,  ..., 29947,  7284,  2305]])\n[2024-09-16 23:09:09.036896][INFO][training:1083] - iteration=1 [6/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  367, 19310,  1891,  ...,  2408,   292,   263],\n  [  470,  3307,  5713,  ...,   568,  2594, 19385],\n  [29953, 29905,  1631,  ...,  1118,   343, 29897],\n  [10261,   373,  5490,  ...,   511,   297,  1760]])\n[2024-09-16 23:09:09.039401][INFO][training:1083] - iteration=1 [7/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 1006,   326, 29901,  ..., 14834,  6694,  9595],\n  [12058,  5446, 29892,  ..., 29889,  8246,  3310],\n  [ 7483,   310,   278,  ...,   402,  9851,  4423],\n  [ 8041,   813,   322,  ...,  3303,  3900,   393]])\nIteration 2:\n[2024-09-16 23:09:09.050766][INFO][training_log:661] -  iteration=       2/  635782 | consumed_samples=        1536 | consumed_tokens=     6291456 | elapsed_time_per_iteration_ms=106.8 | learning_rate=1.88744e-08 | global_batch_size=  768 | loss_scale=1.0 | grad_norm=6.363 | actual_seqlen= 4096 | number_of_skipped_iterations=  1 | number_of_nan_iterations=  0 | samples_per_second=7190.781 | tokens_per_gpu_per_second_tgs=1227226.651 | [LM]TFLOPs=5620.92 | [DS]TFLOPs=7247.49 |\n[2024-09-16 23:09:09.055864][INFO][training:1069] - Caught 3 in 'ranges_to_skip', skipping!\n[2024-09-16 23:09:09.057929][INFO][training:1082] - torch.Size([4, 4097]), len(train_data_iterator)=490723200\n[2024-09-16 23:09:09.059118][INFO][training:1083] - iteration=2 [0/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 1858,  3851, 29889,  ...,   500,    13,    13],\n[  349,  6156,  1650,  ...,  5806, 28557,  3519],\n[16554,   304,  1653,  ...,   322,  6934, 14722],\n[ 4955,   310, 10465,  ...,  1438,  3841, 29892]])\n[2024-09-16 23:09:09.061999][INFO][training:1083] - iteration=2 [1/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  363,  1302, 16453,  ...,  7967, 29891,   484],\n[  367,   766,  4752,  ...,     1, 29871, 30143],\n[29899,   855,  1503,  ...,  3786, 29892,  5100],\n[  465,  1974,   289,  ..., 21588,   533,   304]])\n[2024-09-16 23:09:09.065494][INFO][training:1083] - iteration=2 [2/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[29889,    13,  4806,  ...,  3086, 26040,  9220],\n[  293,  7207,   355,  ..., 18131,   520,  1247],\n[ 8619, 29889, 29871,  ...,   304, 10029,   266],\n[  363, 15202, 29892,  ...,   482, 17162, 19104]])\n[2024-09-16 23:09:09.069035][INFO][training:1083] - iteration=2 [3/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[25561,   411,   278,  ...,   297,  2898, 26163],\n[22574,  2607, 18134,  ...,    13,  4706,   500],\n[20190, 24820,  1623,  ...,   310,   901, 29892],\n[29892,  1951,  4486,  ...,   869,   887, 30010]])\n[2024-09-16 23:09:09.072577][INFO][training:1083] - iteration=2 [4/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[ 5371, 22417, 29892,  ...,    13,  6716,   901],\n[  353,  1565, 29936,  ..., 29878,  3567,  7196],\n[17296,   338,  1985,  ...,  3741,  9089,   422],\n[  694, 13331,   310,  ..., 21180, 29892,   607]])\n[2024-09-16 23:09:09.075789][INFO][training:1083] - iteration=2 [5/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  292,  8818,   267,  ..., 29892, 11275,  7407],\n[ 1870, 29897,    13,  ...,  2697, 29901,    13],\n[29913,   338,   263,  ..., 29892,   591,  3394],\n[ 2253,   472,  1554,  ...,   982,   304,   376]])\n[2024-09-16 23:09:09.079052][INFO][training:1083] - iteration=2 [6/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  391,  2598, 29883,  ..., 22629,   346,   440],\n[29871, 29896, 29906,  ...,   407,   583,  2833],\n[ 4262,  1836,    13,  ...,   310,   263, 10608],\n[ 1199,   411, 24770,  ...,   272,  2153, 29889]])\n[2024-09-16 23:09:09.082739][INFO][training:1083] - iteration=2 [7/8]: (torch.Size([4, 4097]))\n_tokens[:10]=tensor([[  620, 20503,   428,  ...,   297,  1009,  9443],\n[  950, 25078,   892,  ...,   408, 10636,   284],\n[ 1012,  2003,   364,  ...,  7313, 29912, 19303],\n[29906, 29892, 29945,  ...,   967, 26414,   472]])\nIteration 3:\n[2024-09-16 23:09:09.135651][INFO][training_log:661] - iteration= 3/ 635782 | consumed_samples= 2304 | consumed_tokens= 9437184 | elapsed_time_per_iteration_ms=84.7 | learning_rate=2.83116e-08 | global_batch_size= 768 | loss_scale=1.0 | grad_norm=6.363 | actual_seqlen= 4096 | number_of_skipped_iterations= 1 | number_of_nan_iterations= 0 | samples_per_second=9070.783 | tokens_per_gpu_per_second_tgs=1548080.271 | [LM]TFLOPs=7090.49 | [DS]TFLOPs=9142.31 |\n[2024-09-16 23:09:09.143511][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[496,   313, 29941,  ...,  1316,   408,  4857],\n  [29899,  3204, 29889,  ...,  1074,   330,  2547],\n  [29916, 29900, 29946,  ..., 18455, 29889,  4002],\n  [26406,   338,  1641,  ...,   670,  1914,  6900]])\n[2024-09-16 23:09:09.971988][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[29945, 29900,   867,  ...,  7601, 12091,   310],\n  [  975, 29871, 29896,  ...,  3573,   825,   306],\n  [29906, 29900,  4638,  ..., 29227, 23145, 29892],\n  [  278, 14368,   322,  ..., 14909, 29936, 25913]])\n[2024-09-16 23:09:10.843966][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[988,   306,  1033,  ...,   437,   408,  1532],\n  [  450, 10317,   310,  ...,   322,   752, 13036],\n  [11405,  8020, 29889,  ...,   471, 18096,   287],\n  [  288,  3594, 19284,  ...,   910,   338,   385]])\n[2024-09-16 23:09:11.715513][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[322, 15151, 29946,  ..., 11648,  1497, 29889],\n  [24233,   362,   467,  ...,  4513,  1353,   322],\n  [ 3311, 13605, 29912,  ...,   945, 29899,  4181],\n  [ 1951,   366,   508,  ...,  6589,   491,   777]])\n[2024-09-16 23:09:12.584136][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[29889, 29900,    13,  ...,  6017,   424,  1711],\n  [  297,  5500,  1489,  ...,   310,  3802,  7875],\n  [ 8078,  5314,   515,  ...,   373,   278,  6991],\n  [13763,  6204,  6359,  ...,  4706,  2024,  1347]])\n[2024-09-16 23:09:13.450767][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[13,  4806,  3512,  ...,   278,  7824,  6438],\n  [ 2294,   938,   903,  ...,  4537,  3047,   449],\n  [ 1230,  4123,   767,  ...,   310,   963, 21003],\n  [ 1152,  2319, 10365,  ...,   367, 14040,   363]])\n[2024-09-16 23:09:14.317517][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[27297, 29924,   801,  ..., 28947, 29892,   470],\n  [12542,  5568,   703,  ...,   426,    13,  4706],\n  [ 6907,   800,   322,  ..., 29892,  1661, 30304],\n  [29900, 13630,   293,  ..., 26552,   363,   975]])\n[2024-09-16 23:09:15.187191][INFO][pretrain_gpt_alcf:198] - args.iteration=3: data['text'][:10]=tensor([[13, 29946, 29953,  ..., 29953, 29945, 29871],\n  [ 1283, 16578,  1156,  ...,   408,  2215,   408],\n  [29906,  4229,  7671,  ...,    13,  1576,  1014],\n  [  526,  2898,   304,  ...,   471,  4802, 29991]])",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü§ñ AuroraGPT",
      "üèîÔ∏è Spike Skipper"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html",
    "href": "posts/ai-for-physics/diffusion/index.html",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "",
    "text": "2D U(1)\nfrom l2hmc.configs import dict_to_list_of_overrides\n\nseed = np.random.randint(0, 2**32)\nconsole.print(f\"seed = {seed}\")\n\noverrides = {\n    \"seed\": f\"{seed}\",\n    \"precision\": \"float32\",\n    \"init_wandb\": False,\n    \"init_aim\": False,\n    \"use_wandb\": False,\n    \"dynamics\": {\n        \"latvolume\": [32, 32],\n        \"nleapfrog\": 10,\n        \"nchains\": 16,\n        \"eps\": 0.05,\n    },\n    \"network\": {\n        \"use_batch_norm\": False,\n    },\n    'annealing_schedule': {\n        'beta_init': 6.0,\n        'beta_final': 6.0,\n    },\n\n}\nOVERRIDES = dict_to_list_of_overrides(overrides)\nfrom pathlib import Path\nfrom l2hmc.common import get_timestamp\nfrom enrich.console import get_theme, Console\nconsole = Console(theme=get_theme())\n\nOUTDIR = Path(\n    'l2hmc-diffusion-2dU1'\n).joinpath(get_timestamp(\"%Y-%m-%d\"))\nOUTDIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"OUTDIR: {OUTDIR}\")\n\ndate = get_timestamp('%Y-%m-%d')\nPLOTS_DIR = OUTDIR.joinpath('plots')\nPLOTS_DIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"Saving figures to: {PLOTS_DIR}\")\n#os.environ['MASTER_PORT'] = '5436'\n\nexp = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=pytorch',\n        'backend=DDP'\n    ]\n)\nstate = exp.trainer.dynamics.random_state(6.0)\nxdim = state.x.flatten().shape[0]\n\ndim = xdim\nlow_bound = (-np.pi) * np.ones(dim)\nhigh_bound = (np.pi) * np.ones(dim)\nsigma = 0.15\nretrains = 10\nsamples_per_retrain = 100\ndiffusion_prob = 0.1\nsns.set_context('notebook')\n\noutputs = {}\noutputs['hmc'] = exp.trainer.eval(\n    job_type='hmc',\n    beta=6.0,\n    nprint=100,\n    nchains=16,\n    eval_steps=1000\n)\n#hdset = exp.save_dataset(job_type='hmc', nchains=1)\n# %matplotlib inline\nfrom l2hmc.common import plot_dataset\nsns.set_context('notebook')\nhdataset = outputs['hmc']['history'].get_dataset()\nplot_dataset(hdataset, outdir=PLOTS_DIR, job_type='HMC')\nimport torch\n\ninitial_states = []\nstate_init = exp.trainer.dynamics.random_state(6.0)\nx = state_init.x\nbeta = state_init.beta\n\nNSAMPLES = 1000\nfor idx in range(NSAMPLES + int(0.1 * NSAMPLES)):\n    if idx % 100 == 0:\n        console.print(f\"step: {idx}\")\n    x, metrics = exp.trainer.hmc_step((x, beta))\n    if idx &gt; int((0.1 * NSAMPLES)):\n        initial_states.append(x)\n\ninitial_states = torch.stack(initial_states).squeeze()\ninitial_states_np = initial_states.detach().cpu().numpy()\ninitial_states_np.shape\nx_ = initial_states_np.reshape(-1, 16, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nconsole.print(f'{x_.shape}')\nconsole.print(f'{tmp_.shape}')\nfrom l2hmc.common import savefig\n\n#x_ = initial_states_np[:100].reshape(-1, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nfig, ax = plt.subplots()\nsns.kdeplot(\n    x=tmp_[-100:, 0].flatten(),\n    y=tmp_[-100:, 1].flatten(),\n    # ax=ax,\n    cmap='viridis',\n    # ax=axes[0],\n    # cmap=\"Blues\",\n    shade=False,\n    # bw_adjust=0.5,\n    thresh=0\n)\nax.set_xlim((-4, 4))\nax.set_ylim((-4, 4))\nsavefig(\n    f'hmc_samples-{NSAMPLES}',\n    Path(PLOTS_DIR),\n    tstamp=True,\n)\nclass Diffusion:\n    def __init__(\n            self,\n            noise_steps: int = 1000,\n            beta_start: float = 1e-4,\n            beta_end: float = 0.02,\n            nchannels: int = 2,\n            img_size: int = 256,\n            device: str = \"cuda\"\n    ):\n        self.noise_steps = noise_steps\n        self.beta_start = beta_start\n        self.beta_end = beta_end\n        self.img_size = img_size\n        self.device = device\n        self.nchannels = nchannels\n\n        self.beta = self.prepare_noise_schedule().to(device)\n        self.alpha = 1. - self.beta\n        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n\n    def prepare_noise_schedule(self):\n        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n\n    def noise_images(self, x, t):\n        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n        sqrt_one_minus_alpha_hat = torch.sqrt(\n            1 - self.alpha_hat[t]\n        )[:, None, None, None]\n        eps = torch.randn_like(x)\n        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * eps, eps\n\n    def sample_timesteps(self, n):\n        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n\n    def sample(self, model, n):\n        # console.print(f\"Sampling {n} new images....\")\n        model.eval()\n        with torch.no_grad():\n            x = torch.randn(\n                (n, self.nchannels, self.img_size, self.img_size)\n            ).to(self.device)\n            sample_bar = tqdm(\n                reversed(range(1, self.noise_steps)),\n                position=0,\n                total=self.noise_steps - 1,\n                dynamic_ncols=True,\n            )\n            for i in sample_bar:\n                t = (torch.ones(n) * i).long().to(self.device)\n                predicted_noise = model(x, t)\n                alpha = self.alpha[t][:, None, None, None]\n                alpha_hat = self.alpha_hat[t][:, None, None, None]\n                beta = self.beta[t][:, None, None, None]\n                if i &gt; 1:\n                    noise = torch.randn_like(x)\n                else:\n                    noise = torch.zeros_like(x)\n                x = (\n                    (1 / torch.sqrt(alpha))\n                    * (\n                        x \n                        - ((1 - alpha) / (torch.sqrt(1 - alpha_hat)))\n                        * predicted_noise\n                    ) \n                    + (torch.sqrt(beta) * noise)\n                )\n        model.train()\n        x = (x + np.pi) % (2 * np.pi) - np.pi\n        return x\ninitial_states.shape\nTrain Diffusion Model\nimport torchvision\nimport os\nimport random\nfrom pathlib import Path\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nimport numpy as np\nfrom PIL import Image\n#from fastdownload import FastDownload\nfrom torch.utils.data import DataLoader\n\ndef save_images(images, path, **kwargs):\n    grid = torchvision.utils.make_grid(images, **kwargs)\n    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n    im = Image.fromarray(ndarr)\n    im.save(path)\nBuild Diffusion Model with UNet Architecure\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nfrom l2hmc.common import savefig\nfrom l2hmc.diffusion.modules import NoiseScheduler, UNet\nfrom l2hmc.diffusion import ddpm\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nconfig = {\n    'channels_in': 2,\n    'channels_out': 2,\n    'train_batch_size': 5,\n    'learning_rate': 0.001,\n    'num_epochs': 1,\n    'noise_steps': 100,\n    'beta': 6.0,\n    'img_size': 32,\n    'retrains': 10,\n    'samples_per_retrain': 500,\n    'diffusion_prob': 0.1,\n}\n\nmodel = UNet(c_in=2, c_out=2)\n\ndataset = TensorDataset(initial_states.reshape(-1, 2, 32, 32))\ndataloader = DataLoader(\n    dataset,\n    batch_size=config[\"train_batch_size\"],\n    shuffle=False,\n    drop_last=True\n)\n\n\noptimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\nmse = nn.MSELoss()\ndiffusion = Diffusion(\n    noise_steps=100,\n    img_size=32,\n    device=DEVICE,\n    nchannels=2,\n)\n#logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\nl = len(dataloader)\n\nrun_name = 'diffusion2dU1'\nPerform initial training on HMC samples\nfrom torch import optim\ndevice = 'cpu'\n#dataloader = get_data(args)\n#model = UNet().to(device)\n\nsampled_images_history = []\n\nfor epoch in range(config['num_epochs']):\n    console.print(f\"Starting epoch {epoch}:\")\n    pbar = tqdm(dataloader)\n    for i, images in enumerate(pbar):\n        if isinstance(images, (tuple, list)) and len(images) == 1:\n            images = images[0]\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(images, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        pbar.set_postfix({'epoch': epoch, 'batch': i, 'MSE': loss.item()})\n    console.print(f'epoch: {epoch}, loss: {loss.item()}')\n    sampled_images = diffusion.sample(model, n=images.shape[0])\n    sampled_images_history.append(sampled_images)\n    sns.set_context('notebook')\n    #tmp = initial_states.reshape(-1, 2, 32, 32)\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(sampled_images[0, 0, :, :])\n    _ = ax[1].imshow(sampled_images[0, 1, :, :])\n    _ = ax[0].set_xticklabels([])\n    _ = ax[1].set_xticklabels([])\n    _ = ax[0].set_yticklabels([])\n    _ = ax[1].set_yticklabels([])\n    _ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n    _ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n    _ = fig.suptitle('Diffusion Samples', y=0.8)\n    plt.show()\n    savefig(fname=f'sampled_image_epoch{epoch}', outdir=PLOTS_DIR, tstamp=True)\n    MODEL_FILE = OUTDIR.joinpath(\"models\", f\"unet-diffusion-epoch{epoch}.pt\")\n    MODEL_FILE.parent.mkdir(exist_ok=True, parents=True)\n    console.print(f\"Saving model checkpoint to: {MODEL_FILE}\")\n    torch.save(model.state_dict(), MODEL_FILE)\nsns.set_context('notebook')\ntmp = initial_states.reshape(-1, 2, 32, 32)\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(tmp[0, 0, :, :])\n_ = ax[1].imshow(tmp[0, 1, :, :])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('HMC Samples', y=0.8)\nsampled_images_history_ = torch.stack(sampled_images_history)\nsampled_images_history_.shape\n\ntorch.Size([1, 5, 2, 32, 32])\nsns.set_context('notebook')\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(sampled_images_history_[0][0][0])\n_ = ax[1].imshow(sampled_images_history_[0][0][1])\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('Diffusion Samples', y=0.85)\nfor idx in range(sampled_images_history_.shape[0]):\n    q = exp.trainer.lattice.charges(x=sampled_images_history_[idx])\n    console.print(f'{idx}: {q}')\nHMC Sampling with Diffusion\n#for retrain_iter in range(config['retrains']):\nstate = exp.trainer.dynamics.random_state(config['beta'])\nx = state.x\n\nhistories = {}\nsamples = []\nhmc_samples = []\ndiffusion_samples = []\n\nglobal_step = 0\nwatcher = {}\nupdate_types = []\ncombined_samples = {}\nglobal_step\nfor retrain_iter in range(2):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    histories[retrain_iter] = {\n        'diffusion': [],\n        'hmc': [],\n    }\n    #for idx in range(config['samples_per_retrain']):\n    sbar = tqdm(range(10))\n    for idx in sbar:\n        t0_ = time.perf_counter()\n        if idx % 100 == 0:\n            console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if (retrain_iter &gt;= 1) and rand &lt; diffusion_prob:\n            console.print(f'rand: {rand} &lt; {diffusion_prob}')\n            # Sample from diffusion model\n            x_ = diffusion.sample(model, n=x.shape[0])\n            ll_ = exp.trainer.dynamics.potential_energy(x_, config['beta'])\n            ll = exp.trainer.dynamics.potential_energy(x, config['beta'])\n            ratio = ll_ / ll\n            a = torch.min(torch.ones_like(ratio), ratio)\n            u = torch.rand(a.shape)\n            #u = np.random.uniform()\n            #for jdx in range(u.shape[0]):\n            #    if u[jdx] &lt; a[jdx]:\n            #        samples.append(x_[jdx])\n            #        diffusion_samples.append(x_[jdx])\n            #x = torch.where((u &lt; a), x_, x.reshape_as(x_)).reshape_as(x)\n            x = torch.where((u &lt; a)[:, None, None, None], x_, x.reshape_as(x_))\n            samples.append(x)\n            diffusion_samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'diffusion'\n            #diffusion_samples.extend(x)\n            #samples.extend(x)\n            #ndiff_acc += \n            #if u &lt; a:\n            #    console.print('Accepted diffusion sample!')\n            #    console.print(f'{ndiff_acc} / {ndiff_proposed}')\n            #    ndiff_acc += 1\n            #    x = x_\n            #    diffusion_samples.append(x)\n            #    samples.append(x)\n        else:\n            # Oherwise, HMC\n            x, metrics = exp.trainer.hmc_step((x, config['beta']))\n            hmc_samples.append(x)\n            samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'HMC'\n        smetrics = {\n            'idx': idx,\n            'global_step': global_step,\n            'dt': time.perf_counter() - t0_,\n        }\n        global_step += 1\n        #smetrics |= {\n        #    f'{k}': {torch.tensor(v).mean().item()} for k, v in metrics.items()\n        #}\n        sbar.set_postfix(smetrics)\n    # Train loop\n    dataset = TensorDataset(\n        torch.stack(hmc_samples).reshape(-1, 2, 32, 32)\n    )\n    dataloader = DataLoader(\n        dataset,\n        shuffle=False,\n        drop_last=True,\n        batch_size=config[\"train_batch_size\"],\n    )\n    pbar = tqdm(dataloader)\n    for i, batch in enumerate(pbar):\n        if i == 0:\n            console.print('Retraining...')\n        if isinstance(batch, (tuple, list)) and len(batch) == 1:\n            batch, = batch\n        batch = batch.reshape(-1, 2, 32, 32)\n        t0 = time.time()\n        t = diffusion.sample_timesteps(batch.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(batch, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        t1 = time.time()\n        pbar.set_postfix(\n            {\n                'global_step': global_step,\n                'retrain_iter': retrain_iter,\n                'batch': i,\n                'dt': t1 - t0,\n                'MSE': loss.item()\n            }\n        )\nconsole.print('\\n'.join([f\"{i.shape}\" for i in samples[:100]]))\nsamples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in samples])\nsamples_.shape\n\ntorch.Size([30, 16, 2, 32, 32])\nlen(hmc_samples)\nlen(diffusion_samples)\n\n2\nhmc_samples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in hmc_samples])\ndiffusion_samples_ = torch.stack(\n    [i.reshape(-1, 2, 32, 32) for i in diffusion_samples]\n)\nhmc_samples_.shape\n\ntorch.Size([28, 16, 2, 32, 32])\ndiffusion_samples_.shape\nsamples_.shape\ndef calc_plaqs(x):\n    return torch.stack([\n        exp.trainer.lattice.plaqs(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n\ndef calc_intQ(x):\n    return torch.stack([\n        exp.trainer.lattice.int_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n    \ndef calc_sinQ(x):\n    return torch.stack([\n        exp.trainer.lattice.sin_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\nsamples_init_ = initial_states.reshape(-1, initial_states.shape[1], 2, 32, 32)\nsamples_init_.shape\nmetrics_init_ = {\n    'plaqs': calc_plaqs(samples_init_),\n    'intQ': calc_intQ(samples_init_),\n    'sinQ': calc_sinQ(samples_init_)\n}\n    \nmetrics_ = {\n    'plaqs': calc_plaqs(samples_),\n    'intQ': calc_intQ(samples_),\n    'sinQ': calc_sinQ(samples_)\n}\n\nmetrics_hmc_ = {\n    'plaqs': calc_plaqs(hmc_samples_),\n    'intQ': calc_intQ(hmc_samples_),\n    'sinQ': calc_sinQ(hmc_samples_)\n}\n\nmetrics_diffusion_ = {\n    'plaqs': calc_plaqs(diffusion_samples_),\n    'intQ': calc_intQ(diffusion_samples_),\n    'sinQ': calc_sinQ(diffusion_samples_)\n}\nmetrics_['plaqs'].shape\nconsole.print('\\n'.join([f\"{k}: {v}\" for k, v in watcher.items()]))\nfig, ax = plt.subplots()\n\n_ = ax.plot(metrics_['plaqs'][:, 0], label='Combined')\n_ = ax.plot(metrics_hmc_['plaqs'][:, 0], label='HMC')\n_ = ax.plot(metrics_diffusion_['plaqs'][:, 0], label='Diffusion')\n#_ = ax.plot(metrics_hmc1['plaqs'], label='HMC 1')\n#_ = ax.plot(metrics_diff_['plaqs'], label='Diffusion')\n_ = ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1.00))\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_init_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC (Initial Samples)')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Initial HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Combined')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Combined Samples\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_hmc_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_diffusion_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Diffusion')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated Diffusion States\", y=0.92)\nfrom l2hmc.lattice.u1.pytorch.lattice import plaq_exact\nplaq_exact(torch.tensor(6.0))\nfig, ax = plt.subplots()\n#_ = plt.hist(metrics_['intQ'].flatten(), color='C0', alpha=0.6, label='Combined', edgecolor='none')\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    alpha=0.6,\n    edgecolor='none',\n    label='Diffusion',\n    density=True,\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C1',\n    alpha=0.6,\n    edgecolor='none',\n    label='HMC',\n    density=True,\n)\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666')\n_ = ax.set_xlabel(r\"$Q$\", loc='center')\n_ = ax.set_title('Topological Charge ($Q$) Distribution', loc='center')\nfig, ax = plt.subplots()\n_ = plt.plot(metrics_['plaqs'][:, 0], color='C0', label='Diffusion')\n_ = plt.plot(metrics_hmc_['plaqs'][:, 0], color='C1', label='HMC')\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666', ncols=2)\n_ = ax.set_ylabel(r\"$\\left\\langle U_{\\mu\\nu}\\right\\rangle $\", loc='center')\n_ = ax.set_xlabel(f\"Draw\", loc='center')\nwloops = {\n    'hmc': [\n        exp.trainer.lattice.wilson_loops(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.wilson_loops(i) for i in diffusion_samples_\n    ],\n}\n\nplaqs = {\n    'hmc': [\n        exp.trainer.lattice.plaqs(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.plaqs(i) for i in diffusion_samples_\n    ],\n}\nwlhmc = torch.stack(wloops['hmc']).squeeze()\nwldiff = torch.stack(wloops['diffusion']).squeeze()\nwlhmc.shape\n_ = plt.tight_layout()\nfor idx in range(2):\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(wlhmc[idx, 0])\n    _ = ax[0].set_title(\"HMC\", loc='center')\n    _ = ax[1].imshow(wldiff[idx, 0])\n    _ = ax[1].set_title(\"Diffusion\", loc='center')\n    _ = fig.suptitle(r\"$U_{\\mu\\nu}$\", y=0.8)\n    for ax_ in ax:\n        _ = ax_.set_xticklabels([])\n        _ = ax_.set_yticklabels([])\nqhmc = metrics_hmc_['intQ']\nqdiff = metrics_diffusion_['intQ']\nqhmc.shape\nphmc = torch.stack(plaqs['hmc']).squeeze()\npdiff = torch.stack(plaqs['diffusion']).squeeze()\nphmc.shape\npdiff.shape\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['plaqs'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['plaqs'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['plaqs'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel(r\"$U_{\\mu\\nu}$\", loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Plaquette Distribution', loc='center')\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['intQ'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel('$Q_{\\mathbb{Z}}$', loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Charge Distribution', loc='center')\nglobal_step = 0\nframes = []\nlosses = []\nprint(\"Training model...\")\nfor epoch in range(config[\"num_epochs\"]):\n    model.train()\n    progress_bar = tqdm(total=len(dataloader))\n    progress_bar.set_description(f\"Epoch {epoch}\")\n    for step, batch in enumerate(dataloader):\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n\n        noise = torch.randn(batch.shape)\n        timesteps = torch.randint(\n            0, noise_scheduler.num_timesteps, (batch.shape[0],)\n        ).long()\n\n        #noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n        noisy = noise_scheduler.noise_images(batch, timesteps)\n        noise_pred = model(noisy, timesteps)\n        loss = F.mse_loss(noise_pred, noise)\n        loss.backward(loss)\n\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n\n        progress_bar.update(1)\n        logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n        losses.append(loss.detach().item())\n        progress_bar.set_postfix(**logs)\n        global_step += 1\n    progress_bar.close()\n\n    if epoch % config[\"save_images_step\"] == 0 or epoch == config[\"num_epochs\"] - 1:\n        # generate data with the model to later visualize the learning process\n        model.eval()\n        sample = torch.randn(config[\"eval_batch_size\"], 2)\n        timesteps = list(range(len(noise_scheduler)))[::-1]\n        for i, t in enumerate(tqdm(timesteps)):\n            t = torch.from_numpy(np.repeat(t, config[\"eval_batch_size\"])).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample = noise_scheduler.step(residual, t[0], sample)\n        frames.append(sample.numpy())\ndataset[6]\nlen(dataloader)\neval_batch_size = 10\nnum_timesteps = 50\nplot_step = 5\nnoise_scheduler = ddpm.NoiseScheduler(num_timesteps=num_timesteps)\nsample = torch.randn(eval_batch_size, 2)\ntimesteps = list(range(num_timesteps))[::-1]\nsamples = []\nsteps = []\n\nretrains = 10\ndiffusion_prob = 0.3\nsamples_per_retrain = 100\neval_batch_size = 10\nt = torch.from_numpy(np.repeat(timesteps[0], eval_batch_size)).long()\nwith torch.no_grad():\n    residual = model(sample, t)\nsample_ = noise_scheduler.step(residual, t[0], sample)\nsample.shape\nresidual.shape\nsample_.shape\ndiffusion_samples = []\nhmc_samples = []\nbeta = 1.\nfor retrain_iter in range(retrains):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    for idx in range(samples_per_retrain):\n        console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if rand &lt; diffusion_prob:\n            ndiff_proposed += 1\n            rand_pick = randrange(len(dataloader))\n            #theta_prime = dataset[rand_pick]\n            t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample_ = noise_scheduler.step(residual, t[0], sample)\n            ratio = (\n                log_likelihood_2dU1(sample_, 2)\n                / log_likelihood_2dU1(sample, 2)\n            )\n            a = min(1, ratio)\n            u = np.random.uniform()\n            if u &lt; a:\n                ndiff_acc += 1\n                sample = sample_\n                diffusion_samples.append(sample)\n        else:\n            sample_, metrics = exp.trainer.hmc_step((sample_, beta))\n            hmc_samples.append(sample)\nfor i, t in enumerate(tqdm(timesteps)):\n    t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n    with torch.no_grad():\n        residual = model(sample, t)\n    sample = noise_scheduler.step(residual, t[0], sample)\n    if (i + 1) % plot_step == 0:\n        samples.append(sample.numpy())\n        steps.append(i + 1)\nAlternate\ndiffusion_ = DiffusionAlt(img_size=64, device='cpu')\nimage = torch.rand(1, 2, 64, 64)\nt = diffusion_.sample_timesteps(image.shape[0]).to('cpu')\nunet(image, t)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#denoising-diffusion-probabilistic-models",
    "href": "posts/ai-for-physics/diffusion/index.html#denoising-diffusion-probabilistic-models",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "Denoising Diffusion Probabilistic Models",
    "text": "Denoising Diffusion Probabilistic Models",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#imports--setup",
    "href": "posts/ai-for-physics/diffusion/index.html#imports--setup",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "Imports / Setup",
    "text": "Imports / Setup\n\nfrom __future__ import absolute_import, print_function, annotations, division\nfrom dataclasses import dataclass\n\nimport sys\nimport os\nimport math\nimport numpy as np\nimport scipy\nimport time\nfrom random import randrange\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\nfrom ezpz.dist import setup_torch\n\nport = np.random.randint(5000, 6000)\nprint(f\"Using port: {port}\")\n\nRANK = setup_torch(\n    backend=\"DDP\",\n    port=f\"{port}\"\n)\n\n\nUsing port: 5561\n\nUsing DDP for distributed training\n\nGlobal Rank: 0 / 0\n\n\n\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nimport opinionated\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nfrom pandas.io.formats import style\nimport scipy\nimport time\nfrom random import randrange\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\n\nset_plot_style()\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\n\nUsing device: cpu\nFailed to download font: Source Sans Pro, skipping!\nFailed to download font: Titillium WebRoboto Condensed, skipping!\nTrue\nFalse\n\n\n\nplt.style.use(opinionated.STYLES['opinionated_min'])\nsns.set_context('notebook')",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#2d-u1",
    "href": "posts/ai-for-physics/diffusion/index.html#2d-u1",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "2D U(1)",
    "text": "2D U(1)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#train-diffusion-model",
    "href": "posts/ai-for-physics/diffusion/index.html#train-diffusion-model",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "Train Diffusion Model",
    "text": "Train Diffusion Model",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#build-diffusion-model-with-unet-architecure",
    "href": "posts/ai-for-physics/diffusion/index.html#build-diffusion-model-with-unet-architecure",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "Build Diffusion Model with UNet Architecure",
    "text": "Build Diffusion Model with UNet Architecure",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#hmc-sampling-with-diffusion",
    "href": "posts/ai-for-physics/diffusion/index.html#hmc-sampling-with-diffusion",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "HMC Sampling with Diffusion",
    "text": "HMC Sampling with Diffusion",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/diffusion/index.html#alternate",
    "href": "posts/ai-for-physics/diffusion/index.html#alternate",
    "title": "üé≤ MCMC + Diffusion Sampling",
    "section": "Alternate",
    "text": "Alternate",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé≤ MCMC + Diffusion Sampling"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "",
    "text": "l2hmc: Example\n \nThis notebook will (attempt) to walk through the steps needed to successfully instantiate and ‚Äúrun‚Äù an experiment.\nFor this example, we wish to train the L2HMC sampler for the 2D U(1) lattice gauge model with Wilson action:\n\\begin{equation*}\nS_{\\beta}(n) = \\beta \\sum_{n}\\sum_{\\mu&lt;\\nu}\\mathrm{Re}\\left[1 - U_{\\mu\\nu}(n) \\right]\n\\end{equation*}\nThis consists of the following steps:\n\nBuild an Experiment by parsing our configuration object\nTrain our model using the Experiment.train() method\nEvaluate our trained model Experiment.evaluate(job_type='eval')\nCompare our trained models‚Äô performance against generic HMC Experiment.evaluate(job_type='hmc')\n\n\nEvaluating Performance\nExplicitly, we measure the performance of our model by comparing the tunneling rate \\delta Q of our trained sampler to that of generic HMC.\nExplicitly, the tunneling rate is given by:\n\n\\delta Q = \\frac{1}{N_{\\mathrm{chains}}}\\sum_{\\mathrm{chains}} \\left|Q_{i+1} - Q_{i}\\right|\n\nwhere the difference is between subsequent states in a chain, and the sum is over all N chains (each being ran in parallel, independently).\nSince our goal is to generate independent configurations, the more our sampler tunnels between different topological sectors (tunneling rate), the more efficient our sampler.\nImports / Setup\n! nvidia-smi | tail --lines -7\n# automatically detect and reload local changes to modules\n%load_ext autoreload\n%autoreload 2\n%matplotlib widget\n\nimport os\nimport warnings\n\nos.environ['COLORTERM'] = 'truecolor'\n\nwarnings.filterwarnings('ignore')\n# --------------------------------------\n# BE SURE TO GRAB A FRESH GPU !\nos.environ['CUDA_VISIBLE_DEVICES'] = '2'\n!echo $CUDA_VISIBLE_DEVICES\n# --------------------------------------\n\n2\ndevices = os.environ.get('CUDA_VISIBLE_DEVICES', None)\nprint(devices)\n!getconf _NPROCESSORS_ONLN  # get number of availble CPUs\n\n2\n256\nos.environ['TORCH_CPP_LOG_LEVEL'] = 'ERROR'\nos.environ['AUTOGRAPH_VERBOSITY'] = '10'\n!echo $CUDA_VISIBLE_DEVICES\n\n2\nfrom __future__ import absolute_import, print_function, annotations, division\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import set_matplotlib_formats\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nset_plot_style()\nplt.rcParams['grid.alpha'] = 0.8\nplt.rcParams['grid.color'] = '#404040'\nsns.set(rc={\"figure.dpi\":100, 'savefig.dpi':300})\nsns.set_context('notebook')\nsns.set_style(\"ticks\")\nset_matplotlib_formats('retina')\nplt.rcParams['figure.figsize'] = [12.4, 4.8]\n\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\n--------------------------------------------------------------------------\nWARNING: There was an error initializing an OpenFabrics device.\n\n  Local host:   thetagpu23\n  Local device: mlx5_0\n--------------------------------------------------------------------------\n\n\nTrue\n\n\nFalse\nimport l2hmc\nl2hmc.__file__\n\n'/lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/__init__.py'\nInitialize and Build Experiment objects:\n\nThe l2hmc.main module provides a function build_experiment:\n\ndef build_experiment(overrides: list[str]) -&gt; tfExperiment | ptExperiment:\n    ...\nwhich will:\n\nLoad the default options from conf/config.yaml\nOverride the default options with any values provided in overrides\nParse these options and build an ExperimentConfig which uniquely defines an experiment\nInstantiate / return an Experiment from the ExperimentConfig. Depending on framework=pytorch|tensorflow: a. framework=pytorch -&gt; l2hmc.experiment.pytorch.Experiment b. framework=tensorflow -&gt; l2hmc.experiment.tensorflow.Experiment\n\n&gt;&gt;&gt; train_output = experiment.train()\n&gt;&gt;&gt; eval_output = experiment.evaluate(job_type='eval')\n&gt;&gt;&gt; hmc_output = experiment.evaluate(job_type='hmc')\n\nOverriding Defaults\nSpecifics about the training / evaluation / hmc runs can be flexibly overridden by passing arguments to the training / evaluation / hmc runs, respectively\nimport numpy as np\n\n#seed = np.random.randint(100000)\nseed=76043\n\nDEFAULTS = {\n    'seed': f'{seed}',\n    'precision': 'fp16',\n    'init_aim': False,\n    'init_wandb': False,\n    'use_wandb': False,\n    'restore': False,\n    'save': False,\n    'use_tb': False,\n    'dynamics': {\n        'nleapfrog': 10,\n        'nchains': 4096,\n        'eps': 0.05,\n    },\n    'conv': 'none',\n    'steps': {\n        'log': 20,\n        'print': 250,\n        'nepoch': 5000,\n        'nera': 1,\n    },\n    'annealing_schedule': {\n        'beta_init': 4.0,\n        'beta_final': 4.0,\n    },\n    #'learning_rate': {\n    #    #'lr_init': 0.0005,\n    #    #'clip_norm': 10.0,\n    #},\n}\n\noutputs = {\n    'pytorch': {\n        'train': {},\n        'eval': {},\n        'hmc': {},\n    },\n    'tensorflow': {\n        'train': {},\n        'eval': {},\n        'hmc': {},\n    },\n}\nfrom l2hmc.configs import dict_to_list_of_overrides\nOVERRIDES = dict_to_list_of_overrides(DEFAULTS)\nOVERRIDES\n\n['seed=76043',\n 'precision=fp16',\n 'init_aim=False',\n 'init_wandb=False',\n 'use_wandb=False',\n 'restore=False',\n 'save=False',\n 'use_tb=False',\n 'dynamics.nleapfrog=10',\n 'dynamics.nchains=4096',\n 'dynamics.eps=0.05',\n 'conv=none',\n 'steps.log=20',\n 'steps.print=250',\n 'steps.nepoch=5000',\n 'steps.nera=1',\n 'annealing_schedule.beta_init=4.0',\n 'annealing_schedule.beta_final=4.0']\n# Build PyTorch Experiment\nptExpU1 = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=pytorch',\n        'backend=DDP',\n    ]\n)\n\n[06/23/23 12:57:55][INFO][dist.py:338] - Global Rank: 0 / 0\n\n\n2023-06-23 12:57:58.015160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n[06/23/23 12:58:15][INFO][dist.py:226] - Caught MASTER_PORT:2345 from environment!\n[06/23/23 12:58:15][INFO][dist.py:226] - Caught MASTER_PORT:2345 from environment!\n[06/23/23 12:58:15][WARNING][trainer.py:435] - Using torch.float16 on cuda!\n[06/23/23 12:58:17][WARNING][trainer.py:435] - Using `torch.optim.Adam` optimizer\n[06/23/23 12:58:17][INFO][trainer.py:283] - num_params in model: 1486740\n[06/23/23 12:58:17][WARNING][trainer.py:250] - logging with freq 20 for wandb.watch\n# Build TensorFlow Experiment\nimport tensorflow as tf\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\ntfExpU1 = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=tensorflow',\n        'backend=horovod',\n    ]\n)\n\nINFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\nYour GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-80GB, compute capability 8.0\n[06/23/23 12:58:18][INFO][dist.py:82] - 1, Physical GPUs and 1 Logical GPUs\n[06/23/23 12:58:18][WARNING][dist.py:108] - Using: float32 precision\n[06/23/23 12:58:18][INFO][dist.py:109] - RANK: 0, LOCAL_RANK: 0\nPyTorch\nTraining\noutputs['pytorch']['train'] = ptExpU1.trainer.train()\n    #nera=5,\n    #nepoch=2000,\n    #beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n#)\n\n_ = ptExpU1.save_dataset(job_type='train', nchains=32)\n\n\n\n\n[06/23/23 12:58:19][INFO][trainer.py:439] - [TRAINING] x.dtype: torch.float32\n[06/23/23 12:58:19][INFO][trainer.py:439] - [TRAINING] self._dtype: torch.float16\n[06/23/23 12:58:19][INFO][trainer.py:107] - ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n[06/23/23 12:58:19][INFO][trainer.py:108] - ‚îÉ ERA: 0 / 1, BETA: 4.000 ‚îÉ\n[06/23/23 12:58:19][INFO][trainer.py:109] - ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n[06/23/23 12:58:24][INFO][trainer.py:439] - Thermalizing configs @ 4.00 took 4.7326 s\n[06/23/23 12:58:25][INFO][trainer.py:1722] - era=0 epoch=0 tstep=1 dt=0.781 beta=4.000 loss=59.439 dQsin=0.016 dQint=0.005 energy=398.887 logprob=398.650 logdet=0.237 sldf=0.143 sldb=-0.117 sld=0.237 xeps=0.050 veps=0.050 acc=0.057 sumlogdet=0.003 acc_mask=0.057 plaqs=0.864 intQ=0.009 sinQ=0.006 lr=0.001\n[06/23/23 13:00:59][INFO][trainer.py:1722] - era=0 epoch=240 tstep=241 dt=0.600 beta=4.000 loss=-4.980 dQsin=0.212 dQint=0.069 energy=396.331 logprob=395.966 logdet=0.365 sldf=0.199 sldb=-0.146 sld=0.365 xeps=0.044 veps=0.043 acc=0.781 sumlogdet=-0.003 acc_mask=0.777 plaqs=0.864 intQ=-0.012 sinQ=-0.012 lr=0.001\n[06/23/23 13:03:34][INFO][trainer.py:1722] - era=0 epoch=500 tstep=501 dt=0.599 beta=4.000 loss=-7.162 dQsin=0.239 dQint=0.084 energy=396.375 logprob=395.945 logdet=0.431 sldf=0.234 sldb=-0.186 sld=0.431 xeps=0.051 veps=0.050 acc=0.846 sumlogdet=0.002 acc_mask=0.851 plaqs=0.864 intQ=0.053 sinQ=0.049 lr=0.001\n[06/23/23 13:06:07][INFO][trainer.py:1722] - era=0 epoch=740 tstep=741 dt=0.591 beta=4.000 loss=-8.272 dQsin=0.253 dQint=0.095 energy=396.330 logprob=395.886 logdet=0.444 sldf=0.243 sldb=-0.216 sld=0.444 xeps=0.052 veps=0.051 acc=0.872 sumlogdet=0.001 acc_mask=0.882 plaqs=0.864 intQ=0.013 sinQ=0.015 lr=0.001\n[06/23/23 13:08:39][INFO][trainer.py:1722] - era=0 epoch=1000 tstep=1001 dt=0.594 beta=4.000 loss=-8.689 dQsin=0.246 dQint=0.092 energy=396.763 logprob=396.257 logdet=0.505 sldf=0.277 sldb=-0.258 sld=0.505 xeps=0.058 veps=0.056 acc=0.865 sumlogdet=0.002 acc_mask=0.861 plaqs=0.863 intQ=-0.037 sinQ=-0.038 lr=0.001\n[06/23/23 13:11:12][INFO][trainer.py:1722] - era=0 epoch=1240 tstep=1241 dt=0.607 beta=4.000 loss=-8.190 dQsin=0.242 dQint=0.101 energy=396.304 logprob=395.726 logdet=0.578 sldf=0.316 sldb=-0.282 sld=0.578 xeps=0.065 veps=0.063 acc=0.840 sumlogdet=0.001 acc_mask=0.846 plaqs=0.864 intQ=-0.040 sinQ=-0.035 lr=0.001\n[06/23/23 13:13:44][INFO][trainer.py:1722] - era=0 epoch=1500 tstep=1501 dt=0.592 beta=4.000 loss=-9.732 dQsin=0.238 dQint=0.121 energy=397.387 logprob=396.435 logdet=0.952 sldf=0.519 sldb=-0.430 sld=0.952 xeps=0.083 veps=0.078 acc=0.752 sumlogdet=0.002 acc_mask=0.748 plaqs=0.863 intQ=0.039 sinQ=0.035 lr=0.001\n[06/23/23 13:16:17][INFO][trainer.py:1722] - era=0 epoch=1740 tstep=1741 dt=0.592 beta=4.000 loss=-10.209 dQsin=0.235 dQint=0.134 energy=397.590 logprob=396.320 logdet=1.271 sldf=0.692 sldb=-0.577 sld=1.271 xeps=0.094 veps=0.087 acc=0.725 sumlogdet=0.007 acc_mask=0.723 plaqs=0.864 intQ=0.005 sinQ=0.008 lr=0.001\n[06/23/23 13:18:52][INFO][trainer.py:1722] - era=0 epoch=2000 tstep=2001 dt=0.599 beta=4.000 loss=-12.075 dQsin=0.234 dQint=0.149 energy=399.553 logprob=397.752 logdet=1.800 sldf=0.980 sldb=-0.801 sld=1.800 xeps=0.106 veps=0.094 acc=0.638 sumlogdet=0.005 acc_mask=0.633 plaqs=0.863 intQ=0.013 sinQ=0.007 lr=0.001\n[06/23/23 13:21:25][INFO][trainer.py:1722] - era=0 epoch=2240 tstep=2241 dt=0.592 beta=4.000 loss=-13.515 dQsin=0.239 dQint=0.162 energy=399.697 logprob=397.477 logdet=2.220 sldf=1.209 sldb=-0.991 sld=2.220 xeps=0.114 veps=0.099 acc=0.616 sumlogdet=0.007 acc_mask=0.618 plaqs=0.863 intQ=0.005 sinQ=0.004 lr=0.001\n[06/23/23 13:23:58][INFO][trainer.py:1722] - era=0 epoch=2500 tstep=2501 dt=0.591 beta=4.000 loss=-11.498 dQsin=0.216 dQint=0.155 energy=400.518 logprob=397.818 logdet=2.700 sldf=1.470 sldb=-1.218 sld=2.700 xeps=0.125 veps=0.104 acc=0.538 sumlogdet=0.010 acc_mask=0.541 plaqs=0.863 intQ=-0.033 sinQ=-0.027 lr=0.001\n[06/23/23 13:26:30][INFO][trainer.py:1722] - era=0 epoch=2740 tstep=2741 dt=0.591 beta=4.000 loss=-13.669 dQsin=0.239 dQint=0.178 energy=400.852 logprob=397.768 logdet=3.084 sldf=1.679 sldb=-1.381 sld=3.084 xeps=0.132 veps=0.112 acc=0.586 sumlogdet=0.012 acc_mask=0.589 plaqs=0.864 intQ=0.052 sinQ=0.040 lr=0.001\n[06/23/23 13:29:03][INFO][trainer.py:1722] - era=0 epoch=3000 tstep=3001 dt=0.825 beta=4.000 loss=-13.659 dQsin=0.229 dQint=0.175 energy=402.199 logprob=398.541 logdet=3.658 sldf=1.994 sldb=-1.676 sld=3.658 xeps=0.142 veps=0.118 acc=0.541 sumlogdet=0.008 acc_mask=0.545 plaqs=0.863 intQ=-0.034 sinQ=-0.035 lr=0.001\n[06/23/23 13:31:36][INFO][trainer.py:1722] - era=0 epoch=3240 tstep=3241 dt=0.593 beta=4.000 loss=-14.593 dQsin=0.232 dQint=0.182 energy=403.727 logprob=399.641 logdet=4.087 sldf=2.232 sldb=-1.965 sld=4.087 xeps=0.151 veps=0.121 acc=0.489 sumlogdet=0.012 acc_mask=0.498 plaqs=0.863 intQ=-0.009 sinQ=-0.012 lr=0.001\n[06/23/23 13:34:09][INFO][trainer.py:1722] - era=0 epoch=3500 tstep=3501 dt=0.600 beta=4.000 loss=-10.267 dQsin=0.202 dQint=0.161 energy=404.429 logprob=399.713 logdet=4.716 sldf=2.575 sldb=-2.237 sld=4.716 xeps=0.152 veps=0.130 acc=0.432 sumlogdet=0.010 acc_mask=0.451 plaqs=0.863 intQ=-0.003 sinQ=-0.003 lr=0.001\n[06/23/23 13:36:44][INFO][trainer.py:1722] - era=0 epoch=3740 tstep=3741 dt=0.602 beta=4.000 loss=-16.740 dQsin=0.239 dQint=0.202 energy=404.274 logprob=399.215 logdet=5.059 sldf=2.765 sldb=-2.461 sld=5.059 xeps=0.163 veps=0.133 acc=0.503 sumlogdet=0.013 acc_mask=0.507 plaqs=0.863 intQ=-0.027 sinQ=-0.024 lr=0.001\n[06/23/23 13:39:19][INFO][trainer.py:1722] - era=0 epoch=4000 tstep=4001 dt=0.602 beta=4.000 loss=-17.072 dQsin=0.242 dQint=0.215 energy=405.285 logprob=399.736 logdet=5.549 sldf=3.037 sldb=-2.781 sld=5.549 xeps=0.171 veps=0.135 acc=0.460 sumlogdet=0.012 acc_mask=0.464 plaqs=0.864 intQ=0.013 sinQ=0.013 lr=0.001\n[06/23/23 13:41:53][INFO][trainer.py:1722] - era=0 epoch=4240 tstep=4241 dt=0.600 beta=4.000 loss=-18.798 dQsin=0.236 dQint=0.218 energy=406.449 logprob=400.293 logdet=6.156 sldf=3.370 sldb=-3.104 sld=6.156 xeps=0.179 veps=0.137 acc=0.455 sumlogdet=0.011 acc_mask=0.451 plaqs=0.864 intQ=0.009 sinQ=0.007 lr=0.001\n[06/23/23 13:44:28][INFO][trainer.py:1722] - era=0 epoch=4500 tstep=4501 dt=0.598 beta=4.000 loss=-18.046 dQsin=0.242 dQint=0.215 energy=406.391 logprob=400.047 logdet=6.343 sldf=3.476 sldb=-3.278 sld=6.343 xeps=0.183 veps=0.144 acc=0.463 sumlogdet=0.011 acc_mask=0.465 plaqs=0.864 intQ=-0.019 sinQ=-0.016 lr=0.001\n[06/23/23 13:47:02][INFO][trainer.py:1722] - era=0 epoch=4740 tstep=4741 dt=0.601 beta=4.000 loss=-16.357 dQsin=0.230 dQint=0.206 energy=407.460 logprob=400.501 logdet=6.958 sldf=3.815 sldb=-3.604 sld=6.958 xeps=0.188 veps=0.147 acc=0.423 sumlogdet=0.010 acc_mask=0.426 plaqs=0.864 intQ=0.023 sinQ=0.022 lr=0.001\n[06/23/23 13:49:51][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 13:49:56][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 13:50:00][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 13:50:05][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 13:50:09][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 13:50:13][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 13:50:56][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/train_data.h5\n[06/23/23 13:51:06][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 13:51:06][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nInference\nEvaluation\noutputs['pytorch']['eval'] = ptExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = ptExpU1.save_dataset(job_type='eval', nchains=32)\n\n[06/23/23 13:52:42][WARNING][trainer.py:435] - x.shape (original): torch.Size([4096, 2, 16, 16])\n[06/23/23 13:52:42][WARNING][trainer.py:435] - x[:nchains].shape: torch.Size([128, 2, 16, 16])\n[06/23/23 13:52:42][INFO][trainer.py:1051] - eps=None\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7f2722bfbdf0&gt;\nnprint=500\neval_steps=2000\nnleapfrog=None\n\n\n\n\n\n[06/23/23 13:52:46][INFO][trainer.py:1181] - estep=0 dt=0.278 beta=4.000 loss=-26.568 dQsin=0.310 dQint=0.328 energy=412.448 logprob=405.216 logdet=7.232 sldf=3.974 sldb=-3.865 sld=7.232 xeps=0.193 veps=0.148 acc=0.484 sumlogdet=0.003 acc_mask=0.508 plaqs=0.863 intQ=-0.086 sinQ=-0.055\n[06/23/23 13:54:55][INFO][trainer.py:1181] - estep=500 dt=0.226 beta=4.000 loss=-23.825 dQsin=0.266 dQint=0.227 energy=407.989 logprob=400.742 logdet=7.247 sldf=3.976 sldb=-3.845 sld=7.247 xeps=0.193 veps=0.148 acc=0.470 sumlogdet=0.029 acc_mask=0.492 plaqs=0.862 intQ=-0.164 sinQ=-0.105\n[06/23/23 13:57:02][INFO][trainer.py:1181] - estep=1000 dt=0.228 beta=4.000 loss=-23.745 dQsin=0.270 dQint=0.250 energy=410.211 logprob=402.944 logdet=7.266 sldf=3.987 sldb=-3.842 sld=7.266 xeps=0.193 veps=0.148 acc=0.456 sumlogdet=0.011 acc_mask=0.461 plaqs=0.863 intQ=-0.023 sinQ=-0.042\n[06/23/23 13:59:11][INFO][trainer.py:1181] - estep=1500 dt=0.230 beta=4.000 loss=-18.855 dQsin=0.285 dQint=0.227 energy=408.605 logprob=401.337 logdet=7.267 sldf=3.984 sldb=-3.841 sld=7.267 xeps=0.193 veps=0.148 acc=0.432 sumlogdet=0.019 acc_mask=0.508 plaqs=0.863 intQ=0.125 sinQ=0.103\n[06/23/23 14:01:28][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:01:32][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:01:37][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:01:41][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:01:45][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:01:50][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:02:02][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/eval_data.h5\n[06/23/23 14:02:03][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:02:03][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nHMC\noutputs['pytorch']['hmc'] = ptExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = ptExpU1.save_dataset(job_type='hmc', nchains=32)\n\n[06/23/23 14:02:13][WARNING][trainer.py:435] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[06/23/23 14:02:13][WARNING][trainer.py:435] - x.shape (original): torch.Size([4096, 2, 16, 16])\n[06/23/23 14:02:13][WARNING][trainer.py:435] - x[:nchains].shape: torch.Size([128, 2, 16, 16])\n[06/23/23 14:02:13][INFO][trainer.py:1051] - eps=0.1\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7f266407a500&gt;\nnprint=500\neval_steps=2000\nnleapfrog=20\n\n\n\n\n\n[06/23/23 14:02:17][INFO][trainer.py:1181] - hstep=0 dt=0.034 beta=4.000 loss=-11.965 dQsin=0.256 dQint=0.172 energy=395.464 logprob=395.464 logdet=0.000 acc=0.762 sumlogdet=0.000 acc_mask=0.734 plaqs=0.864 intQ=0.203 sinQ=0.148\n[06/23/23 14:02:47][INFO][trainer.py:1181] - hstep=500 dt=0.035 beta=4.000 loss=-15.159 dQsin=0.263 dQint=0.156 energy=395.520 logprob=395.520 logdet=0.000 acc=0.771 sumlogdet=0.000 acc_mask=0.734 plaqs=0.864 intQ=-0.078 sinQ=-0.086\n[06/23/23 14:03:20][INFO][trainer.py:1181] - hstep=1000 dt=0.035 beta=4.000 loss=-17.856 dQsin=0.307 dQint=0.156 energy=395.126 logprob=395.126 logdet=0.000 acc=0.832 sumlogdet=0.000 acc_mask=0.859 plaqs=0.864 intQ=0.125 sinQ=0.102\n[06/23/23 14:03:52][INFO][trainer.py:1181] - hstep=1500 dt=0.035 beta=4.000 loss=-9.512 dQsin=0.242 dQint=0.055 energy=397.486 logprob=397.486 logdet=0.000 acc=0.791 sumlogdet=0.000 acc_mask=0.812 plaqs=0.863 intQ=-0.148 sinQ=-0.106\n[06/23/23 14:04:26][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:04:32][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:04:36][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:04:46][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/hmc_data.h5\n[06/23/23 14:04:46][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:04:46][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nTensorFlow\nTrain\noutputs['tensorflow']['train'] = tfExpU1.trainer.train()\n#    nera=5,\n#    nepoch=2000,\n#    beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n#)\n_ = tfExpU1.save_dataset(job_type='train', nchains=32)\n\n[06/23/23 14:05:07][INFO][trainer.py:200] - Looking for checkpoints in: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-10/xsplit-True/sepnets-True/merge-True/net-16-16-16_dp-0.2_bn-False/tensorflow\n[06/23/23 14:05:07][INFO][trainer.py:200] - No checkpoints found to load from. Continuing\n\n\n\n\n\n[06/23/23 14:05:07][INFO][trainer.py:1266] - ERA: 0 / 1, BETA: 4.000\n[06/23/23 14:06:32][INFO][trainer.py:200] - Thermalizing configs @ 4.00 took 85.1316 s\n\n\n{\"model_id\":\"3ce8a6d5ef17444abb0644b54156bbcf\",\"version_major\":2,\"version_minor\":0}\n\n\nWARNING:tensorflow:From /lus/grand/projects/datascience/foremans/locations/thetaGPU/miniconda3/envs/2023-04-26/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\nInstructions for updating:\nLambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n[06/23/23 14:08:07][INFO][trainer.py:1089] - era=0 epoch=0 tstep=1.000 dt=93.926 beta=4.000 loss=97.795 dQsin=0.001 dQint=0.001 energy=1281.699 logprob=1281.654 logdet=0.046 sldf=0.060 sldb=0.094 sld=0.046 xeps=0.050 veps=0.050 acc=0.001 sumlogdet=-0.001 acc_mask=0.001 plaqs=0.021 intQ=-0.042 sinQ=0.020 lr=0.001\n[06/23/23 14:09:11][INFO][trainer.py:1089] - era=0 epoch=240 tstep=241.000 dt=0.239 beta=4.000 loss=-0.984 dQsin=0.153 dQint=0.055 energy=395.706 logprob=396.037 logdet=-0.332 sldf=-0.175 sldb=0.045 sld=-0.332 xeps=0.048 veps=0.044 acc=0.550 sumlogdet=0.004 acc_mask=0.555 plaqs=0.864 intQ=0.010 sinQ=0.003 lr=0.001\n[06/23/23 14:10:15][INFO][trainer.py:1089] - era=0 epoch=500 tstep=501.000 dt=0.241 beta=4.000 loss=-4.051 dQsin=0.190 dQint=0.064 energy=394.337 logprob=395.721 logdet=-1.383 sldf=-0.746 sldb=0.488 sld=-1.383 xeps=0.047 veps=0.043 acc=0.709 sumlogdet=-0.025 acc_mask=0.708 plaqs=0.864 intQ=-0.025 sinQ=-0.025 lr=0.001\n[06/23/23 14:11:22][INFO][trainer.py:1089] - era=0 epoch=740 tstep=741.000 dt=0.236 beta=4.000 loss=-6.052 dQsin=0.206 dQint=0.072 energy=394.177 logprob=395.854 logdet=-1.677 sldf=-0.908 sldb=0.629 sld=-1.677 xeps=0.048 veps=0.043 acc=0.759 sumlogdet=-0.001 acc_mask=0.754 plaqs=0.864 intQ=0.006 sinQ=0.003 lr=0.001\n[06/23/23 14:12:27][INFO][trainer.py:1089] - era=0 epoch=1000 tstep=1001.000 dt=0.244 beta=4.000 loss=-6.203 dQsin=0.221 dQint=0.075 energy=394.858 logprob=396.599 logdet=-1.742 sldf=-0.942 sldb=0.653 sld=-1.742 xeps=0.049 veps=0.045 acc=0.811 sumlogdet=-0.011 acc_mask=0.812 plaqs=0.863 intQ=0.029 sinQ=0.026 lr=0.001\n[06/23/23 14:13:32][INFO][trainer.py:1089] - era=0 epoch=1240 tstep=1241.000 dt=0.234 beta=4.000 loss=-7.401 dQsin=0.235 dQint=0.084 energy=394.913 logprob=396.405 logdet=-1.493 sldf=-0.809 sldb=0.544 sld=-1.493 xeps=0.050 veps=0.046 acc=0.833 sumlogdet=0.004 acc_mask=0.831 plaqs=0.863 intQ=0.023 sinQ=0.021 lr=0.001\n[06/23/23 14:14:40][INFO][trainer.py:1089] - era=0 epoch=1500 tstep=1501.000 dt=0.241 beta=4.000 loss=-7.387 dQsin=0.239 dQint=0.089 energy=394.786 logprob=395.871 logdet=-1.084 sldf=-0.586 sldb=0.393 sld=-1.084 xeps=0.051 veps=0.047 acc=0.854 sumlogdet=-0.001 acc_mask=0.854 plaqs=0.864 intQ=-0.008 sinQ=-0.012 lr=0.001\n[06/23/23 14:15:46][INFO][trainer.py:1089] - era=0 epoch=1740 tstep=1741.000 dt=0.276 beta=4.000 loss=-8.684 dQsin=0.250 dQint=0.086 energy=394.998 logprob=395.804 logdet=-0.806 sldf=-0.438 sldb=0.318 sld=-0.806 xeps=0.053 veps=0.049 acc=0.878 sumlogdet=0.001 acc_mask=0.873 plaqs=0.864 intQ=0.036 sinQ=0.023 lr=0.001\n[06/23/23 14:16:52][INFO][trainer.py:1089] - era=0 epoch=2000 tstep=2001.000 dt=0.280 beta=4.000 loss=-8.376 dQsin=0.255 dQint=0.095 energy=394.788 logprob=395.364 logdet=-0.576 sldf=-0.314 sldb=0.244 sld=-0.576 xeps=0.054 veps=0.050 acc=0.896 sumlogdet=0.002 acc_mask=0.897 plaqs=0.863 intQ=-0.023 sinQ=-0.021 lr=0.001\n[06/23/23 14:17:56][INFO][trainer.py:1089] - era=0 epoch=2240 tstep=2241.000 dt=0.238 beta=4.000 loss=-9.100 dQsin=0.258 dQint=0.106 energy=395.875 logprob=396.324 logdet=-0.449 sldf=-0.245 sldb=0.219 sld=-0.449 xeps=0.059 veps=0.054 acc=0.904 sumlogdet=-0.002 acc_mask=0.902 plaqs=0.863 intQ=0.029 sinQ=0.027 lr=0.001\n[06/23/23 14:19:00][INFO][trainer.py:1089] - era=0 epoch=2500 tstep=2501.000 dt=0.244 beta=4.000 loss=-9.489 dQsin=0.247 dQint=0.103 energy=395.602 logprob=395.899 logdet=-0.297 sldf=-0.165 sldb=0.195 sld=-0.297 xeps=0.064 veps=0.058 acc=0.876 sumlogdet=0.001 acc_mask=0.864 plaqs=0.864 intQ=0.028 sinQ=0.024 lr=0.001\n[06/23/23 14:20:04][INFO][trainer.py:1089] - era=0 epoch=2740 tstep=2741.000 dt=0.251 beta=4.000 loss=-9.468 dQsin=0.250 dQint=0.107 energy=395.899 logprob=396.116 logdet=-0.217 sldf=-0.122 sldb=0.183 sld=-0.217 xeps=0.072 veps=0.065 acc=0.857 sumlogdet=0.001 acc_mask=0.854 plaqs=0.863 intQ=-0.045 sinQ=-0.034 lr=0.001\n[06/23/23 14:21:08][INFO][trainer.py:1089] - era=0 epoch=3000 tstep=3001.000 dt=0.236 beta=4.000 loss=-10.554 dQsin=0.248 dQint=0.132 energy=395.727 logprob=395.661 logdet=0.065 sldf=0.030 sldb=0.088 sld=0.065 xeps=0.084 veps=0.071 acc=0.782 sumlogdet=0.002 acc_mask=0.781 plaqs=0.864 intQ=0.024 sinQ=0.015 lr=0.001\n[06/23/23 14:22:12][INFO][trainer.py:1089] - era=0 epoch=3240 tstep=3241.000 dt=0.253 beta=4.000 loss=-10.425 dQsin=0.252 dQint=0.141 energy=396.195 logprob=396.024 logdet=0.171 sldf=0.086 sldb=0.076 sld=0.171 xeps=0.094 veps=0.080 acc=0.790 sumlogdet=0.002 acc_mask=0.795 plaqs=0.864 intQ=-0.002 sinQ=-0.000 lr=0.001\n[06/23/23 14:23:17][INFO][trainer.py:1089] - era=0 epoch=3500 tstep=3501.000 dt=0.271 beta=4.000 loss=-13.095 dQsin=0.254 dQint=0.161 energy=396.836 logprob=396.210 logdet=0.627 sldf=0.335 sldb=-0.134 sld=0.627 xeps=0.109 veps=0.089 acc=0.709 sumlogdet=0.002 acc_mask=0.708 plaqs=0.864 intQ=0.045 sinQ=0.043 lr=0.001\n[06/23/23 14:24:22][INFO][trainer.py:1089] - era=0 epoch=3740 tstep=3741.000 dt=0.242 beta=4.000 loss=-13.164 dQsin=0.226 dQint=0.160 energy=399.160 logprob=397.731 logdet=1.429 sldf=0.772 sldb=-0.496 sld=1.429 xeps=0.123 veps=0.093 acc=0.585 sumlogdet=-0.003 acc_mask=0.574 plaqs=0.864 intQ=0.002 sinQ=-0.000 lr=0.001\n[06/23/23 14:25:27][INFO][trainer.py:1089] - era=0 epoch=4000 tstep=4001.000 dt=0.254 beta=4.000 loss=-15.590 dQsin=0.251 dQint=0.197 energy=399.077 logprob=397.221 logdet=1.856 sldf=1.005 sldb=-0.672 sld=1.856 xeps=0.138 veps=0.104 acc=0.600 sumlogdet=-0.006 acc_mask=0.601 plaqs=0.863 intQ=-0.021 sinQ=-0.013 lr=0.001\n[06/23/23 14:26:31][INFO][trainer.py:1089] - era=0 epoch=4240 tstep=4241.000 dt=0.244 beta=4.000 loss=-14.301 dQsin=0.232 dQint=0.177 energy=401.006 logprob=398.483 logdet=2.523 sldf=1.369 sldb=-1.005 sld=2.523 xeps=0.150 veps=0.109 acc=0.538 sumlogdet=0.006 acc_mask=0.539 plaqs=0.864 intQ=0.018 sinQ=0.008 lr=0.001\n[06/23/23 14:27:38][INFO][trainer.py:1089] - era=0 epoch=4500 tstep=4501.000 dt=0.245 beta=4.000 loss=-14.125 dQsin=0.209 dQint=0.183 energy=403.764 logprob=400.618 logdet=3.145 sldf=1.714 sldb=-1.357 sld=3.145 xeps=0.166 veps=0.109 acc=0.411 sumlogdet=-0.002 acc_mask=0.407 plaqs=0.863 intQ=0.014 sinQ=0.017 lr=0.001\n[06/23/23 14:28:43][INFO][trainer.py:1089] - era=0 epoch=4740 tstep=4741.000 dt=0.241 beta=4.000 loss=-21.004 dQsin=0.266 dQint=0.235 energy=402.266 logprob=399.061 logdet=3.205 sldf=1.750 sldb=-1.493 sld=3.205 xeps=0.172 veps=0.121 acc=0.536 sumlogdet=0.002 acc_mask=0.539 plaqs=0.863 intQ=-0.024 sinQ=-0.016 lr=0.001\n[06/23/23 14:29:47][INFO][trainer.py:1303] - Saving took: 3.12328e-05s\n[06/23/23 14:29:47][INFO][trainer.py:1304] - Checkpoint saved to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-10/xsplit-True/sepnets-True/merge-True/net-16-16-16_dp-0.2_bn-False/tensorflow\n[06/23/23 14:29:47][INFO][trainer.py:1305] - Era 0 took: 1480.06s\n[06/23/23 14:29:52][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:29:58][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:30:03][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:30:08][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:30:13][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:30:18][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:31:02][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/train_data.h5\n[06/23/23 14:31:12][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:31:12][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nInference\nEvaluate\noutputs['tensorflow']['eval'] = tfExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = tfExpU1.save_dataset(job_type='eval', nchains=32)\n\n[06/23/23 14:31:23][WARNING][trainer.py:196] - x.shape (original): (4096, 2, 16, 16)\n[06/23/23 14:31:23][WARNING][trainer.py:196] - x[:nchains].shape: (128, 2, 16, 16)\n[06/23/23 14:31:23][INFO][trainer.py:200] - eps = None\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7f26042c9e70&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = None\n\n\n\n\n\n{\"model_id\":\"42d6b6d371eb4dbca473bb047e79f408\",\"version_major\":2,\"version_minor\":0}\n\n\n[06/23/23 14:33:00][INFO][trainer.py:200] - estep=0 dt=13.921 beta=4.000 loss=-34.934 dQsin=0.296 dQint=0.242 energy=402.696 logprob=398.796 logdet=3.900 sldf=2.138 sldb=-1.896 sld=3.900 xeps=0.183 veps=0.124 acc=0.472 sumlogdet=0.008 acc_mask=0.469 plaqs=0.865 intQ=0.094 sinQ=0.060\n[06/23/23 14:33:49][INFO][trainer.py:200] - estep=500 dt=0.049 beta=4.000 loss=-14.736 dQsin=0.258 dQint=0.203 energy=404.299 logprob=400.366 logdet=3.932 sldf=2.151 sldb=-1.896 sld=3.932 xeps=0.183 veps=0.124 acc=0.456 sumlogdet=-0.009 acc_mask=0.500 plaqs=0.862 intQ=-0.211 sinQ=-0.169\n[06/23/23 14:34:27][INFO][trainer.py:200] - estep=1000 dt=0.048 beta=4.000 loss=-14.039 dQsin=0.233 dQint=0.211 energy=403.103 logprob=399.185 logdet=3.917 sldf=2.142 sldb=-1.890 sld=3.917 xeps=0.183 veps=0.124 acc=0.477 sumlogdet=0.034 acc_mask=0.477 plaqs=0.864 intQ=0.070 sinQ=0.055\n[06/23/23 14:35:05][INFO][trainer.py:200] - estep=1500 dt=0.048 beta=4.000 loss=-19.743 dQsin=0.225 dQint=0.203 energy=402.832 logprob=398.931 logdet=3.901 sldf=2.136 sldb=-1.895 sld=3.901 xeps=0.183 veps=0.124 acc=0.437 sumlogdet=-0.012 acc_mask=0.453 plaqs=0.864 intQ=-0.016 sinQ=-0.026\n[06/23/23 14:35:49][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:35:54][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:35:59][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:36:04][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:36:09][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:36:14][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:36:29][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/eval_data.h5\n[06/23/23 14:36:29][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:36:29][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nHMC\noutputs['tensorflow']['hmc'] = tfExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = tfExpU1.save_dataset(job_type='hmc', nchains=32)\n\n[06/23/23 14:36:40][WARNING][trainer.py:196] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[06/23/23 14:36:40][WARNING][trainer.py:196] - x.shape (original): (4096, 2, 16, 16)\n[06/23/23 14:36:40][WARNING][trainer.py:196] - x[:nchains].shape: (128, 2, 16, 16)\n[06/23/23 14:36:40][INFO][trainer.py:200] - eps = 0.1\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7f17f07da080&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = 20\n\n\n\n\n\n{\"model_id\":\"c9e14ead5fda4789a4a40038a941d064\",\"version_major\":2,\"version_minor\":0}\n\n\n[06/23/23 14:38:03][INFO][trainer.py:200] - hstep=0 dt=0.197 beta=4.000 loss=-14.990 dQsin=0.288 dQint=0.195 energy=397.008 logprob=397.008 logdet=0.000 acc=0.822 sumlogdet=0.000 acc_mask=0.828 plaqs=0.862 intQ=-0.148 sinQ=-0.153\n[06/23/23 14:39:55][INFO][trainer.py:200] - hstep=500 dt=0.193 beta=4.000 loss=-11.040 dQsin=0.261 dQint=0.141 energy=396.582 logprob=396.582 logdet=0.000 acc=0.815 sumlogdet=0.000 acc_mask=0.781 plaqs=0.862 intQ=0.055 sinQ=0.060\n[06/23/23 14:41:47][INFO][trainer.py:200] - hstep=1000 dt=0.193 beta=4.000 loss=-14.025 dQsin=0.287 dQint=0.180 energy=395.838 logprob=395.838 logdet=0.000 acc=0.818 sumlogdet=0.000 acc_mask=0.836 plaqs=0.863 intQ=-0.117 sinQ=-0.090\n[06/23/23 14:43:39][INFO][trainer.py:200] - hstep=1500 dt=0.193 beta=4.000 loss=-18.793 dQsin=0.300 dQint=0.195 energy=393.051 logprob=393.051 logdet=0.000 acc=0.813 sumlogdet=0.000 acc_mask=0.844 plaqs=0.862 intQ=0.047 sinQ=0.039\n[06/23/23 14:45:36][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:45:45][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:45:49][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:46:01][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/hmc_data.h5\n[06/23/23 14:46:01][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:46:01][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nModel Performance\nOur goal is improving the efficiency of our MCMC sampler.\nIn particular, we are interested in generating independent save_datasetrations which we can then use to calculate expectation values of physical observables.\nFor our purposes, we are interested in obtaining lattice configurations from distinct topological charge sectors, as characterized by a configurations topological charge, Q.\nHMC is known to suffer from critical slowing down, a phenomenon in which our configurations remains stuck in some local topological charge sector and fails to produce distinct configurations.\nIn particular, it is known that the integrated autocorrelation time of the topological charge \\tau grows exponentially with decreasing lattice spacing (i.e.¬†continuum limit), making this theory especially problematic.\nBecause of this, we can assess our models‚Äô performance by looking at the tunneling rate, i.e.¬†the rate at which our sampler jumps between these different charge sectors.\nWe can write this quantity as:\n\n\\delta Q = |Q^{(i)} - Q^{(i-1)}|\n\nwhere we look at the difference in the topological charge between sequential configurations.\n\nNote: The efficiency of our sampler is directly proportional to the tunneling rate, which is inversely proportional to the integrated autocorrelation time \\tau, i.e.\n¬†\n\n\\text{Efficiency} \\propto \\delta Q \\propto \\frac{1}{\\tau}\n\nExplicitly, this means that the more efficient the model \\longrightarrow\n- the larger tunneling rate - the smaller integrated autocorrelation time for Q\nimport xarray as xr\n\ndef get_thermalized_configs(\n        x: np.ndarray | xr.DataArray,\n        drop: int = 5\n) -&gt; np.ndarray | xr.DataArray:\n    \"\"\"Drop the first `drop` states across all chains.\n\n    x.shape = [draws, chains]\n    \"\"\"\n    if isinstance(x, np.ndarray):\n        return np.sort(x)[..., :-drop]\n    if isinstance(x, xr.DataArray):\n        return x.sortby(\n            ['chain', 'draw'],\n            ascending=False\n        )[..., :-drop]\n    raise TypeError\nComparisons\nWe can measure our models‚Äô performance explicitly by looking at the average tunneling rate, \\delta Q_{\\mathbb{Z}}, for our trained model and comparing it against generic HMC.\nRecall,\n\\delta Q_{\\mathbb{Z}} := \\big|Q^{(i+1)}_{\\mathbb{Z}} - Q^{(i)}_{\\mathbb{Z}}\\big|\nwhere a higher value of \\delta Q_{\\mathbb{Z}} corresponds to better tunneling of the topological charge, Q_{\\mathbb{Z}}.\nNote that we can get a concise representation of the data from different parts of our run via:\nNote that the data from each of the different parts of our experiment (i.e.¬†train, eval, and hmc) are stored as a dict, e.g.\n&gt;&gt;&gt; list(ptExpU1.trainer.histories.keys())\n['train', 'eval', 'hmc']\n&gt;&gt;&gt; train_history = ptExpU1.trainer.histories['train']\n&gt;&gt;&gt; train_dset = train_history.get_dataset()\n&gt;&gt;&gt; assert isinstance(train_history, l2hmc.utils.history.BaseHistory)\n&gt;&gt;&gt; assert isinstance(train_dset, xarray.Dataset)\n(see below, for example)\nWe aggregate the data into the dsets dict below, grouped by:\n\nFramework (pytorch / tensorflow)\nJob type (train, eval, hmc)\nimport logging\nlog = logging.getLogger(__name__)\ndsets = {}\nfws = ['pt', 'tf']\nmodes = ['train', 'eval', 'hmc']\nfor fw in fws:\n    dsets[fw] = {}\n    for mode in modes:\n        hist = None\n        if fw == 'pt':\n            hist = ptExpU1.trainer.histories.get(mode, None)\n        elif fw == 'tf':\n            hist = tfExpU1.trainer.histories.get(mode, None)\n        if hist is not None:\n            console.print(f'Getting dataset for {fw}: {mode}')\n            dsets[fw][mode] = hist.get_dataset()\n\nGetting dataset for pt: train\nGetting dataset for pt: eval\nGetting dataset for pt: hmc\nGetting dataset for tf: train\nGetting dataset for tf: eval\nGetting dataset for tf: hmc\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['text.usetex'] = False\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import COLORS, set_plot_style\n\nset_plot_style()\n\nfig, ax = plt.subplots(figsize=(16, 3), ncols=2)\n\n# ---------------------------------------------\n# ---- DROP FIRST 20% FOR THERMALIZATION ------\n# ---------------------------------------------\nKEEP = int(0.8 * len(dsets['tf']['eval'].draw))\ndqpte = get_thermalized_configs(dsets['pt']['eval']['dQint'].astype('int'))\ndqpth = get_thermalized_configs(dsets['pt']['hmc']['dQint'].astype('int'))\n\ndqtfe = get_thermalized_configs(dsets['tf']['eval']['dQint'].astype('int'))\ndqtfh = get_thermalized_configs(dsets['tf']['hmc']['dQint'].astype('int'))\n\n_ = sns.distplot(\n    dqpte.sum('chain'),\n    kde=False,\n    color=COLORS['blue'],\n    label='Eval',\n    ax=ax[0]\n)\n_ = sns.distplot(\n    dqpth.sum('chain'),\n    kde=False,\n    color=COLORS['red'],\n    label='HMC',\n    ax=ax[0]\n)\n\n_ = ax[0].set_title('PyTorch')\n_ = ax[0].set_xlabel(\n    f'# tunneling events / {dqpte.shape[-1]} configurations'\n)\n_ = ax[0].legend(loc='best', frameon=False)\nplt.legend()\n\n_ = sns.distplot(\n    dqtfe.sum('chain'),\n    kde=False,\n    color=COLORS['blue'],\n    label='Eval',\n    ax=ax[1]\n)\n_ = sns.distplot(\n    dqtfh.sum('chain'),\n    kde=False,\n    color=COLORS['red'],\n    label='HMC',\n    ax=ax[1]\n)\n\n_ = ax[1].set_title('TensorFlow')\n_ = ax[1].set_xlabel(\n    #r\"\"\"$\\sum_{i=0} \\left|\\delta Q_{i}\\right|$\"\"\",\n    #fontsize='large',\n    f'# tunneling events / {dqpte.shape[-1]} configurations'\n)\n_ = ax[1].legend(loc='best', frameon=False)\nTensorFlow Results\nimport rich\nsns.set_context('notebook')\nndraws = len(dsets['tf']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['tf']['eval']['dQint'][:, -90:]\ndqh = dsets['tf']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\nfigsize = (2.5 * fsize[0], fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}', fontsize='x-large');\n_ = ax[1].set_title(f'HMC, total: {htot.values}', fontsize='x-large');\n_ = fig.suptitle(fr'TensorFlow Improvement: {100*(etot / htot):3.0f}%', fontsize='x-large')\n\nconsole.print(f\"TensorFlow, EVAL\\n dQint.sum('chain'):\\n {dqe.astype(int).sum('chain').T}\")\nconsole.print(f\"dQint.sum(): {dqe.astype(int).sum().T}\")\nconsole.print(f\"TensorFlow, HMC\\n dQint.sum('chain'):\\n {dqh.astype(int).sum('chain').T}\")\nconsole.print(f\"dQint.sum(): {dqh.astype(int).sum().T}\")\n\nTensorFlow, EVAL\n dQint.sum('chain'):\n &lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([13, 22, 11, 25, 14, 19, 20, 25, 13, 19, 22, 18, 10, 10, 15, 12, 17,\n       10, 19, 23, 17, 16, 14, 24, 16, 29, 15, 18, 16, 16, 20, 14,  5,  8,\n        9, 13, 14, 20, 24, 12, 12, 15, 23, 20,  8, 14, 16, 12, 17, 28, 18,\n       19, 18, 12, 27, 16, 24, 14, 21, 20, 19, 14, 14, 21, 22, 11, 22, 17,\n       23, 20, 17, 15, 22, 11, 12, 13, 17, 12, 17, 24, 27, 16, 12, 13, 12,\n       17, 18, 18, 16, 24])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199\ndQint.sum(): &lt;xarray.DataArray 'dQint' ()&gt;\narray(1527)\nTensorFlow, HMC\n dQint.sum('chain'):\n &lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([ 8,  5,  9,  7, 14, 16, 12, 12, 15, 12, 10, 13, 13, 12,  8, 13, 12,\n        3, 11, 12,  7, 12, 10,  6,  8, 16,  8, 17,  8,  9,  7,  1, 10, 12,\n       13, 11, 21, 15, 11, 11,  7, 10,  6,  6, 13,  7,  8,  9, 11,  5, 12,\n       15, 13, 10,  6, 10,  6,  8,  7,  6, 11, 12, 12, 13,  7, 16,  8, 10,\n       14, 17, 11, 11, 13,  9,  9, 11,  9, 11, 13,  9, 11,  9,  7,  4,  6,\n        7, 10, 12, 17, 14])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199\ndQint.sum(): &lt;xarray.DataArray 'dQint' ()&gt;\narray(928)\nPyTorch Results\nsns.set_context('notebook')\nndraws = len(dsets['pt']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['pt']['eval']['dQint'][:, -90:]\ndqh = dsets['pt']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\nfigsize = (2.5 * fsize[0], 0.8 * fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}', fontsize='x-large');\n_ = ax[1].set_title(f'HMC, total: {htot.values}', fontsize='x-large');\n_ = fig.suptitle(fr'PyTorch Improvement: {100*(etot / htot):3.0f}%', fontsize='x-large')\n\nconsole.print(60 * '-')\nconsole.print(f\"PyTorch, EVAL\\n dQint.sum('chain'):\\n {dqe.astype(int).sum('chain').T.values}\")\nconsole.print(f\"dQint.sum(): {dqe.astype(int).sum().T.values}\")\nconsole.print(60 * '-')\nconsole.print(f\"PyTorch, HMC\\n dQint.sum('chain'):\\n {dqh.astype(int).sum('chain').T.values}\")\nconsole.print(f\"dQint.sum(): {dqh.astype(int).sum().T.values}\")\n\n------------------------------------------------------------\nPyTorch, EVAL\n dQint.sum('chain'):\n [26 16 12 23 13 16 39 18 18 18 15 16 27 17 25 16 11 21 20 18 22 21 13 20\n 16 19 12 26 17 16 13 17 14 18 15 15 18 23 29 20 17 23 11 16 15 15 19 22\n 25 22 19 28 20 20 20 11 24 24 13 15 26 22 14 22 23 23 19 17 21 10 20 14\n 16 17 19 11 21 19 15 20 13 16  9 20 21 20 21 22 23 15]\ndQint.sum(): 1677\n------------------------------------------------------------\nPyTorch, HMC\n dQint.sum('chain'):\n [14  6 10  5  7  9 14  8 12 10 19  8  4  6  9  7  9 17  9  7 11 13  9 11\n  4  9  7 14 10  6 15  6 10  9 13  7 15 10  7  9  3 14  8  6 11  9  9  6\n  9  6 16  6  8 10 14 16  9 12 15 10  9  9  5  6 12 17  6  8  9 12  5 12\n 16  9  7  8 11 15 16 12 12  7  5 14  9  9 13  6 12 10]\ndQint.sum(): 883\nComparisons\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import set_plot_style, COLORS\n\nimport seaborn as sns\nset_plot_style()\nplt.rcParams['axes.linewidth'] = 2.0\nsns.set_context('notebook')\nfigsize = plt.rcParamsDefault['figure.figsize']\nplt.rcParams['figure.dpi'] = plt.rcParamsDefault['figure.dpi']\n\nfor idx in range(4):\n    fig, (ax, ax1) = plt.subplots(\n        ncols=2,\n        #nrows=4,\n        figsize=(3. * figsize[0], figsize[1]),\n    )\n    _ = ax.plot(\n        dsets['pt']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[100:],\n        color=COLORS['red'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n    );\n\n    _ = ax.plot(\n        dsets['pt']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[100:],\n        ls='-',\n        label='HMC',\n        color='#666666',\n        zorder=5,\n        lw=2.0,\n    );\n\n    _ = ax1.plot(\n        dsets['tf']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[-100:],\n        color=COLORS['blue'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n\n    );\n    _ = ax1.plot(\n        dsets['tf']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[-100:],\n        color='#666666',\n        ls='-',\n        label='HMC',\n        zorder=5,\n        lw=2.0,\n    );\n    _ = ax.set_title('PyTorch', fontsize='x-large')\n    _ = ax1.set_title('TensorFlow', fontsize='x-large')\n    #_ = ax1.set_ylim(ax.get_ylim())\n    _ = ax.grid(True, alpha=0.2)\n    _ = ax1.grid(True, alpha=0.2)\n    _ = ax.set_xlabel('MD Step', fontsize='large')\n    _ = ax1.set_xlabel('MD Step', fontsize='large')\n    _ = ax.set_ylabel('dQint', fontsize='large')\n    _ = ax.legend(loc='best', ncol=2, labelcolor='#939393')\n    _ = ax1.legend(loc='best', ncol=2, labelcolor='#939393')",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#contents",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#contents",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "Contents",
    "text": "Contents\n\nl2hmc: Example\nImports / Setup\nInitialize and Build Experiment objects:\nPyTorch\nTraining\nInference\nTensorFlow\nTrain\nInference\nModel Performance\nComparisons\nTensorFlow Results\nPyTorch Results\nComparisons",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#imports-setup",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#imports-setup",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "Imports / Setup",
    "text": "Imports / Setup",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#pytorch",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#pytorch",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "PyTorch",
    "text": "PyTorch",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#tensorflow",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#tensorflow",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "TensorFlow",
    "text": "TensorFlow",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#tensorflow-results",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#tensorflow-results",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "TensorFlow Results",
    "text": "TensorFlow Results",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#comparisons-1",
    "href": "posts/ai-for-physics/l2hmc-qcd/2dU1/index.html#comparisons-1",
    "title": "üé¢ l2hmc-qcd Example: 2D U(1)",
    "section": "Comparisons",
    "text": "Comparisons",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "‚öõÔ∏è AI for Physics",
      "üé¢ L2HMC for LQCD",
      "üé¢ <code>l2hmc-qcd</code> Example: 2D U(1)"
    ]
  },
  {
    "objectID": "posts/ai-for-physics/l2hmc-qcd/index.html",
    "href": "posts/ai-for-physics/l2hmc-qcd/index.html",
    "title": "üé¢ L2HMC for LQCD",
    "section": "",
    "text": "CitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {üé¢ {L2HMC} for {LQCD}},\n  url = {https://samforeman.me/posts/ai-for-physics/l2hmc-qcd/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äúüé¢ L2HMC for LQCD.‚Äù https://samforeman.me/posts/ai-for-physics/l2hmc-qcd/."
  },
  {
    "objectID": "posts/ezpz-at-alcf/index.html#getting-started",
    "href": "posts/ezpz-at-alcf/index.html#getting-started",
    "title": "üçã ezpz @ ALCF",
    "section": "üê£ Getting Started",
    "text": "üê£ Getting Started\nThere are two main, distinct components of ezpz:\n\nüêç Python Library\nüêö Shell Utilities",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üçã <code>ezpz</code> @ ALCF"
    ]
  },
  {
    "objectID": "posts/ezpz-at-alcf/index.html#shell-utilities",
    "href": "posts/ezpz-at-alcf/index.html#shell-utilities",
    "title": "üçã ezpz @ ALCF",
    "section": "üêö Shell Utilities",
    "text": "üêö Shell Utilities\nThe Shell Utilities can be roughly broken up further into two main components\n\nSetup Environment:\n\nSetup Python:\n\nSetup Conda\nSetup Virtual Environment\n\nSetup Job:\n\n\nWe provide a variety of helper functions designed to make your life easier when working with job schedulers (e.g.¬†PBS Pro @ ALCF or slurm elsewhere).\nAll of these functions are:\n\nlocated in utils.sh\nprefixed with ezpz_* (e.g.¬†ezpz_setup_python)1\n\nTo use these, we can source the file directly via:\nexport PBS_O_WORKDIR=$(pwd) # if on ALCF\nsource /dev/stdin &lt;&lt;&lt; $(curl 'https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh')\n\n‚öôÔ∏è Setup Environment\nWe would like to write our application in such a way that it is able to take full advantage of the resources allocated by the job scheduler.\nThat is to say, we want to have a single script with the ability to dynamically launch python applications across any number of accelerators on any of the systems under consideration.\nIn order to do this, there is some basic setup and information gathering that needs to occur.\nIn particular, we need mechanisms for:\n\nSetting up a python environment\nDetermining what system / machine we‚Äôre on\n\n+ what job scheduler we‚Äôre using (e.g.¬†PBS Pro @ ALCF or slurm elsewhere)\n\nDetermining how many nodes have been allocated in the current job (NHOSTS)\n\n+ Determining how many accelerators exist on each of these nodes (NGPU_PER_HOST)\n\n\nThis allows us to calculate the total number of accelerators (GPUs) as: N_{\\mathrm{GPU}} = N_{\\mathrm{HOST}} \\times n_{\\mathrm{GPU}}\nwhere n_{\\mathrm{GPU}} = N_{\\mathrm{GPU}} / N_{\\mathrm{HOST}} is the number of GPUs per host.\nWith this we have everything we need to build the appropriate {mpi{run, exec}, slurm} command for launching our python application across them.\nNow, there are a few functions in particular worth elaborating on.\n\n\n\n\n\nShell Functions\n\n\n¬†\nFunction\nDescription\n\n\n\n\nSetup Environment\nezpz_setup_env\nWrapper around ezpz_setup_python && ezpz_setup_job\n\n\nSetup Job\nezpz_setup_job\nDetermine {NGPUS, NGPU_PER_HOST, NHOSTS}, build launch command alias\n\n\nSetup Python\nezpz_setup_python\nWrapper around ezpz_setup_conda && ezpz_setup_venv_from_conda\n\n\nSetup Conda\nezpz_setup_conda\nFind and activate appropriate conda module to load2\n\n\nSetup Virtual Environment\nezpz_setup_venv_from_conda\nFrom ${CONDA_NAME}, build or activate the virtual env located in venvs/${CONDA_NAME}/\n\n\n\n\n\n\nTable¬†1: Shell Functions\n\n\n\n\n\n\n\n\n\nWarningWhere am I?\n\n\n\n\n\nSome of the ezpz_* functions (e.g.¬†ezpz_setup_python), will try to create / look for certain directories.\nIn an effort to be explicit, these directories will be defined relative to a WORKING_DIR (e.g.¬†\"${WORKING_DIR}/venvs/\")\nThis WORKING_DIR will be assigned to the first non-zero match found below:\n\nPBS_O_WORKDIR: If found in environment, paths will be relative to this\nSLURM_SUBMIT_DIR: Next in line. If not @ ALCF, maybe using slurm‚Ä¶\n$(pwd): Otherwise, no worries. Use your actual working directory.\n\n\n\n\n\n\nüìù Example\n\nClone repo:\ngit clone https://github.com/saforem2/ezpz\ncd ezpz\nSetup environment:\nexport PBS_O_WORKDIR=$(pwd) && source src/ezpz/bin/utils.sh && ezpz_setup_env\n\n\nOutput\n\n$ export PBS_O_WORKDIR=$(pwd) && source src/ezpz/bin/utils.sh && ezpz_setup_env\nUsing WORKING_DIR: /gila/Aurora_deployment/foremans/projects/saforem2/ezpz\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) mpich/icc-all-pmix-gpu/20240717\n\nThe following have been reloaded with a version change:\n  1) oneapi/eng-compiler/2024.07.30.002 =&gt; oneapi/release/2024.2.1\n\nFound conda at: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1\nNo VIRTUAL_ENV found in environment!\n    - Trying to setup from /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1\n    - Using VENV_DIR=/gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1\n\n    - Creating a new virtual env on top of aurora_nre_models_frameworks-2024.2.1_u1 in /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1\n[python] Using /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\n\n[üçã ezpz/bin/utils.sh]\n    ‚Ä¢ USER=foremans\n    ‚Ä¢ MACHINE=sunspot\n    ‚Ä¢ HOST=x1922c5s0b0n0\n    ‚Ä¢ TSTAMP=2024-11-28-133756\n\n[ezpz_setup_host_pbs]\n    ‚Ä¢ Using hostfile: /var/spool/pbs/aux/10283088.amn-0001\n    ‚Ä¢ Found in environment:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/10283088.amn-0001\n        ‚Ä¢ Writing PBS vars to: /home/foremans/.pbsenv\n\n[ezpz_save_pbs_env]\n    ‚Ä¢ Setting:\n        ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/10283088.amn-0001\n        ‚Ä¢ JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n    ‚Ä¢ [host:0] - x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com\n    ‚Ä¢ [host:1] - x1922c5s2b0n0.hostmgmt2001.cm.americas.sgi.com\n    ‚Ä¢ [host:2] - x1922c5s4b0n0.hostmgmt2001.cm.americas.sgi.com\n    ‚Ä¢ [host:3] - x1922c6s1b0n0.hostmgmt2001.cm.americas.sgi.com\n\n[DIST INFO]\n    ‚Ä¢ NGPUS=48\n    ‚Ä¢ NHOSTS=4\n    ‚Ä¢ NGPU_PER_HOST=12\n    ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/10283088.amn-0001\n    ‚Ä¢ DIST_LAUNCH=mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\n\n[LAUNCH]:\n    ‚Ä¢ To launch across all available GPUs, use: launch\n\n      launch = mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\n\ntook: 0h:00m:12s\n\nInstall ezpz:\npython3 -m pip install -e \".\" --require-virtualenv\nCheck launch:\n$ which launch\nlaunch: aliased to mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\nRun ezpz.test_dist:\nlaunch python3 src/ezpz/test_dist.py\n\n\nOutput\n\n#[üêç aurora_nre_models_frameworks-2023.2.1_u1](üëª aurora_nre_models_frameworks-2024.2.1_u1)\n#[üåª][01:42:37 PM][foremans@x1922c5s0b0n0][‚Ä¶/ezpz][üå± saforem2-patch-1]via ‚®Å v1.4.552\n$ launch python3 -m ezpz.test_dist\nDisabling local launch: multi-node application\nConnected to tcp://x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com:7919\nFound executable /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\nLaunching application ecd9868b-2b3b-4a0e-b2e6-79769ecc7eff\n[2024-11-28 13:43:41.385960][INFO][dist.py:348] - [device='xpu'][rank=3/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:43:41.386603][INFO][dist.py:348] - [device='xpu'][rank=1/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:43:41.386605][INFO][dist.py:348] - [device='xpu'][rank=2/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:43:41.386834][INFO][dist.py:348] - [device='xpu'][rank=6/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:43:41.387707][INFO][dist.py:348] - [device='xpu'][rank=8/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:43:41.387290][INFO][dist.py:348] - [device='xpu'][rank=4/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:43:41.387235][INFO][dist.py:348] - [device='xpu'][rank=10/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:43:41.387362][INFO][dist.py:348] - [device='xpu'][rank=11/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:43:41.387761][INFO][dist.py:348] - [device='xpu'][rank=5/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:43:41.387958][INFO][dist.py:348] - [device='xpu'][rank=9/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:43:46.384505][INFO][dist.py:348] - [device='xpu'][rank=7/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.816252][INFO][dist.py:348] - [device='xpu'][rank=15/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.821175][INFO][dist.py:348] - [device='xpu'][rank=17/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.824021][INFO][dist.py:348] - [device='xpu'][rank=22/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.825905][INFO][dist.py:348] - [device='xpu'][rank=41/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.826590][INFO][dist.py:348] - [device='xpu'][rank=38/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.838048][INFO][dist.py:348] - [device='xpu'][rank=23/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.838526][INFO][dist.py:348] - [device='xpu'][rank=21/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.838825][INFO][dist.py:348] - [device='xpu'][rank=19/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.838817][INFO][dist.py:348] - [device='xpu'][rank=36/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.838665][INFO][dist.py:348] - [device='xpu'][rank=35/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.839033][INFO][dist.py:348] - [device='xpu'][rank=25/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.838855][INFO][dist.py:348] - [device='xpu'][rank=26/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.839144][INFO][dist.py:348] - [device='xpu'][rank=33/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.840785][INFO][dist.py:348] - [device='xpu'][rank=37/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.840740][INFO][dist.py:348] - [device='xpu'][rank=47/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.844721][INFO][dist.py:348] - [device='xpu'][rank=46/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.845202][INFO][dist.py:348] - [device='xpu'][rank=30/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.845888][INFO][dist.py:348] - [device='xpu'][rank=18/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.849905][INFO][dist.py:348] - [device='xpu'][rank=20/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.849947][INFO][dist.py:348] - [device='xpu'][rank=32/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.850232][INFO][dist.py:348] - [device='xpu'][rank=39/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.850301][INFO][dist.py:348] - [device='xpu'][rank=44/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.850795][INFO][dist.py:348] - [device='xpu'][rank=14/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.851872][INFO][dist.py:348] - [device='xpu'][rank=28/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.852078][INFO][dist.py:348] - [device='xpu'][rank=12/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.853836][INFO][dist.py:348] - [device='xpu'][rank=16/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.853997][INFO][dist.py:348] - [device='xpu'][rank=24/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.855526][INFO][dist.py:348] - [device='xpu'][rank=13/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.856609][INFO][dist.py:348] - [device='xpu'][rank=40/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.857991][INFO][dist.py:348] - [device='xpu'][rank=42/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.863239][INFO][dist.py:348] - [device='xpu'][rank=29/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.864956][INFO][dist.py:348] - [device='xpu'][rank=45/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.867388][INFO][dist.py:348] - [device='xpu'][rank=27/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.867764][INFO][dist.py:348] - [device='xpu'][rank=43/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.873106][INFO][dist.py:348] - [device='xpu'][rank=34/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.877043][INFO][dist.py:348] - [device='xpu'][rank=31/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.887609][INFO][dist.py:92] -\n\n[dist_info]:\n  ‚Ä¢ DEVICE=xpu\n  ‚Ä¢ DEVICE_ID=xpu:0\n  ‚Ä¢ DISTRIBUTED_BACKEND=ccl\n  ‚Ä¢ GPUS_PER_NODE=12\n  ‚Ä¢ HOSTS=['x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c5s2b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c5s4b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c6s1b0n0.hostmgmt2001.cm.americas.sgi.com']\n  ‚Ä¢ HOSTFILE=/var/spool/pbs/aux/10283088.amn-0001\n  ‚Ä¢ HOSTNAME=x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com\n  ‚Ä¢ LOCAL_RANK=0\n  ‚Ä¢ MACHINE=SunSpot\n  ‚Ä¢ NUM_NODES=4\n  ‚Ä¢ NGPUS=48\n  ‚Ä¢ NGPUS_AVAILABLE=48\n  ‚Ä¢ NODE_ID=0\n  ‚Ä¢ RANK=0\n  ‚Ä¢ SCHEDULER=PBS\n  ‚Ä¢ WORLD_SIZE_TOTAL=48\n  ‚Ä¢ WORLD_SIZE_IN_USE=48\n  ‚Ä¢ LAUNCH_CMD=mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 16\n\n\n[2024-11-28 13:44:32.933415][INFO][dist.py:725] - Using oneccl_bindings from: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/oneccl_bindings_for_pytorch/__init__.py\n[2024-11-28 13:44:32.933861][INFO][dist.py:727] - Using ipex from: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/intel_extension_for_pytorch/__init__.py\n[2024-11-28 13:44:32.934238][INFO][dist.py:728] - [0/48] Using device='xpu' with backend='DDP' + 'ccl' for distributed training.\n[2024-11-28 13:44:32.940188][INFO][dist.py:348] - [device='xpu'][rank=0/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.940746][WARNING][_logger.py:68] - Using [48 / 48] available \"xpu\" devices !!\n[2024-11-28 13:44:34.193788][INFO][dist.py:882] - Setting up wandb from rank: 0\n[2024-11-28 13:44:34.194312][INFO][dist.py:883] - Using: WB PROJECT: ezpz.test_dist\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Currently logged in as: foremans (aurora_gpt). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.18.7\nwandb: Run data is saved locally in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/wandb/run-20241128_134434-4mwyy84l\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run driven-wind-683\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/aurora_gpt/ezpz.test_dist\nwandb: üöÄ View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l\n[2024-11-28 13:44:35.481364][INFO][dist.py:908] - W&B RUN: [driven-wind-683](https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l)\n[2024-11-28 13:44:35.495959][INFO][dist.py:304] - Updating wandb.run: driven-wind-683 config with \"DIST_INFO\"\n[2024-11-28 13:44:35.500222][INFO][dist.py:936] - Running on machine='SunSpot'\n[2024-11-28 13:44:35.501304][INFO][dist.py:92] -\n\n[CONFIG]:\n  ‚Ä¢ warmup=0\n  ‚Ä¢ log_freq=1\n  ‚Ä¢ batch_size=64\n  ‚Ä¢ input_size=128\n  ‚Ä¢ output_size=128\n  ‚Ä¢ dtype=torch.float32\n  ‚Ä¢ device=xpu\n  ‚Ä¢ world_size=48\n  ‚Ä¢ train_iters=100\n\n\n[2024-11-28 13:44:35.575161][INFO][test_dist.py:147] - model=Network(\n  (layers): Sequential(\n    (0): Linear(in_features=128, out_features=1024, bias=True)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=256, bias=True)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n)\n[2024-11-28 13:44:48.340596][INFO][test_dist.py:228] - iter=1 dt=0.019713 dtf=0.002959 dtb=0.016754 loss=1821.131958 sps=3246.551823\n[2024-11-28 13:44:48.346527][INFO][test_dist.py:228] - iter=2 dt=0.004083 dtf=0.000822 dtb=0.003261 loss=1348.032227 sps=15673.877930\n[2024-11-28 13:44:48.351387][INFO][test_dist.py:228] - iter=3 dt=0.003260 dtf=0.000735 dtb=0.002525 loss=1072.068359 sps=19634.479814\n[2024-11-28 13:44:48.356043][INFO][test_dist.py:228] - iter=4 dt=0.003117 dtf=0.000716 dtb=0.002401 loss=928.493774 sps=20534.414826\n[2024-11-28 13:44:48.360830][INFO][test_dist.py:228] - iter=5 dt=0.003181 dtf=0.000798 dtb=0.002384 loss=867.221558 sps=20116.568892\n[2024-11-28 13:44:48.365608][INFO][test_dist.py:228] - iter=6 dt=0.003146 dtf=0.000738 dtb=0.002408 loss=794.671204 sps=20341.929281\n[2024-11-28 13:44:48.370473][INFO][test_dist.py:228] - iter=7 dt=0.003149 dtf=0.000751 dtb=0.002398 loss=748.687500 sps=20324.551047\n[2024-11-28 13:44:48.375126][INFO][test_dist.py:228] - iter=8 dt=0.003105 dtf=0.000719 dtb=0.002385 loss=720.116943 sps=20614.492256\n[2024-11-28 13:44:48.379744][INFO][test_dist.py:228] - iter=9 dt=0.003057 dtf=0.000698 dtb=0.002359 loss=714.217957 sps=20937.174740\n[2024-11-28 13:44:48.384429][INFO][test_dist.py:228] - iter=10 dt=0.003083 dtf=0.000703 dtb=0.002380 loss=718.780884 sps=20760.967373\n[2024-11-28 13:44:48.390098][INFO][test_dist.py:228] - iter=11 dt=0.003931 dtf=0.000802 dtb=0.003129 loss=699.931152 sps=16281.262548\n[2024-11-28 13:44:48.395638][INFO][test_dist.py:228] - iter=12 dt=0.003698 dtf=0.000865 dtb=0.002832 loss=687.315857 sps=17308.773026\n[2024-11-28 13:44:48.400852][INFO][test_dist.py:228] - iter=13 dt=0.003502 dtf=0.000792 dtb=0.002709 loss=685.231995 sps=18276.152786\n[2024-11-28 13:44:48.406145][INFO][test_dist.py:228] - iter=14 dt=0.003501 dtf=0.000788 dtb=0.002714 loss=678.643860 sps=18278.977230\n[2024-11-28 13:44:48.411186][INFO][test_dist.py:228] - iter=15 dt=0.003366 dtf=0.000760 dtb=0.002606 loss=675.734375 sps=19012.740109\n[2024-11-28 13:44:48.416092][INFO][test_dist.py:228] - iter=16 dt=0.003308 dtf=0.000764 dtb=0.002545 loss=656.803894 sps=19345.774997\n[2024-11-28 13:44:48.421088][INFO][test_dist.py:228] - iter=17 dt=0.003326 dtf=0.000800 dtb=0.002526 loss=663.846558 sps=19240.551489\n[2024-11-28 13:44:48.426305][INFO][test_dist.py:228] - iter=18 dt=0.003439 dtf=0.000805 dtb=0.002634 loss=646.870605 sps=18607.582468\n[2024-11-28 13:44:48.431107][INFO][test_dist.py:228] - iter=19 dt=0.003217 dtf=0.000730 dtb=0.002488 loss=631.541504 sps=19893.098888\n[2024-11-28 13:44:48.436171][INFO][test_dist.py:228] - iter=20 dt=0.003447 dtf=0.000707 dtb=0.002741 loss=645.819580 sps=18564.526433\n[2024-11-28 13:44:48.441333][INFO][test_dist.py:228] - iter=21 dt=0.003465 dtf=0.000921 dtb=0.002543 loss=642.620361 sps=18470.919500\n[2024-11-28 13:44:48.446923][INFO][test_dist.py:228] - iter=22 dt=0.003732 dtf=0.000822 dtb=0.002910 loss=639.229980 sps=17149.966074\n[2024-11-28 13:44:48.451965][INFO][test_dist.py:228] - iter=23 dt=0.003386 dtf=0.000778 dtb=0.002608 loss=627.894897 sps=18902.966756\n[2024-11-28 13:44:48.457006][INFO][test_dist.py:228] - iter=24 dt=0.003367 dtf=0.000807 dtb=0.002560 loss=604.797424 sps=19007.381386\n[2024-11-28 13:44:48.461850][INFO][test_dist.py:228] - iter=25 dt=0.003164 dtf=0.000721 dtb=0.002443 loss=614.561523 sps=20229.778931\n[2024-11-28 13:44:48.466983][INFO][test_dist.py:228] - iter=26 dt=0.003473 dtf=0.000759 dtb=0.002714 loss=617.550781 sps=18428.700435\n[2024-11-28 13:44:48.471925][INFO][test_dist.py:228] - iter=27 dt=0.003289 dtf=0.000758 dtb=0.002531 loss=618.434082 sps=19457.441792\n[2024-11-28 13:44:48.477516][INFO][test_dist.py:228] - iter=28 dt=0.003872 dtf=0.000930 dtb=0.002942 loss=607.261475 sps=16528.336617\n[2024-11-28 13:44:48.482581][INFO][test_dist.py:228] - iter=29 dt=0.003365 dtf=0.000773 dtb=0.002591 loss=601.454590 sps=19021.673645\n[2024-11-28 13:44:48.487622][INFO][test_dist.py:228] - iter=30 dt=0.003288 dtf=0.000825 dtb=0.002463 loss=594.649170 sps=19463.454229\n[2024-11-28 13:44:48.492493][INFO][test_dist.py:228] - iter=31 dt=0.003211 dtf=0.000734 dtb=0.002477 loss=582.087036 sps=19933.062380\n[2024-11-28 13:44:48.497510][INFO][test_dist.py:228] - iter=32 dt=0.003360 dtf=0.000851 dtb=0.002509 loss=582.850586 sps=19050.324061\n[2024-11-28 13:44:48.502534][INFO][test_dist.py:228] - iter=33 dt=0.003299 dtf=0.000751 dtb=0.002547 loss=574.619019 sps=19402.524122\n[2024-11-28 13:44:48.507516][INFO][test_dist.py:228] - iter=34 dt=0.003318 dtf=0.000843 dtb=0.002475 loss=571.530273 sps=19291.396984\n[2024-11-28 13:44:48.512324][INFO][test_dist.py:228] - iter=35 dt=0.003162 dtf=0.000718 dtb=0.002444 loss=569.056335 sps=20239.766403\n[2024-11-28 13:44:48.517314][INFO][test_dist.py:228] - iter=36 dt=0.003338 dtf=0.000803 dtb=0.002535 loss=570.773315 sps=19171.898987\n[2024-11-28 13:44:48.522111][INFO][test_dist.py:228] - iter=37 dt=0.003111 dtf=0.000712 dtb=0.002399 loss=564.691101 sps=20571.738756\n[2024-11-28 13:44:48.527333][INFO][test_dist.py:228] - iter=38 dt=0.003581 dtf=0.000698 dtb=0.002883 loss=555.157349 sps=17870.995302\n[2024-11-28 13:44:48.532827][INFO][test_dist.py:228] - iter=39 dt=0.003596 dtf=0.000841 dtb=0.002755 loss=542.374756 sps=17796.934508\n[2024-11-28 13:44:48.538391][INFO][test_dist.py:228] - iter=40 dt=0.003673 dtf=0.000872 dtb=0.002801 loss=538.616821 sps=17424.614226\n[2024-11-28 13:44:48.543835][INFO][test_dist.py:228] - iter=41 dt=0.003606 dtf=0.000837 dtb=0.002769 loss=546.055054 sps=17746.977167\n[2024-11-28 13:44:48.548728][INFO][test_dist.py:228] - iter=42 dt=0.003171 dtf=0.000786 dtb=0.002385 loss=541.741455 sps=20183.008810\n[2024-11-28 13:44:48.553392][INFO][test_dist.py:228] - iter=43 dt=0.003091 dtf=0.000675 dtb=0.002415 loss=541.895630 sps=20707.731509\n[2024-11-28 13:44:48.558674][INFO][test_dist.py:228] - iter=44 dt=0.003598 dtf=0.000797 dtb=0.002801 loss=532.636841 sps=17789.399613\n[2024-11-28 13:44:48.563691][INFO][test_dist.py:228] - iter=45 dt=0.003305 dtf=0.000726 dtb=0.002579 loss=527.679077 sps=19363.041186\n[2024-11-28 13:44:48.568927][INFO][test_dist.py:228] - iter=46 dt=0.003472 dtf=0.000776 dtb=0.002696 loss=519.220581 sps=18435.547756\n[2024-11-28 13:44:48.573801][INFO][test_dist.py:228] - iter=47 dt=0.003203 dtf=0.000723 dtb=0.002480 loss=527.749268 sps=19982.521481\n[2024-11-28 13:44:48.578761][INFO][test_dist.py:228] - iter=48 dt=0.003253 dtf=0.000782 dtb=0.002471 loss=524.344238 sps=19672.846752\n[2024-11-28 13:44:48.583369][INFO][test_dist.py:228] - iter=49 dt=0.003042 dtf=0.000652 dtb=0.002390 loss=514.100464 sps=21038.853899\n[2024-11-28 13:44:48.588292][INFO][test_dist.py:228] - iter=50 dt=0.003210 dtf=0.000763 dtb=0.002447 loss=513.998962 sps=19936.401969\n[2024-11-28 13:44:48.593155][INFO][test_dist.py:228] - iter=51 dt=0.003210 dtf=0.000763 dtb=0.002447 loss=506.444519 sps=19937.409848\n[2024-11-28 13:44:48.598482][INFO][test_dist.py:228] - iter=52 dt=0.003648 dtf=0.000781 dtb=0.002868 loss=505.063721 sps=17542.989327\n[2024-11-28 13:44:48.603395][INFO][test_dist.py:228] - iter=53 dt=0.003258 dtf=0.000742 dtb=0.002516 loss=500.011047 sps=19642.561466\n[2024-11-28 13:44:48.608385][INFO][test_dist.py:228] - iter=54 dt=0.003292 dtf=0.000797 dtb=0.002495 loss=508.445740 sps=19439.362133\n[2024-11-28 13:44:48.613115][INFO][test_dist.py:228] - iter=55 dt=0.003151 dtf=0.000699 dtb=0.002452 loss=492.626648 sps=20310.433009\n[2024-11-28 13:44:48.618036][INFO][test_dist.py:228] - iter=56 dt=0.003251 dtf=0.000727 dtb=0.002524 loss=487.402435 sps=19684.735824\n[2024-11-28 13:44:48.623122][INFO][test_dist.py:228] - iter=57 dt=0.003449 dtf=0.000979 dtb=0.002469 loss=474.962097 sps=18556.851343\n[2024-11-28 13:44:48.628167][INFO][test_dist.py:228] - iter=58 dt=0.003343 dtf=0.000811 dtb=0.002532 loss=479.064941 sps=19143.536594\n[2024-11-28 13:44:48.633070][INFO][test_dist.py:228] - iter=59 dt=0.003256 dtf=0.000787 dtb=0.002468 loss=471.197083 sps=19658.706785\n[2024-11-28 13:44:48.638373][INFO][test_dist.py:228] - iter=60 dt=0.003548 dtf=0.000853 dtb=0.002696 loss=469.964081 sps=18037.965649\n[2024-11-28 13:44:48.643270][INFO][test_dist.py:228] - iter=61 dt=0.003225 dtf=0.000736 dtb=0.002489 loss=476.972076 sps=19844.166872\n[2024-11-28 13:44:48.648256][INFO][test_dist.py:228] - iter=62 dt=0.003214 dtf=0.000745 dtb=0.002469 loss=463.572174 sps=19912.478524\n[2024-11-28 13:44:48.652939][INFO][test_dist.py:228] - iter=63 dt=0.003095 dtf=0.000683 dtb=0.002411 loss=462.910156 sps=20679.849741\n[2024-11-28 13:44:48.657892][INFO][test_dist.py:228] - iter=64 dt=0.003239 dtf=0.000746 dtb=0.002492 loss=457.325439 sps=19762.175344\n[2024-11-28 13:44:48.662903][INFO][test_dist.py:228] - iter=65 dt=0.003293 dtf=0.000729 dtb=0.002563 loss=453.347168 sps=19438.021843\n[2024-11-28 13:44:48.667970][INFO][test_dist.py:228] - iter=66 dt=0.003276 dtf=0.000788 dtb=0.002488 loss=450.351135 sps=19534.356115\n[2024-11-28 13:44:48.672824][INFO][test_dist.py:228] - iter=67 dt=0.003192 dtf=0.000735 dtb=0.002457 loss=450.714233 sps=20047.789409\n[2024-11-28 13:44:48.677882][INFO][test_dist.py:228] - iter=68 dt=0.003330 dtf=0.000799 dtb=0.002530 loss=440.284546 sps=19220.840096\n[2024-11-28 13:44:48.682532][INFO][test_dist.py:228] - iter=69 dt=0.003081 dtf=0.000663 dtb=0.002418 loss=444.536011 sps=20770.230742\n[2024-11-28 13:44:48.687492][INFO][test_dist.py:228] - iter=70 dt=0.003307 dtf=0.000766 dtb=0.002541 loss=446.201233 sps=19354.965715\n[2024-11-28 13:44:48.692350][INFO][test_dist.py:228] - iter=71 dt=0.003225 dtf=0.000737 dtb=0.002488 loss=427.167328 sps=19845.047963\n[2024-11-28 13:44:48.697422][INFO][test_dist.py:228] - iter=72 dt=0.003415 dtf=0.000881 dtb=0.002534 loss=434.620087 sps=18740.536560\n[2024-11-28 13:44:48.702393][INFO][test_dist.py:228] - iter=73 dt=0.003299 dtf=0.000740 dtb=0.002559 loss=425.558777 sps=19402.652860\n[2024-11-28 13:44:48.707240][INFO][test_dist.py:228] - iter=74 dt=0.003180 dtf=0.000789 dtb=0.002391 loss=428.168945 sps=20126.919392\n[2024-11-28 13:44:48.712103][INFO][test_dist.py:228] - iter=75 dt=0.003322 dtf=0.000680 dtb=0.002642 loss=417.153503 sps=19263.558998\n[2024-11-28 13:44:48.717120][INFO][test_dist.py:228] - iter=76 dt=0.003405 dtf=0.000787 dtb=0.002618 loss=412.435059 sps=18794.204421\n[2024-11-28 13:44:48.722012][INFO][test_dist.py:228] - iter=77 dt=0.003208 dtf=0.000722 dtb=0.002487 loss=426.690186 sps=19947.873515\n[2024-11-28 13:44:48.727040][INFO][test_dist.py:228] - iter=78 dt=0.003330 dtf=0.000775 dtb=0.002554 loss=404.138733 sps=19220.615648\n[2024-11-28 13:44:48.731946][INFO][test_dist.py:228] - iter=79 dt=0.003218 dtf=0.000757 dtb=0.002461 loss=396.998413 sps=19886.330391\n[2024-11-28 13:44:48.736956][INFO][test_dist.py:228] - iter=80 dt=0.003362 dtf=0.000818 dtb=0.002544 loss=405.073059 sps=19036.951133\n[2024-11-28 13:44:48.742154][INFO][test_dist.py:228] - iter=81 dt=0.003309 dtf=0.000840 dtb=0.002468 loss=408.205780 sps=19341.447610\n[2024-11-28 13:44:48.747100][INFO][test_dist.py:228] - iter=82 dt=0.003301 dtf=0.000801 dtb=0.002500 loss=391.203918 sps=19389.697222\n[2024-11-28 13:44:48.752235][INFO][test_dist.py:228] - iter=83 dt=0.003488 dtf=0.000732 dtb=0.002756 loss=401.911407 sps=18347.650097\n[2024-11-28 13:44:48.757468][INFO][test_dist.py:228] - iter=84 dt=0.003567 dtf=0.000886 dtb=0.002681 loss=390.872192 sps=17942.862497\n[2024-11-28 13:44:48.762431][INFO][test_dist.py:228] - iter=85 dt=0.003272 dtf=0.000769 dtb=0.002502 loss=390.741089 sps=19562.065370\n[2024-11-28 13:44:48.767527][INFO][test_dist.py:228] - iter=86 dt=0.003390 dtf=0.000795 dtb=0.002596 loss=393.982513 sps=18877.408330\n[2024-11-28 13:44:48.772363][INFO][test_dist.py:228] - iter=87 dt=0.003198 dtf=0.000727 dtb=0.002471 loss=378.682495 sps=20014.348794\n[2024-11-28 13:44:48.777779][INFO][test_dist.py:228] - iter=88 dt=0.003666 dtf=0.000914 dtb=0.002752 loss=378.739502 sps=17459.234394\n[2024-11-28 13:44:48.783160][INFO][test_dist.py:228] - iter=89 dt=0.003529 dtf=0.000832 dtb=0.002697 loss=382.028931 sps=18136.158201\n[2024-11-28 13:44:48.788498][INFO][test_dist.py:228] - iter=90 dt=0.003442 dtf=0.000809 dtb=0.002633 loss=371.271118 sps=18594.284077\n[2024-11-28 13:44:48.793524][INFO][test_dist.py:228] - iter=91 dt=0.003358 dtf=0.000754 dtb=0.002603 loss=371.135925 sps=19060.348912\n[2024-11-28 13:44:48.798593][INFO][test_dist.py:228] - iter=92 dt=0.003336 dtf=0.000791 dtb=0.002545 loss=368.860168 sps=19183.369504\n[2024-11-28 13:44:48.803491][INFO][test_dist.py:228] - iter=93 dt=0.003227 dtf=0.000725 dtb=0.002502 loss=371.283356 sps=19831.370522\n[2024-11-28 13:44:48.808397][INFO][test_dist.py:228] - iter=94 dt=0.003250 dtf=0.000769 dtb=0.002481 loss=362.983154 sps=19693.397864\n[2024-11-28 13:44:48.813075][INFO][test_dist.py:228] - iter=95 dt=0.003098 dtf=0.000703 dtb=0.002396 loss=365.535828 sps=20656.015873\n[2024-11-28 13:44:48.818465][INFO][test_dist.py:228] - iter=96 dt=0.003581 dtf=0.000872 dtb=0.002709 loss=344.663239 sps=17873.310048\n[2024-11-28 13:44:48.823831][INFO][test_dist.py:228] - iter=97 dt=0.003509 dtf=0.000834 dtb=0.002675 loss=361.620361 sps=18238.825661\n[2024-11-28 13:44:48.828930][INFO][test_dist.py:228] - iter=98 dt=0.003326 dtf=0.000804 dtb=0.002522 loss=347.258301 sps=19245.190902\n[2024-11-28 13:44:48.834103][INFO][test_dist.py:228] - iter=99 dt=0.003474 dtf=0.000740 dtb=0.002733 loss=346.517212 sps=18424.412945\nFailed to download font: IBM Plex Sans, skipping!\nFailed to download font: IBM Plex Sans Condensed, skipping!\nFailed to download font: IBM Plex Serif, skipping!\n[2024-11-28 13:44:50.885911][INFO][history.py:696] - Saving train_iter plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:51.498182][INFO][history.py:696] - Saving train_dt plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:51.758706][INFO][history.py:696] - Saving train_dtf plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.022463][INFO][history.py:696] - Saving train_dtb plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.309521][INFO][history.py:696] - Saving train_loss plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.562425][INFO][history.py:696] - Saving train_sps plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n                        train_iter [2024-11-28-134452]\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n99.0‚î§                                                                 ‚ñó‚ñÑ‚ñÑ‚ñÄ‚îÇ\n    ‚îÇ                                                              ‚ñÑ‚ñû‚ñÄ‚ñò   ‚îÇ\n    ‚îÇ                                                          ‚ñÑ‚ñÑ‚ñÄ‚ñÄ       ‚îÇ\n82.7‚î§                                                      ‚ñÑ‚ñÑ‚ñÄ‚ñÄ           ‚îÇ\n    ‚îÇ                                                  ‚ñó‚ñÑ‚ñû‚ñÄ               ‚îÇ\n    ‚îÇ                                              ‚ñÑ‚ñÑ‚ñÄ‚ñÄ‚ñò                  ‚îÇ\n66.3‚î§                                          ‚ñó‚ñÑ‚ñÄ‚ñÄ                       ‚îÇ\n    ‚îÇ                                      ‚ñó‚ñÑ‚ñû‚ñÄ‚ñò                          ‚îÇ\n50.0‚î§                                  ‚ñó‚ñÑ‚ñû‚ñÄ‚ñò                              ‚îÇ\n    ‚îÇ                               ‚ñÑ‚ñÑ‚ñÄ‚ñò                                  ‚îÇ\n    ‚îÇ                          ‚ñó‚ñÑ‚ñû‚ñÄ‚ñÄ                                      ‚îÇ\n33.7‚î§                       ‚ñÑ‚ñû‚ñÄ‚ñò                                          ‚îÇ\n    ‚îÇ                   ‚ñÑ‚ñÑ‚ñÄ‚ñÄ                                              ‚îÇ\n    ‚îÇ              ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñÄ                                                  ‚îÇ\n17.3‚î§           ‚ñÑ‚ñÑ‚ñû‚ñò                                                      ‚îÇ\n    ‚îÇ       ‚ñÑ‚ñÑ‚ñÄ‚ñÄ                                                          ‚îÇ\n    ‚îÇ   ‚ñó‚ñÑ‚ñÄ‚ñÄ                                                              ‚îÇ\n 1.0‚î§‚ñÑ‚ñû‚ñÄ‚ñò                                                                 ‚îÇ\n    ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n      2 5  11 16 20   27 31 36   43  48 53 57 61  68 71  78 81 86 91   98\ntrain_iter                        train/iter\n[2024-11-28 13:44:52.868990][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_iter.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_iter.txt\n                          train_dt [2024-11-28-134452]\n      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.0197‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0169‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0142‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0114‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0086‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0058‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñö      ‚ññ          ‚ñó                                                ‚îÇ\n0.0030‚î§ ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñû‚ñù‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÄ‚ñò‚ñÄ‚ñÑ‚ñÄ‚ñÄ‚ñÑ‚ñö‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ‚ñû‚ñÑ‚ñö‚ñÑ‚ñÄ‚ñÑ‚ñö‚ñÑ‚ñÑ‚ñû‚ñÑ‚ñû‚ñÑ‚ñö‚ñÄ‚ñö‚ñÄ‚ñö‚ñû‚ñû‚ñÄ‚ñÄ‚ñÄ‚ñû‚ñÑ‚ñÄ‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñû‚ñÄ‚ñÄ‚îÇ\n      ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n        2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_dt                           train/iter\n[2024-11-28 13:44:52.888254][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dt.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dt.txt\n                           train_dtf [2024-11-28-134452]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.00296‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n0.00257‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n0.00219‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n0.00181‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n0.00142‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n0.00104‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå            ‚ñó    ‚ññ                  ‚ñü                 ‚ñó  ‚ññ       ‚îÇ\n       ‚îÇ‚ñù‚ññ‚ñó   ‚ñó‚ñû‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñó‚ñò‚ñö‚ñÑ‚ñó‚ñü‚ñö‚ñü‚ñû‚ñÑ‚ñå‚ñó ‚ñû‚ñÄ‚ñÑ‚ñó ‚ññ‚ñó ‚ñÑ‚ññ‚ñó ‚ñõ‚ñÑ‚ñü   ‚ñó ‚ññ‚ññ‚ñü ‚ññ‚ññ‚ñó‚ñÑ‚ñÄ‚ññ‚ñõ‚ñÑ‚ñü‚ñù‚ñö‚ñÑ‚ññ‚ññ‚ñû‚ñö‚ññ‚îÇ\n0.00065‚î§ ‚ñù‚ñò‚ñÄ‚ñÄ‚ñÄ‚ñò     ‚ñÄ   ‚ñò   ‚ñò ‚ñù‚ñò‚ñÄ  ‚ñù‚ñå‚ñÄ‚ñù‚ñÄ‚ñû ‚ñù‚ñò‚ñÄ‚ñò  ‚ñÄ‚ñö‚ñÄ‚ñò‚ñÄ‚ñú‚ñù‚ñò‚ñÄ‚ñú‚ñù‚ñò  ‚ñù‚ñò ‚ñù   ‚ñù‚ñù‚ñò ‚ñù‚îÇ\n       ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n         2 5  11 16 20  27 31 36   43 48 53 57 61  68  74   81 86  91  98\ntrain_dtf                           train/iter\n[2024-11-28 13:44:52.904574][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtf.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtf.txt\n                          train_dtb [2024-11-28-134452]\n      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n0.0168‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0144‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0120‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0096‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0072‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n0.0048‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñö      ‚ññ                                                           ‚îÇ\n0.0024‚î§ ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñû‚ñù‚ñÄ‚ñÄ‚ñÑ‚ñû‚ñÑ‚ñö‚ñû‚ñö‚ñÑ‚ñö‚ñû‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ‚ñû‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÄ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñû‚ñÄ‚ñû‚ñÑ‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñÑ‚ñû‚ñö‚ñû‚îÇ\n      ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n        2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_dtb                          train/iter\n[2024-11-28 13:44:52.920733][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtb.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtb.txt\n                         train_loss [2024-11-28-134452]\n      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n1821.1‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n1575.1‚î§‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñå                                                                  ‚îÇ\n      ‚îÇ‚ñö                                                                  ‚îÇ\n1329.0‚î§‚ñê                                                                  ‚îÇ\n      ‚îÇ‚ñù‚ññ                                                                 ‚îÇ\n1082.9‚î§ ‚ñå                                                                 ‚îÇ\n      ‚îÇ ‚ñê                                                                 ‚îÇ\n      ‚îÇ ‚ñù‚ññ                                                                ‚îÇ\n 836.8‚î§  ‚ñö                                                                ‚îÇ\n      ‚îÇ   ‚ñÄ‚ññ                                                              ‚îÇ\n      ‚îÇ    ‚ñù‚ñÄ‚ñö‚ñÑ‚ñÑ‚ñÑ ‚ññ                                                       ‚îÇ\n 590.7‚î§          ‚ñÄ‚ñù‚ñÄ‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ññ                                             ‚îÇ\n      ‚îÇ                     ‚ñù‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ                              ‚îÇ\n      ‚îÇ                                     ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñö‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ  ‚ñó            ‚îÇ\n 344.7‚î§                                                    ‚ñÄ‚ñÄ‚ñò‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ\n      ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n        2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_loss                         train/iter\n[2024-11-28 13:44:52.939625][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_loss.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_loss.txt\n                           train_sps [2024-11-28-134452]\n       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n21038.9‚î§  ‚ññ‚ñó‚ñÑ‚ñû‚ññ                 ‚ññ   ‚ññ  ‚ñó‚ñö   ‚ññ    ‚ñó   ‚ñó                 ‚ññ  ‚îÇ\n       ‚îÇ ‚ñê‚ñù‚ñò  ‚ñå   ‚ññ‚ñó‚ñå  ‚ñó‚ñå‚ñó ‚ñó‚ñå‚ñó‚ñû‚ñü‚ñå  ‚ñû‚ñå‚ñó‚ñû‚ñü ‚ñú ‚ñü‚ñù‚ññ ‚ñÑ‚ñÄ‚ñÄ‚ñÑ‚ñÑ‚ñö‚ñõ‚ñÑ‚ñå‚ñÑ‚ñö‚ñó‚ñô‚ñö‚ñó‚ññ ‚ññ‚ñü   ‚ñû‚ñû‚ñå  ‚îÇ\n       ‚îÇ ‚ñå    ‚ñå ‚ñÑ‚ñû‚ñù‚ñü‚ñö‚ñÑ‚ñû‚ñÄ‚ñö‚ñú‚ñû‚ñò‚ñù‚ñò ‚ñù‚ñå ‚ñó‚ñò‚ñô‚ñÄ‚ñå  ‚ñê‚ñê  ‚ñö‚ñÄ‚ñà     ‚ñò ‚ñú  ‚ñò‚ñù ‚ñò‚ñù‚ñü‚ñù‚ñú ‚ñó‚ñÄ‚ñò ‚ñå‚ñó‚ñö‚îÇ\n18073.5‚î§ ‚ñå    ‚ñå‚ñê     ‚ñê‚ñå  ‚ñê‚ñå     ‚ñù‚ñÄ‚ñû ‚ñù    ‚ñù‚ñå    ‚ñù               ‚ñù ‚ñù‚ñÑ‚ñò   ‚ñù‚ñò ‚îÇ\n       ‚îÇ‚ñê     ‚ñö‚ñò      ‚ñò  ‚ñù‚ñå                                               ‚îÇ\n       ‚îÇ‚ñê                                                                 ‚îÇ\n15108.1‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n12142.7‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n 9177.3‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n 6211.9‚î§‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n       ‚îÇ‚ñå                                                                 ‚îÇ\n 3246.6‚î§‚ñå                                                                 ‚îÇ\n       ‚îî‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò\n         2 5  11 16 20  27 31 36   43 48 53 57 61  68  74   81 86  91  98\ntrain_sps                           train/iter\n[2024-11-28 13:44:52.955997][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_sps.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_sps.txt\n[2024-11-28 13:44:53.002178][INFO][test_dist.py:246] - dataset=&lt;xarray.Dataset&gt; Size: 5kB\nDimensions:     (draw: 99)\nCoordinates:\n  * draw        (draw) int64 792B 0 1 2 3 4 5 6 7 8 ... 91 92 93 94 95 96 97 98\nData variables:\n    train_iter  (draw) int64 792B 1 2 3 4 5 6 7 8 9 ... 92 93 94 95 96 97 98 99\n    train_dt    (draw) float64 792B 0.01971 0.004083 ... 0.003326 0.003474\n    train_dtf   (draw) float64 792B 0.002959 0.0008221 ... 0.0008038 0.0007404\n    train_dtb   (draw) float64 792B 0.01675 0.003261 ... 0.002522 0.002733\n    train_loss  (draw) float32 396B 1.821e+03 1.348e+03 ... 347.3 346.5\n    train_sps   (draw) float64 792B 3.247e+03 1.567e+04 ... 1.925e+04 1.842e+04\n\n  _     ._   __/__   _ _  _  _ _/_   Recorded: 13:44:35  Samples:  2127\n /_//_/// /_\\ / //_// / //_'/ //     Duration: 17.440    CPU time: 29.088\n/   _/                      v5.0.0\n\nProfile at /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/profile.py:101\n\n17.440 &lt;module&gt;  ezpz/test_dist.py:1\n‚îî‚îÄ 17.440 main  ezpz/test_dist.py:177\n   ‚îú‚îÄ 10.558 build_model_and_optimizer  ezpz/test_dist.py:136\n   ‚îÇ  ‚îî‚îÄ 10.547 DistributedDataParallel.__init__  torch/nn/parallel/distributed.py:622\n   ‚îÇ     ‚îî‚îÄ 10.502 _verify_param_shape_across_processes  torch/distributed/utils.py:266\n   ‚îÇ        ‚îî‚îÄ 10.502 PyCapsule._verify_params_across_processes  &lt;built-in&gt;\n   ‚îú‚îÄ 3.256 History.plot_all  ezpz/history.py:636\n   ‚îÇ  ‚îú‚îÄ 1.809 savefig  matplotlib/pyplot.py:974\n   ‚îÇ  ‚îÇ     [38 frames hidden]  matplotlib, PIL, &lt;built-in&gt;, numpy\n   ‚îÇ  ‚îú‚îÄ 0.895 &lt;module&gt;  seaborn/__init__.py:1\n   ‚îÇ  ‚îÇ     [8 frames hidden]  seaborn, scipy\n   ‚îÇ  ‚îú‚îÄ 0.227 History.get_dataset  ezpz/history.py:752\n   ‚îÇ  ‚îÇ  ‚îî‚îÄ 0.183 History.to_DataArray  ezpz/history.py:712\n   ‚îÇ  ‚îÇ     ‚îî‚îÄ 0.183 DataArray.__init__  xarray/core/dataarray.py:437\n   ‚îÇ  ‚îÇ           [5 frames hidden]  xarray\n   ‚îÇ  ‚îî‚îÄ 0.179 make_ridgeplots  ezpz/plot.py:900\n   ‚îú‚îÄ 2.016 _forward_step  ezpz/test_dist.py:193\n   ‚îÇ  ‚îî‚îÄ 1.963 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528\n   ‚îÇ        [4 frames hidden]  torch\n   ‚îÇ           1.945 Network._call_impl  torch/nn/modules/module.py:1534\n   ‚îÇ           ‚îî‚îÄ 1.943 Network.forward  ezpz/test_dist.py:128\n   ‚îÇ              ‚îî‚îÄ 1.943 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528\n   ‚îÇ                    [6 frames hidden]  torch, &lt;built-in&gt;\n   ‚îú‚îÄ 0.716 &lt;module&gt;  ambivalent/__init__.py:1\n   ‚îÇ     [20 frames hidden]  ambivalent, requests, urllib3, http, ...\n   ‚îî‚îÄ 0.495 _backward_step  ezpz/test_dist.py:198\n      ‚îî‚îÄ 0.457 Tensor.backward  torch/_tensor.py:466\n            [3 frames hidden]  torch, &lt;built-in&gt;\n\n\n[2024-11-28 13:44:54.356012][INFO][profile.py:115] - Saving pyinstrument profile output to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles\n[2024-11-28 13:44:54.356642][INFO][profile.py:123] - PyInstrument profile saved (as html) to:  /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-11-28-134454.html\n[2024-11-28 13:44:54.357100][INFO][profile.py:131] - PyInstrument profile saved (as text) to:  /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-11-28-134454.txt\n[2024-11-28 13:44:54.716119][INFO][profile.py:143] - Finished with pyinstrument profiler. Took: 17.44008s\n[2024-11-28 13:44:54.717891][INFO][test_dist.py:269] - [0] runtime=73.419312s\nwandb: üöÄ View run driven-wind-683 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l\nwandb: Find logs at: ../../../../../../lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/wandb/run-20241128_134434-4mwyy84l/logs\nApplication ecd9868b resources: utime=2078s stime=374s maxrss=2509188KB inblock=786752 oublock=12104 minflt=13378945 majflt=181980 nvcsw=1704995 nivcsw=216931\ntook: 0h:01m:32s\n\n\n \n\nüõ†Ô∏è Setup Python\nezpz_setup_python\nThis will:\n\nAutomatically load and activate conda using the ezpz_setup_conda function.\nHow this is done, in practice, varies from machine to machine:\n\nALCF3: Automatically load the most recent conda module and activate the base environment.\nFrontier: Load the appropriate AMD modules (e.g.¬†rocm, RCCL, etc.), and activate base conda\nPerlmutter: Load the appropriate pytorch module and activate environment\nUnknown: In this case, we will look for a conda, mamba, or micromamba executable, and if found, use that to activate the base environment.\n\n\n\n\n\n\n\nTipUsing your own conda\n\n\n\n\n\nIf you are already in a conda environment when calling ezpz_setup_python then it will try and use this instead.\nFor example, if you have a custom conda env at ~/conda/envs/custom, then this would bootstrap the custom conda environment and create the virtual env in venvs/custom/\n\n\n\n\n\nBuild (or activate, if found) a virtual environment on top of (the active) base conda environment.\nBy default, it will try looking in:\n\n$PBS_O_WORKDIR, otherwise\n${SLURM_SUBMIT_DIR}, otherwise\n$(pwd)\n\nfor a nested folder named \"venvs/${CONDA_NAME}\".\nIf this doesn‚Äôt exist, it will attempt to create a new virtual environment at this location using:\npython3 -m venv venvs/${CONDA_NAME} --system-site-packages\n(where we‚Äôve pulled in the --system-site-packages from conda).\n\n\n\nüß∞ Setup Job\nezpz_setup_job\nNow that we are in a suitable python environment, we need to construct the command that we will use to run python on each of our acceleratorss.\nTo do this, we need a few things:\n\nWhat machine we‚Äôre on (and what scheduler is it using i.e.¬†{PBS, SLURM})\nHow many nodes are available in our active job\nHow many GPUs are on each of those nodes\nWhat type of GPUs are they\n\nWith this information, we can then use mpi{exec,run} or srun to launch python across all of our accelerators.\nAgain, how this is done will vary from machine to machine and will depend on the job scheduler in use.\nTo identify where we are, we look at our $(hostname) and see if we‚Äôre running on one of the known machines:\n\nALCF4: Using PBS Pro via qsub and mpiexec / mpirun.\n\nx4*: Aurora\nAurora: x4* (or aurora* on login nodes)\nSunspot: x1* (or uan*)\nSophia: sophia-*\nPolaris / Sirius: x3*\n\nto determine between the two, we look at \"${PBS_O_HOST}\"\n\n\n\n\nOLCF: Using Slurm via sbatch / srun.\n\nfrontier*: Frontier, using Slurm\nnid*: Perlmutter, using Slurm\n\nUnknown machine: If $(hostname) does not match one of these patterns we assume that we are running on an unknown machine and will try to use mpirun as our generic launch command\nOnce we have this, we can:\n\nGet PBS_NODEFILE from $(hostname):\n\nezpz_qsme_running: For each (running) job owned by ${USER}, print out both the jobid as well as a list of hosts the job is running on, e.g.:\n&lt;jobid0&gt; host00 host01 host02 host03 ...\n&lt;jobid1&gt; host10 host11 host12 host13 ...\n...\nezpz_get_pbs_nodefile_from_hostname: Look for $(hostname) in the output from the above command to determine our ${PBS_JOBID}.\nOnce we‚Äôve identified our ${PBS_JOBID} we then know the location of our ${PBS_NODEFILE} since they are named according to:\njobid=$(ezpz_qsme_running | grep \"$(hostname)\" | awk '{print $1}')\nprefix=/var/spool/pbs/aux\nmatch=$(/bin/ls \"${prefix}\" | grep \"${jobid}\")\nhostfile=\"${prefix}/${match}\"\n\nIdentify number of available accelerators:",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üçã <code>ezpz</code> @ ALCF"
    ]
  },
  {
    "objectID": "posts/ezpz-at-alcf/index.html#python-library",
    "href": "posts/ezpz-at-alcf/index.html#python-library",
    "title": "üçã ezpz @ ALCF",
    "section": "üêç Python Library",
    "text": "üêç Python Library\nTo install5:\npython3 -m pip install -e \"git+https://github.com/saforem2/ezpz#egg=ezpz\" --require-virtualenv\n\nüìÇ ezpz / src / ezpz/\n\nüìÇ bin/:\n\nutils.sh: Shell utilities for ezpz\n\nüìÇ conf/:\n\n‚öôÔ∏è config.yaml: Default TrainConfig object\n‚öôÔ∏è ds_config.json: DeepSpeed configuration\n\nüìÇ log/: Logging configuration.\nüêç __about__.py: Version information\nüêç __init__.py: Main module\nüêç __main__.py: Entry point\nüêç configs.py: Configuration module\nüêçcria.py: Baby Llama\nüêçdist.py: Distributed training module\nüêçhistory.py: History module\nüêçjobs.py: Jobs module\nüêçmodel.py: Model module\nüêçplot.py: Plot modul\nüêçprofile.py: Profile module\nüêçruntime.py: Runtime module\nüêçtest.py: Test module\nüêçtest_dist.py: Distributed training test module\nüêçtrain.py: train module\nüêçtrainer.py: trainer module\nüêçutils.py: utility module\n\n\nüìÇ /ezpz/src/ezpz/\n‚î£‚îÅ‚îÅ üìÇ bin/\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ affinity.sh\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ getjobenv\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ savejobenv\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ saveslurmenv\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ setup.sh\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ train.sh\n‚îÉ   ‚îó‚îÅ‚îÅ üìÑ utils.sh\n‚î£‚îÅ‚îÅ üìÇ conf/\n‚îÉ   ‚î£‚îÅ‚îÅ üìÇ hydra/\n‚îÉ   ‚îÉ   ‚îó‚îÅ‚îÅ üìÇ job_logging/\n‚îÉ   ‚îÉ       ‚î£‚îÅ‚îÅ ‚öôÔ∏è colorlog1.yaml\n‚îÉ   ‚îÉ       ‚î£‚îÅ‚îÅ ‚öôÔ∏è custom.yaml\n‚îÉ   ‚îÉ       ‚îó‚îÅ‚îÅ ‚öôÔ∏è enrich.yaml\n‚îÉ   ‚î£‚îÅ‚îÅ üìÇ logdir/\n‚îÉ   ‚îÉ   ‚îó‚îÅ‚îÅ ‚öôÔ∏è default.yaml\n‚îÉ   ‚î£‚îÅ‚îÅ ‚öôÔ∏è config.yaml\n‚îÉ   ‚î£‚îÅ‚îÅ üìÑ ds_config.json\n‚îÉ   ‚îó‚îÅ‚îÅ ‚öôÔ∏è ds_config.yaml\n‚î£‚îÅ‚îÅ üìÇ log/\n‚îÉ   ‚î£‚îÅ‚îÅ üìÇ conf/\n‚îÉ   ‚îÉ   ‚îó‚îÅ‚îÅ üìÇ hydra/\n‚îÉ   ‚îÉ       ‚îó‚îÅ‚îÅ üìÇ job_logging/\n‚îÉ   ‚îÉ           ‚îó‚îÅ‚îÅ ‚öôÔ∏è enrich.yaml\n‚îÉ   ‚î£‚îÅ‚îÅ üêç __init__.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç __main__.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç config.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç console.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç handler.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç style.py\n‚îÉ   ‚î£‚îÅ‚îÅ üêç test.py\n‚îÉ   ‚îó‚îÅ‚îÅ üêç test_log.py\n‚î£‚îÅ‚îÅ üêç __about__.py\n‚î£‚îÅ‚îÅ üêç __init__.py\n‚î£‚îÅ‚îÅ üêç __main__.py\n‚î£‚îÅ‚îÅ üêç configs.py\n‚î£‚îÅ‚îÅ üêç cria.py\n‚î£‚îÅ‚îÅ üêç dist.py\n‚î£‚îÅ‚îÅ üêç history.py\n‚î£‚îÅ‚îÅ üêç jobs.py\n‚î£‚îÅ‚îÅ üêç loadjobenv.py\n‚î£‚îÅ‚îÅ üêç model.py\n‚î£‚îÅ‚îÅ üêç plot.py\n‚î£‚îÅ‚îÅ üêç profile.py\n‚î£‚îÅ‚îÅ üêç runtime.py\n‚î£‚îÅ‚îÅ üêç savejobenv.py\n‚î£‚îÅ‚îÅ üêç test.py\n‚î£‚îÅ‚îÅ üêç test_dist.py\n‚î£‚îÅ‚îÅ üêç train.py\n‚î£‚îÅ‚îÅ üêç trainer.py\n‚îó‚îÅ‚îÅ üêç utils.py",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üçã <code>ezpz</code> @ ALCF"
    ]
  },
  {
    "objectID": "posts/ezpz-at-alcf/index.html#footnotes",
    "href": "posts/ezpz-at-alcf/index.html#footnotes",
    "title": "üçã ezpz @ ALCF",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlus this is useful for tab-completions in your shell, e.g.:\n$ ezpz_&lt;TAB&gt;\nezpz_check_and_kill_if_running\nezpz_get_dist_launch_cmd\nezpz_get_job_env\n--More--\n‚Ü©Ô∏é\nThis is system dependent. See ezpz_setup_conda‚Ü©Ô∏é\nAny of {Aurora, Polaris, Sophia, Sunspot, Sirius}‚Ü©Ô∏é\nAt ALCF, if our $(hostname) starts with x*, we‚Äôre on a compute node.‚Ü©Ô∏é\nNote the --require-virtualenv isn‚Äôt strictly required, but I highly recommend to always try and work within a virtual environment, when possible.‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üçã <code>ezpz</code> @ ALCF"
    ]
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "üì¨ Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        When - Oldest\n      \n      \n        When - Newest\n      \n      \n        What\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nWhat\n\n\n\nWhen\n\n\n\nUpdated\n\n\n\nCategories\n\n\n\n\n\n\n\n\nüèóÔ∏è Building PyTorch 2.8 from Source on Aurora\n\n\n2025-06-14\n\n\n2025-06-15\n\n\npytorch, Aurora\n\n\n\n\n\n\nüßú‚Äç‚ôÄÔ∏è Mermaid\n\n\n2025-06-02\n\n\n2025-06-03\n\n\nstyle, personal\n\n\n\n\n\n\nüì∞ Nice Headings\n\n\n2025-06-01\n\n\n2025-06-01\n\n\nstyle, personal\n\n\n\n\n\n\nüöß Frameworks Issue with numpy &gt; 2\n\n\n2025-05-03\n\n\n2025-06-07\n\n\nframeworks, Aurora, pytorch, bug\n\n\n\n\n\n\nüî• Building PyTorch 2.6 from Source on Aurora\n\n\n2025-04-28\n\n\n2025-06-14\n\n\npytorch, Aurora\n\n\n\n\n\n\nüë§ R√©sum√©\n\n\n2025-04-26\n\n\n2025-05-18\n\n\nCV, personal, r√©sum√©\n\n\n\n\n\n\nü™õ Torchtune on Aurora\n\n\n2025-03-23\n\n\n2025-03-29\n\n\nAurora, pytorch, bug\n\n\n\n\n\n\nüöë Torchtune Patch on Aurora\n\n\n2025-03-23\n\n\n2025-05-01\n\n\nAurora, pytorch, bug\n\n\n\n\n\n\nü´• svgbob\n\n\n2024-11-15\n\n\n2025-05-01\n\n\ndiagrams, style\n\n\n\n\n\n\nüíæ Converting Checkpoints\n\n\n2024-10-17\n\n\n2025-04-28\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüèîÔ∏è Spike Skipper\n\n\n2024-09-17\n\n\n2025-03-29\n\n\nAuroraGPT\n\n\n\n\n\n\nüçã ezpz @ ALCF\n\n\n2024-08-23\n\n\n2025-03-29\n\n\nezpz, ML, ai4science\n\n\n\n\n\n\nüìù ezpz-v1\n\n\n2024-08-23\n\n\n2025-05-01\n\n\nezpz, ML, ai4science\n\n\n\n\n\n\nüíÖ How to Make Dope Slides\n\n\n2024-08-13\n\n\n2025-05-04\n\n\nslides, revealjs, style\n\n\n\n\n\n\nüé∞ Deterministic flash-attn\n\n\n2024-06-17\n\n\n2025-04-26\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüì∏ flash-attn on Sunspot\n\n\n2024-06-17\n\n\n2025-04-26\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüèéÔ∏è Megatron-DeepSpeed on Intel XPU\n\n\n2024-06-15\n\n\n2025-04-26\n\n\nALCF, AuroraGPT, Aurora, Megatron-DeepSpeed, XPU\n\n\n\n\n\n\nüêõ mpi4py bug on Sunspot\n\n\n2024-05-25\n\n\n2025-03-29\n\n\nAuroraGPT\n\n\n\n\n\n\nüé≤ MCMC + Diffusion Sampling\n\n\n2024-04-15\n\n\n2025-04-07\n\n\nai4science, lqcd, mcmc, diffusion\n\n\n\n\n\n\nüê¢ Starting Up Distributed Training on Aurora\n\n\n2024-03-21\n\n\n2025-04-07\n\n\nAuroraGPT\n\n\n\n\n\n\nüöÇ Loooooooong Sequence Lengths\n\n\n2024-02-12\n\n\n2025-03-29\n\n\nAuroraGPT\n\n\n\n\n\n\nüèÅ l2hmc Example: 2D U(1)\n\n\n2024-02-12\n\n\n2025-04-07\n\n\nai4science, lqcd, mcmc\n\n\n\n\n\n\nüé¢ l2hmc-qcd Example: 2D U(1)\n\n\n2023-12-14\n\n\n2025-06-09\n\n\nai4science, lqcd, mcmc\n\n\n\n\n\n\nüî≥ l2hmc-qcd Example: 4D SU(3)\n\n\n2023-12-06\n\n\n2025-05-02\n\n\nai4science, lqcd, mcmc\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman,\n  author = {Foreman, Sam},\n  title = {üì¨ {Posts}},\n  url = {https://samforeman.me/posts/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. n.d. ‚Äúüì¨ Posts.‚Äù https://samforeman.me/posts/.",
    "crumbs": [
      "talks",
      "üì¨ Posts"
    ]
  },
  {
    "objectID": "posts/jupyter/l2hmc/4dSU3/index.html#imports",
    "href": "posts/jupyter/l2hmc/4dSU3/index.html#imports",
    "title": "üî≥ l2hmc-qcd Example: 4D SU(3)",
    "section": "Imports",
    "text": "Imports\n# %matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nimport os\nos.environ['COLORTERM'] = 'truecolor'\nimport lovely_tensors as lt\nlt.monkey_patch()\nlt.set_config(color=False)\n# automatically detect and reload local changes to modules\n%load_ext autoreload\n%autoreload 2\nimport ezpz\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import FigAxes\nimport ambivalent\nplt.style.use(ambivalent.STYLES['ambivalent'])\n#set_plot_style()\n\n\nOutput:\n\n\n[2025-04-30 15:42:06,938] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to mps (auto detect)\nW0430 15:42:09.268000 24193 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\nUsing device: cpu\n\nFailed to download font: IBM Plex Sans, skipping! Failed to download font: IBM Plex Sans Condensed, skipping!\nFailed to download font: IBM Plex Serif, skipping!\n\n\nimport ezpz\nfrom pathlib import Path\nfrom typing import Optional\nfrom rich import print\n\nimport lovely_tensors as lt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport yaml\n\n# from l2hmc.utils.dist import setup_torch\nseed = np.random.randint(2 ** 32)\nprint(f\"seed: {seed}\")\n\n_ = ezpz.setup_torch(seed=seed)\ntorch.set_default_dtype(torch.float64)\n\nlogger = ezpz.get_logger()\n\nimport l2hmc.group.su3.pytorch.group as g\nfrom l2hmc.common import grab_tensor, print_dict\nfrom l2hmc.configs import dict_to_list_of_overrides, get_experiment\nfrom l2hmc.experiment.pytorch.experiment import Experiment, evaluate  # noqa\n\n\nOutput:\n\n\nseed: 3107208906\n\n[2025-04-30 15:42:15][I][ezpz/dist:557] Using get_torch_device_type()='mps' with backend='gloo'\n\n[2025-04-30 15:42:15][I][ezpz/dist:873] Using device='mps' with backend='ddp' + 'gloo' for distributed training.\n\n[2025-04-30 15:42:15][I][ezpz/dist:923] ['Sams-MacBook-Pro-2.local'][0/0]\n\n\n\nfrom l2hmc.utils.plot_helpers import (  # noqa\n    plot_scalar,\n    plot_chains,\n    plot_leapfrogs\n)\n\ndef savefig(fig: plt.Figure, fname: str, outdir: os.PathLike):\n    pngfile = Path(outdir).joinpath(f\"pngs/{fname}.png\")\n    svgfile = Path(outdir).joinpath(f\"svgs/{fname}.svg\")\n    pngfile.parent.mkdir(exist_ok=True, parents=True)\n    svgfile.parent.mkdir(exist_ok=True, parents=True)\n    fig.savefig(svgfile, transparent=True, bbox_inches='tight')\n    fig.savefig(pngfile, transparent=True, bbox_inches='tight', dpi=300)\n\ndef plot_metrics(metrics: dict, title: Optional[str] = None, **kwargs):\n    outdir = Path(f\"./plots-4dSU3/{title}\")\n    outdir.mkdir(exist_ok=True, parents=True)\n    for key, val in metrics.items():\n        fig, ax = plot_metric(val, name=key, **kwargs)\n        if title is not None:\n            ax.set_title(title)\n        console.log(f\"Saving {key} to {outdir}\")\n        savefig(fig, f\"{key}\", outdir=outdir)\n        plt.show()\n\ndef plot_metric(\n    metric: torch.Tensor,\n    name: Optional[str] = None,\n    **kwargs,\n):\n    assert len(metric) &gt; 0\n    if isinstance(metric[0], (int, float, bool, np.floating)):\n        y = np.stack(metric)\n        return plot_scalar(y, ylabel=name, **kwargs)\n    element_shape = metric[0].shape\n    if len(element_shape) == 2:\n        y = grab_tensor(torch.stack(metric))\n        return plot_leapfrogs(y, ylabel=name)\n    if len(element_shape) == 1:\n        y = grab_tensor(torch.stack(metric))\n        return plot_chains(y, ylabel=name, **kwargs)\n    if len(element_shape) == 0:\n        y = grab_tensor(torch.stack(metric))\n        return plot_scalar(y, ylabel=name, **kwargs)\n    raise ValueError",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "L2hmc",
      "üî≥ <code>l2hmc-qcd</code> Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/jupyter/l2hmc/4dSU3/index.html#load-config-build-experiment",
    "href": "posts/jupyter/l2hmc/4dSU3/index.html#load-config-build-experiment",
    "title": "üî≥ l2hmc-qcd Example: 4D SU(3)",
    "section": "Load config + build Experiment",
    "text": "Load config + build Experiment\nfrom rich import print\n\nfrom l2hmc.configs import CONF_DIR\nsu3conf = Path(f\"{CONF_DIR}/su3test.yaml\")\nwith su3conf.open('r') as stream:\n    conf = dict(yaml.safe_load(stream))\nimport json\nfrom rich import print_json\nprint_json(json.dumps(conf, indent=4, sort_keys=True))\noverrides = dict_to_list_of_overrides(conf)\n\n\nOutput:\n\n\n{\n  \"annealing_schedule\": {\n    \"beta_final\": 6.0,\n    \"beta_init\": 6.0\n  },\n  \"backend\": \"DDP\",\n  \"conv\": \"none\",\n  \"dynamics\": {\n    \"eps\": 0.01,\n    \"eps_fixed\": false,\n    \"group\": \"SU3\",\n    \"latvolume\": [\n        4,\n        4,\n        4,\n        4\n    ],\n    \"merge_directions\": true,\n    \"nchains\": 8,\n    \"nleapfrog\": 4,\n    \"use_separate_networks\": false,\n    \"use_split_xnets\": false,\n    \"verbose\": true\n  },\n  \"framework\": \"pytorch\",\n  \"init_aim\": false,\n  \"init_wandb\": false,\n  \"learning_rate\": {\n    \"clip_norm\": 1.0,\n    \"lr_init\": \"1e-04\"\n  },\n  \"loss\": {\n    \"aux_weight\": 0.0,\n    \"charge_weight\": 0.0,\n    \"plaq_weight\": 0.1,\n    \"rmse_weight\": 0.1,\n    \"use_mixed_loss\": true\n  },\n  \"net_weights\": {\n    \"v\": {\n        \"q\": 1.0,\n        \"s\": 1.0,\n        \"t\": 1.0\n    },\n    \"x\": {\n        \"q\": 1.0,\n        \"s\": 0.0,\n        \"t\": 1.0\n    }\n  },\n  \"network\": {\n    \"activation_fn\": \"tanh\",\n    \"dropout_prob\": 0.0,\n    \"units\": [\n        256\n    ],\n    \"use_batch_norm\": false\n  },\n  \"restore\": false,\n  \"save\": false,\n  \"steps\": {\n    \"log\": 1,\n    \"nepoch\": 10,\n    \"nera\": 1,\n    \"print\": 1,\n    \"test\": 50\n  },\n  \"use_tb\": false,\n  \"use_wandb\": false\n}\n\n\n\nptExpSU3 = get_experiment(overrides=[*overrides], build_networks=True)\n\n# console.print(ptExpSU3.config)\nstate = ptExpSU3.trainer.dynamics.random_state(6.0)\nlogger.info(f\"checkSU(state.x): {g.checkSU(state.x)}\")\nlogger.info(f\"checkSU(state.x): {g.checkSU(g.projectSU(state.x))}\")\nassert isinstance(state.x, torch.Tensor)\nassert isinstance(state.beta, torch.Tensor)\nassert isinstance(ptExpSU3, Experiment)\n\n\nOutput:\n\n\n[2025-04-30 15:42:54][I][utils/dist:229:l2hmc.utils.dist] Caught MASTER_PORT:1234 from environment!\n\n[2025-04-30 15:42:54][I][utils/dist:229:l2hmc.utils.dist] Caught MASTER_PORT:1234 from environment!\n\n[2025-04-30 15:42:54][W][pytorch/trainer:467:l2hmc.trainers.pytorch.trainer] Using torch.float32 on cpu!\n\n[2025-04-30 15:42:54][W][pytorch/trainer:467:l2hmc.trainers.pytorch.trainer] Using `torch.optim.Adam` optimizer\n\n[2025-04-30 15:42:54][I][pytorch/trainer:305:l2hmc.trainers.pytorch.trainer] num_params in model: 27880456\n\n[2025-04-30 15:42:55][W][pytorch/trainer:271:l2hmc.trainers.pytorch.trainer] logging with freq 1 for wandb.watch\n\n[2025-04-30 15:42:55][I][ipykernel_24193/1455121896:5:ezpz.log] checkSU(state.x): (tensor[8] f64 x‚àà[1.374e-14, 2.051e-13] Œº=5.186e-14 œÉ=6.363e-14 [2.328e-14, 1.850e-14, 5.587e-14, 2.051e-13, 4.692e-14, 1.374e-14, 1.985e-14, 3.163e-14], tensor[8] f64 x‚àà[2.012e-13, 6.500e-12] Œº=1.497e-12 œÉ=2.096e-12 [4.096e-13, 4.134e-13, 1.774e-12, 6.500e-12, 1.446e-12, 2.012e-13, 4.689e-13, 7.596e-13])\n\n[2025-04-30 15:42:55][I][ipykernel_24193/1455121896:6:ezpz.log] checkSU(state.x): (tensor[8] f64 x‚àà[2.705e-16, 2.883e-16] Œº=2.798e-16 œÉ=5.148e-18 [2.763e-16, 2.705e-16, 2.803e-16, 2.883e-16, 2.825e-16, 2.819e-16, 2.804e-16, 2.783e-16], tensor[8] f64 x‚àà[8.900e-16, 9.337e-16] Œº=9.098e-16 œÉ=1.819e-17 [8.903e-16, 9.331e-16, 9.147e-16, 8.903e-16, 9.337e-16, 9.114e-16, 8.900e-16, 9.147e-16])\n\n\n\n# from l2hmc.utils.plot_helpers import set_plot_style\n# set_plot_style()\n\nfrom l2hmc.common import get_timestamp\nTSTAMP = get_timestamp()\nOUTPUT_DIR = Path(f\"./outputs/pt4dSU3/{TSTAMP}\")\nHMC_DIR = OUTPUT_DIR.joinpath('hmc')\nEVAL_DIR = OUTPUT_DIR.joinpath('eval')\nTRAIN_DIR = OUTPUT_DIR.joinpath('train')\nHMC_DIR.mkdir(exist_ok=True, parents=True)\nEVAL_DIR.mkdir(exist_ok=True, parents=True)\nTRAIN_DIR.mkdir(exist_ok=True, parents=True)\nptExpSU3.trainer.print_grads_and_weights()\nlogger.info(ptExpSU3.config)\n#console.print(ptExpSU3.config)\n\n\nOutput:\n\n\n[2025-04-30 15:43:03][I][pytorch/trainer:2000:l2hmc.trainers.pytorch.trainer] --------------------------------------------------------------------------------\n\n[2025-04-30 15:43:03][I][pytorch/trainer:2001:l2hmc.trainers.pytorch.trainer] GRADS:\n\n[2025-04-30 15:43:03][I][l2hmc/common:97] networks.xnet.input_layer.xlayer.weight: None None\nNone\nnetworks.xnet.input_layer.xlayer.bias: None None\nNone\nnetworks.xnet.input_layer.vlayer.weight: None None\nNone\nnetworks.xnet.input_layer.vlayer.bias: None None\nNone\nnetworks.xnet.scale.coeff: None None\nNone\nnetworks.xnet.scale.layer.weight: None None\nNone\nnetworks.xnet.scale.layer.bias: None None\nNone\nnetworks.xnet.transf.coeff: None None\nNone\nnetworks.xnet.transf.layer.weight: None None\nNone\nnetworks.xnet.transf.layer.bias: None None\nNone\nnetworks.xnet.transl.weight: None None\nNone\nnetworks.xnet.transl.bias: None None\nNone\nnetworks.vnet.input_layer.xlayer.weight: None None\nNone\nnetworks.vnet.input_layer.xlayer.bias: None None\nNone\nnetworks.vnet.input_layer.vlayer.weight: None None\nNone\nnetworks.vnet.input_layer.vlayer.bias: None None\nNone\nnetworks.vnet.scale.coeff: None None\nNone\nnetworks.vnet.scale.layer.weight: None None\nNone\nnetworks.vnet.scale.layer.bias: None None\nNone\nnetworks.vnet.transf.coeff: None None\nNone\nnetworks.vnet.transf.layer.weight: None None\nNone\nnetworks.vnet.transf.layer.bias: None None\nNone\nnetworks.vnet.transl.weight: None None\nNone\nnetworks.vnet.transl.bias: None None\nNone\nxeps.0: None None\nNone\nxeps.1: None None\nNone\nxeps.2: None None\nNone\nxeps.3: None None\nNone\nveps.0: None None\nNone\nveps.1: None None\nNone\nveps.2: None None\nNone\nveps.3: None None\nNone\n\n[2025-04-30 15:43:03][I][pytorch/trainer:2003:l2hmc.trainers.pytorch.trainer] --------------------------------------------------------------------------------\n\n[2025-04-30 15:43:03][I][pytorch/trainer:2004:l2hmc.trainers.pytorch.trainer] WEIGHTS:\n\n[2025-04-30 15:43:03][I][l2hmc/common:97] networks.xnet.input_layer.xlayer.weight: torch.Size([256, 18432]) torch.float64\n[[-4.19951343e-03 -4.26238340e-03  2.35647156e-03 ...  1.68137878e-03\n  -1.50068399e-03  3.15863944e-03]\n [ 2.39342553e-04 -4.97551288e-03  7.26050381e-03 ... -5.64728922e-03\n  -5.55020874e-03  1.17323965e-03]\n [ 5.26405398e-03 -3.91491501e-03  7.14260998e-04 ... -6.31723398e-03\n   5.23567487e-03  2.05607864e-03]\n ...\n [ 6.68730979e-03 -6.91921820e-03  8.95772739e-05 ... -4.07246778e-03\n  -2.29316978e-03 -3.43056826e-03]\n [-1.77016491e-03 -1.95781418e-03 -5.01585640e-03 ... -6.46914302e-03\n   4.20147742e-03 -7.09234809e-03]\n [-1.94973833e-03 -7.26403514e-03  4.98051500e-04 ... -6.28795095e-03\n   6.79912449e-04 -9.21666063e-04]]\nnetworks.xnet.input_layer.xlayer.bias: torch.Size([256]) torch.float64\n[ 3.15653089e-03 -6.53747057e-03 -6.14933637e-03 -5.49529500e-03\n -4.48003873e-03 -7.03491801e-03 -6.56321877e-03  4.67182499e-03\n  4.36532234e-03 -5.36476346e-03 -6.09211776e-03 -7.10460550e-03\n -6.52009109e-03 -6.43876671e-03 -1.97297283e-03  5.79927976e-03\n -5.49722940e-03  6.75426645e-03  6.06732313e-03  2.56460577e-03\n -5.80235106e-03  1.03618414e-03  6.36349657e-04  1.60436063e-03\n -3.06399032e-05 -7.50359147e-04  4.36385955e-03  1.00302522e-03\n  7.32044498e-03 -1.43824191e-03 -2.50594005e-03 -6.82552956e-03\n -4.71028329e-03  1.71534301e-03  6.10709162e-03 -4.05667409e-03\n -2.30713007e-03 -5.12144947e-03 -7.15109109e-04 -4.44328498e-03\n -4.94695187e-04  3.15081409e-03 -2.37185464e-03 -1.91157742e-03\n  6.91548413e-03  3.81991132e-04 -4.31922342e-03 -1.98542428e-03\n  4.05912039e-03  1.92396383e-03  3.53810871e-03  6.53665668e-04\n -5.06483635e-04 -5.86019994e-03 -2.86685524e-03 -2.27205811e-03\n  7.25025555e-03 -5.94056580e-03 -1.54673733e-03  8.73715266e-04\n -4.36832096e-03  4.80786903e-03  1.69290306e-03 -1.38375220e-03\n  6.96793511e-03  5.39967604e-03 -4.38277881e-03  4.86837191e-03\n -4.63730538e-03 -2.72580171e-04  5.81442710e-03  1.45265237e-03\n  5.09906755e-03 -5.65087549e-03 -1.40143350e-03 -6.84733200e-03\n  1.19933276e-03  7.28487144e-03 -1.88899102e-03 -1.74111447e-03\n -2.23510673e-03  2.73357402e-03 -1.06047067e-03 -5.84367407e-04\n -1.07953771e-03 -7.04448438e-03  3.29054140e-03  1.94660675e-04\n -1.10677934e-03 -2.41696262e-03 -1.78325949e-03  1.03577164e-03\n  7.27804628e-03 -5.85394151e-03 -4.49392971e-03 -6.15160667e-03\n -4.20118105e-03  4.69744100e-03 -4.00506019e-03 -3.18274408e-03\n  6.46112415e-03  2.89159411e-03  5.58561882e-05 -2.93133409e-03\n  8.16798907e-04 -6.32176171e-03  5.56053897e-03 -6.36041217e-04\n -5.79233323e-03  5.06384306e-03 -3.84639758e-03  4.87318855e-03\n  2.09912290e-04  4.33691731e-03  3.37906617e-03 -5.05196960e-03\n  1.02895130e-03  4.08134740e-03 -1.53992986e-03  2.17678400e-03\n -6.35111539e-03 -5.66248347e-03 -1.10881411e-03 -4.16939110e-03\n -2.41698897e-03  7.25206709e-03  3.52455892e-03 -2.72657199e-03\n -4.46049487e-03  6.27997800e-03  4.12822311e-03 -4.29568963e-03\n  3.27822525e-03  4.74422437e-04 -7.36276516e-03  6.08754623e-04\n  5.07836316e-03 -2.49084412e-03  6.68436632e-03  1.63677606e-03\n -6.40259777e-03 -3.89026602e-03  5.53970429e-04 -4.87297662e-03\n  5.29615772e-03 -7.04606173e-03  3.74678711e-03  3.76877809e-03\n  4.02093817e-03 -4.28408453e-04 -5.69630100e-03  7.00086373e-03\n -3.02440694e-03  2.58179140e-03  5.33379816e-03 -6.61146570e-03\n  1.48293246e-03  2.37842092e-03 -4.01829177e-03  5.58703024e-03\n -5.74216662e-04  5.99784977e-03 -4.73664072e-03  2.37927320e-03\n -3.39304510e-03 -2.54775472e-03  4.55417377e-03  8.61042071e-04\n  5.07867546e-03  5.38944149e-03  8.43247180e-05 -3.12868764e-03\n -1.34245397e-03  6.48412301e-03  7.15439817e-03  1.66651130e-04\n  4.06732860e-03  2.83814521e-03  7.24635495e-03  6.22788597e-03\n  4.20149888e-03  6.49253302e-04 -3.91114083e-03 -3.58432497e-03\n -3.86471098e-03  2.81108473e-03  1.78824730e-03  1.68233903e-03\n  2.84089912e-03  6.25876716e-03 -4.43284225e-03  1.18857102e-03\n -4.23199176e-03  6.52209025e-03  3.10487973e-04  7.15578276e-03\n -2.14404584e-03  5.07581213e-03 -5.91204650e-03  6.67434357e-03\n -3.67739919e-04  4.18005262e-04 -2.95130127e-04  4.67975206e-03\n  1.59355487e-03  5.93234468e-03 -2.09718803e-03  2.76864020e-03\n  1.19992438e-03  5.40846449e-03  1.29281665e-03  7.07159381e-03\n  1.41238172e-03 -5.80262790e-03  3.72717315e-03 -4.90456269e-03\n -6.72488463e-03 -5.56823441e-03 -5.23051378e-03 -6.76384914e-03\n -3.99397980e-03  3.39150096e-03  2.88789147e-03 -5.20359136e-04\n  2.38952795e-03  1.60403547e-03 -2.61388670e-03  2.66299234e-03\n -8.18143279e-04 -2.57845668e-03  4.40694062e-03  2.04237922e-03\n  5.15184399e-03 -3.10021599e-03  6.17029479e-03  7.23334944e-03\n  3.18039373e-03 -1.86054513e-03 -3.84445095e-03  3.61909527e-03\n -6.88008789e-03 -4.94012773e-03  3.70646320e-03  5.90539612e-03\n -6.96513871e-03  5.62814758e-03 -7.02268337e-03 -7.26117535e-03\n  4.51210770e-03 -4.71571024e-03 -1.22832005e-04 -8.83315043e-04\n -9.59028740e-04  6.38134499e-03 -2.59574649e-03 -1.15310570e-03]\nnetworks.xnet.input_layer.vlayer.weight: torch.Size([256, 18432]) torch.float64\n[[ 0.00463266 -0.00236656 -0.00706409 ... -0.00116637 -0.0052418\n  -0.00603106]\n [-0.0070495  -0.00672454 -0.00573184 ... -0.0050628   0.00602185\n  -0.00735768]\n [ 0.00696305 -0.00561956 -0.00690782 ...  0.0012015   0.00509584\n   0.00545731]\n ...\n [-0.00098264  0.00689178 -0.00444889 ... -0.0024313   0.0057689\n   0.00241326]\n [-0.00321381 -0.00520019 -0.00651976 ... -0.00382101 -0.00310216\n  -0.00372552]\n [-0.00202929  0.00629375  0.00024414 ... -0.00602879  0.0022714\n  -0.00331077]]\nnetworks.xnet.input_layer.vlayer.bias: torch.Size([256]) torch.float64\n[ 7.13954968e-03  2.33497538e-03 -1.57597373e-03 -2.46922688e-03\n  1.36409845e-03 -3.54782344e-03  6.88996067e-03  1.10860886e-03\n  1.38812383e-03 -7.19016211e-03  1.45510027e-03  3.02318547e-03\n -7.32138405e-03 -8.43571075e-04  4.28112049e-03  2.40885560e-03\n  7.18076241e-03  1.56188999e-03  7.62330334e-04  6.74154006e-04\n  3.15126920e-03  5.91587112e-03 -4.05739295e-03 -5.78828923e-03\n  1.94070617e-04 -4.62861933e-03 -3.08415149e-04  3.08347898e-04\n -1.03532907e-03  1.76321011e-03  1.00590336e-03  5.19000988e-03\n -6.80118548e-03 -3.83583844e-03  2.23868496e-03 -3.56978474e-03\n  4.79782172e-03 -2.77326189e-03  7.04744644e-03  3.53315120e-03\n -3.15971697e-03 -3.91518415e-03 -1.13455609e-03 -9.63908149e-04\n  2.64954937e-03  5.46426969e-03  4.37747118e-03  3.15638766e-03\n -1.92890249e-03  5.45232414e-03  3.35068143e-03  4.33478276e-04\n -4.31518024e-03 -6.72472428e-03  4.54341573e-03 -2.88636991e-03\n  3.70153548e-03 -6.86245384e-03  4.75460380e-03  6.41603726e-03\n -6.26087807e-03  3.02317812e-03  5.73602283e-03 -4.28468460e-04\n  6.01001762e-03 -1.69198965e-03  5.43279470e-03  5.62699022e-03\n -2.88454197e-03 -3.30683965e-03  4.35496712e-03  6.48480591e-03\n -5.20145666e-03 -3.04176444e-03 -4.21770568e-03 -3.28701122e-03\n  5.91868810e-03  6.96211411e-03  4.04241174e-03 -4.78452628e-03\n  6.74957958e-03  6.22083070e-03 -3.88811704e-04  1.82479643e-03\n  5.20908605e-03  2.60155604e-03  6.63469193e-03  8.44931789e-04\n -8.29745518e-04  3.60376697e-03  9.97494182e-04  3.64541569e-03\n -6.90072487e-03  3.80146210e-03 -5.36299117e-03 -6.35306719e-03\n  1.03268753e-03  3.54132643e-03 -4.01312104e-03  2.90626746e-03\n  1.29579833e-03  5.81664084e-03  2.46191290e-03  5.72887267e-03\n  5.45967242e-03  4.87193795e-03  6.61741538e-03 -3.24694377e-03\n -3.05439571e-03 -4.30007078e-03 -4.81643057e-03  5.23719897e-03\n -2.92609792e-03  3.11786964e-03  5.06377992e-03  6.93156574e-04\n -6.34295901e-03 -5.20360405e-03  6.53520633e-03 -2.19878290e-03\n -4.23761225e-03 -4.46902040e-03  3.49561972e-03 -3.77943695e-03\n -1.19474523e-03 -5.53529271e-03 -5.21859423e-03  5.27612485e-04\n -3.22711340e-03  1.97883571e-03 -1.37254251e-03 -4.60044753e-03\n -5.11436754e-03 -4.77549801e-03 -3.34637898e-03 -6.94803859e-03\n  2.89079417e-03 -7.18483197e-03 -9.93689973e-05 -4.96657772e-03\n  6.76707823e-03 -4.62419960e-03  5.78926771e-03 -5.18438170e-03\n -2.05662931e-03  3.27891351e-04 -8.57164219e-04 -4.31960935e-03\n -4.55563453e-03  7.15334687e-03  1.82591525e-03  7.99936920e-05\n  2.45142075e-03  5.73190392e-03 -1.54055161e-03 -1.51643201e-03\n -7.22129499e-03 -5.17472970e-04 -8.08219555e-04 -6.38394953e-03\n  5.06663481e-03 -5.11019352e-03  3.69304729e-03  1.81648701e-03\n -8.70826108e-04  5.90869986e-03  2.05946655e-03 -4.32638973e-03\n -2.48755354e-03  1.63676471e-03 -7.25196707e-03  4.79333334e-03\n  4.19589915e-03  6.51303768e-04  2.76840533e-03 -2.50836736e-03\n -6.46075359e-03  1.25353015e-03  1.33234235e-03 -2.13799161e-04\n -2.87122657e-04 -4.04575035e-03 -5.93910528e-03  1.06039907e-03\n  5.28653467e-04 -5.54096450e-03 -6.83464033e-03 -6.89233810e-03\n -3.02152888e-03  1.23447448e-03  2.23110257e-03 -5.61453445e-03\n -5.80583301e-03 -6.01375088e-04  5.93332855e-03  7.31844717e-03\n -4.38679230e-03 -2.48353842e-03 -4.45933690e-03 -4.31983253e-03\n  6.04181330e-03 -2.29214770e-03 -2.65686023e-03  1.07060705e-03\n  3.17073542e-04  6.97229815e-03 -2.62600050e-03  3.63202727e-03\n  3.41508028e-03 -6.49521498e-03 -9.85550166e-04  4.92309670e-03\n -4.84045929e-03 -6.10941181e-03 -6.26433188e-03  1.96075852e-04\n  1.70661732e-03  4.63002121e-03 -3.52289210e-03  2.43618431e-03\n -2.64042274e-03 -5.41311502e-03 -7.33775376e-03 -7.14481501e-04\n -6.46917530e-03 -5.40453482e-03  7.22469128e-03  2.06925380e-03\n  1.81981272e-03 -9.21539612e-04  5.48254267e-03 -5.33146979e-03\n -3.48952775e-04  3.75635835e-03 -6.01750009e-03  3.11628044e-03\n -6.52624412e-03  3.47105111e-03 -1.11631997e-03 -3.85723350e-03\n -4.40994989e-03  1.17136573e-03 -3.24804979e-03 -2.00483200e-03\n  5.87188180e-04  5.16416785e-03  2.25585266e-03  3.65669899e-04\n  5.02527363e-04  1.09367410e-03 -2.92367173e-03  4.60333182e-03\n  2.98082391e-03  6.09591745e-03 -2.61550086e-04 -3.48777157e-03]\nnetworks.xnet.scale.coeff: torch.Size([1, 9216]) torch.float64\n[[0. 0. 0. ... 0. 0. 0.]]\nnetworks.xnet.scale.layer.weight: torch.Size([9216, 256]) torch.float64\n[[-0.0314128   0.02457701 -0.01737903 ...  0.05324728  0.02920562\n  -0.01480562]\n [ 0.04872326  0.04276607 -0.03822993 ...  0.04910911 -0.00361292\n  -0.0327975 ]\n [-0.007368    0.04980131 -0.03215754 ... -0.00088707  0.04168787\n   0.01848812]\n ...\n [-0.02830753 -0.05883997  0.00450329 ...  0.05939779  0.03053409\n  -0.00791589]\n [-0.03962345 -0.01745788 -0.00161624 ...  0.03181425 -0.04709787\n   0.04662044]\n [-0.05086516  0.01152248 -0.02808823 ...  0.05979598  0.0187143\n   0.02237458]]\nnetworks.xnet.scale.layer.bias: torch.Size([9216]) torch.float64\n[ 0.05768892 -0.05574379 -0.02721741 ...  0.0429844  -0.0245669\n  0.01514744]\nnetworks.xnet.transf.coeff: torch.Size([1, 9216]) torch.float64\n[[0. 0. 0. ... 0. 0. 0.]]\nnetworks.xnet.transf.layer.weight: torch.Size([9216, 256]) torch.float64\n[[-5.48741770e-02  5.88052983e-02 -4.66361299e-02 ...  4.88506894e-03\n   4.86617921e-03 -4.32845085e-02]\n [ 1.52577676e-02 -3.61066089e-02 -2.71776527e-02 ... -3.64660092e-02\n  -2.36572372e-02  3.22652308e-02]\n [-1.60658234e-02  1.18504295e-02  5.53077906e-02 ...  2.12042919e-03\n  -3.51854507e-02 -2.75998519e-02]\n ...\n [ 5.39795249e-02  5.57953445e-02 -5.10586758e-02 ...  1.91429723e-02\n   7.08082998e-05 -5.18016647e-02]\n [ 5.80865506e-03 -6.10658241e-02  2.19656541e-02 ...  3.99923136e-02\n  -2.62750389e-02 -4.53906247e-02]\n [-4.22715684e-02  2.91019650e-02 -2.99350749e-02 ...  5.93449722e-03\n  -2.18851812e-02 -3.72887999e-02]]\nnetworks.xnet.transf.layer.bias: torch.Size([9216]) torch.float64\n[ 0.0160626   0.03637902 -0.04792599 ... -0.02090929  0.03092064\n -0.02681802]\nnetworks.xnet.transl.weight: torch.Size([9216, 256]) torch.float64\n[[ 0.0597546   0.04724709  0.00974501 ...  0.03109464  0.05561356\n  -0.06129477]\n [-0.00993569  0.01303274  0.03429567 ... -0.0537229   0.02269541\n   0.0060408 ]\n [-0.03242319  0.05091612 -0.04957046 ...  0.02764103  0.0523916\n   0.00046056]\n ...\n [-0.02372713  0.02379183  0.04659715 ... -0.02335574  0.00308037\n   0.0329444 ]\n [ 0.04570751 -0.01026316 -0.02490364 ...  0.06235519 -0.0481135\n   0.04846663]\n [-0.01367436  0.02093689  0.00793577 ... -0.03375852  0.03164459\n  -0.0471489 ]]\nnetworks.xnet.transl.bias: torch.Size([9216]) torch.float64\n[-0.05460216 -0.00158335  0.00726456 ... -0.00648457 -0.03945205\n  0.03027343]\nnetworks.vnet.input_layer.xlayer.weight: torch.Size([256, 8192]) torch.float64\n[[ 9.16479776e-03 -5.02985351e-03 -1.02646308e-02 ... -5.54809175e-03\n   2.49656214e-03  5.17212957e-03]\n [-1.10012665e-02  1.43435235e-03  2.52587170e-03 ...  2.85077495e-03\n   7.27665005e-03  1.25115602e-04]\n [-4.05602443e-03  5.24941517e-05  2.08143842e-03 ... -8.23178343e-03\n  -1.25323771e-03  1.87069762e-03]\n ...\n [ 1.65006943e-03  5.20871048e-03 -1.00319636e-02 ... -8.65131086e-04\n  -3.36906845e-03  9.64724941e-03]\n [-4.45201502e-03 -7.09414820e-03  1.06516265e-02 ... -1.70374089e-03\n   5.39770888e-03  1.16063326e-03]\n [-2.58663111e-03 -7.89414569e-03 -3.60060986e-03 ...  2.35312618e-03\n   3.82747698e-03  6.42668906e-03]]\nnetworks.vnet.input_layer.xlayer.bias: torch.Size([256]) torch.float64\n[ 7.19072073e-03  8.54899036e-03 -2.74573756e-04 -1.00589086e-02\n -1.01545971e-02 -4.92664753e-03  3.33148504e-03 -9.15564118e-03\n -2.42099720e-03  2.73065021e-03  9.08042100e-03  5.53534517e-03\n -7.83710822e-03 -7.49573676e-03  6.42186908e-03  8.03173418e-03\n -5.40192935e-03  6.03333723e-03  7.86975860e-03  9.10750021e-03\n  7.69085484e-03  5.75742039e-03  5.05968312e-03 -1.08030831e-02\n  3.19505866e-03  4.33518487e-03 -8.13443321e-03  3.26326675e-03\n -2.42816999e-04 -4.49394122e-03 -5.71015658e-03  1.04592739e-02\n  8.85128136e-03  9.48734877e-03  9.57133407e-04 -4.04794034e-03\n -5.37902552e-04  6.59268074e-03 -8.24567402e-03 -9.85347305e-03\n -3.42285874e-03 -6.53992756e-03  1.22830194e-03  7.85893246e-03\n -5.83300876e-03  9.63272175e-03  1.00944380e-02 -8.23972365e-03\n  6.38082055e-03 -8.30738685e-03 -1.28466574e-03 -5.92072715e-03\n -9.94081339e-04 -5.04786137e-03 -4.81081172e-03  7.90118625e-03\n  1.71037484e-03  4.65126599e-03  3.37058664e-03 -4.20112172e-03\n  3.59920358e-03  7.24500793e-03 -3.96064082e-03  7.38878616e-03\n -4.49233823e-03  1.05992911e-02  6.25592970e-04 -1.42090120e-03\n  9.97637162e-03 -5.69488534e-03  8.76500682e-04 -1.01360952e-02\n -2.37918758e-03  9.16485953e-03 -5.39184741e-04 -9.55458902e-03\n  2.15706793e-03  6.87956224e-03  9.80659942e-03  1.44044538e-03\n -1.47955633e-03 -6.09390842e-03  3.60479523e-03 -6.82449391e-03\n  5.40907839e-03  1.01111670e-03 -6.58945581e-03  2.83824036e-04\n  8.00948478e-03  9.06618547e-03  2.53404918e-03 -2.60766025e-03\n  8.65071755e-03  4.25651017e-04  5.35529727e-03  1.99133934e-03\n  2.17451416e-03  5.14984483e-03 -4.56392209e-03  2.18987254e-03\n  2.15989875e-03  2.69606540e-04  3.48712402e-03  1.87305008e-04\n -3.78771696e-03 -1.00614225e-03  3.22000781e-03  1.19988308e-04\n  2.42807845e-03  7.89254160e-03  9.15674794e-03  5.91687571e-03\n  1.07615647e-02  1.00567930e-03 -7.01280272e-03  2.52361863e-03\n -2.47741325e-03 -1.00704911e-02 -7.94936428e-03  9.14483937e-03\n  6.37746665e-03  7.03343740e-03  5.14637055e-03 -5.11663552e-03\n -8.00740179e-03  8.83483394e-03  6.53089076e-03  9.00223946e-03\n  3.97538834e-03  6.24483879e-03  7.31143293e-03 -1.00182043e-02\n -9.54410363e-03 -5.58611888e-03 -2.97078564e-03 -4.44242630e-03\n -1.97398918e-03  2.85262394e-03 -2.06799186e-05 -6.70357733e-03\n -2.88790893e-03  2.64525844e-03 -4.77558126e-03  2.39335661e-03\n -2.24044925e-03 -4.06998727e-03  1.06852282e-02 -4.68211211e-03\n -2.39275674e-05  1.78237780e-03  7.35727064e-03  3.83212756e-03\n  1.05362754e-02 -1.04227983e-02  5.49080533e-03 -4.21863781e-03\n -8.09427094e-03  4.07019125e-03 -2.45255795e-03 -2.53837092e-03\n -8.00514087e-03  8.73080505e-03 -8.95351911e-04  5.55943184e-03\n  1.05709522e-02  1.08791111e-02 -1.27190779e-03 -6.14560145e-03\n  3.24457839e-03  5.82486941e-03  8.54307159e-03  1.00030933e-02\n -1.72313442e-03 -8.25437185e-03 -1.09750088e-02  1.56909026e-03\n  1.03776179e-02  6.30748559e-03 -6.85598815e-03 -1.12541891e-03\n  9.08712741e-03  8.86892888e-03 -6.65631585e-03  4.50625609e-03\n  6.52531325e-03 -7.26732740e-03  1.06536875e-03 -4.89295777e-03\n  8.56154583e-03 -1.37062236e-03  7.88639999e-03  4.09090142e-03\n  2.70268365e-03  2.09226824e-03 -8.10420964e-03 -5.58339073e-03\n -1.20819768e-03  7.11240267e-03  9.43157146e-03 -3.08990524e-03\n  8.97867491e-03  3.34746366e-03  1.09295356e-02 -8.33854547e-03\n  8.38929734e-04 -3.84791235e-03 -4.82723130e-03 -3.57815038e-03\n -9.57405736e-03 -1.26486527e-03  1.80339331e-04 -9.96310653e-03\n -5.69077756e-03  1.02989043e-02  7.48580783e-03 -7.39925761e-03\n  1.63322755e-03  8.09922551e-03  2.04141394e-03 -2.41658959e-03\n -3.70372619e-04  9.03762479e-03 -4.80271241e-03 -7.08458501e-03\n -5.17033153e-03 -5.79945109e-03  1.24089517e-03 -3.33699629e-03\n  3.73987379e-03  9.65713624e-03 -4.10453665e-03  4.65230530e-03\n  9.41206321e-03  1.98615070e-03  1.89076444e-04 -1.09669487e-02\n -1.05897327e-02 -6.85746166e-03  9.04909639e-03  3.74210626e-03\n  7.73146379e-03 -5.16318588e-03 -2.38919870e-03 -8.10861969e-03\n -2.64679669e-03 -2.54794893e-03 -5.72662559e-03  2.21213630e-03\n -3.11922885e-03 -8.05962367e-03 -5.62810358e-03 -4.50267728e-03\n  6.65414399e-03  6.62929741e-03  4.13247675e-04  1.00713824e-02]\nnetworks.vnet.input_layer.vlayer.weight: torch.Size([256, 8192]) torch.float64\n[[-1.14911505e-04  1.02167470e-03  1.40021033e-03 ...  1.24707499e-03\n   7.39021474e-03 -7.66842841e-05]\n [ 1.94857639e-03 -1.01153101e-02  5.93229540e-03 ... -7.92573245e-04\n  -4.16384139e-03 -2.18078512e-03]\n [ 6.67728377e-04  2.17963982e-03  5.26611412e-03 ...  9.58798745e-03\n   2.09696865e-03 -9.27834153e-03]\n ...\n [ 6.47180548e-03 -1.07005036e-02  3.93737006e-03 ... -5.18451888e-04\n  -6.75962666e-03  3.20640579e-03]\n [ 4.78800955e-03  9.73209930e-03 -8.75317563e-03 ... -1.81879817e-03\n   4.40209660e-03 -3.12276728e-03]\n [-8.81313864e-03 -3.99257134e-03  8.84710606e-03 ... -6.06736885e-03\n  -7.77339244e-04  7.38524802e-03]]\nnetworks.vnet.input_layer.vlayer.bias: torch.Size([256]) torch.float64\n[-8.62724045e-03  1.42222980e-03 -6.96917869e-03 -5.58672282e-03\n -1.08436920e-02  1.92805181e-03  9.85077112e-03 -3.70476600e-03\n -1.09324801e-02 -3.16374460e-03  1.03695714e-02  5.06699318e-05\n -4.99672326e-04 -1.99306211e-03 -2.84156206e-03  4.66317161e-03\n -3.03587761e-03  7.51455137e-03 -2.33996069e-03  2.59240772e-05\n  7.89245214e-03 -8.62472647e-04  1.73067098e-03  3.98049967e-03\n  1.73062241e-03  6.62573647e-03  7.40045855e-03  2.67644125e-03\n -9.08800186e-03  5.89813445e-03  8.16554978e-03  6.63839573e-03\n -9.42590336e-03 -4.87546360e-04 -3.67365451e-03 -7.04534530e-03\n  4.69672830e-03  2.60295575e-03 -5.76011135e-03 -6.28032865e-03\n  1.91679316e-03  2.98078939e-03  3.62183797e-03 -3.00271988e-03\n  1.63915131e-03  2.34721714e-03  6.65671087e-03 -2.31834993e-03\n -9.18060747e-03 -9.18534600e-03 -2.52645532e-03 -5.11630776e-03\n -1.44994545e-03 -1.03017183e-02 -9.78218895e-03 -1.01023624e-02\n  1.18473846e-03  1.06675516e-02 -4.46746439e-03 -8.31554290e-03\n  3.62939942e-03 -2.85054999e-03  3.50449313e-04  5.88476446e-03\n -7.41086950e-04 -1.88300384e-03 -9.95598461e-03 -3.86232625e-03\n  8.51256252e-03 -4.71688463e-03  5.85945792e-03 -4.08366811e-03\n  3.74353387e-03 -7.63856755e-03  6.01017018e-03 -2.08397059e-04\n -5.98487160e-03 -2.90322952e-03 -1.70036238e-03 -9.92108061e-03\n -2.22982220e-03  4.83112948e-03 -2.99896346e-03  3.67172178e-03\n -6.98774964e-04 -8.77047812e-03  1.62358117e-03 -1.78590660e-03\n  5.38471356e-03 -3.43516886e-03  8.14706400e-03 -5.83946133e-03\n -3.43393746e-03  7.73027246e-03  6.63517574e-04 -1.97393104e-03\n -6.85942244e-03  9.00629517e-03  7.97936788e-03 -9.46204611e-03\n -9.91962740e-04 -1.10322243e-02  2.51705047e-03  9.34333540e-03\n -2.04383936e-03 -3.20343216e-03  9.29710695e-03 -3.91017821e-03\n  6.39077050e-03  6.43472117e-03  9.74522830e-03 -6.93840319e-03\n -2.08547302e-03  1.38644474e-03  9.37315176e-03  4.56605920e-03\n -7.89351592e-03  9.38851564e-03  5.63796455e-03 -9.00095278e-03\n  5.18531879e-03  5.30712437e-03 -8.30732223e-03 -7.40450098e-03\n -8.20939741e-03 -2.84902854e-03 -4.78296110e-03  4.23491318e-03\n -6.74215327e-04  7.31200359e-03  5.35229365e-03  5.08346832e-03\n  4.55305812e-04 -9.43407806e-03 -3.95355860e-03  4.08208203e-03\n  9.17557942e-03 -5.82235799e-03 -2.40188538e-03  5.86607196e-03\n  9.26253560e-04  3.60195632e-04  5.37108378e-03  9.55347231e-03\n  2.21315472e-03  2.83197797e-03  2.42350609e-03  4.04436381e-03\n  5.66261568e-03  9.10928763e-03 -9.95752380e-03  9.69473082e-03\n -7.39153944e-04  3.66869476e-03 -1.01362383e-02  9.56476828e-03\n -2.82710541e-04  7.12206993e-03 -5.87929074e-04 -7.01050166e-03\n -4.23527215e-03 -8.87308949e-03 -1.39642809e-04  9.37101367e-03\n  9.67923506e-05  1.99839363e-03 -8.40962420e-03  8.90230844e-03\n -1.01463100e-02 -1.92307743e-03  4.56673532e-03 -6.56275075e-03\n  9.59734817e-04  1.02384073e-02 -5.02270952e-03  8.87749118e-03\n -1.08131623e-02 -4.46696784e-03  5.71411620e-04 -8.43994833e-03\n  4.43985783e-03  1.97354673e-03 -1.01913055e-02 -4.17295006e-03\n -4.20001283e-03 -4.55569830e-03 -4.80213356e-03  4.86272493e-03\n  4.45352684e-03 -2.98058407e-04 -2.77590550e-04  7.66098638e-03\n  5.67088367e-03 -1.01337152e-02 -8.72584257e-03 -6.31807112e-03\n  1.36405857e-03  2.23078281e-03 -7.77014046e-03 -5.62621277e-03\n  1.21089554e-03 -8.25528093e-03 -4.31437392e-03  6.83876641e-03\n -2.20724004e-03 -6.96057323e-03  1.10153134e-02  9.20152266e-03\n -5.46451809e-04  3.95414653e-03 -6.12336496e-03 -1.01812970e-02\n  2.58442604e-03  3.99579709e-03  2.15366084e-03  3.09138548e-03\n -1.98773575e-03  9.45093202e-03  4.53305893e-03 -4.35642434e-03\n -9.85531045e-04 -2.68568653e-03 -1.70380022e-03 -5.19579726e-03\n -1.04297413e-02  5.08077444e-03  8.74058023e-03  6.00930085e-03\n  1.54289208e-03  6.84188667e-03 -9.08237877e-03  4.24600744e-03\n  9.33722584e-06 -3.77439462e-03  8.54248635e-03 -7.56578027e-03\n -6.76504009e-03 -5.90847587e-03  4.09332418e-03  3.55476762e-03\n  5.98836902e-04 -7.42746846e-03  9.41937684e-03  5.74515692e-03\n  9.33460074e-03  1.01823407e-02  4.62239994e-03  4.47014706e-04\n -1.10312440e-02 -1.09556414e-02  1.00085173e-02  7.71189410e-03\n -8.37871661e-03  1.06354341e-03  1.81342397e-03  1.59670919e-03]\nnetworks.vnet.scale.coeff: torch.Size([1, 9216]) torch.float64\n[[0. 0. 0. ... 0. 0. 0.]]\nnetworks.vnet.scale.layer.weight: torch.Size([9216, 256]) torch.float64\n[[-0.00228215 -0.03766236  0.00310601 ...  0.03574621 -0.03147162\n   0.05768579]\n [ 0.04740894  0.05251629  0.05302966 ...  0.03484848 -0.02955205\n   0.06163016]\n [ 0.01222568  0.00514609 -0.0334526  ...  0.01297469 -0.02803657\n   0.06087524]\n ...\n [ 0.05592883 -0.0102075  -0.05230017 ... -0.00338015 -0.00971749\n  -0.02981181]\n [-0.04028498  0.04087614  0.04200986 ... -0.02805969  0.03686787\n   0.04125376]\n [ 0.00587553  0.01966032 -0.00264878 ...  0.04938714  0.054406\n  -0.00516837]]\nnetworks.vnet.scale.layer.bias: torch.Size([9216]) torch.float64\n[ 0.00492612  0.05642332  0.01745884 ...  0.05758128  0.03186792\n -0.00131235]\nnetworks.vnet.transf.coeff: torch.Size([1, 9216]) torch.float64\n[[0. 0. 0. ... 0. 0. 0.]]\nnetworks.vnet.transf.layer.weight: torch.Size([9216, 256]) torch.float64\n[[-0.04669794 -0.02162502 -0.05433034 ...  0.05776646 -0.04041847\n  -0.03207429]\n [ 0.01005234 -0.04020476 -0.04877582 ...  0.05317922  0.01688223\n   0.00213256]\n [-0.05261319  0.0362059  -0.04666302 ... -0.02129076 -0.03451092\n  -0.01450992]\n ...\n [ 0.00717067  0.04310912  0.04005595 ... -0.01275533 -0.0141606\n  -0.04939128]\n [-0.02057675 -0.04490391 -0.0232821  ...  0.02815117 -0.03451967\n  -0.03208819]\n [ 0.04748397 -0.05835794 -0.04562179 ...  0.02394428  0.00509771\n   0.01316225]]\nnetworks.vnet.transf.layer.bias: torch.Size([9216]) torch.float64\n[ 0.00330597  0.02071309  0.00124246 ...  0.03318861 -0.03303616\n -0.04279837]\nnetworks.vnet.transl.weight: torch.Size([9216, 256]) torch.float64\n[[ 0.00344245 -0.04238582 -0.04490574 ... -0.02783231 -0.04849146\n   0.01404108]\n [ 0.02450462  0.04666956  0.03030368 ...  0.04106765 -0.00071757\n   0.00888672]\n [-0.00462819 -0.04935891 -0.008225   ...  0.00929701 -0.01122217\n   0.01513675]\n ...\n [ 0.05063408  0.00755534 -0.00132726 ... -0.00643975  0.02790855\n   0.01580877]\n [ 0.01441602 -0.00605052  0.05652107 ...  0.01595805 -0.03783348\n   0.0410961 ]\n [ 0.00295196 -0.03321374  0.05530547 ...  0.02630581  0.04170922\n  -0.04991051]]\nnetworks.vnet.transl.bias: torch.Size([9216]) torch.float64\n[ 0.04973598 -0.01250011 -0.00308125 ...  0.04882267  0.00540407\n -0.03680365]\nxeps.0: torch.Size([]) torch.float64\n0.01\nxeps.1: torch.Size([]) torch.float64\n0.01\nxeps.2: torch.Size([]) torch.float64\n0.01\nxeps.3: torch.Size([]) torch.float64\n0.01\nveps.0: torch.Size([]) torch.float64\n0.01\nveps.1: torch.Size([]) torch.float64\n0.01\nveps.2: torch.Size([]) torch.float64\n0.01\nveps.3: torch.Size([]) torch.float64\n0.01\n\n[2025-04-30 15:43:03][I][pytorch/trainer:2006:l2hmc.trainers.pytorch.trainer] --------------------------------------------------------------------------------\n\n[2025-04-30 15:43:03][I][ipykernel_24193/3178487732:2:ezpz.log] ExperimentConfig(wandb={'setup': {'id': None, 'group': None, 'config': None, 'save_code': True, 'sync_tensorboard': True, 'mode': 'online', 'resume': 'allow', 'entity': 'l2hmc-qcd', 'project': 'l2hmc-qcd', 'settings': {'start_method': 'thread'}, 'tags': ['beta_init=6.0', 'beta_final=6.0']}}, steps=Steps(nera=1, nepoch=10, test=50, log=1, print=1, extend_last_era=1), framework='pytorch', loss=LossConfig(use_mixed_loss=True, charge_weight=0.0, rmse_weight=0.1, plaq_weight=0.1, aux_weight=0.0), network=NetworkConfig(units=[256], activation_fn='tanh', dropout_prob=0.0, use_batch_norm=False), conv=ConvolutionConfig(filters=[], sizes=[], pool=[]), net_weights=NetWeights(x=NetWeight(s=0.0, t=1.0, q=1.0), v=NetWeight(s=1.0, t=1.0, q=1.0)), dynamics=DynamicsConfig(nchains=8, group='SU3', latvolume=[4, 4, 4, 4], nleapfrog=4, eps=0.01, eps_hmc=0.25, use_ncp=True, verbose=True, eps_fixed=False, use_split_xnets=False, use_separate_networks=False, merge_directions=True), learning_rate=LearningRateConfig(lr_init=0.0001, mode='auto', monitor='loss', patience=5, cooldown=0, warmup=1000, verbose=True, min_lr=1e-06, factor=0.98, min_delta=0.0001, clip_norm=1.0), annealing_schedule=AnnealingSchedule(beta_init=6.0, beta_final=6.0, dynamic=False), gradient_accumulation_steps=1, restore=False, save=False, c1=0.0, port='2345', compile=True, profile=False, init_aim=False, init_wandb=False, use_wandb=False, use_tb=False, debug_mode=False, default_mode=True, print_config=True, precision='float32', ignore_warnings=True, backend='DDP', seed=9992, ds_config_path='/Users/samforeman/projects/saforem2/l2hmc-qcd/src/l2hmc/conf/ds_config.yaml', name=None, width=200, nchains=None, compression=False)",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "L2hmc",
      "üî≥ <code>l2hmc-qcd</code> Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/jupyter/l2hmc/4dSU3/index.html#hmc",
    "href": "posts/jupyter/l2hmc/4dSU3/index.html#hmc",
    "title": "üî≥ l2hmc-qcd Example: 4D SU(3)",
    "section": "HMC",
    "text": "HMC\nxhmc, history_hmc = evaluate(\n    nsteps=50,\n    exp=ptExpSU3,\n    beta=6.0,\n    x=state.x,\n    eps=0.1,\n    nleapfrog=8,\n    job_type='hmc',\n    nlog=1,\n    nprint=50,\n    grab=True\n)\n\n\nOutput:\n\n\n[2025-04-30 15:43:31][I][pytorch/experiment:117:l2hmc.experiment.pytorch.experiment] Running 50 steps of hmc at beta=6.0000\n\n[2025-04-30 15:43:31][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 0\n\n[2025-04-30 15:43:31][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 1\n\n[2025-04-30 15:43:31][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 2\n\n[2025-04-30 15:43:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 3\n\n[2025-04-30 15:43:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 4\n\n[2025-04-30 15:43:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 5\n\n[2025-04-30 15:43:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 6\n\n[2025-04-30 15:43:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 7\n\n[2025-04-30 15:43:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 8\n\n[2025-04-30 15:43:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 9\n\n[2025-04-30 15:43:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 10\n\n[2025-04-30 15:43:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 11\n\n[2025-04-30 15:43:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 12\n\n[2025-04-30 15:43:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 13\n\n[2025-04-30 15:43:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 14\n\n[2025-04-30 15:43:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 15\n\n[2025-04-30 15:43:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 16\n\n[2025-04-30 15:43:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 17\n\n[2025-04-30 15:43:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 18\n\n[2025-04-30 15:43:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 19\n\n[2025-04-30 15:43:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 20\n\n[2025-04-30 15:43:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 21\n\n[2025-04-30 15:43:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 22\n\n[2025-04-30 15:43:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 23\n\n[2025-04-30 15:43:37][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 24\n\n[2025-04-30 15:43:37][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 25\n\n[2025-04-30 15:43:37][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 26\n\n[2025-04-30 15:43:37][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 27\n\n[2025-04-30 15:43:38][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 28\n\n[2025-04-30 15:43:38][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 29\n\n[2025-04-30 15:43:38][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 30\n\n[2025-04-30 15:43:38][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 31\n\n[2025-04-30 15:43:39][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 32\n\n[2025-04-30 15:43:39][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 33\n\n[2025-04-30 15:43:39][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 34\n\n[2025-04-30 15:43:39][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 35\n\n[2025-04-30 15:43:40][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 36\n\n[2025-04-30 15:43:40][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 37\n\n[2025-04-30 15:43:40][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 38\n\n[2025-04-30 15:43:40][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 39\n\n[2025-04-30 15:43:41][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 40\n\n[2025-04-30 15:43:41][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 41\n\n[2025-04-30 15:43:41][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 42\n\n[2025-04-30 15:43:41][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 43\n\n[2025-04-30 15:43:42][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 44\n\n[2025-04-30 15:43:42][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 45\n\n[2025-04-30 15:43:42][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 46\n\n[2025-04-30 15:43:42][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 47\n\n[2025-04-30 15:43:43][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 48\n\n[2025-04-30 15:43:43][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 49\n\n\n\ndataset_hmc = history_hmc.get_dataset()\n_ = history_hmc.plot_all(title='HMC')\n\n\nOutput:\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\nxhmc = ptExpSU3.trainer.dynamics.unflatten(xhmc)\nprint(f\"checkSU(x_eval): {g.checkSU(xhmc)}\")\nprint(f\"checkSU(x_eval): {g.checkSU(g.projectSU(xhmc))}\")\n\n\nOutput:\n\n\ncheckSU(x_eval): (tensor[8] f64 x‚àà[2.314e-16, 5.581e-16] Œº=3.985e-16 œÉ=1.437e-16 [5.220e-16, 5.581e-16, 2.338e-16,\n5.152e-16, 5.239e-16, 2.825e-16, 2.314e-16, 3.214e-16], tensor[8] f64 x‚àà[6.633e-16, 1.660e-15] Œº=1.198e-15\nœÉ=3.983e-16 [1.438e-15, 1.657e-15, 6.633e-16, 1.660e-15, 1.449e-15, 8.822e-16, 8.161e-16, 1.014e-15])\n\ncheckSU(x_eval): (tensor[8] f64 x‚àà[2.099e-16, 3.202e-16] Œº=2.785e-16 œÉ=4.123e-17 [3.078e-16, 3.202e-16, 2.099e-16,\n3.114e-16, 3.049e-16, 2.593e-16, 2.294e-16, 2.850e-16], tensor[8] f64 x‚àà[7.639e-16, 9.703e-16] Œº=8.714e-16\nœÉ=8.022e-17 [9.119e-16, 9.703e-16, 7.805e-16, 9.469e-16, 9.134e-16, 7.639e-16, 7.940e-16, 8.903e-16])",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "L2hmc",
      "üî≥ <code>l2hmc-qcd</code> Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/jupyter/l2hmc/4dSU3/index.html#training",
    "href": "posts/jupyter/l2hmc/4dSU3/index.html#training",
    "title": "üî≥ l2hmc-qcd Example: 4D SU(3)",
    "section": "Training",
    "text": "Training\nimport time\nfrom l2hmc.utils.history import BaseHistory, summarize_dict\n\nhistory_train = BaseHistory()\nx = state.x\nfor step in range(100):\n# log.info(f'HMC STEP: {step}')\ntic = time.perf_counter()\nx, metrics_ = ptExpSU3.trainer.train_step(\n    (x, state.beta)\n)\ntoc = time.perf_counter()\nmetrics = {\n    'train_step': step,\n    'dt': toc - tic,\n    **metrics_,\n}\nif step % 5 == 0:\n    avgs = history_train.update(metrics)\n    summary = summarize_dict(avgs)\n    logger.info(summary)\n\n\nOutput:\n\n\n[2025-04-30 15:45:44][I][ipykernel_24193/30352159:21:ezpz.log] train_step=0 dt=1.577 energy=33.403 logprob=33.488 logdet=-0.085 sldf=-0.065 sldb=0.086 sld=-0.085 xeps=0.010 veps=0.010 acc=0.131 sumlogdet=0.000 beta=6.000 acc_mask=0.000 loss=88.118 plaqs=-0.004 sinQ=-0.002 intQ=-0.026 dQint=0.000 dQsin=0.000\n\n[2025-04-30 15:45:51][I][ipykernel_24193/30352159:21:ezpz.log] train_step=5 dt=1.256 energy=-372.669 logprob=-372.955 logdet=0.285 sldf=0.191 sldb=-0.217 sld=0.285 xeps=0.010 veps=0.010 acc=1.000 sumlogdet=-0.091 beta=6.000 acc_mask=1.000 loss=-647.866 plaqs=0.038 sinQ=-0.002 intQ=-0.034 dQint=0.009 dQsin=0.001\n\n[2025-04-30 15:45:58][I][ipykernel_24193/30352159:21:ezpz.log] train_step=10 dt=1.308 energy=-780.851 logprob=-781.247 logdet=0.396 sldf=0.254 sldb=-0.276 sld=0.396 xeps=0.011 veps=0.010 acc=0.952 sumlogdet=-0.044 beta=6.000 acc_mask=1.000 loss=-538.541 plaqs=0.088 sinQ=-0.002 intQ=-0.036 dQint=0.017 dQsin=0.001\n\n[2025-04-30 15:46:05][I][ipykernel_24193/30352159:21:ezpz.log] train_step=15 dt=1.487 energy=-1234.642 logprob=-1235.128 logdet=0.486 sldf=0.303 sldb=-0.298 sld=0.486 xeps=0.011 veps=0.010 acc=1.000 sumlogdet=0.011 beta=6.000 acc_mask=1.000 loss=-617.539 plaqs=0.134 sinQ=-0.003 intQ=-0.038 dQint=0.022 dQsin=0.002\n\n[2025-04-30 15:46:13][I][ipykernel_24193/30352159:21:ezpz.log] train_step=20 dt=1.424 energy=-1559.334 logprob=-1559.934 logdet=0.600 sldf=0.370 sldb=-0.363 sld=0.600 xeps=0.012 veps=0.010 acc=1.000 sumlogdet=0.029 beta=6.000 acc_mask=1.000 loss=-450.278 plaqs=0.169 sinQ=0.000 intQ=0.005 dQint=0.016 dQsin=0.001\n\n[2025-04-30 15:46:20][I][ipykernel_24193/30352159:21:ezpz.log] train_step=25 dt=1.611 energy=-1901.485 logprob=-1902.100 logdet=0.615 sldf=0.383 sldb=-0.382 sld=0.615 xeps=0.012 veps=0.010 acc=0.766 sumlogdet=0.082 beta=6.000 acc_mask=0.625 loss=-306.696 plaqs=0.203 sinQ=-0.001 intQ=-0.018 dQint=0.013 dQsin=0.001\n\n[2025-04-30 15:46:28][I][ipykernel_24193/30352159:21:ezpz.log] train_step=30 dt=1.358 energy=-2024.281 logprob=-2025.102 logdet=0.821 sldf=0.522 sldb=-0.530 sld=0.821 xeps=0.013 veps=0.010 acc=0.751 sumlogdet=-0.083 beta=6.000 acc_mask=0.750 loss=-136.896 plaqs=0.224 sinQ=0.001 intQ=0.016 dQint=0.012 dQsin=0.001\n\n[2025-04-30 15:46:36][I][ipykernel_24193/30352159:21:ezpz.log] train_step=35 dt=1.532 energy=-2218.666 logprob=-2219.663 logdet=0.997 sldf=0.624 sldb=-0.624 sld=0.997 xeps=0.013 veps=0.011 acc=0.673 sumlogdet=0.001 beta=6.000 acc_mask=0.625 loss=-26.350 plaqs=0.242 sinQ=0.002 intQ=0.033 dQint=0.012 dQsin=0.001\n\n[2025-04-30 15:46:44][I][ipykernel_24193/30352159:21:ezpz.log] train_step=40 dt=1.553 energy=-2388.089 logprob=-2389.183 logdet=1.093 sldf=0.706 sldb=-0.754 sld=1.093 xeps=0.013 veps=0.011 acc=0.386 sumlogdet=-0.040 beta=6.000 acc_mask=0.375 loss=239.300 plaqs=0.259 sinQ=0.002 intQ=0.029 dQint=0.012 dQsin=0.001\n\n[2025-04-30 15:46:52][I][ipykernel_24193/30352159:21:ezpz.log] train_step=45 dt=1.609 energy=-2497.524 logprob=-2498.931 logdet=1.408 sldf=0.886 sldb=-0.906 sld=1.408 xeps=0.013 veps=0.011 acc=0.414 sumlogdet=0.014 beta=6.000 acc_mask=0.375 loss=76.319 plaqs=0.274 sinQ=0.002 intQ=0.026 dQint=0.003 dQsin=0.000\n\n[2025-04-30 15:46:59][I][ipykernel_24193/30352159:21:ezpz.log] train_step=50 dt=1.623 energy=-2696.907 logprob=-2698.606 logdet=1.699 sldf=1.064 sldb=-1.083 sld=1.699 xeps=0.013 veps=0.012 acc=0.665 sumlogdet=0.006 beta=6.000 acc_mask=0.750 loss=-231.184 plaqs=0.293 sinQ=0.002 intQ=0.036 dQint=0.013 dQsin=0.001\n\n[2025-04-30 15:47:07][I][ipykernel_24193/30352159:21:ezpz.log] train_step=55 dt=1.554 energy=-2865.825 logprob=-2867.770 logdet=1.945 sldf=1.209 sldb=-1.215 sld=1.945 xeps=0.013 veps=0.012 acc=0.770 sumlogdet=0.153 beta=6.000 acc_mask=0.750 loss=-210.427 plaqs=0.311 sinQ=0.003 intQ=0.041 dQint=0.016 dQsin=0.001\n\n[2025-04-30 15:47:15][I][ipykernel_24193/30352159:21:ezpz.log] train_step=60 dt=1.709 energy=-2985.928 logprob=-2987.915 logdet=1.987 sldf=1.251 sldb=-1.296 sld=1.987 xeps=0.013 veps=0.012 acc=1.000 sumlogdet=-0.029 beta=6.000 acc_mask=1.000 loss=-278.412 plaqs=0.323 sinQ=0.003 intQ=0.043 dQint=0.010 dQsin=0.001\n\n[2025-04-30 15:47:23][I][ipykernel_24193/30352159:21:ezpz.log] train_step=65 dt=1.557 energy=-3155.115 logprob=-3157.112 logdet=1.997 sldf=1.252 sldb=-1.281 sld=1.997 xeps=0.013 veps=0.013 acc=1.000 sumlogdet=0.006 beta=6.000 acc_mask=1.000 loss=-363.215 plaqs=0.342 sinQ=0.002 intQ=0.025 dQint=0.021 dQsin=0.001\n\n[2025-04-30 15:47:30][I][ipykernel_24193/30352159:21:ezpz.log] train_step=70 dt=1.474 energy=-3309.328 logprob=-3311.369 logdet=2.041 sldf=1.279 sldb=-1.318 sld=2.041 xeps=0.013 veps=0.013 acc=1.000 sumlogdet=-0.011 beta=6.000 acc_mask=1.000 loss=-374.258 plaqs=0.360 sinQ=-0.000 intQ=-0.003 dQint=0.018 dQsin=0.001\n\n[2025-04-30 15:47:37][I][ipykernel_24193/30352159:21:ezpz.log] train_step=75 dt=1.599 energy=-3493.874 logprob=-3496.069 logdet=2.195 sldf=1.355 sldb=-1.349 sld=2.195 xeps=0.013 veps=0.014 acc=1.000 sumlogdet=0.130 beta=6.000 acc_mask=1.000 loss=-380.764 plaqs=0.378 sinQ=0.001 intQ=0.022 dQint=0.011 dQsin=0.001\n\n[2025-04-30 15:47:45][I][ipykernel_24193/30352159:21:ezpz.log] train_step=80 dt=1.682 energy=-3625.884 logprob=-3627.857 logdet=1.973 sldf=1.234 sldb=-1.251 sld=1.973 xeps=0.013 veps=0.015 acc=1.000 sumlogdet=0.019 beta=6.000 acc_mask=1.000 loss=-442.163 plaqs=0.396 sinQ=-0.000 intQ=-0.003 dQint=0.020 dQsin=0.001\n\n[2025-04-30 15:47:53][I][ipykernel_24193/30352159:21:ezpz.log] train_step=85 dt=1.588 energy=-3841.913 logprob=-3843.908 logdet=1.995 sldf=1.230 sldb=-1.213 sld=1.995 xeps=0.012 veps=0.015 acc=1.000 sumlogdet=0.146 beta=6.000 acc_mask=1.000 loss=-556.948 plaqs=0.416 sinQ=0.000 intQ=0.004 dQint=0.008 dQsin=0.001\n\n[2025-04-30 15:48:01][I][ipykernel_24193/30352159:21:ezpz.log] train_step=90 dt=1.512 energy=-4034.155 logprob=-4035.872 logdet=1.718 sldf=1.085 sldb=-1.128 sld=1.718 xeps=0.012 veps=0.016 acc=1.000 sumlogdet=-0.056 beta=6.000 acc_mask=1.000 loss=-518.971 plaqs=0.435 sinQ=-0.000 intQ=-0.001 dQint=0.016 dQsin=0.001\n\n[2025-04-30 15:48:09][I][ipykernel_24193/30352159:21:ezpz.log] train_step=95 dt=1.604 energy=-4136.090 logprob=-4137.796 logdet=1.707 sldf=1.071 sldb=-1.091 sld=1.707 xeps=0.012 veps=0.016 acc=1.000 sumlogdet=-0.034 beta=6.000 acc_mask=1.000 loss=-613.025 plaqs=0.455 sinQ=-0.001 intQ=-0.008 dQint=0.012 dQsin=0.001\n\n\n\ndataset_train = history_train.get_dataset()\n_ = history_train.plot_all(\n    title='Train',\n    num_chains=x.shape[0],\n)\n\n\nOutput:\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "L2hmc",
      "üî≥ <code>l2hmc-qcd</code> Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/jupyter/l2hmc/4dSU3/index.html#evaluation",
    "href": "posts/jupyter/l2hmc/4dSU3/index.html#evaluation",
    "title": "üî≥ l2hmc-qcd Example: 4D SU(3)",
    "section": "Evaluation",
    "text": "Evaluation\n# state = ptExpSU3.trainer.dynamics.random_state(6.0)\nxeval, history_eval = evaluate(\n    nsteps=50,\n    exp=ptExpSU3,\n    beta=6.0,\n# x=state.x,\n    job_type='eval',\n    nlog=1,\n    nprint=50,\n    grab=True,\n)\n\n\nOutput:\n\n\n[2025-04-30 15:56:12][I][pytorch/experiment:117:l2hmc.experiment.pytorch.experiment] Running 50 steps of eval at beta=6.0000\n\n[2025-04-30 15:56:12][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 0\n\n[2025-04-30 15:56:12][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 1\n\n[2025-04-30 15:56:13][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 2\n\n[2025-04-30 15:56:14][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 3\n\n[2025-04-30 15:56:14][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 4\n\n[2025-04-30 15:56:15][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 5\n\n[2025-04-30 15:56:15][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 6\n\n[2025-04-30 15:56:16][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 7\n\n[2025-04-30 15:56:16][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 8\n\n[2025-04-30 15:56:17][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 9\n\n[2025-04-30 15:56:17][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 10\n\n[2025-04-30 15:56:18][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 11\n\n[2025-04-30 15:56:18][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 12\n\n[2025-04-30 15:56:19][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 13\n\n[2025-04-30 15:56:19][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 14\n\n[2025-04-30 15:56:20][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 15\n\n[2025-04-30 15:56:20][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 16\n\n[2025-04-30 15:56:21][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 17\n\n[2025-04-30 15:56:21][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 18\n\n[2025-04-30 15:56:22][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 19\n\n[2025-04-30 15:56:22][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 20\n\n[2025-04-30 15:56:23][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 21\n\n[2025-04-30 15:56:23][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 22\n\n[2025-04-30 15:56:24][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 23\n\n[2025-04-30 15:56:24][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 24\n\n[2025-04-30 15:56:24][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 25\n\n[2025-04-30 15:56:25][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 26\n\n[2025-04-30 15:56:25][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 27\n\n[2025-04-30 15:56:26][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 28\n\n[2025-04-30 15:56:26][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 29\n\n[2025-04-30 15:56:27][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 30\n\n[2025-04-30 15:56:27][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 31\n\n[2025-04-30 15:56:28][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 32\n\n[2025-04-30 15:56:28][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 33\n\n[2025-04-30 15:56:29][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 34\n\n[2025-04-30 15:56:29][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 35\n\n[2025-04-30 15:56:29][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 36\n\n[2025-04-30 15:56:30][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 37\n\n[2025-04-30 15:56:30][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 38\n\n[2025-04-30 15:56:31][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 39\n\n[2025-04-30 15:56:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 40\n\n[2025-04-30 15:56:32][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 41\n\n[2025-04-30 15:56:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 42\n\n[2025-04-30 15:56:33][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 43\n\n[2025-04-30 15:56:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 44\n\n[2025-04-30 15:56:34][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 45\n\n[2025-04-30 15:56:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 46\n\n[2025-04-30 15:56:35][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 47\n\n[2025-04-30 15:56:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 48\n\n[2025-04-30 15:56:36][I][pytorch/experiment:121:l2hmc.experiment.pytorch.experiment] STEP: 49\n\n\n\ndataset_eval = history_eval.get_dataset()\n_ = history_eval.plot_all(title='Eval')\n\n\nOutput:\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\n\nsvg\n\n\n\n\nxeval = ptExpSU3.trainer.dynamics.unflatten(xeval)\nlogger.info(f\"checkSU(x_eval): {g.checkSU(xeval)}\")\nlogger.info(f\"checkSU(x_eval): {g.checkSU(g.projectSU(xeval))}\")\n\n\nOutput:\n\n\n[2025-04-30 16:08:39][I][ipykernel_24193/2193937887:2:ezpz.log] checkSU(x_eval): (tensor[8] f64 x‚àà[1.387e-16, 1.458e-16] Œº=1.433e-16 œÉ=2.311e-18 [1.425e-16, 1.457e-16, 1.387e-16, 1.458e-16, 1.436e-16, 1.422e-16, 1.432e-16, 1.447e-16], tensor[8] f64 x‚àà[5.173e-16, 7.840e-16] Œº=6.551e-16 œÉ=1.029e-16 [7.840e-16, 6.628e-16, 5.173e-16, 6.288e-16, 6.088e-16, 7.452e-16, 5.299e-16, 7.638e-16])\n\n[2025-04-30 16:08:39][I][ipykernel_24193/2193937887:3:ezpz.log] checkSU(x_eval): (tensor[8] f64 x‚àà[1.352e-16, 1.451e-16] Œº=1.409e-16 œÉ=3.802e-18 [1.451e-16, 1.352e-16, 1.431e-16, 1.416e-16, 1.366e-16, 1.445e-16, 1.378e-16, 1.430e-16], tensor[8] f64 x‚àà[4.654e-16, 7.451e-16] Œº=5.900e-16 œÉ=9.667e-17 [7.451e-16, 6.309e-16, 4.961e-16, 6.874e-16, 4.654e-16, 6.100e-16, 5.204e-16, 5.651e-16])\n\n\n\nimport matplotlib.pyplot as plt\npdiff = dataset_eval.plaqs - dataset_hmc.plaqs\npdiff\nimport xarray as xr\n\nfig, ax = plt.subplots(figsize=(12, 4))\n(pdiff ** 2).plot(ax=ax)  #, robust=True)\nax.set_title(r\"$\\left|\\delta U_{\\mu\\nu}\\right|^{2}$ (HMC - Eval)\")\noutfile = Path(EVAL_DIR).joinpath('pdiff.svg')\n#%xmode fig.savefig(outfile.as_posix(), dpi=400, bbox_inches='tight')\nplt.show()\n\n\nOutput:\n\n\n\n\n\nsvg",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üìó Jupyter",
      "L2hmc",
      "üî≥ <code>l2hmc-qcd</code> Example: 4D SU(3)"
    ]
  },
  {
    "objectID": "posts/resume/index.html#sam-foreman",
    "href": "posts/resume/index.html#sam-foreman",
    "title": "üë§ R√©sum√©",
    "section": "Sam Foreman",
    "text": "Sam Foreman\nComputational Scientist\nsamforeman.me\nGitHub ‚Ä¢ Google Scholar ‚Ä¢ ORCID ‚Ä¢ Twitter\n\nR√©sum√©\n\nüéì Education\n\nPh.D., Physics\n\nUniversity of Iowa, 2019\n\nLearning Better Physics: A Machine Learning Approach to Lattice Gauge Theory\n\nB.S. in Engineering Physics\n\nUniversity of Illinois at Urbana-Champaign, 2015\nEnergy Storage in Quantum Resonators (US Patent #US9741492B2)\n\nB.S. in Applied Mathematics\n\nUniversity of Illinois at Urbana-Champaign, 2015\n\n\n\n\nüßë‚Äçüî¨ Professional Experience\n\nAssistant Computational Scientist\n\nArgonne National Laboratory, Argonne Leadership Computing Facility (ALCF)\n\nLemont, IL | 2022 ‚Äì Present\n\nResearch lead on scaling large language models (LLMs) and generative AI for science on supercomputers (Aurora, Frontier, LUMI, Leonardo, ‚Ä¶).\nOptimize large-scale training of foundation models and language models for scientific applications.\n\nCollaborate with interdisciplinary teams to enhance simulation efficiency and scalability.\nFocus on AI and HPC for scientific applications, including:\n\nDeveloping improved sampling algorithms for lattice quantum chromodynamics (QCD)\nTraining large language models on supercomputers\n\nhttps://www.alcf.anl.gov/about/people/sam-foreman\n\n\nPostdoctoral Researcher\n\nArgonne National Laboratory, Argonne Leadership Computing Facility (ALCF)\n\nLemont, IL | 2019 ‚Äì 2022\n\nApplied deep learning to lattice gauge theory and quantum field simulations.\nDeveloped ML-enhanced Monte Carlo methods for QCD.\nEngaged in AI-for-Science collaborations with national labs and university partners.\n\n\nGraduate Researcher\n\nArgonne National Laboratory, Math and Computer Sciences (MCS)\nLemont, IL | 2018 ‚Äì 2019\n\nCollaborated with ALCF while completing Ph.D., integrating ML into physical sciences workflows.\n\n\n\n\nüèÜ Awards and Honors\n\nACM Gordon Bell Special Prize for High Performance Computing-Based COVID-19 Research, 2022\n\nRecognized for contributions to the GenSLMs project, which developed genome-scale language models to study SARS-CoV-2 evolutionary dynamics.\nhttps://www.acm.org/media-center/2022/november/gordon-bell-special-prize-covid-research-2022\n\nFinalist, ACM Gordon Bell Prize, 2024\n\nAcknowledged for the MProt-DPO project, which achieved over 4 ExaFLOP sustained performance in multimodal protein design workflows using Direct Preference Optimization.\nhttps://sc.cels.anl.gov/gordon-bell-argonne-team-breaks-new-ground-in-ai-driven-protein-design/\n\nDOE Office of Science Graduate Student Research Fellow, 2018\n\nAwarded by the Department of Energy for outstanding research contributions during graduate studies.\n\n\n\n\nüìö Publications1\n\nMProt-DPO: Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows with Direct Preference Optimization\nGenSLMs: Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics\nApplications of Machine Learning to Lattice Quantum Field Theory\nHMC with Normalizing Flows\nDeep Learning Hamiltonian Monte Carlo\nExamples of Renormalization Group Transformations for Image Sets\n\n\n\nüé§ Selected Talks2\n\nAuroraGPT: Foundation Models for Science @ Foundation Models for the Electric Grid [02/2025]\nParallel Training Methods @ AI-for-Science on Supercomputers [11/2024]\nAuroraGPT @ HPC User Forum, 2024 [09/2024]\nMachine Learning and Foundation Models at Scale @ 2024 ALCF Hands-On HPC Workshop [10/2024]\nTraining LLMs at Scale @ ATPESC, 2024 [08/2024]\nLLMs from Scratch @ LLM Tutorial Workshop [02/2024]\nExascale Science on Aurora @ Intel oneAPI Workshop @ UIC [10/2023]\nScaling LLMs for Science @ Data-Intensive Computing + AI/ML at Scale [08/2023]\nMLMC: Machine Learning Monte Carlo @ Lattice 2023 [07/2023]\nGenerative Modeling and Efficient Sampling @ PASC23 [07/2023]",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üë§ R√©sum√©"
    ]
  },
  {
    "objectID": "posts/resume/index.html#footnotes",
    "href": "posts/resume/index.html#footnotes",
    "title": "üë§ R√©sum√©",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee full list on Google Scholar‚Ü©Ô∏é\nSee full list at: samforeman.me/talks‚Ü©Ô∏é",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "üë§ R√©sum√©"
    ]
  },
  {
    "objectID": "posts/torchtune-aurora/index.html#patch-on-aurora",
    "href": "posts/torchtune-aurora/index.html#patch-on-aurora",
    "title": "ü™õ Torchtune on Aurora",
    "section": "Patch on Aurora",
    "text": "Patch on Aurora\ndiff --git a/torchtune/training/_distributed.py b/torchtune/training/_distributed.py\nindex ff959c5f..c3966290 100644\n--- a/torchtune/training/_distributed.py\n+++ b/torchtune/training/_distributed.py\n@@ -14,7 +14,11 @@ import torch\n import torch.distributed as dist\n from torch import nn\n\n-from torch.distributed._composable.fsdp import CPUOffloadPolicy, fully_shard\n+try:\n+    from torch.distributed._composable.fsdp import fully_shard\n+except (ImportError, ModuleNotFoundError):\n+    from torch.distributed._composable.fsdp.fully_shard import fully_shard\n+\n from torch.distributed._tensor import distribute_tensor, DTensor\n from torch.distributed._tensor.placement_types import DTensorSpec, TensorMeta\n from torch.distributed.checkpoint.state_dict import (\n@@ -532,6 +536,11 @@ def shard_model(\n     \"\"\"\n     fsdp_kwargs = {\"reshard_after_forward\": reshard_after_forward}\n     if cpu_offload:\n+        try:\n+            from torch.distributed._composable.fsdp import CPUOffloadPolicy\n+        except (ImportError, ModuleNotFoundError):\n+            from torch.distributed._composable.fsdp._fsdp_api import MixedPrecisionPolicy, CPUOffloadPolicy\n+            # from torch.distributed._composable import CPUOffloadPolicy\n         fsdp_kwargs[\"offload_policy\"] = CPUOffloadPolicy()\n\n     # Shard the model with FSDP, iterating in reverse to start with",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü™õ Torchtune on Aurora"
    ]
  },
  {
    "objectID": "posts/torchtune-aurora/index.html#using-pytorch-2.5",
    "href": "posts/torchtune-aurora/index.html#using-pytorch-2.5",
    "title": "ü™õ Torchtune on Aurora",
    "section": "Using PyTorch 2.5",
    "text": "Using PyTorch 2.5\nUsing the new enviroment with pytorch==2.5 and after applying the above patch, I am almost able to get things working before ultimately crashing with:\n[rank0]: RuntimeError: Tried to instantiate dummy base class Stream\nThe full command (and output) are included below:\n\nCommand:\n#[üêç anl_2024_12_release_2](üëª anl_2024_12_release_2)\n#[08:47:46 AM][x4204c5s6b0n0][/f/A/f/p/p/torchtune][üå± main][!?][‚è±Ô∏è 2s]\n$ tune run full_finetune_distributed --config llama3_1/8B_full optimizer.fused=False\nOutput:\n\n\nOutput:\n\n[W128 08:49:19.162113524 OperatorEntry.cpp:155] Warning: Warning only once for all operators,  other operators may also be overridden.\nOverriding a previously registered kernel for the same operator and the same dispatch key\noperator: aten::_cummax_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -&gt; ()\nregistered at /build/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\ndispatch key: XPU\nprevious kernel: registered at /build/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30476\nnew kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:2971 (function operator())\n[2025-01-28 08:49:37][I][ezpz/dist:823] Using device='xpu' with backend='DDP' + 'gloo' for distributed training.\n[2025-01-28 08:49:37][I][ezpz/dist:869] ['x4204c5s6b0n0'][0/0]\n[2025-01-28 08:49:37][I][config/_utils:28:torchtune.utils._logging] Running FullFinetuneRecipeDistributed with resolved config:\n\nbatch_size: 2\ncheckpointer:\n_component_: torchtune.training.FullModelHFCheckpointer\ncheckpoint_dir: Meta-Llama-3.1-8B-Instruct/\ncheckpoint_files:\n- model-00001-of-00004.safetensors\n- model-00002-of-00004.safetensors\n- model-00003-of-00004.safetensors\n- model-00004-of-00004.safetensors\nmodel_type: LLAMA3\noutput_dir: /tmp/torchtune/llama3_1_8B/full\nrecipe_checkpoint: null\nclip_grad_norm: null\ncompile: false\ncustom_sharded_layers:\n- tok_embeddings\n- output\ndataset:\n_component_: torchtune.datasets.alpaca_dataset\npacked: false\ndevice: xpu\ndtype: bf16\nenable_activation_checkpointing: false\nenable_activation_offloading: false\nepochs: 1\ngradient_accumulation_steps: 1\nlog_every_n_steps: 1\nlog_peak_memory_stats: true\nloss:\n_component_: torchtune.modules.loss.CEWithChunkedOutputLoss\nmax_steps_per_epoch: null\nmetric_logger:\n_component_: torchtune.training.metric_logging.DiskLogger\nlog_dir: /tmp/torchtune/llama3_1_8B/full/logs\nmodel:\n_component_: torchtune.models.llama3_1.llama3_1_8b\noptimizer:\n_component_: torch.optim.AdamW\nfused: false\nlr: 2.0e-05\noptimizer_in_bwd: false\noutput_dir: /tmp/torchtune/llama3_1_8B/full\nprofiler:\n_component_: torchtune.training.setup_torch_profiler\nactive_steps: 2\ncpu: true\ncuda: true\nenabled: false\nnum_cycles: 1\noutput_dir: /tmp/torchtune/llama3_1_8B/full/profiling_outputs\nprofile_memory: false\nrecord_shapes: true\nwait_steps: 5\nwarmup_steps: 3\nwith_flops: false\nwith_stack: false\nresume_from_checkpoint: false\nseed: null\nshuffle: true\ntokenizer:\n_component_: torchtune.models.llama3.llama3_tokenizer\nmax_seq_len: null\npath: Meta-Llama-3.1-8B-Instruct/original/tokenizer.model\n\n[2025-01-28 08:49:37][I][recipes/full_finetune_distributed:141:__main__] log_peak_memory_stats was set to True, however, training does not use cuda. Setting log_peak_memory_stats=False.\n/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/training/checkpointing/_checkpoint_client.py:75: FutureWarning: get_world_size_and_rank is deprecated and will be removed in future versions. `get_world_size_and_rank` will move to `torchtune.utils._device` in future releases. Please use `torchtune.utils.get_world_size_and_rank` instead.\n_, self._rank = training.get_world_size_and_rank()\n[2025-01-28 08:49:37][D][training/seed:60:torchtune.utils._logging] Setting manual seed to local seed 4028640460. Local seed is seed + rank = 4028640460 + 0\nWriting logs to /tmp/torchtune/llama3_1_8B/full/logs/log_1738075777.txt\n[2025-01-28 08:49:39][I][recipes/full_finetune_distributed:499:__main__] FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/tensor/_random.py:45: UserWarning: DTensor random operators may not have complete support on cpu device mesh\nwarnings.warn(\n[2025-01-28 08:49:53][I][recipes/full_finetune_distributed:568:__main__] Instantiating model and loading checkpoint took 13.79 secs\n[2025-01-28 08:49:53][I][training/memory:301:torchtune.utils._logging] Memory stats after model init:\nXPU peak memory allocation: 1.04 GiB\nXPU peak memory reserved: 1.14 GiB\nXPU peak memory active: 1.04 GiB\n[2025-01-28 08:49:53][I][recipes/full_finetune_distributed:632:__main__] Optimizer is initialized.\n[2025-01-28 08:49:53][I][recipes/full_finetune_distributed:317:__main__] Loss is initialized.\n[2025-01-28 08:49:55][I][recipes/full_finetune_distributed:685:__main__] Dataset and Sampler are initialized.\n[2025-01-28 08:49:55][I][recipes/full_finetune_distributed:382:__main__] No learning rate scheduler configured. Using constant learning rate.\n[2025-01-28 08:49:55][W][training/_profiler:53:torchtune.utils._logging]  Profiling disabled.\n[2025-01-28 08:49:55][I][recipes/full_finetune_distributed:467:__main__]  Profiler config after instantiation: {'enabled': False}\n0%|                                                                                                                                                          | 0/26001 [00:00&lt;?, ?it/s][rank0]: Traceback (most recent call last):\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/venvs/anl_2024_12_release_2/bin/tune\", line 8, in &lt;module&gt;\n[rank0]:     sys.exit(main())\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/tune.py\", line 49, in main\n[rank0]:     parser.run(args)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/tune.py\", line 43, in run\n[rank0]:     args.func(args)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/run.py\", line 214, in _run_cmd\n[rank0]:     self._run_single_device(args, is_builtin=is_builtin)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/run.py\", line 108, in _run_single_device\n[rank0]:     runpy.run_path(str(args.recipe), run_name=\"__main__\")\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/runpy.py\", line 289, in run_path\n[rank0]:     return _run_module_code(code, init_globals, run_name,\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/runpy.py\", line 96, in _run_module_code\n[rank0]:     _run_code(code, mod_globals, init_globals,\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/runpy.py\", line 86, in _run_code\n[rank0]:     exec(code, run_globals)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 928, in &lt;module&gt;\n[rank0]:     sys.exit(recipe_main())\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/config/_parse.py\", line 99, in wrapper\n[rank0]:     sys.exit(recipe_main(conf))\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 923, in recipe_main\n[rank0]:     recipe.train()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 749, in train\n[rank0]:     logits = self._model(**batch)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n[rank0]:     return inner()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1769, in inner\n[rank0]:     args_kwargs_result = hook(self, args, kwargs)  # type: ignore[misc]\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 66, in fsdp_hook_wrapper\n[rank0]:     return torch._dynamo.disable(func, recursive=True)(*args, **kwargs)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\n[rank0]:     return fn(*args, **kwargs)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 224, in _pre_forward\n[rank0]:     args, kwargs = self._root_pre_forward(module, args, kwargs)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 117, in _root_pre_forward\n[rank0]:     self._lazy_init()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 175, in _lazy_init\n[rank0]:     self._init_shared_state()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 183, in _init_shared_state\n[rank0]:     self._comm_ctx.lazy_init()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/micromamba/envs/anl_2024_12_release_2/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_param_group.py\", line 48, in lazy_init\n[rank0]:     raise RuntimeError(\"FSDP requires CUDA for streams\")\n[rank0]: RuntimeError: FSDP requires CUDA for streams\n0%|                                                                                                                                                          | 0/26001 [00:00&lt;?, ?it/s]\n[1]    135144 exit 1     tune run full_finetune_distributed --config llama3_1/8B_full\ntook: 0h:00m:55s",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü™õ Torchtune on Aurora"
    ]
  },
  {
    "objectID": "posts/torchtune-aurora/index.html#using-pytorch-2.3",
    "href": "posts/torchtune-aurora/index.html#using-pytorch-2.3",
    "title": "ü™õ Torchtune on Aurora",
    "section": "Using PyTorch 2.3",
    "text": "Using PyTorch 2.3\n\nCommand:\n#[üêç aurora_nre_models_frameworks-2024.2.1_u1](:ghost: aurora_nre_models_frameworks-2024.2.1_u1)\n#[08:07:29 AM][x4204c5s6b0n0][/f/A/f/p/p/torchtune][:seedling: main][!?][:stopwatch: 13s]\n$ tune run full_finetune_distributed --config llama4_1/8B_full optimizer.fused=False\nOutput:\n\n\nOutput:\n\n[2025-01-28 08:07:38][I][ezpz/dist:823] Using device='xpu' with backend='DDP' + 'ccl' for distributed training.\n[2025-01-28 08:07:38][I][ezpz/dist:869] ['x4204c5s6b0n0'][0/0]\n2025:01:28-08:07:38:(115657) |CCL_WARN| did not find MPI-launcher specific variables, switch to ATL/OFI, to force enable ATL/MPI set CCL_ATL_TRANSPORT=mpi\n2025:01:28-08:07:38:(115657) |CCL_WARN| value of CCL_LOCAL_RANK changed to be 0 (default:-1)\n2025:01:28-08:07:38:(115657) |CCL_WARN| value of CCL_LOCAL_SIZE changed to be 1 (default:-1)\n2025:01:28-08:07:38:(115657) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be none (default:hydra)\n[2025-01-28 08:07:38][I][config/_utils:28:torchtune.utils._logging] Running FullFinetuneRecipeDistributed with resolved config:\n\nbatch_size: 2\ncheckpointer:\n  _component_: torchtune.training.FullModelHFCheckpointer\n  checkpoint_dir: Meta-Llama-3.1-8B-Instruct/\n  checkpoint_files:\n  - model-00001-of-00004.safetensors\n  - model-00002-of-00004.safetensors\n  - model-00003-of-00004.safetensors\n  - model-00004-of-00004.safetensors\n  model_type: LLAMA3\n  output_dir: /tmp/torchtune/llama3_1_8B/full\n  recipe_checkpoint: null\nclip_grad_norm: null\ncompile: false\ncustom_sharded_layers:\n- tok_embeddings\n- output\ndataset:\n  _component_: torchtune.datasets.alpaca_dataset\n  packed: false\ndevice: xpu\ndtype: bf16\nenable_activation_checkpointing: false\nenable_activation_offloading: false\nepochs: 1\ngradient_accumulation_steps: 1\nlog_every_n_steps: 1\nlog_peak_memory_stats: true\nloss:\n  _component_: torchtune.modules.loss.CEWithChunkedOutputLoss\nmax_steps_per_epoch: null\nmetric_logger:\n  _component_: torchtune.training.metric_logging.DiskLogger\n  log_dir: /tmp/torchtune/llama3_1_8B/full/logs\nmodel:\n  _component_: torchtune.models.llama3_1.llama3_1_8b\noptimizer:\n  _component_: torch.optim.AdamW\n  fused: false\n  lr: 2.0e-05\noptimizer_in_bwd: false\noutput_dir: /tmp/torchtune/llama3_1_8B/full\nprofiler:\n  _component_: torchtune.training.setup_torch_profiler\n  active_steps: 2\n  cpu: true\n  cuda: true\n  enabled: false\n  num_cycles: 1\n  output_dir: /tmp/torchtune/llama3_1_8B/full/profiling_outputs\n  profile_memory: false\n  record_shapes: true\n  wait_steps: 5\n  warmup_steps: 3\n  with_flops: false\n  with_stack: false\nresume_from_checkpoint: false\nseed: null\nshuffle: true\ntokenizer:\n  _component_: torchtune.models.llama3.llama3_tokenizer\n  max_seq_len: null\n  path: Meta-Llama-3.1-8B-Instruct/original/tokenizer.model\n\n[2025-01-28 08:07:38][I][recipes/full_finetune_distributed:141:__main__] log_peak_memory_stats was set to True, however, training does not use cuda. Setting log_peak_memory_stats=False.\n/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/training/checkpointing/_checkpoint_client.py:75: FutureWarning: get_world_size_and_rank is deprecated and will be removed in future versions. `get_world_size_and_rank` will move to `torchtune.utils._device` in future releases. Please use `torchtune.utils.get_world_size_and_rank` instead.\n  _, self._rank = training.get_world_size_and_rank()\n[2025-01-28 08:07:38][D][training/seed:60:torchtune.utils._logging] Setting manual seed to local seed 2201534845. Local seed is seed + rank = 2201534845 + 0\nWriting logs to /tmp/torchtune/llama3_1_8B/full/logs/log_1738073258.txt\n[2025-01-28 08:07:39][I][recipes/full_finetune_distributed:499:__main__] FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_tensor/random.py:36: UserWarning: DTensor random operators may not have complete support on cpu device mesh\n  warnings.warn(\n[2025-01-28 08:07:45][I][recipes/full_finetune_distributed:568:__main__] Instantiating model and loading checkpoint took 5.74 secs\n[2025-01-28 08:07:45][I][training/memory:301:torchtune.utils._logging] Memory stats after model init:\n        XPU peak memory allocation: 1.04 GiB\n        XPU peak memory reserved: 1.14 GiB\n        XPU peak memory active: 1.04 GiB\n[2025-01-28 08:07:45][I][recipes/full_finetune_distributed:632:__main__] Optimizer is initialized.\n[2025-01-28 08:07:45][I][recipes/full_finetune_distributed:317:__main__] Loss is initialized.\nREADME.md: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.47k/7.47k [00:00&lt;00:00, 85.6MB/s]\n(‚Ä¶)-00000-of-00001-a09b74b3ef9c3b56.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24.2M/24.2M [00:00&lt;00:00, 105MB/s]\nGenerating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52002/52002 [00:01&lt;00:00, 45116.86 examples/s]\n[2025-01-28 08:07:49][I][recipes/full_finetune_distributed:685:__main__] Dataset and Sampler are initialized.\n[2025-01-28 08:07:49][I][recipes/full_finetune_distributed:382:__main__] No learning rate scheduler configured. Using constant learning rate.\n[2025-01-28 08:07:49][W][training/_profiler:53:torchtune.utils._logging]  Profiling disabled.\n[2025-01-28 08:07:49][I][recipes/full_finetune_distributed:467:__main__]  Profiler config after instantiation: {'enabled': False}\n  0%|                                                                                                                                                                                                                                                       | 0/26001 [00:00&lt;?, ?it/s][rank0]: Traceback (most recent call last):\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/tune\", line 10, in &lt;module&gt;\n[rank0]:     sys.exit(main())\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/tune.py\", line 49, in main\n[rank0]:     parser.run(args)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/tune.py\", line 43, in run\n[rank0]:     args.func(args)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/run.py\", line 214, in _run_cmd\n[rank0]:     self._run_single_device(args, is_builtin=is_builtin)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/_cli/run.py\", line 108, in _run_single_device\n[rank0]:     runpy.run_path(str(args.recipe), run_name=\"__main__\")\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/runpy.py\", line 289, in run_path\n[rank0]:     return _run_module_code(code, init_globals, run_name,\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/runpy.py\", line 96, in _run_module_code\n[rank0]:     _run_code(code, mod_globals, init_globals,\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/runpy.py\", line 86, in _run_code\n[rank0]:     exec(code, run_globals)\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 928, in &lt;module&gt;\n[rank0]:     sys.exit(recipe_main())\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/torchtune/config/_parse.py\", line 99, in wrapper\n[rank0]:     sys.exit(recipe_main(conf))\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 923, in recipe_main\n[rank0]:     recipe.train()\n[rank0]:   File \"/lus/flare/projects/Aurora_deployment/foremans/projects/pytorch/torchtune/recipes/full_finetune_distributed.py\", line 749, in train\n[rank0]:     logits = self._model(**batch)\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1561, in _call_impl\n[rank0]:     args_kwargs_result = hook(self, args, kwargs)  # type: ignore[misc]\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 153, in _pre_forward\n[rank0]:     args, kwargs = self._root_pre_forward(module, args, kwargs)\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 67, in _root_pre_forward\n[rank0]:     self._lazy_init()\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 112, in _lazy_init\n[rank0]:     self._init_shared_state()\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_state.py\", line 120, in _init_shared_state\n[rank0]:     self._comm_ctx.init()\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/distributed/_composable/fsdp/_fsdp_param_group.py\", line 49, in init\n[rank0]:     self.all_gather_copy_in_stream = torch.cuda.Stream(priority=high_priority)\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/cuda/streams.py\", line 34, in __new__\n[rank0]:     return super().__new__(cls, priority=priority, **kwargs)\n[rank0]:   File \"/opt/aurora/24.180.3/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/torch/_utils.py\", line 907, in err_fn\n[rank0]:     raise RuntimeError(f\"Tried to instantiate dummy base class {class_name}\")\n[rank0]: RuntimeError: Tried to instantiate dummy base class Stream\n  0%|                                                                                                                                                                                                                                                       | 0/26001 [00:00&lt;?, ?it/s]\n[1]    115657 exit 1     tune run full_finetune_distributed --config llama3_1/8B_full",
    "crumbs": [
      "talks",
      "üì¨ Posts",
      "ü™õ Torchtune on Aurora"
    ]
  }
]