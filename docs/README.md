Sam Foreman
2025-11-27

<div style="font-size:1.0em; text-align: center;">

<span class="profile-avatar"><img width=75 height=75 src="./assets/avi-small.webp" width="100%" aria-label="Sam Foreman" alt="Sam Foreman"></img></span>

<span style="font-size: 1.5rem; color: var(--dim-text)!important; padding-bottom: 0pt;"><span class="dim-text">üëã
Hi, I‚Äôm Sam!</span> [<span class="orcid-green"
style="background: none!important;"></span>]</span>

<div class="flex-container icon-flex"
style="font-size: 1.5rem; justify-content: center; flex-direction: row;">

<p>

<span class="fa-li"><a style="color: #838383;" href="https://samforeman.me/" data-original-href="https://samforeman.me/"><iconify-icon class="icon-home" loading="lazy" role="img" inline="true" icon="ph:house" aria-label="Homepage" title="Homepage"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://github.com/saforem2"><iconify-icon class="icon-github" loading="lazy" role="img" inline="true" icon="ph:github-logo" aria-label="GitHub" title="GitHub"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://twitter.com/saforem2"><iconify-icon class="icon-twitter" loading="lazy" role="img" inline="true" icon="ph:twitter-logo" aria-label="Twitter" title="Twitter"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://bsky.app/profile/samforeman.bsky.social"><iconify-icon class="icon-bluesky" loading="lazy" role="img" inline="true" icon="ph:butterfly" aria-label="Bluesky" title="Bluesky"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://scholar.google.com/citations?user=vV_1zDwAAAAJ&hl=en"><iconify-icon class="icon-scholar" loading="lazy" role="img" inline="true" icon="ph:graduation-cap" aria-label="Google Scholar" title="Google Scholar"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="mailto:foremans@anl.gov"><iconify-icon class="icon-email" loading="lazy" role="img" inline="true" icon="ph:envelope-open" aria-label="Email" title="Email"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://outlook.office.com/"><iconify-icon class="icon-calendar" loading="lazy" role="img" inline="true" icon="ph:calendar" aria-label="Schedule Time" title="Email"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://linkedin.com/in/saforem2" data-original-href="https://linkedin.com/in/saforem2" target="_blank" rel="noopener"><iconify-icon class="icon-linkedin" loading="lazy" role="img" inline="true" icon="ph:linkedin-logo" aria-label="LinkedIn" title="LinkedIn"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://open.spotify.com/user/saforem2" data-original-href="https://open.spotify.com/user/saforem2" target="_blank" rel="noopener"><iconify-icon class="icon-spotify" loading="lazy" role="img" inline="true" icon="ph:spotify-logo" aria-label="Spotify" title="Spotify"></iconify-icon></a></span>
<span class="fa-li"><a style="color: #838383;" href="https://www.last.fm/user/saforem2" data-original-href="https://www.last.fm/user/saforem2" target="_blank" rel="noopener"><iconify-icon class="icon-lastfm" loading="lazy" role="img" inline="true" icon="ph:lastfm-logo" aria-label="LastFM" title="LastFM"></iconify-icon></a></span>
</p>

</div>

</div>

<div class="panel-tabset"
style="justify-content: center; loading='lazy';">

### üßëüèª‚Äçüíª About

<div class="flex-container" style="gap: 5pt;">

<div class="column" style="width:50%;">

I‚Äôm a [Computational Scientist][Argonne National Laboratory] in the [AI
/ ML group] at the [Argonne Leadership Computing Facility (ALCF)].

I‚Äôm generally interested in the large scale distributed training of AI
models for scientific applications, and am the co-lead of the [Models /
Pre-Training group] for the [AuroraGPT] project.

Prior to this, I received my PhD in Physics from the University of Iowa
in 2019, where I used ML to build better Markov Chain Monte Carlo
sampling techniques for Lattice Quantum Chromodynamics ([`l2hmc-qcd`]).

</div>

<div class="column" style="width: 50%;">

> [!TIP]
>
> ### ‚ú® New!
>
> üåé <span class="highlight-green">AERIS</span>: [Argonne Earth Systems
> Model for Reliable and Skillful Predictions][^1] (Hatanp√§√§ et al.
> (2025))

> [!TIP]
>
> ### ‚úèÔ∏è Last Updated
>
> <pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Updated: <span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">2025</span><span style="color: #e599f7; text-decoration-color: #e599f7">-</span><span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">11</span><span style="color: #e599f7; text-decoration-color: #e599f7">-</span><span style="color: #e599f7; text-decoration-color: #e599f7; font-weight: bold">27</span> <span style="color: #838383; text-decoration-color: #838383">@</span> <span style="color: #00ccff; text-decoration-color: #00ccff; font-weight: bold">10:20:54</span>
> </pre>

> [!TIP]
>
> ### üé∂ Now Playing
>
> > [!TIP]
> >
> > ### <span style="color:#1CD760;"><img loading="lazy" src="./assets/spotify-green.svg" class="inline-icon img-fluid" height="24" width="24" style="height:1.25rem; width: auto; vertical-align:text-top;" alt="spotify" /> Now Playing</span>
> >
> > <a href="https://open.spotify.com/user/saforem2" target="_blank"><img src="https://spotify-github-profile.kittinanx.com/api/view?uid=saforem2&cover_image=true&theme=novatorem&show_offline=false&background_color=1CD7607Fnone&interchange=true" alt="Now Playing" style="background-color:rgba(0,0,0,0.025); width:auto; max-width: 100%;"/></a>
>
> > [!TIP]
> >
> > ### <a href="https://last.fm/user/saforem2" target="_blank"><img src="https://api.iconify.design/logos:lastfm.svg" alt="last.fm" style="overflow: visible;"/></a>
> >
> > <script>
> > /**
> >   Developed by Prashant Shrestha
> >   + https://prashant.me
> > */
> > var lastfmData = {
> >   baseURL:
> >     "https://ws.audioscrobbler.com/2.0/?method=user.getrecenttracks&user=",
> >   // Your Last.fm Username
> >   user: "saforem2",
> >   // Your API key
> >   api_key: "1dbc15037c1fe71ce06acbb3f73adc75",
> >   additional: "&format=json&limit=1"
> > };
> > &#10;var getSetLastFM = function() {
> >   $.ajax({
> >     type: "GET",
> >     url:
> >       lastfmData.baseURL +
> >       lastfmData.user +
> >       "&api_key=" +
> >       lastfmData.api_key +
> >       lastfmData.additional,
> >     dataType: "json",
> >     success: function(resp) {
> >       var recentTrack = resp.recenttracks.track[0];
> >       var formatted =
> >         // "<img src='https://api.iconify.design/streamline-emojis:musical-notes.svg?color=%23888888'>" + recentTrack.name;
> >         "üé∂ " + recentTrack.name;
> >       $("a#tracktitle")
> >         .html(formatted)
> >         .attr("href", recentTrack.url)
> >         .attr("title", recentTrack.name + " by " + recentTrack.artist["#text"])
> >         .attr("target", "_blank");
> > &#10;      var artistFormatted =
> >         // "<img src='https://api.iconify.design/material-symbols:person.svg?color=%23888888'>" + recentTrack.artist["#text"];
> >         "üó£Ô∏è " + recentTrack.artist["#text"];
> >       $("a#trackartist")
> >         .html(artistFormatted)
> >         .attr("title", "Artist : " + recentTrack.artist["#text"]);
> >       $("img#trackart").attr("src", recentTrack.image[2]["#text"]);
> >     },
> >     error: function(resp) {
> >       $("a#tracktitle").html(
> >         "<img src='https://api.iconify.design/streamline-emojis:muted-speaker.svg?color=%23888888'>" + "Silence!"
> >       );
> >       $("img#trackart").attr("src", "üßëüèª‚Äçüíª");
> >       var artistFormatted =
> >         "Sam Foreman";
> >       $("a#trackartist")
> >         .html(artistFormatted)
> >         .attr("href", "https://samforeman.me");
> >     }
> >   });
> > };
> > &#10;// Get the new one.
> > getSetLastFM();
> > // Start the countdown.
> > setInterval(getSetLastFM, 10 * 5000);
> > </script> <div class="nowplayingcard">
> > <div class="nowplayingcontainer-inner">
> > <img id="trackart" src="#">
> > <div class="trackInfo">
> > <a id="tracktitle"></a>
> > <a href="#" id="trackartist"></a>
> > </div>
> > </div>
> > </div>

</div>

</div>

> [!TIP]
>
> ### ‚ûï More
>
> > [!TIP]
> >
> > ### üî• What I Work on
> >
> > As a member of the [AI / ML Group] at [ALCF], I work on:
> >
> > <div class="flex-container">
> >
> > <div class="flex-container">
> >
> > - ü§ñ üß™ [AI + Science]
> >
> > - üé≤ [Building better sampling methods for Lattice QCD][`l2hmc-qcd`]
> >
> > - üß¨ [Genome-Scale Language Models]
> >
> >   - [ GenSLM]
> >
> >   - ü•á [ACM Gordon Bell Special Prize]
> >
> > </div>
> >
> > <div class="flex-container">
> >
> > - üåç [Foundation models for long term climate forecasting]
> >
> > - üèÉ‚Äç‚ôÇÔ∏è [Scaling Large Language Models]
> >
> > - üèéÔ∏è [Distributed training across thousands of GPUs]
> >
> > </div>
> >
> > </div>
>
> > [!TIP]
> >
> > ### üìç How I got here
> >
> > My [current research] focuses on using deep generative modeling to
> > help build better sampling algorithms in lattice gauge theory. In
> > particular, I‚Äôm interested in building gauge equivariant neural
> > network architectures and using inductive priors to incorporate
> > physical symmetries into machine learning models.
> >
> > <br>
> >
> > I received my PhD in Physics from the University of Iowa in 2019 and
> > my thesis was on [Learning Better Physics: A Machine Learning
> > Approach to Lattice Gauge Theory].
> >
> > <br>
> >
> > Prior to this, I completed two bachelors degrees (Engineering
> > Physics and Applied Mathematics, 2015) at The University of Illinois
> > at Urbana-Champaign. My undergraduate dissertation was titled
> > [Energy Storage in Quantum Resonators] and was supervised by
> > Professor [Alfred H√ºbler] within the Center for Complex Systems
> > Research at UIUC.
> >
> > This work ultimately resulted in a [patent] !!
>
> > [!TIP]
> >
> > ### üíå Contact
> >
> > <script data-letterbirduser="sam" src="https://letterbird.co/embed/v1.js"></script>
>
> <div style="text-align:center;">
>
> <img loading="lazy" alt="hits" src="https://hitscounter.dev/api/hit?url=samforeman.me&label=samforeman.me&icon=check2-square&color=%236c757d">
>
> <span class="dim-text">¬© Copyright 2025 [Sam Foreman]</span>
>
> </div>

### üì¨ Posts

<div id="listing-posts">

</div>

### üìä Talks

> [!TIP]
>
> ### \[HTML ‚áÜ Reveal.js\]
>
> Convert from HTML to slideshow version of a page by appending
> `/slides` to the end of its URL, e.g.
>
> - HTML: <https://samforeman.me/talks/ai-for-science-2024/>
> - Slides: <https://samforeman.me/talks/ai-for-science-2024/slides>

<div id="listing-talks">

</div>

## üìÜ 2025

> [!TIP]
>
> ### <span class="dim-text">[Training Foundation Models on Supercomputers] @ UIUC \[10/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/2025/10/24/slides#" title="Training Foundation Models on Supercomputers" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Training Foundation Models on Supercomputers][1] @ Georgia Institute of Technology \[10/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/2025/10/15/slides#" title="Training Foundation Models on Supercomputers" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[AERIS: Argonne Earth Systems Model] @ [2025 ALCF Hands On HPC Workshop][] \[10/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/2025/10/08/slides#" title="AERIS: Argonne Earth Systems Model" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Training Foundation Models on Supercomputers][2] @ [2025 ALCF Hands On HPC Workshop][] \[09/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/2025/09/24/slides#" title="Training Foundation Models on Supercomputers" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Scientific AI at Scale: AI for Science] @ [Open SkAI 2025][] \[09/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/openskai25/ai4science/slides#" title="Scientific AI at Scale: AI for Science" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Scientific AI at Scale: Distributed Training] @ [Open SkAI 2025][3] \[09/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/openskai25/training/slides.html" title="Scientific AI at Scale: Distributed Training" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Large Scale Training on Diverse Accelerators] @ [Scalable Deep Learning, *SIAM AN2025*][] \[07/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/AuroraGPT-SIAM25/slides#" title="AuroraGPT: Large Scale Training on Diverse Accelerators" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[LLMs on Aurora: üåå AuroraGPT] @ [*2025 ALCF INCITE GPU Hackathon*][] \[05/2025\]</span>
>
> - [üé• video]
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/incite-hackathon-2025/AuroraGPT/slides#/section" title="LLMs on Aurora: AuroraGPT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[LLMs on Aurora: üçã ezpz] @ [*2025 ALCF INCITE GPU Hackathon*][] \[05/2025\]</span>
>
> - [üé• video][4]
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="https://samforeman.me/talks/incite-hackathon-2025/ezpz/slides#/section" title="üçã ezpz on Aurora" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[AuroraGPT: Foundation Models for Science] @ [*Foundation Models for the Electric Grid*][] \[02/2025\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="/talks/aurora-gpt-fm-for-electric-grid/slides.html" title="AuroraGPT: Foundation Models for Science" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

## üìÜ 2024

> [!TIP]
>
> ### <span class="dim-text">[Parallel Training Methods] @ [*AI-for-Science on Supercomputers*][*Foundation Models for the Electric Grid*] \[11/2024\]</span>
>
> - [üé• video][5]
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="/talks/ai-for-science-2024/slides.html" title="Parallel Training Methods" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[AuroraGPT][6] @ [*2024 ALCF Hands-On HPC Workshop*][] \[10/2024\]</span>
>
> - [üé• video][4]
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck" loading="lazy" src="/talks/AuroraGPT/alcf-hpc-workshop-2024/slides.html" title="AuroraGPT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Machine Learning and Foundation Models at Scale] @ [*2024 ALCF Hands-On HPC Workshop*][] \[10/2024\]</span>
>
> <div class="reveal-full-page">
>
> <iframe class="slide-deck" loading="lazy" src="https://samforeman.me/talks/alcf-hpc-workshop-2024/slides#/section" title="Machine Learning and Foundation Models at Scale" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[AuroraGPT][7] @ [*HPC User Forum*, 2024][] \[09/2024\]</span>
>
> <iframe class="slide-deck reveal-full-page" loading="lazy" src="/talks/hpc-user-forum/slides.html" title="AuroraGPT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>

> [!TIP]
>
> ### <span class="dim-text">[Training LLMs at Scale] @ [*ATPESC*, 2024][] \[08/2024\]</span>
>
> <iframe class="slide-deck" loading="lazy" src="/talks/llms-at-scale/slides.html" title="Training LLMs at Scale" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>

> [!TIP]
>
> ### <span class="dim-text">[LLMs on Polaris] @ [*Center for Scientific Foundation Models*, Summer School 24‚Äô][] \[07/2024\]</span>
>
> <iframe class="slide-deck" loading="lazy" src="/talks/llms-on-polaris/slides.html" title="LLMs on Polaris" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>

> [!TIP]
>
> ### <span class="dim-text">[Parallel Training Techniques] @ [*AI-4-Science Training Series*][] \[03/2024\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/parallel-training-slides" title="Parallel Training Techniques" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[LLMs from Scratch] @ [LLM Tutorial Workshop][] \[02/2024\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/llm-workshop-talk" title="LLMs from Scratch" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

## üìÜ 2023

> [!TIP]
>
> ### <span class="dim-text">[Creating Small(-ish) LLMs] @ [LLM Tutorial Workshop (1)][] \[11/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/LLM-tutorial" title="Creating Small(-ish) LLMs" align="center" frameborder="0" webkitallowfullscreen allowfullscreen>
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Exascale Science on Aurora] @ [Intel oneAPI Workshop @ UIC][] \[10/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/oneapi-talk" title="Exascale Science on Aurora" align="center" frameborder="0" webkitallowfullscreen allowfullscreen>
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[LLM Lunch Talk] @ [ALCF Hands On HPC Workshop][Intel oneAPI Workshop @ UIC] \[10/2023\]</span>
>
> - [üé• video][8]
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/llm-lunch-talk/#/section" title="LLMs on Polaris" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Scaling LLMs for Science] @ [Data-Intensive Computing + AI/ML at Scale][] \[08/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/scaling4science/#/section" title="Scaling LLMs for Science and Ongoing Collaborations" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[MLMC: Machine Learning Monte Carlo] @ [Lattice 2023][] \[07/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/lattice23/#/title-slide" title="MLMC: Machine Learning Monte Carlo" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Generative Modeling and Efficient Sampling] @ [PASC23][] \[07/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/lqcd-pasc23/" title="Generative Modeling and Efficient Sampling" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Efficient Sampling for LGT] @ [Deep Fridays @ U. Bologna][] \[04/2023\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/deep-fridays/" title="Efficient Sampling for LGT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

## üìÜ 2022

> [!TIP]
>
> ### <span class="dim-text">[Large Scale Training] @ [AI4Science on Supercomputers (ALCF)][] \[11/2022\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/ai4sci-large-scale-training/#" title="Large Scale Training" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Hyperparameter Management] @ [ALCF SDL Workshop][] \[10/2022\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/hparam-management-sdl2022" title="Hyperparameter Management" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Statistical Learning] @ [ATPESC 2022][] \[08/2022\]</span>
>
> - [üìï accompanying notebook]
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/ATPESC-StatisticalLearning/#/" title="Statistical Learning" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Scientific Data Science: An Emerging Symbiosis] @ ANL (05/2022)</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/anl-job-talk" title="Scientific Data Science" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Machine Learning in HEP] @ UNC Greensboro \[03/2022\]</span>
>
> - [Machine Learning in HEP], at UNC Greensboro, March 2022
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/physicsSeminar" title="Machine Learning in HEP" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="width:100%!important; ">
>
> </iframe>
>
> </div>

## üìÜ 2021

> [!TIP]
>
> ### <span class="dim-text">[Accelerated Sampling Methods for LGT], @ [DWQ @ 25 \[BNL\]][9] \[12/2021\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/l2hmc-dwq25/" title="Accelerated Sampling Methods for LGT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[Training Topological Samplers for LGT] @ [ML4HEP, ECT\* Trento][] \[09/2021\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://saforem2.github.io/l2hmc_talk_ect2021" title="Training Topological Samplers for LGT" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

> [!TIP]
>
> ### <span class="dim-text">[l2hmc-qcd][`l2hmc-qcd`] @ MIT Lattice Group Seminar \[2021\]</span>
>
> [l2hmc-qcd][`l2hmc-qcd`] at the *MIT Lattice Group Seminar*, 2021

> [!TIP]
>
> ### <span class="dim-text">[Deep Learning HMC for Improved Gauge Generation] @ [ML in LQCD Workshop][] \[2021\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://slides.com/samforeman/dlhmc/embed" title="Deep Learning HMC for Improved Gauge Generation" scrolling="no" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

## üìÜ 2020

> [!TIP]
>
> ### <span class="dim-text">[Machine Learning for Lattice QCD] @ U. Iowa \[2020\]</span>
>
> <div class="embedded-slide">
>
> <iframe class="slide-deck" loading="lazy" src="https://slides.com/samforeman/l2hmc-qcd/embed" title="Machine Learning for Lattice QCD" align="center" frameborder="0" webkitallowfullscreen allowfullscreen style="aspect-ratio:1.3671875;">
>
> </iframe>
>
> </div>

### üìù Work

> [!NOTE]
>
> <span style="color:#4582ec;">You can find a full list of my
> publications on my [Google Scholar]</span>

1.  üåé [<span class="highlight-green">**AERIS**</span>: **Argonne Earth
    Systems Model for Reliable and Skillful
    Predictions**][Argonne Earth Systems Model for Reliable and Skillful Predictions]
    (Hatanp√§√§ et al. (2025))
    - ‚ú® [*2025 ACM Gordon Bell Prize for Climate Modeling Finalist*]
2.  Aurora: Architecting Argonne‚Äôs First Exascale Supercomputer for
    Accelerated Scientific Discovery (Allen et al. (2025))
3.  [HiPerRAG: High-Performance Retrieval Augmented Generation for
    Scientific Insights] (Gokdemir et al. (2025))
4.  [Automated Tuning for HMC Mass Ratios] (Torsiello et al. (2025))
5.  [MOFA: Discovering Materials for Carbon Capture with a GenAI and
    Simulation-Based Workflow] (Yan et al. (2025))
6.  üß™ [<span class="highlight-pink">**MProt-DPO**</span>: **Breaking
    the ExaFLOPS Barrier for Multimodal Protein Design with DPO**]
    (Dharuman et al. (2024))
    - üåü [*2024 ACM Gordon Bell Finalist*]
7.  [Intro to HPC Bootcamp: Engaging New Communities Through Energy
    Justice Projects] (Leung et al. (2024))
8.  [Thorough Characterization and Analysis of Large Transformer Model
    Training At-Scale] (Cheng et al. (2024))
9.  [MLMC: Machine Learning Monte Carlo for Lattice Gauge Theory] (Sam
    Foreman, Jin, and Osborn (2023))
10. [Protein Generation via Genome-scale Language Models with
    Bio-physical Scoring] (Dharuman et al. (2023))
11.  [DeepSpeed4Science Initiative: Enabling Large-Scale Scientific
    Discovery] (Song et al. (2023))
    - [üì∞ DeepSpeed4Science.ai Blog Post]
    - [üöÇ Loooooooong Sequence Lengths]
12. [Comprehensive Performance Study of LLMs on Novel AI Accelerators]
    (Emani et al. (2023))
13. [Exploratory Analysis of Climate Data with
    `ClimRR`][Foundation models for long term climate forecasting],
    [Intro to HPC Bootcamp @ NERSC] (Sam Foreman (2023))
14. üß¨ [<span class="highlight">**GenSLMs**</span>: **Genome-scale
    language models reveal SARS-Cov-2 evolutionary dynamics**] (Zvyagin
    et al. (2023))
    - Winner of the [üèÜ *ACM Gordon Bell Special Prize for High
      Performance Computing-Based COVID-19
      Research*][ACM Gordon Bell Special Prize]
15. [Lattice QCD and Particle Physics] (Kronfeld et al. (2022))
16. [Applications of ML to Lattice QFT] (Boyda et al. (2022))
17. [LeapFrogLayers: Trainable Framework for Effective Sampling] (Sam
    Foreman et al. (2021))
18. [HMC with Normalizing Flows][] \[[slides]\] (Sam Foreman et al.
    (2021))
19. [Deep Learning Hamiltonian Monte Carlo][] \[[+ poster]\] (Sam
    Foreman, Jin, and C. (2021))
20. [Machine Learning and Neural Networks for Field Theory] (Sam
    Foreman, Jin, and Osborn (2020))
21. [Examples of renormalization group transformations for image sets]
    (Samuel Foreman et al. (2018))
22. [RG inspired Machine Learning for lattice field theory] (Sam Foreman
    et al. (2018))
23. [Large Energy Density in Three-Plate Nanocapacitors due to Coulomb
    Blockade] (Hubler et al. (2018))
24. [Superconductivity of In and Sn Samples] (Deamont and Foreman
    (2014))

> [!NOTE]
>
> ### üìì References
>
> <div id="refs" class="references csl-bib-body hanging-indent"
> entry-spacing="0">
>
> <div id="ref-allen2025aurora" class="csl-entry">
>
> Allen, Benjamin S., James Anchell, Victor Anisimov, Thomas
> Applencourt, Abhishek Bagusetty, Ramesh Balakrishnan, Riccardo Balin,
> et al. 2025. ‚ÄúAurora: Architecting Argonne‚Äôs First Exascale
> Supercomputer for Accelerated Scientific Discovery.‚Äù
> <https://arxiv.org/abs/2509.08207>.
>
> </div>
>
> <div id="ref-boyda2022applications" class="csl-entry">
>
> Boyda, Denis, Salvatore Calƒ±ÃÄ, Sam Foreman, Lena Funcke, Daniel C
> Hackett, Yin Lin, Gert Aarts, et al. 2022. ‚ÄúApplications of Machine
> Learning to Lattice Quantum Field Theory.‚Äù *arXiv Preprint
> arXiv:2202.05838*. <https://arxiv.org/abs/2202.05838>.
>
> </div>
>
> <div id="ref-cheng2024thorough" class="csl-entry">
>
> Cheng, Scott, Jun-Liang Lin, Murali Emani, Siddhisanket Raskar, Sam
> Foreman, Zhen Xie, Venkatram Vishwanath, and Mahmut Taylan Kandemir.
> 2024. ‚ÄúThorough Characterization and Analysis of Large Transformer
> Model Training at-Scale.‚Äù *Proc. ACM Meas. Anal. Comput. Syst.* 8 (1).
> <https://doi.org/10.1145/3639034>.
>
> </div>
>
> <div id="ref-deamont2014superconductivity" class="csl-entry">
>
> Deamont, George, and Sam Foreman. 2014. ‚ÄúSuperconductivity of in and
> Sn Samples.‚Äù
>
> </div>
>
> <div id="ref-mprot-dpo2024" class="csl-entry">
>
> Dharuman, Gautham, Kyle Hippe, Alexander Brace, Sam Foreman, V√§in√∂
> Hatanp√§√§, Varuni K. Sastry, Huihuo Zheng, et al. 2024. ‚ÄúMProt-DPO:
> Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows
> with Direct Preference Optimization.‚Äù In *Proceedings of the
> International Conference for High Performance Computing, Networking,
> Storage, and Analysis*. SC ‚Äô24. Atlanta, GA, USA: IEEE Press.
> <https://doi.org/10.1109/SC41406.2024.00013>.
>
> </div>
>
> <div id="ref-dharuman2023protein" class="csl-entry">
>
> Dharuman, Gautham, Logan Ward, Heng Ma, Priyanka V Setty, Ozan
> Gokdemir, Sam Foreman, Murali Emani, et al. 2023. ‚ÄúProtein Generation
> via Genome-Scale Language Models with Bio-Physical Scoring.‚Äù In
> *Proceedings of the SC‚Äô23 Workshops of the International Conference on
> High Performance Computing, Network, Storage, and Analysis*, 95‚Äì101.
>
> </div>
>
> <div id="ref-emani2023comprehensive" class="csl-entry">
>
> Emani, Murali, Sam Foreman, Varuni Sastry, Zhen Xie, Siddhisanket
> Raskar, William Arnold, Rajeev Thakur, Venkatram Vishwanath, and
> Michael E Papka. 2023. ‚ÄúA Comprehensive Performance Study of Large
> Language Models on Novel AI Accelerators.‚Äù *arXiv Preprint
> arXiv:2310.04607*. <https://arxiv.org/abs/2310.04607>.
>
> </div>
>
> <div id="ref-foreman2023climrr" class="csl-entry">
>
> Foreman, Sam. 2023. ‚ÄúEnergy Justice Analysis of Climate Data with
> ClimRR.‚Äù August 7, 2023.
> <https://saforem2.github.io/climate-analysis>.
>
> </div>
>
> <div id="ref-foreman2018rg" class="csl-entry">
>
> Foreman, Sam, Joel Giedt, Yannick Meurice, and Judah Unmuth-Yockey.
> 2018. ‚Äú<span class="nocase">RG-inspired machine learning for lattice
> field theory</span>.‚Äù In *European Physical Journal Web of
> Conferences*, 175:11025. European Physical Journal Web of Conferences.
> <https://doi.org/10.1051/epjconf/201817511025>.
>
> </div>
>
> <div id="ref-foreman2021hmc" class="csl-entry">
>
> Foreman, Sam, Taku Izubuchi, Luchang Jin, Xiao-Yong Jin, James C
> Osborn, and Akio Tomiya. 2021. ‚ÄúHMC with Normalizing Flows.‚Äù *arXiv
> Preprint arXiv:2112.01586*. <https://arxiv.org/abs/2112.01586>.
>
> </div>
>
> <div id="ref-foreman2021deep" class="csl-entry">
>
> Foreman, Sam, Xiao-Yong Jin, and Osborn James C. 2021. ‚ÄúDeep Learning
> Hamiltonian Monte Carlo.‚Äù <https://arxiv.org/abs/2105.03418>.
>
> </div>
>
> <div id="ref-foreman2020machine" class="csl-entry">
>
> Foreman, Sam, Xiao-Yong Jin, and James C Osborn. 2020. ‚ÄúMachine
> Learning and Neural Networks for Field Theory.‚Äù
>
> </div>
>
> <div id="ref-foreman2023mlmc" class="csl-entry">
>
> Foreman, Sam, Xiao-Yong Jin, and James C. Osborn. 2023. ‚ÄúMLMC: Machine
> Learning Monte Carlo for Lattice Gauge Theory.‚Äù
> <https://arxiv.org/abs/2312.08936>.
>
> </div>
>
> <div id="ref-foreman2018examples" class="csl-entry">
>
> Foreman, Samuel, Joel Giedt, Yannick Meurice, and Judah Unmuth-Yockey.
> 2018. ‚ÄúExamples of Renormalization Group Transformations for Image
> Sets.‚Äù *Physical Review E* 98 (5): 052129.
>
> </div>
>
> <div id="ref-gokdemir2025hiperrag" class="csl-entry">
>
> Gokdemir, Ozan, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian
> Hsu, Kyle Hippe, Priyanka V. Setty, et al. 2025. ‚ÄúHiPerRAG:
> High-Performance Retrieval Augmented Generation for Scientific
> Insights.‚Äù <https://arxiv.org/abs/2505.04846>.
>
> </div>
>
> <div id="ref-stock2025aeris" class="csl-entry">
>
> Hatanp√§√§, V√§in√∂, Eugene Ku, Jason Stock, Murali Emani, Sam Foreman,
> Chunyong Jung, Sandeep Madireddy, et al. 2025. ‚ÄúAERIS: Argonne Earth
> Systems Model for Reliable and Skillful Predictions.‚Äù
> <https://arxiv.org/abs/2509.13523>.
>
> </div>
>
> <div id="ref-hubler2018large" class="csl-entry">
>
> Hubler, A, S Foreman, J Liu, and L Wortsmann. 2018. ‚ÄúLarge Energy
> Density in Three-Plate Nanocapacitors Due to Coulomb Blockade.‚Äù
> *Journal of Applied Physics* 123 (10).
>
> </div>
>
> <div id="ref-kronfeld2022lattice" class="csl-entry">
>
> Kronfeld, Andreas S, Tanmoy Bhattacharya, Thomas Blum, Norman H
> Christ, Carleton DeTar, William Detmold, Robert Edwards, et al. 2022.
> ‚ÄúLattice QCD and Particle Physics.‚Äù *arXiv Preprint arXiv:2207.07641*.
> <https://arxiv.org/abs/2207.07641>.
>
> </div>
>
> <div id="ref-leung2024intro" class="csl-entry">
>
> Leung, Mary Ann, Katharine Cahill, Rebecca Hartman-Baker, Paige
> Kinsley, Lois Curfman McInnes, Suzanne Parete-Koon, Sreeranjani
> Ramprakash, et al. 2024. ‚ÄúIntro to HPC Bootcamp: Engaging New
> Communities Through Energy Justice Projects.‚Äù *Journal of
> Computational Science Education* 15 (1).
> <https://doi.org/10.22369/issn.2153-4136/15/1/10>.
>
> </div>
>
> <div id="ref-song2023deepspeed4science" class="csl-entry">
>
> Song, Shuaiwen Leon, Bonnie Kruft, Minjia Zhang, Conglong Li, Shiyang
> Chen, Chengming Zhang, Masahiro Tanaka, et al. 2023.
> ‚ÄúDeepSpeed4Science Initiative: Enabling Large-Scale Scientific
> Discovery Through Sophisticated AI System Technologies.‚Äù *arXiv
> Preprint arXiv:2310.04610*. <https://arxiv.org/abs/2310.04610>.
>
> </div>
>
> <div id="ref-torsiello2025automated" class="csl-entry">
>
> Torsiello, J., G. T. Fleming, S. Foreman, X.-Y. Jin, and J. C. Osborn.
> 2025. ‚ÄúAutomated Tuning for HMC Mass Ratios.‚Äù *PoS*. Argonne, ALCF;
> Argonne National Laboratory (ANL), Argonne, IL (United States); Temple
> U.; Fermi National Accelerator Laboratory (FNAL), Batavia, IL (United
> States). <https://doi.org/10.22323/1.466.0052>.
>
> </div>
>
> <div id="ref-yan2025mofa" class="csl-entry">
>
> Yan, Xiaoli, Nathaniel Hudson, Hyun Park, Daniel Grzenda, J. Gregory
> Pauloski, Marcus Schwarting, Haochen Pan, et al. 2025. ‚ÄúMOFA:
> Discovering Materials for Carbon Capture with a GenAI- and
> Simulation-Based Workflow.‚Äù <https://arxiv.org/abs/2501.10651>.
>
> </div>
>
> <div id="ref-zvyagin2023genslms" class="csl-entry">
>
> Zvyagin, Maxim, Alexander Brace, Kyle Hippe, Yuntian Deng, Bin Zhang,
> Cindy Orozco Bohorquez, Austin Clyde, et al. 2023. ‚ÄúGenSLMs:
> Genome-Scale Language Models Reveal SARS-CoV-2 Evolutionary Dynamics.‚Äù
> *The International Journal of High Performance Computing Applications*
> 37 (6): 683‚Äì705.
>
> </div>
>
> </div>

### üìÇ Projects

<style>
  .repo-grid {
    display: flex;
    flex-wrap: wrap;
    gap: 1rem;
    justify-content: flex-start;
    align-items: stretch;
    margin-top: 1.5rem;
  }
&#10;  .repo-card {
    flex: 1 1 260px; /* responsive: min width ~260px */
    max-width: 360px;
    border-radius: 0pt;
    padding: 1rem 1.1rem;
    border: 1px solid var(--bs-border-color, #dee2e6);
    background-color: var(--bs-body-bg, #ffffff);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.04);
    display: flex;
    flex-direction: column;
    transition: transform 0.15s ease, box-shadow 0.15s ease,
                border-color 0.15s ease, background-color 0.15s ease;
  }
&#10;  .repo-card:hover {
    transform: translateY(-3px);
    box-shadow: 0 8px 22px rgba(0, 0, 0, 0.08);
    border-color: var(--bs-primary, #0d6efd);
  }
&#10;  .repo-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    gap: 0.4rem;
    margin-bottom: 0.35rem;
  }
&#10;  .repo-name {
    color: inherit;
    background: none;
    font-size: 1.0rem;
    font-weight: 600;
    margin: 0;
    word-break: break-word;
  }
&#10;  .repo-name a {
    text-decoration: none;
    color: var(--bs-link-color, #0d6efd);
  }
&#10;  .repo-name a:hover {
    text-decoration: underline;
    border: none;
  }
&#10;  .repo-badge {
    font-size: 0.7rem;
    padding: 0.15rem 0.45rem;
    /* border-radius: 999px; */
    border: 1px solid var(--bs-border-color, #dee2e6);
    background: var(--bs-secondary-bg, #f5f5f5);
    white-space: nowrap;
  }
&#10;  .repo-description {
    font-size: 0.9rem;
    margin: 0.3rem 0 0.6rem;
    color: var(--bs-secondary-color, #6c757d);
    min-height: 2.2em; /* keep rows roughly aligned */
  }
&#10;  .repo-meta {
    display: flex;
    flex-wrap: wrap;
    align-items: center;
    gap: 0.6rem;
    margin-top: auto;
    font-size: 0.8rem;
    color: var(--bs-secondary-color, #6c757d);
  }
&#10;  .repo-meta span {
    display: inline-flex;
    align-items: center;
    gap: 0.2rem;
  }
&#10;  .repo-language-dot {
    width: 0.55rem;
    height: 0.55rem;
    /* border-radius: 999px; */
    background: currentColor;
  }
&#10;  /* Dark mode tweaks when using Quarto's theme toggle */
  body[data-mode="dark"] .repo-card {
    background-color: var(--bs-body-bg, #111827);
    border-color: var(--bs-border-color, #374151);
    box-shadow: 0 6px 18px rgba(0, 0, 0, 0.6);
  }
&#10;  body[data-mode="dark"] .repo-badge {
    background: var(--bs-secondary-bg, #1f2933);
  }
&#10;  .repo-grid-loading {
    font-size: 0.9rem;
    color: var(--bs-secondary-color, #6c757d);
    margin-top: 0.75rem;
  }
</style>

<div class="repo-grid-container">

<h2 class="anchored">

GitHub Repositories
</h2>

<p class="repo-grid-loading" id="repo-grid-status">

Loading repositories from GitHub‚Ä¶
</p>

<div id="repo-grid" class="repo-grid" data-github-user="saforem2">

</div>

</div>

<script>
  (async function () {
    const grid = document.getElementById("repo-grid");
    const status = document.getElementById("repo-grid-status");
    if (!grid) return;
&#10;    const username = grid.getAttribute("data-github-user") || "saforem2";
    const apiUrl = `https://api.github.com/users/${username}/repos?per_page=100&sort=updated`;
&#10;    try {
      const res = await fetch(apiUrl);
      if (!res.ok) throw new Error(`GitHub API error: ${res.status}`);
      const repos = await res.json();
&#10;      // Filter out forks if you don't want them:
      const filtered = repos.filter(r => !r.fork);
&#10;      if (filtered.length === 0) {
        if (status) status.textContent = "No repositories found.";
        return;
      }
      if (status) status.remove();
&#10;      // Small helper: nice abbreviations for numbers
      function formatNumber(n) {
        if (n >= 1_000_000) return (n / 1_000_000).toFixed(1).replace(/\.0$/, "") + "M";
        if (n >= 1_000) return (n / 1_000).toFixed(1).replace(/\.0$/, "") + "k";
        return String(n);
      }
&#10;      filtered.forEach(repo => {
        const card = document.createElement("div");
        card.className = "repo-card";
&#10;        const header = document.createElement("div");
        header.className = "repo-header";
&#10;        const title = document.createElement("h3");
        title.className = "repo-name";
        const link = document.createElement("a");
        link.href = repo.html_url;
        link.textContent = repo.name;
        link.target = "_blank";
        link.rel = "noopener noreferrer";
        title.appendChild(link);
&#10;        const badge = document.createElement("span");
        badge.className = "repo-badge";
        badge.textContent = repo.private ? "Private" : "Public";
&#10;        header.appendChild(title);
        header.appendChild(badge);
&#10;        const desc = document.createElement("p");
        desc.className = "repo-description";
        desc.textContent = repo.description || "No description provided.";
&#10;        const meta = document.createElement("div");
        meta.className = "repo-meta";
&#10;        if (repo.language) {
          const langSpan = document.createElement("span");
          const dot = document.createElement("span");
          dot.className = "repo-language-dot";
          langSpan.appendChild(dot);
          const langText = document.createElement("span");
          langText.textContent = repo.language;
          langSpan.appendChild(langText);
          meta.appendChild(langSpan);
        }
&#10;        const starsSpan = document.createElement("span");
        starsSpan.innerHTML = "‚≠êÔ∏è " + formatNumber(repo.stargazers_count || 0);
        meta.appendChild(starsSpan);
&#10;        const updatedSpan = document.createElement("span");
        const updatedDate = new Date(repo.updated_at);
        updatedSpan.textContent = "Updated " + updatedDate.toLocaleDateString(undefined, {
          year: "numeric",
          month: "short",
          day: "numeric"
        });
        meta.appendChild(updatedSpan);
&#10;        card.appendChild(header);
        card.appendChild(desc);
        card.appendChild(meta);
        grid.appendChild(card);
      });
    } catch (err) {
      console.error(err);
      if (status) {
        status.textContent = "Failed to load repositories from GitHub.";
      }
    }
  })();
</script>

### üëî Experience

## üéì Education

- **Ph.D., Physics**  
  *University of Iowa* \| 2015‚Äì2019
  - [*Learning Better Physics: A Machine Learning Approach to Lattice
    Gauge Theory*]
- **B.S. in Engineering Physics**  
  *University of Illinois at Urbana-Champaign* \| 2010‚Äì2015
  - [Energy Storage in Quantum Resonators (US Patent \#US9741492B2)]
- **B.S. in Applied Mathematics**  
  *University of Illinois at Urbana-Champaign* \| 2010‚Äì2015

## üëî Professional Experience

- **Assistant Computational Scientist**
  - *Argonne National Laboratory*, Leadership Computing Facility (ALCF)
    Lemont, IL \| 2022‚ÄìPresent
    - Research lead on scaling large language models (LLMs) and
      generative AI for science on supercomputers (Aurora, Frontier,
      LUMI, Leonardo, ‚Ä¶).
      - Co-lead the Models and Pretraining team of the [AuroraGPT]
        project
    - Optimize large-scale training of foundation models and language
      models for scientific applications.
    - Collaborate with interdisciplinary teams to enhance simulation
      efficiency and scalability
    - Focus on AI and HPC for scientific applications, including:
      - Training large language models on supercomputers
      - Genome scale language models (GenSLMs) for studying SARS-CoV-2
        evolutionary dynamics
      - Direct Preference Optimization (DPO) for multimodal protein
        design workflows
      - Climate modeling and weather forecasting using foundation models
      - Developing improved sampling algorithms for lattice quantum
        chromodynamics (QCD)
    - <https://www.alcf.anl.gov/about/people/sam-foreman>
- **Postdoctoral Researcher**
  - *Argonne National Laboratory*, Leadership Computing Facility (ALCF)
    Lemont, IL \| 2019 ‚Äì 2022
    - Applied deep learning to lattice gauge theory and quantum field
      simulations.
    - Developed ML-enhanced Monte Carlo methods for QCD
      ([l2hmc-qcd][`l2hmc-qcd`]).
    - Engaged in AI-for-Science collaborations with national labs and
      university partners.
- **Graduate Researcher (DOE SCGSR Fellowship)**
  - *Argonne National Laboratory*, Mathematics and Computer Sciences
    Division (MCS)  
    Lemont, IL \| 2018 ‚Äì 2019
    - Development of [l2hmc-qcd][`l2hmc-qcd`] in collaboration with ALCF
      for my PhD Thesis research

## üèÜ Awards and Honors

- Nominated to serve on the US [**Coordinating Panel for Software and
  Computing**] by the Division of Particles and Fields of the American
  Physical Society (APS).

- **Finalist, ACM Gordon Bell Prize in Climate Modeling**, 2025

  - Recognized for our work on  
    üåé **AERIS** (Hatanp√§√§ et al. (2025)): The first billion-parameter
    pixel-level diffusion model for global weather and
    subseasonal-to-seasonal forecasting. Trained efficiently at scales
    from 1.3‚Äì80B parameters with our sequence-window parallelism (SWiPe)
    strategy, we achieve a sustained mixed-precision performance of
    10.21 ExaFLOPS and peak performance of 11.21 ExaFLOPS, scaling to
    10,080 nodes (120,960 GPUs) on the Aurora supercomputer.

- **Finalist, ACM Gordon Bell Prize**, 2024

  - Acknowledged for the MProt-DPO (Dharuman et al. (2024)) project,
    which achieved over 4 ExaFLOP sustained performance in multimodal
    protein design workflows using Direct Preference Optimization.
    - [Argonne team breaks new ground in AI-driven protein design ‚Äì
      Argonne @ SC]

- **ACM Gordon Bell Special Prize for High Performance Computing-Based
  COVID-19 Research**, 2022

  - Recognized for contributions to the GenSLMs (Zvyagin et al. (2023))
    project, which developed genome-scale language models to study
    SARS-CoV-2 evolutionary dynamics.
    - [ACM Gordon Bell Special Prize for HPC-Based COVID-19 Research
      Awarded to Team for Modelling How Pandemic-Causing Viruses,
      Especially SARS-CoV-2, are Identified and
      Classified][ACM Gordon Bell Special Prize]

- **DOE Office of Science Graduate Student Research Fellow**, 2018

  - Awarded by the Department of Energy for outstanding research
    contributions during graduate studies.

## üé™ Events

- Organizer for:
  - [SC25 Workshop: High Performance Python for Science at Scale
    (HPPSS)], November 2025
  - [SC25 Tutorial: Accelerating and Scaling Python for HPC]
  - [SC24 Workshop: High Performance Python for Science at Scale
    (HPPSS)], November 2024
  - [SC23 Workshop: High Performance Python for Science at Scale
    (HPPSS)], November 2023
  - [Machine Learning and Quantum Computing for Earth Sciences] at
    17th U. S. National Congress on Computational Mechanics, July 2023

### üé∂ Music

<div class="light-content">

<div class="flex-container"
style="display: grid; text-align:center; gap: 10px; grid-template-columns: repeat(2, minmax(120px, 1fr)); grid-template-rows: masonry;">

<a href="https://github.com/kittinan/spotify-github-profile"><img loading="lazy" src="https://spotify-github-profile.kittinanx.com/api/view?uid=saforem2&cover_image=true&loading=lazy&theme=default&show_offline=false&background_color=f8f8f8&interchange=false" /></a>

<a href="https://last.fm/user/saforem2"><img loading="lazy" src="https://lastfm-recently-played.vercel.app/api?user=saforem2" align="center" /></a>

<iframe loading="lazy" width="auto" src="https://descent.live/saforem2" style="width: 100%; border: none; height: min(800px, calc(0.8*100vh)); border-radius: 4pt;">

</iframe>

<a href="https://music-profile.rayriffy.com"><img loading="lazy" src="https://music-profile.rayriffy.com/theme/light.svg?uid=002028.5a338f21979147c78f6193b6138a1ec7.1532" align="center" /></a>

</div>

</div>

<div class="dark-content">

<div class="flex-container"
style="display: grid; text-align:center; gap: 10px; grid-template-columns: repeat(2, minmax(120px, 1fr)); grid-template-rows: masonry;">

<a href="https://github.com/kittinan/spotify-github-profile"><img loading="lazy" src="https://spotify-github-profile.kittinanx.com/api/view?uid=saforem2&cover_image=true&loading=lazy&theme=default&show_offline=false&background_color=1c1c1c&interchange=false" /></a>

<a href="https://last.fm/user/saforem2"><img loading="lazy" src="https://lastfm-recently-played.vercel.app/api?user=saforem2" align="center" /></a>

<iframe loading="lazy" width="auto" src="https://descent.live/saforem2" style="width: 100%; border: none; height: min(800px, calc(0.8*100vh)); border-radius: 4pt;">

</iframe>

<a href="https://music-profile.rayriffy.com"><img loading="lazy" src="https://music-profile.rayriffy.com/theme/dark.svg?uid=002028.5a338f21979147c78f6193b6138a1ec7.1532" align="center" /></a>

</div>

</div>

### üí≠ Thoughts

- From <https://sf.status.lol>:

  <script src="https://status.lol/sf.js?time&link&fluent&pretty"></script>

### üíå Guestbook

<iframe src="https://guestbooks.meadow.cafe/guestbook/745" width="100%" height="600" frameborder="0" style="border: 1px dotted #666666; border-radius: 0px;">

</iframe>

</div>

[^1]: üèÖ Finalist for the Gordon Bell Prize in Climate Based Modeling at
    SC25!

  [Argonne National Laboratory]: https://alcf.anl.gov/about/people/sam-foreman
  [<span class="orcid-green" style="background: none!important;"></span>]:
    https://orcid.org/0000-0002-9981-0876
  [AI / ML group]: https://www.alcf.anl.gov/about/people/group/506
  [Argonne Leadership Computing Facility (ALCF)]: https://www.alcf.anl.gov/
  [Models / Pre-Training group]: https://auroragpt.anl.gov/about/#teams
  [AuroraGPT]: https://auroragpt.anl.gov
  [`l2hmc-qcd`]: https://github.com/saforem2/l2hmc-qcd
  [Argonne Earth Systems Model for Reliable and Skillful Predictions]: https://arxiv.org/abs/2509.13523
  [ALCF]: https://alcf.anl.gov
  [AI + Science]: https://github.com/saforem2/
  [Genome-Scale Language Models]: https://www.biorxiv.org/content/10.1101/2022.10.10.511571v2
  [GenSLM]: https://github.com/ramanathanlab/genslm
  [ACM Gordon Bell Special Prize]: https://www.acm.org/media-center/2022/november/gordon-bell-special-prize-covid-research-2022
  [Foundation models for long term climate forecasting]: https://saforem2.github.io/climate-analysis
  [Scaling Large Language Models]: https://github.com/argonne-lcf/Megatron-DeepSpeed
  [Distributed training across thousands of GPUs]: https://github.com/argonne-lcf/mlprof
  [current research]: https://saforem2.github.io/l2hmc-qcd
  [Learning Better Physics: A Machine Learning Approach to Lattice Gauge Theory]:
    https://iro.uiowa.edu/esploro/outputs/doctoral/Learning-better-physics-a-machine-learning/9983776792002771
  [Energy Storage in Quantum Resonators]: https://aip.scitation.org/doi/10.1063/1.5009698
  [Alfred H√ºbler]: https://en.wikipedia.org/wiki/Alfred_H%C3%BCbler
  [patent]: https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vV_1zDwAAAAJ&pagesize=80&citation_for_view=vV_1zDwAAAAJ:SeFeTyx0c_EC
  [Sam Foreman]: https://samforeman.me
  [Training Foundation Models on Supercomputers]: ./talks/2025/10/24/index.html
  [1]: ./talks/2025/10/15/index.html
  [AERIS: Argonne Earth Systems Model]: ./talks/2025/10/08/index.html
  [2025 ALCF Hands On HPC Workshop]: https://www.alcf.anl.gov/events/2025-alcf-hands-hpc-workshop
  [2]: ./talks/2025/09/24/index.html
  [Scientific AI at Scale: AI for Science]: ./talks/openskai25/ai4science/index.html
  [Open SkAI 2025]: https://www.openskai-conference.org
  [Scientific AI at Scale: Distributed Training]: ./talks/openskai25/training/index.html
  [3]: https://www.openskai-conference.org/
  [Large Scale Training on Diverse Accelerators]: ./talks/AuroraGPT-SIAM25/index.html
  [Scalable Deep Learning, *SIAM AN2025*]: https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=84772
  [LLMs on Aurora: üåå AuroraGPT]: ./talks/incite-hackathon-2025/AuroraGPT/index.html
  [*2025 ALCF INCITE GPU Hackathon*]: https://www.alcf.anl.gov/events/alcf-incite-gpu-hackathon
  [üé• video]: https://www.youtube.com/watch?v=KJBbR_oFO2E
  [LLMs on Aurora: üçã ezpz]: ./talks/incite-hackathon-2025/ezpz/index.html
  [4]: https://www.youtube.com/watch?v=15ZK9REQiBo
  [AuroraGPT: Foundation Models for Science]: ./talks/aurora-gpt-fm-for-electric-grid/index.html
  [*Foundation Models for the Electric Grid*]: https://www.alcf.anl.gov/alcf-ai-science-training-series
  [Parallel Training Methods]: ./talks/ai-for-science-2024/index.html
  [5]: https://www.youtube.com/watch?v=4ltulBj4oVk
  [6]: ./talks/AuroraGPT/alcf-hpc-workshop-2024/index.html
  [*2024 ALCF Hands-On HPC Workshop*]: https://www.alcf.anl.gov/events/2024-alcf-hands-hpc-workshop
  [Machine Learning and Foundation Models at Scale]: ./talks/alcf-hpc-workshop-2024/index.html
  [7]: ./talks/hpc-user-forum/index.html
  [*HPC User Forum*, 2024]: https://www.hpcuserforum.com/hpc-user-forum-fall-2024/
  [Training LLMs at Scale]: ./talks/llms-at-scale/
  [*ATPESC*, 2024]: https://extremecomputingtraining.anl.gov/atpesc-2024/
  [LLMs on Polaris]: https://samforeman.me/talks/llms-on-polaris/slides
  [*Center for Scientific Foundation Models*, Summer School 24‚Äô]: https://scifm.ai/summer_school.html
  [Parallel Training Techniques]: https://github.com/saforem2/parallel-training-slides
  [*AI-4-Science Training Series*]: https://github.com/argonne-lcf/ai-science-training-series/tree/main/06_parallel_training
  [LLMs from Scratch]: https://saforem2.github.io/llm-workshop-talk
  [LLM Tutorial Workshop]: https://github.com/argonne-lcf/llm-workshop
  [Creating Small(-ish) LLMs]: https://saforem2.github.io/LLM-tutorial
  [LLM Tutorial Workshop (1)]: https://github.com/brettin/llm_tutorial
  [Exascale Science on Aurora]: https://saforem2.github.io/oneapi-talk
  [Intel oneAPI Workshop @ UIC]: https://www.alcf.anl.gov/events/alcf-hands-hpc-workshop
  [LLM Lunch Talk]: https://saforem2.github.io/llm-lunch-talk
  [8]: https://www.youtube.com/watch?v=mSx9RVd00xU
  [Scaling LLMs for Science]: https://saforem2.github.io/scaling4science
  [Data-Intensive Computing + AI/ML at Scale]: https://events.cels.anl.gov/event/426/overview
  [MLMC: Machine Learning Monte Carlo]: https://saforem2.github.io/lattice23
  [Lattice 2023]: https://indico.fnal.gov/event/57249/contributions/271305/
  [Generative Modeling and Efficient Sampling]: https://saforem2.github.io/lqcd-pasc23/
  [PASC23]: https://pasc23.pasc-conference.org/
  [Efficient Sampling for LGT]: https://saforem2.github.io/deep-fridays
  [Deep Fridays @ U. Bologna]: https://www.cs.unibo.it/~asperti/deep_fridays.html
  [Large Scale Training]: https://saforem2.github.io/ai4sci-large-scale-training
  [AI4Science on Supercomputers (ALCF)]: https://github.com/argonne-lcf/ai-science-training-series
  [Hyperparameter Management]: https://saforem2.github.io/hparam-management-sdl2022/
  [ALCF SDL Workshop]: https://www.alcf.anl.gov/events/2022-alcf-simulation-data-and-learning-workshop
  [Statistical Learning]: https://saforem2.github.io/ATPESC-StatisticalLearning
  [ATPESC 2022]: https://extremecomputingtraining.anl.gov/
  [üìï accompanying notebook]: https://github.com/argonne-lcf/ATPESC_MachineLearning/blob/master/00_statisticalLearning/src/atpesc/notebooks/statistical_learning.ipynb
  [Scientific Data Science: An Emerging Symbiosis]: https://saforem2.github.io/anl-job-talk/
  [Machine Learning in HEP]: https://saforem2.github.io/physicsSeminar
  [Accelerated Sampling Methods for LGT]: https://saforem2.github.io/l2hmc-dwq25/
  [9]: https://indico.bnl.gov/event/13576/
  [Training Topological Samplers for LGT]: https://saforem2.github.io/l2hmc_talk_ect2021
  [ML4HEP, ECT\* Trento]: https://indico.ectstar.eu/event/77/contributions/2349/
  [Deep Learning HMC for Improved Gauge Generation]: https://bit.ly/mainz21
  [ML in LQCD Workshop]: https://bit.ly/mainz21_overview
  [Machine Learning for Lattice QCD]: https://slides.com/samforeman/l2hmc-qcd/embed
  [Google Scholar]: https://scholar.google.com/citations?user=vV_1zDwAAAAJ&hl=en
  [*2025 ACM Gordon Bell Prize for Climate Modeling Finalist*]: https://awards.acm.org/bell-climate
  [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights]:
    https://arxiv.org/abs/2505.04846
  [Automated Tuning for HMC Mass Ratios]: https://www.osti.gov/biblio/2551828
  [MOFA: Discovering Materials for Carbon Capture with a GenAI and Simulation-Based Workflow]:
    https://arxiv.org/abs/2501.10651
  [<span class="highlight-pink">**MProt-DPO**</span>: **Breaking the ExaFLOPS Barrier for Multimodal Protein Design with DPO**]:
    https://doi.org/10.1109/SC41406.2024.00013
  [*2024 ACM Gordon Bell Finalist*]: https://sc24.supercomputing.org/2024/10/presenting-the-finalists-for-the-2024-gordon-bell-prize/
  [Intro to HPC Bootcamp: Engaging New Communities Through Energy Justice Projects]:
    https://jocse.org/downloads/jocse-15-1-10.pdf
  [Thorough Characterization and Analysis of Large Transformer Model Training At-Scale]:
    https://doi.org/10.1145/3639034
  [MLMC: Machine Learning Monte Carlo for Lattice Gauge Theory]: https://arxiv.org/abs/2312.08936
  [Protein Generation via Genome-scale Language Models with Bio-physical Scoring]:
    https://dl.acm.org/doi/abs/10.1145/3624062.3626087
  [DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery]:
    https://arxiv.org/abs/2310.04610
  [üì∞ DeepSpeed4Science.ai Blog Post]: https://www.deepspeed.ai/deepspeed4science/#new-megatron-deepspeed-for-large-scale-ai4science-model-training
  [üöÇ Loooooooong Sequence Lengths]: ./posts/AuroraGPT/long-sequences/index.qmd
  [Comprehensive Performance Study of LLMs on Novel AI Accelerators]: https://arxiv.org/abs/2310.04607
  [Intro to HPC Bootcamp @ NERSC]: https://github.com/NERSC/intro-HPC-bootcamp-2023
  [<span class="highlight">**GenSLMs**</span>: **Genome-scale language models reveal SARS-Cov-2 evolutionary dynamics**]:
    https://www.biorxiv.org/content/10.1101/2022.10.10.511571v1.abstract
  [Lattice QCD and Particle Physics]: https://arxiv.org/abs/2207.07641
  [Applications of ML to Lattice QFT]: https://arxiv.org/abs/2202.05838
  [LeapFrogLayers: Trainable Framework for Effective Sampling]: https://arxiv.org/abs/2112.01582
  [HMC with Normalizing Flows]: https://arxiv.org/abs/2112.01586
  [slides]: https://indico.cern.ch/event/1006302/contributions/4380743/
  [Deep Learning Hamiltonian Monte Carlo]: https://arxiv.org/abs/2105.03418
  [+ poster]: https://simdl.github.io/posters/57-supp_DLHMC_Foreman_SimDL-ICLR2021_poster1.pdf
  [Machine Learning and Neural Networks for Field Theory]: https://bit.ly/snowmass_ml2020
  [Examples of renormalization group transformations for image sets]: https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.052129
  [RG inspired Machine Learning for lattice field theory]: https://arxiv.org/abs/1710.02079
  [Large Energy Density in Three-Plate Nanocapacitors due to Coulomb Blockade]:
    https://doi.org/10.1063/1.5009698
  [Superconductivity of In and Sn Samples]: https://doi.org/10.1063/1.4896340
  [*Learning Better Physics: A Machine Learning Approach to Lattice Gauge Theory*]:
    https://www.proquest.com/openview/95d7f7c12da8da8aa5ead3ac0f6ca0e8/1?cbl=18750&diss=y&pq-origsite=gscholar
  [Energy Storage in Quantum Resonators (US Patent \#US9741492B2)]: https://patents.google.com/patent/US9741492B2/en
  [**Coordinating Panel for Software and Computing**]: https://imfisk.github.io/CPSC/
  [Argonne team breaks new ground in AI-driven protein design ‚Äì Argonne @ SC]:
    https://sc.cels.anl.gov/gordon-bell-argonne-team-breaks-new-ground-in-ai-driven-protein-design/
  [SC25 Workshop: High Performance Python for Science at Scale (HPPSS)]:
    https://hppss.github.io/SC25/
  [SC25 Tutorial: Accelerating and Scaling Python for HPC]: https://sc25.conference-program.com/presentation/?id=tut121&sess=sess255
  [SC24 Workshop: High Performance Python for Science at Scale (HPPSS)]:
    https://hppss.github.io/SC24/
  [SC23 Workshop: High Performance Python for Science at Scale (HPPSS)]:
    https://hppss.github.io/SC23/
  [Machine Learning and Quantum Computing for Earth Sciences]: https://17.usnccm.org/702
