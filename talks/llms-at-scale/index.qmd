---
author:
  name: "[[Sam Foreman]{.dim-text}](https://samforeman.me) [[{{< ai orcid >}}]{.orcid-green}](https://orcid.org/0000-0002-9981-0876)"
  # url: https://samforeman.me
  email: [foremans@anl.gov]
  affiliation: ALCF
  affiliation-url: https://alcf.anl.gov/about/people/sam-foreman
title: "Training LLMs at Scale"
title-slide-attributes:
  data-background-iframe: https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html # space-scroller/index.html
  data-background-size: contain
  # data-background-opacity: "0.5"
toc: false
date: 2024-08-09
date-modified: last-modified
# author-title: ""
# affiliation-title: ""
# published-title: ""
# modified-title: ""
# title-block-categories: false
number-sections: false
ascii: true
bibliography: ../../references.bib
appendix-cite-as: display
# keep-md: false
editor:
  render-on-save: true
twitter-card:
  image: assets/thumbnail.png
  site: "saforem2"
  creator: "saforem2"
  title: "Training LLMs at Scale"
  description: "Training LLMs at Scale"
  card-style: summary
open-graph:
  title: "Training LLMs at Scale"
  description: "Training LLMs at Scale"
  image: assets/thumbnail.png
# author:
#   name: Sam Foreman
#   url: https://samforeman.me
#   orcid: 0000-0002-9981-0876
#   email: foremans@anl.gov
#   affiliation: Argonne National Laboratory
#   affiliation-url: https://alcf.anl.gov/about/people/sam-foreman
citation:
   author: Sam Foreman
   type: speech
   # genre: "Presentation at the 2023 International Symposium on Lattice Field Theory"
   # container-title: https://indico.fnal.gov/event/57249/contributions/271305/
   # title: "MLMC: Machine Learning Monte Carlo for Lattice Gauge Theory"
   url: https://samforeman.me/talks/llms-at-scale
   # abstract: |
   #   We present a trainable framework for efficiently generating gauge
   #   configurations, and discuss ongoing work in this direction. In particular, we
   #   consider the problem of sampling configurations from a 4D ùëÜùëà(3) lattice gauge
   #   theory, and consider a generalized leapfrog integrator in the molecular
   #   dynamics update that can be trained to improve sampling efficiency.
format:
  revealjs:
    # template-partials:
    #  - ../../title-slide.qmd
    # reference-location: section
    navigation-mode: linear
    # output-file: "index.revealjs.html"
    code-line-numbers: true
    code-link: false
    code-copy: false
    # syntax-definitions:
    #   - ./docs/python.xml
    scrollable: true
    title-block-style: none
    slide-number: c
    title-slide-style: default
    chalkboard:
      buttons: false
    auto-animate: true
    # touch: true
    link-external-newwindow: true
    pause: false
    footnotes-hover: true
    citations-hover: true
    preview-links: auto
    controls-tutorial: true
    controls: false
    logo: "https://raw.githubusercontent.com/saforem2/llm-lunch-talk/main/docs/assets/anl.svg"
    history: false
    highlight-style: "atom-one"
    # theme: [css/dark.scss]
    # callout-style: default
    css:
      # - ../../css/text.css
      # - ../../css/default.css
      - ../../css/custom.css
      # - ../../css/reveal/_callouts.scss
      # - ../../css/reveal/light/default.css
      # - ../../css/reveal/light/callouts.css
    theme:
      # - ../../css/reveal/light/light.scss
      # - white
      - ../../css/reveal/reveal.scss
      - ../../css/common.scss
      - ../../css/light.scss
      # - ../../css/syntax-light.scss
      # - ../../css/dark.scss
      # - ../../css/syntax-dark.scss
      # - ../../css/callout-cards.scss
    # css:
    #   - ./theme/light/default.css
    #   - ./theme/light/reset.css
    # theme:
    #   - default
    #   - ./theme/light/common.scss
    #   - ./theme/light/light.scss
    #   - ./theme/light/syntax-light.scss
    #   - ./theme/light/reveal.scss
    # css:
    #   - ./theme/dark/default.css
    #   - ./theme/dark/callouts.css
    # theme: dark
    self-contained: false
    embed-resources: false
    self-contained-math: false
    center: true
    background-color: "#ffffff"
    default-image-extension: svg
    code-overflow: scroll
    html-math-method: katex
    fig-align: center
    mermaid:
      theme: neutral
  # gfm:
  #   output-file: "llms-at-scale.md"
---

<!-- # {.center background-iframe="https://emilhvitfeldt.github.io/quarto-iframe-examples/colored-particles/index.html" loading="lazy"} -->
<!---->
<!-- ::: {style="background-color: rgba(245,245,245, 0.875); border-radius: 10px; text-align:center; padding: 0px; padding-left: 1.5em; padding-right: 1.5em; max-width: min-content; min-width: max-content; margin-left: auto; margin-right: auto; padding-top: 0.2em; padding-bottom: 0.2em; line-height: 1.5em!important;"} -->
<!-- [Training LLMs]{style="color:#333333; font-size:1.75em; font-weight: 600; padding-bottom: 0.25rem;"}   -->
<!-- [(at Scale)]{style="color:#444444; font-size:1.5em; font-weight: 500; padding-bottom: 1rem;"}   -->
<!---->
<!-- [[üè°](https://samforeman.me) Sam Foreman]{style="color:#555555"}   -->
<!-- [@ [ATPESC 2024](https://extremecomputingtraining.anl.gov/agenda-2024/)]{.dim-text style="font-size: 0.75em"}   -->
<!-- [üóìÔ∏è 2024-08-09]{.dim-text style="font-size: 0.66em;"}   -->
<!-- ::: -->
<!---->
<!-- &nbsp;<br>   -->
<!---->
<!-- ::: footer -->
<!-- ::: {style="display: flex; flex-direction: row; align-items: center; text-align: center!important; justify-content: center;"} -->
<!---->
<!-- [[{{< iconify ph house-line-duotone >}}](https://samforeman.me)]{.icon style="font-size:1.5rem; padding-right: 0pt;"} -->
<!-- [[{{< iconify ph github-logo-duotone >}}](https://github.com/saforem2)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph twitter-logo-duotone >}}](https://www.twitter.com/saforem2)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph envelope-open-duotone >}}](mailto:///foremans@anl.gov)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph graduation-cap-duotone >}}](https://scholar.google.com/citations?user=vV_1zDwAAAAJ&hl=en)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph spotify-logo-duotone >}}](https://open.spotify.com/user/saforem2)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph lastfm-logo-duotone >}}](https://www.last.fm/user/saforem2)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!-- [[{{< iconify ph linkedin-logo-duotone >}}](https://linkedin.com/in/saforem2)]{.icon style="font-size:1.5rem; padding-left: 0pt; padding-right: 0pt"} -->
<!---->
<!-- ::: -->
<!---->
<!-- [[samforeman.me/talks/llms-at-scale]{style="color:#137af5!important; background:oklch(from #137af5 calc(l * 1.15) c h / 0.085); border:0px solid #137af5!important; border-radius: 0.25rem; text-shadow: 1px 1px rgba(0, 0, 0, 0.25);"}](https://samforeman.me/talks/llms-at-scale)   -->
<!-- ::: -->

{{< include partials/_about.qmd >}}

{{< include partials/_parallelism.qmd >}}

{{< include partials/_collectives.qmd >}}

{{< include partials/_llms.qmd >}}

{{< include partials/_ezpz.qmd >}}

{{< include partials/_wordplay.qmd >}}

{{< include partials/_acknowledgements.qmd >}}

{{< include partials/_extras.qmd >}}

# References

- üîó See also:
  - [PyTorch Distributed Overview](https://pytorch.org/tutorials/beginner/dist_overview.html)
  - [Distributed Data Parallel ‚Äî PyTorch master documentation](https://pytorch.org/docs/master/notes/ddp.html)
  - [ü§ó Efficient Training on Multiple GPUs](https://huggingface.co/docs/transformers/en/perf_train_gpu_many)
  - [Getting Started - DeepSpeed](https://www.deepspeed.ai/getting-started/)

- See my slides on:
  - [Parallel Training Techniques](https://saforem2.github.io/parallel-training-slides) for additional details
  - [{{< fa brands github >}} `saforem2/llm-lunch-talk`](https://github.com/Hannibal046/Awesome-LLM) [(slides)](https://saforem2.github.io/llm-lunch-talk)

## Bibliography

::: {#refs}
:::
