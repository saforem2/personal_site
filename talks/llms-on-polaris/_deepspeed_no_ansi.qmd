```bash
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:03.636245␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34m__init__␛[0m␛[94m:␛[0m␛[30m156␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSetting logging level to ␛[3;92m'INFO'␛[0m on ␛[3;92m'RANK == 0'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:03.638551␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34m__init__␛[0m␛[94m:␛[0m␛[30m157␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSetting logging level to ␛[3;92m'CRITICAL'␛[0m on all others ␛[3;92m'RANK != 0'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:03.639009␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34m__init__␛[0m␛[94m:␛[0m␛[30m160␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mTo disable this behavior, and log from ALL ranks ␛[1;97m(␛[0mnot recommended␛[1;97m)␛[0m, set: ␛[3;92m'export ␛[0m␛[3;92mLOG_FROM_ALL_RANKS␛[0m␛[3;92m=␛[0m␛[3;92m1␛[0m␛[3;92m'␛[0m  in your environment, and re-run.
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:03.649974␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m81␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSetting HF_DATASETS_CACHE to ␛[32m/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/.cache/huggingface/␛[0m␛[35mdatasets␛[0m
[2024-07-17 07:47:06,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-17 07:47:06,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-17 07:47:06,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-17 07:47:06,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
␛[93m [WARNING] ␛[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
␛[93m [WARNING] ␛[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
␛[93m [WARNING] ␛[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-17 07:47:08,849] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-17 07:47:08,850] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
␛[93m [WARNING] ␛[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
␛[93m [WARNING] ␛[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
␛[93m [WARNING] ␛[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-17 07:47:08,849] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-17 07:47:08,850] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
␛[93m [WARNING] ␛[0m tPlease specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
␛[93m [WARNING] ␛[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
␛[93m [WARNING] ␛[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-17 07:47:08,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-17 07:47:08,850] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
␛[93m [WARNING] ␛[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
␛[93m [WARNING] ␛[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
␛[93m [WARNING] ␛[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-17 07:47:08,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-17 07:47:08,850] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-07-17 07:47:09,088] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=4, master_addr=10.140.58.72, master_port=29500
[2024-07-17 07:47:09,088] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=4, master_addr=10.140.58.72, master_port=29500
[2024-07-17 07:47:09,088] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=4, master_addr=10.140.58.72, master_port=29500
[2024-07-17 07:47:09,088] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=4, master_addr=10.140.58.72, master_port=29500
[2024-07-17 07:47:09,088] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.101631␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m358␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;94mdevice␛[0m=␛[3;92m'cuda'␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mrank␛[0m=␛[95m3␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mlocal_rank␛[0m=␛[95m3␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mnode␛[0m=␛[95m0␛[0m/␛[95m0␛[0m␛[1;97m]␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.101763␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m358␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;94mdevice␛[0m=␛[3;92m'cuda'␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mrank␛[0m=␛[95m1␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mlocal_rank␛[0m=␛[95m1␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mnode␛[0m=␛[95m0␛[0m/␛[95m0␛[0m␛[1;97m]␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.102562␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m358␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;94mdevice␛[0m=␛[3;92m'cuda'␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mrank␛[0m=␛[95m2␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mlocal_rank␛[0m=␛[95m2␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mnode␛[0m=␛[95m0␛[0m/␛[95m0␛[0m␛[1;97m]␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.108339␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m95␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m

␛[1;97m[␛[0mdist_info␛[1;97m]␛[0m:
  • ␛[3;94mDEVICE␛[0m=␛[95mcuda␛[0m
  • ␛[3;94mDEVICE_ID␛[0m=␛[95mcu␛[0m␛[1;92mda␛[0m␛[1;92m:0␛[0m
  • ␛[3;94mDISTRIBUTED_BACKEND␛[0m=␛[95mnccl␛[0m
  • ␛[3;94mGPUS_PER_NODE␛[0m=␛[95m4␛[0m
  • ␛[3;94mHOSTS␛[0m=␛[1;97m[␛[0m␛[3;92m'x3101c0s13b0n0.hsn.cm.polaris.alcf.anl.gov'␛[0m␛[1;97m]␛[0m
  • ␛[3;94mHOSTFILE␛[0m=␛[32m/var/spool/pbs/aux/␛[0m␛[35m2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov␛[0m
  • ␛[3;94mHOSTNAME␛[0m=␛[95mx3101c0s13b0n0␛[0m.hsn.cm.polaris.alcf.anl.gov
  • ␛[3;94mLOCAL_RANK␛[0m=␛[95m0␛[0m
  • ␛[3;94mMACHINE␛[0m=␛[95mPolaris␛[0m
  • ␛[3;94mNUM_NODES␛[0m=␛[95m1␛[0m
  • ␛[3;94mNGPUS␛[0m=␛[95m4␛[0m
  • ␛[3;94mNGPUS_AVAILABLE␛[0m=␛[95m4␛[0m
  • ␛[3;94mNODE_ID␛[0m=␛[95m0␛[0m
  • ␛[3;94mRANK␛[0m=␛[95m0␛[0m
  • ␛[3;94mSCHEDULER␛[0m=␛[95mPBS␛[0m
  • ␛[3;94mWORLD_SIZE_TOTAL␛[0m=␛[95m4␛[0m
  • ␛[3;94mWORLD_SIZE_IN_USE␛[0m=␛[95m4␛[0m
  • ␛[3;94mLAUNCH_CMD␛[0m=␛[95mmpiexec␛[0m --verbose --envall -n ␛[95m4␛[0m -ppn ␛[95m4␛[0m --hostfile ␛[32m/var/spool/pbs/aux/␛[0m␛[35m2024084.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov␛[0m --cpu-bind depth -d ␛[95m16␛[0m


--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. ␛[92m[OKAY]␛[0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
fused_adam ............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
cpu_adam ............... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
cpu_adagrad ............ ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
cpu_lion ............... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
␛[93m [WARNING] ␛[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... ␛[92m[YES]␛[0m ...... ␛[93m[NO]␛[0m
fp_quantizer ........... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
fused_lamb ............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
fused_lion ............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
inference_core_ops ..... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
cutlass_ops ............ ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
transformer_inference .. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
quantizer .............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
ragged_device_ops ...... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
ragged_ops ............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
random_ltd ............. ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
␛[93m [WARNING] ␛[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
␛[93m [WARNING] ␛[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
sparse_attn ............ ␛[93m[NO]␛[0m ....... ␛[93m[NO]␛[0m
spatial_inference ...... ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
transformer ............ ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
stochastic_transformer . ␛[92m[YES]␛[0m ...... ␛[92m[OKAY]␛[0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages/torch']
torch version .................... 2.3.0
deepspeed install path ........... ['/soft/applications/conda/2024-04-29/mconda3/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.14.2+5f631abc, 5f631abc, HEAD
torch cuda version ............... 12.4
torch hip version ................ None
nvcc version ..................... 12.4
deepspeed wheel compiled w. ...... torch 2.3, cuda 12.4
shared memory (/dev/shm) size .... 251.60 GB
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.188080␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m260␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m**** Git info for DeepSpeed: ␛[3;94mgit_hash␛[0m=␛[95munknown␛[0m ␛[3;94mgit_branch␛[0m=␛[95munknown␛[0m ****
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.188630␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m725␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[95m0␛[0m/␛[95m4␛[0m␛[1;97m]␛[0m Using ␛[3;94mdevice␛[0m=␛[3;92m'cuda'␛[0m with ␛[3;94mbackend␛[0m=␛[3;92m'deepspeed'␛[0m + ␛[3;92m'nccl'␛[0m for distributed training.
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.193364␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m358␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;94mdevice␛[0m=␛[3;92m'cuda'␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mrank␛[0m=␛[95m0␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mlocal_rank␛[0m=␛[95m0␛[0m/␛[95m3␛[0m␛[1;97m]␛[0m␛[1;97m[␛[0m␛[3;94mnode␛[0m=␛[95m0␛[0m/␛[95m0␛[0m␛[1;97m]␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.193912␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[93mWARNING␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m364␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mUsing ␛[1;97m[␛[0m␛[95m4␛[0m ␛[32m/␛[0m ␛[95m4␛[0m␛[1;97m]␛[0m available ␛[3;92m"cuda"␛[0m devices !!
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.197150␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m317␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mLoading val from ␛[32m/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/␛[0m␛[35mval.bin␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.197712␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m317␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mLoading train from ␛[32m/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/data/shakespeare_char/␛[0m␛[35mtrain.bin␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.198710␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m442␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mTokens per iteration: ␛[95m262␛[0m,␛[95m144␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.199140␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m465␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mUsing self.␛[3;94mptdtype␛[0m=␛[95mtorch␛[0m.float16 on self.␛[3;94mdevice_type␛[0m=␛[3;92m'cuda'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.199548␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m471␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mInitializing a new model from scratch
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.200128␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m874␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSetting up wandb from rank: ␛[95m0␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:09.200479␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m875␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mUsing: WB PROJECT: WordPlay
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.478428␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m905␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mW&B RUN: ␛[1;97m[␛[0mglowing-jazz-␛[95m18␛[0m␛[1;97m]␛[0m␛[1;97m(␛[0m␛[4;94mhttps://wandb.ai/aurora_gpt/WordPlay/runs/h7727hn1␛[0m␛[4;94m)␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.489926␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m312␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mUpdating wandb.run: glowing-jazz-␛[95m18␛[0m config with ␛[3;92m"DIST_INFO"␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.495074␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mdist␛[0m␛[94m:␛[0m␛[30m938␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mRunning on ␛[3;94mmachine␛[0m=␛[3;92m'Polaris'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.496627␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[93mWARNING␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34m__main__␛[0m␛[94m:␛[0m␛[30m89␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m{␛[0m
    ␛[3;92m"train"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"framework"␛[0m: ␛[3;92m"pytorch"␛[0m,
        ␛[3;92m"backend"␛[0m: ␛[3;92m"deepspeed"␛[0m,
        ␛[3;92m"device"␛[0m: null,
        ␛[3;92m"seed"␛[0m: null,
        ␛[3;92m"port"␛[0m: null,
        ␛[3;92m"ds_config_path"␛[0m: null,
        ␛[3;92m"precision"␛[0m: null,
        ␛[3;92m"ngpus"␛[0m: null,
        ␛[3;92m"use_wandb"␛[0m: true,
        ␛[3;92m"eval_interval"␛[0m: ␛[95m100␛[0m,
        ␛[3;92m"log_interval"␛[0m: ␛[95m10␛[0m,
        ␛[3;92m"eval_iters"␛[0m: ␛[95m200␛[0m,
        ␛[3;92m"eval_only"␛[0m: false,
        ␛[3;92m"always_save_checkpoint"␛[0m: false,
        ␛[3;92m"init_from"␛[0m: ␛[3;92m"scratch"␛[0m,
        ␛[3;92m"wandb_project"␛[0m: ␛[3;92m"WordPlay"␛[0m,
        ␛[3;92m"max_iters"␛[0m: ␛[95m1000␛[0m,
        ␛[3;92m"warmup_iters"␛[0m: ␛[95m100␛[0m,
        ␛[3;92m"dtype"␛[0m: ␛[3;92m"bf16"␛[0m,
        ␛[3;92m"compile"␛[0m: false
    ␛[1;97m}␛[0m,
    ␛[3;92m"model"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"n_layer"␛[0m: ␛[95m12␛[0m,
        ␛[3;92m"n_head"␛[0m: ␛[95m12␛[0m,
        ␛[3;92m"n_embd"␛[0m: ␛[95m768␛[0m,
        ␛[3;92m"batch_size"␛[0m: ␛[95m64␛[0m,
        ␛[3;92m"block_size"␛[0m: ␛[95m1024␛[0m,
        ␛[3;92m"activation"␛[0m: ␛[3;92m"gelu"␛[0m,
        ␛[3;92m"dropout"␛[0m: ␛[95m0.0␛[0m,
        ␛[3;92m"bias"␛[0m: false,
        ␛[3;92m"vocab_size"␛[0m: ␛[95m65␛[0m
    ␛[1;97m}␛[0m,
    ␛[3;92m"data"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"dataset"␛[0m: ␛[3;92m"shakespeare_char"␛[0m,
        ␛[3;92m"out_dir"␛[0m: ␛[3;92m"out-shakespeare-char"␛[0m,
        ␛[3;92m"root_path"␛[0m: null
    ␛[1;97m}␛[0m,
    ␛[3;92m"optimizer"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"gas"␛[0m: ␛[95m1␛[0m,
        ␛[3;92m"name"␛[0m: ␛[3;92m"AdamW"␛[0m,
        ␛[3;92m"learning_rate"␛[0m: ␛[95m0.0006␛[0m,
        ␛[3;92m"weight_decay"␛[0m: ␛[95m0.1␛[0m,
        ␛[3;92m"beta1"␛[0m: ␛[95m0.9␛[0m,
        ␛[3;92m"beta2"␛[0m: ␛[95m0.95␛[0m,
        ␛[3;92m"grad_clip"␛[0m: ␛[95m1.0␛[0m,
        ␛[3;92m"decay_lr"␛[0m: true,
        ␛[3;92m"lr_decay_iters"␛[0m: ␛[95m600000␛[0m,
        ␛[3;92m"min_lr"␛[0m: ␛[95m6e-05␛[0m
    ␛[1;97m}␛[0m
␛[1;97m}␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.499513␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[93mWARNING␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34m__main__␛[0m␛[94m:␛[0m␛[30m90␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mOutput dir: ␛[32m/home/foremans/tmp/polaris-talk/outputs/runs/pytorch/deepspeed/2024-07-17/␛[0m␛[35m07-47-05␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:10.500035␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m246␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mInitializing a new model from scratch
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.275034␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mmodel␛[0m␛[94m:␛[0m␛[30m255␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mnumber of parameters: ␛[95m85.␛[0m00M
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.313390␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m264␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mModel size: ␛[3;94mnum_params␛[0m=␛[95m85003776␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.315995␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mmodel␛[0m␛[94m:␛[0m␛[30m445␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mnum decayed parameter tensors: ␛[95m50␛[0m, with ␛[95m85␛[0m,␛[95m771␛[0m,␛[95m008␛[0m parameters
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.316659␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mmodel␛[0m␛[94m:␛[0m␛[30m449␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mnum non-decayed parameter tensors: ␛[95m25␛[0m, with ␛[95m19␛[0m,␛[95m200␛[0m parameters
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.317612␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mmodel␛[0m␛[94m:␛[0m␛[30m465␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0musing fused AdamW: ␛[3;92mTrue␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:11.320236␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[93mWARNING␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m418␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSetting `train_micro_batch_size_per_gpu` to self.config.model.␛[3;94mbatch_size␛[0m=␛[95m64␛[0m
[2024-07-17 07:47:11,320] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2+5f631abc, git-hash=5f631abc, git-branch=HEAD
[2024-07-17 07:47:12,873] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: True
[2024-07-17 07:47:12,874] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-07-17 07:47:12,874] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-07-17 07:47:12,875] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-07-17 07:47:12,875] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-07-17 07:47:12,875] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 1 optimizer
[2024-07-17 07:47:12,875] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500,000,000
[2024-07-17 07:47:12,875] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500,000,000
[2024-07-17 07:47:12,876] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: False
[2024-07-17 07:47:12,876] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[2024-07-17 07:47:13,706] [INFO] [utils.py:779:see_memory_usage] Before initializing optimizer states
[2024-07-17 07:47:13,707] [INFO] [utils.py:780:see_memory_usage] MA 0.24 GB         Max_MA 0.24 GB         CA 0.24 GB         Max_CA 0 GB 
[2024-07-17 07:47:13,710] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 20.87 GB, percent = 4.1%
[2024-07-17 07:47:13,874] [INFO] [utils.py:779:see_memory_usage] After initializing optimizer states
[2024-07-17 07:47:13,875] [INFO] [utils.py:780:see_memory_usage] MA 0.24 GB         Max_MA 0.32 GB         CA 0.32 GB         Max_CA 0 GB 
[2024-07-17 07:47:13,875] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 20.98 GB, percent = 4.2%
[2024-07-17 07:47:13,876] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
[2024-07-17 07:47:14,036] [INFO] [utils.py:779:see_memory_usage] After initializing ZeRO optimizer
[2024-07-17 07:47:14,037] [INFO] [utils.py:780:see_memory_usage] MA 0.24 GB         Max_MA 0.24 GB         CA 0.32 GB         Max_CA 0 GB 
[2024-07-17 07:47:14,037] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 21.1 GB, percent = 4.2%
[2024-07-17 07:47:14,038] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-07-17 07:47:14,038] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-07-17 07:47:14,039] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-07-17 07:47:14,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0006, 0.0006], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:14,039] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-07-17 07:47:14,040] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-07-17 07:47:14,040] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-07-17 07:47:14,040] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-07-17 07:47:14,040] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-07-17 07:47:14,040] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-07-17 07:47:14,041] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14b628096cd0>
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-07-17 07:47:14,042] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-07-17 07:47:14,043] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-07-17 07:47:14,044] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": true, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-07-17 07:47:14,045] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-07-17 07:47:14,046] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-07-17 07:47:14,047] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-07-17 07:47:14,048] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-07-17 07:47:14,049] [INFO] [config.py:1000:print]   steps_per_print .............. 10
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   train_batch_size ............. 256
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  64
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... True
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-07-17 07:47:14,050] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-07-17 07:47:14,051] [INFO] [config.py:1000:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-07-17 07:47:14,051] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-07-17 07:47:14,051] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. False
[2024-07-17 07:47:14,051] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 1
[2024-07-17 07:47:14,051] [INFO] [config.py:986:print_user_config]   json = {
    "dump_state": false, 
    "wall_clock_breakdown": true, 
    "zero_force_ds_cpu_optimizer": false, 
    "flops_profiler": {
        "enabled": true, 
        "profile_step": 1
    }, 
    "fp16": {
        "enabled": false
    }, 
    "bf16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 1
    }, 
    "gradient_accumulation_steps": 1, 
    "train_micro_batch_size_per_gpu": 64, 
    "steps_per_print": 10
}
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:14.052254␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m356␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m• self.␛[3;94mmodel␛[0m=␛[1;35mGPT␛[0m␛[1;97m(␛[0m
  ␛[1;97m(␛[0mtransformer␛[1;97m)␛[0m: ␛[1;35mModuleDict␛[0m␛[1;97m(␛[0m
    ␛[1;97m(␛[0mwte␛[1;97m)␛[0m: ␛[1;35mEmbedding␛[0m␛[1;97m(␛[0m␛[95m65␛[0m, ␛[95m768␛[0m␛[1;97m)␛[0m
    ␛[1;97m(␛[0mwpe␛[1;97m)␛[0m: ␛[1;35mEmbedding␛[0m␛[1;97m(␛[0m␛[95m1024␛[0m, ␛[95m768␛[0m␛[1;97m)␛[0m
    ␛[1;97m(␛[0mdrop␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
    ␛[1;97m(␛[0mh␛[1;97m)␛[0m: ␛[1;35mModuleList␛[0m␛[1;97m(␛[0m
      ␛[1;97m(␛[0m␛[95m0␛[0m-␛[95m11␛[0m␛[1;97m)␛[0m: ␛[95m12␛[0m x ␛[1;35mBlock␛[0m␛[1;97m(␛[0m
        ␛[1;97m(␛[0mln_1␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
        ␛[1;97m(␛[0mattn␛[1;97m)␛[0m: ␛[1;35mCausalSelfAttention␛[0m␛[1;97m(␛[0m
          ␛[1;97m(␛[0mc_attn␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m2304␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mc_proj␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m768␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mattn_dropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mresid_dropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
        ␛[1;97m)␛[0m
        ␛[1;97m(␛[0mln_2␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
        ␛[1;97m(␛[0mmlp␛[1;97m)␛[0m: ␛[1;35mMLP␛[0m␛[1;97m(␛[0m
          ␛[1;97m(␛[0mc_fc␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m3072␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mact_fn␛[1;97m)␛[0m: ␛[1;35mGELU␛[0m␛[1;97m(␛[0m␛[3;94mapproximate␛[0m=␛[3;92m'none'␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mc_proj␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m3072␛[0m, ␛[3;94mout_features␛[0m=␛[95m768␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mdropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
        ␛[1;97m)␛[0m
      ␛[1;97m)␛[0m
    ␛[1;97m)␛[0m
    ␛[1;97m(␛[0mln_f␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
  ␛[1;97m)␛[0m
  ␛[1;97m(␛[0mlm_head␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m65␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
␛[1;97m)␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:14.056526␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m357␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m• self.␛[3;94mgrad_scaler␛[0m=␛[3;95mNone␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:14.057564␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m358␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m• self.␛[3;94mmodel_engine␛[0m=␛[1;35mDeepSpeedEngine␛[0m␛[1;97m(␛[0m
  ␛[1;97m(␛[0mmodule␛[1;97m)␛[0m: ␛[1;35mGPT␛[0m␛[1;97m(␛[0m
    ␛[1;97m(␛[0mtransformer␛[1;97m)␛[0m: ␛[1;35mModuleDict␛[0m␛[1;97m(␛[0m
      ␛[1;97m(␛[0mwte␛[1;97m)␛[0m: ␛[1;35mEmbedding␛[0m␛[1;97m(␛[0m␛[95m65␛[0m, ␛[95m768␛[0m␛[1;97m)␛[0m
      ␛[1;97m(␛[0mwpe␛[1;97m)␛[0m: ␛[1;35mEmbedding␛[0m␛[1;97m(␛[0m␛[95m1024␛[0m, ␛[95m768␛[0m␛[1;97m)␛[0m
      ␛[1;97m(␛[0mdrop␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
      ␛[1;97m(␛[0mh␛[1;97m)␛[0m: ␛[1;35mModuleList␛[0m␛[1;97m(␛[0m
        ␛[1;97m(␛[0m␛[95m0␛[0m-␛[95m11␛[0m␛[1;97m)␛[0m: ␛[95m12␛[0m x ␛[1;35mBlock␛[0m␛[1;97m(␛[0m
          ␛[1;97m(␛[0mln_1␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mattn␛[1;97m)␛[0m: ␛[1;35mCausalSelfAttention␛[0m␛[1;97m(␛[0m
            ␛[1;97m(␛[0mc_attn␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m2304␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mc_proj␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m768␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mattn_dropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mresid_dropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m)␛[0m
          ␛[1;97m(␛[0mln_2␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
          ␛[1;97m(␛[0mmlp␛[1;97m)␛[0m: ␛[1;35mMLP␛[0m␛[1;97m(␛[0m
            ␛[1;97m(␛[0mc_fc␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m3072␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mact_fn␛[1;97m)␛[0m: ␛[1;35mGELU␛[0m␛[1;97m(␛[0m␛[3;94mapproximate␛[0m=␛[3;92m'none'␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mc_proj␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m3072␛[0m, ␛[3;94mout_features␛[0m=␛[95m768␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
            ␛[1;97m(␛[0mdropout␛[1;97m)␛[0m: ␛[1;35mDropout␛[0m␛[1;97m(␛[0m␛[3;94mp␛[0m=␛[95m0␛[0m␛[95m.0␛[0m, ␛[3;94minplace␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
          ␛[1;97m)␛[0m
        ␛[1;97m)␛[0m
      ␛[1;97m)␛[0m
      ␛[1;97m(␛[0mln_f␛[1;97m)␛[0m: ␛[1;35mLayerNorm␛[0m␛[1;97m(␛[0m␛[1;97m)␛[0m
    ␛[1;97m)␛[0m
    ␛[1;97m(␛[0mlm_head␛[1;97m)␛[0m: ␛[1;35mLinear␛[0m␛[1;97m(␛[0m␛[3;94min_features␛[0m=␛[95m768␛[0m, ␛[3;94mout_features␛[0m=␛[95m65␛[0m, ␛[3;94mbias␛[0m=␛[3;91mFalse␛[0m␛[1;97m)␛[0m
  ␛[1;97m)␛[0m
␛[1;97m)␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:14.061706␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m359␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m• self.␛[3;94moptimizer␛[0m=␛[1m<␛[0m␛[1;95mdeepspeed.runtime.zero.stage_1_and_2.DeepSpeedZeroOptimizer␛[0m␛[39m object at ␛[0m␛[95m0x14b628079050␛[0m␛[1m>␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:14.062574␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m368␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m{␛[0m
    ␛[3;92m"dump_state"␛[0m: false,
    ␛[3;92m"wall_clock_breakdown"␛[0m: true,
    ␛[3;92m"zero_force_ds_cpu_optimizer"␛[0m: false,
    ␛[3;92m"flops_profiler"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"enabled"␛[0m: true,
        ␛[3;92m"profile_step"␛[0m: ␛[95m1␛[0m
    ␛[1;97m}␛[0m,
    ␛[3;92m"fp16"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"enabled"␛[0m: false
    ␛[1;97m}␛[0m,
    ␛[3;92m"bf16"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"enabled"␛[0m: true
    ␛[1;97m}␛[0m,
    ␛[3;92m"zero_optimization"␛[0m: ␛[1;97m{␛[0m
        ␛[3;92m"stage"␛[0m: ␛[95m1␛[0m
    ␛[1;97m}␛[0m,
    ␛[3;92m"gradient_accumulation_steps"␛[0m: ␛[95m1␛[0m,
    ␛[3;92m"train_micro_batch_size_per_gpu"␛[0m: ␛[95m64␛[0m,
    ␛[3;92m"steps_per_print"␛[0m: ␛[95m10␛[0m
␛[1;97m}␛[0m
[2024-07-17 07:47:14,874] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.83 | optimizer_gradients: 0.43 | optimizer_step: 6.97
[2024-07-17 07:47:14,874] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 464.73 | bwd_microstep: 219.93 | bwd_inner_microstep: 215.63 | bwd_allreduce_microstep: 4.24 | step_microstep: 78.11
[2024-07-17 07:47:14,874] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 464.72 | bwd: 219.91 | bwd_inner: 215.62 | bwd_allreduce: 4.22 | step: 78.12
[2024-07-17 07:47:14,875] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2024-07-17 07:47:15,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68

-------------------------- DeepSpeed Flops Profiler --------------------------
Profile Summary at step 2:
Notations:
data parallel size (dp_size), model parallel size(mp_size),
number of parameters (params), number of multiply-accumulate operations(MACs),
number of floating-point operations (flops), floating-point operations per second (FLOPS),
fwd latency (forward propagation latency), bwd latency (backward propagation latency),
step (weights update latency), iter latency (sum of fwd, bwd and step latency)

world size:                                                             4       
data parallel size:                                                     4       
model parallel size:                                                    1       
batch size per GPU:                                                     64      
params per GPU:                                                         85.79 M 
params of model = params per GPU * mp_size:                             85.79 M 
fwd MACs per GPU:                                                       6.81 TMACs
fwd flops per GPU:                                                      13.65 T 
fwd flops of model = fwd flops per GPU * mp_size:                       13.65 T 
fwd latency:                                                            96.8 ms 
fwd FLOPS per GPU = fwd flops per GPU / fwd latency:                    141 TFLOPS
bwd latency:                                                            180.77 ms
bwd FLOPS per GPU = 2 * fwd flops per GPU / bwd latency:                151 TFLOPS
fwd+bwd FLOPS per GPU = 3 * fwd flops per GPU / (fwd+bwd latency):      147.51 TFLOPS
step latency:                                                           3.29 ms 
iter latency:                                                           280.85 ms
FLOPS per GPU = 3 * fwd flops per GPU / iter latency:                   145.79 TFLOPS
samples/second:                                                         911.51  

----------------------------- Aggregated Profile per GPU -----------------------------
Top 1 modules in terms of params, MACs or fwd latency at different model depths:
depth 0:
    params      - {'GPT': '85.79 M'}
    MACs        - {'GPT': '6.81 TMACs'}
    fwd latency - {'GPT': '96.7 ms'}
depth 1:
    params      - {'ModuleDict': '85.79 M'}
    MACs        - {'ModuleDict': '6.8 TMACs'}
    fwd latency - {'ModuleDict': '93.87 ms'}
depth 2:
    params      - {'ModuleList': '84.95 M'}
    MACs        - {'ModuleList': '6.8 TMACs'}
    fwd latency - {'ModuleList': '92.87 ms'}
depth 3:
    params      - {'Block': '84.95 M'}
    MACs        - {'Block': '6.8 TMACs'}
    fwd latency - {'Block': '92.87 ms'}
depth 4:
    params      - {'MLP': '56.62 M'}
    MACs        - {'MLP': '3.71 TMACs'}
    fwd latency - {'MLP': '43.15 ms'}

------------------------------ Detailed Profile per GPU ------------------------------
Each module profile is listed after its name in the following order: 
params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS

Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.
2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.
3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.

GPT(
  85.79 M = 100% Params, 6.81 TMACs = 100% MACs, 96.7 ms = 100% latency, 141.14 TFLOPS
  (transformer): ModuleDict(
    85.79 M = 100% Params, 6.8 TMACs = 99.95% MACs, 93.87 ms = 97.07% latency, 145.33 TFLOPS
    (wte): Embedding(49.92 K = 0.06% Params, 0 MACs = 0% MACs, 540.02 us = 0.56% latency, 0 FLOPS, 65, 768)
    (wpe): Embedding(786.43 K = 0.92% Params, 0 MACs = 0% MACs, 56.03 us = 0.06% latency, 0 FLOPS, 1024, 768)
    (drop): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.04% latency, 0 FLOPS, p=0.0, inplace=False)
    (h): ModuleList(
      (0): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 8.35 ms = 8.64% latency, 136.11 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 645.4 us = 0.67% latency, 389.93 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.74 ms = 2.84% latency, 187.98 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.25 ms = 1.29% latency, 185.36 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 544.31 us = 0.56% latency, 142.03 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 32.42 us = 0.03% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 374.32 us = 0.39% latency, 672.31 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.64 ms = 3.76% latency, 170.66 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.6% latency, 199.67 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 253.13 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 24.8 us = 0.03% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (1): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.71 ms = 7.98% latency, 147.36 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 365.97 us = 0.38% latency, 687.64 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.51 ms = 2.6% latency, 205.18 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.29% latency, 186.61 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 402.69 us = 0.42% latency, 191.98 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 23.37 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 365.5 us = 0.38% latency, 688.54 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.6 ms = 3.73% latency, 172.28 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.6% latency, 200.25 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.27% latency, 252.49 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.41 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (2): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.67 ms = 7.93% latency, 148.16 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 361.2 us = 0.37% latency, 696.72 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.5 ms = 2.58% latency, 206.19 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.29% latency, 186.53 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 398.16 us = 0.41% latency, 194.17 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.89 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 364.07 us = 0.38% latency, 691.25 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.58 ms = 3.71% latency, 173.22 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.59% latency, 200.59 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.21 ms = 1.25% latency, 254.92 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.89 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (3): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.69 ms = 7.95% latency, 147.83 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 363.35 us = 0.38% latency, 692.61 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.5 ms = 2.59% latency, 205.98 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.29% latency, 186.32 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 395.54 us = 0.41% latency, 195.45 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 24.32 us = 0.03% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 361.92 us = 0.37% latency, 695.34 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.59 ms = 3.72% latency, 172.73 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.59% latency, 200.53 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 254.17 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.89 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (4): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.65 ms = 7.91% latency, 148.61 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 365.26 us = 0.38% latency, 688.99 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.48 ms = 2.56% latency, 207.82 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.28% latency, 187.22 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 390.53 us = 0.4% latency, 197.96 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.89 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 363.35 us = 0.38% latency, 692.61 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.58 ms = 3.7% latency, 173.47 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.6% latency, 200.47 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.21 ms = 1.25% latency, 255.07 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.7 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (5): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.66 ms = 7.93% latency, 148.32 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 362.4 us = 0.37% latency, 694.43 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.49 ms = 2.57% latency, 207 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.29% latency, 186.36 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 391.96 us = 0.41% latency, 197.24 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.93 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 366.21 us = 0.38% latency, 687.19 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.58 ms = 3.7% latency, 173.38 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.59% latency, 200.62 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.21 ms = 1.25% latency, 255.02 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.93 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (6): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.67 ms = 7.93% latency, 148.18 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 362.16 us = 0.37% latency, 694.89 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.49 ms = 2.57% latency, 207.24 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.28% latency, 187.25 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 391.48 us = 0.4% latency, 197.48 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.93 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 360.01 us = 0.37% latency, 699.03 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.6 ms = 3.72% latency, 172.53 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.6% latency, 199.27 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 253.18 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.46 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (7): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.71 ms = 7.97% latency, 147.46 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 366.69 us = 0.38% latency, 686.3 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.51 ms = 2.6% latency, 205.25 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.25 ms = 1.29% latency, 185.89 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 398.87 us = 0.41% latency, 193.82 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.22 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 365.5 us = 0.38% latency, 688.54 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.6 ms = 3.73% latency, 172.28 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.61% latency, 199.24 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 253.82 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.7 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (8): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.7 ms = 7.96% latency, 147.64 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 366.93 us = 0.38% latency, 685.86 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.51 ms = 2.6% latency, 205.25 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.25 ms = 1.29% latency, 185.64 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 393.63 us = 0.41% latency, 196.4 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.7 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 363.59 us = 0.38% latency, 692.15 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.6 ms = 3.72% latency, 172.68 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.61% latency, 198.93 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 254.37 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 20.74 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (9): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.68 ms = 7.94% latency, 148.02 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 364.07 us = 0.38% latency, 691.25 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.5 ms = 2.58% latency, 206.39 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.28% latency, 187 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 392.68 us = 0.41% latency, 196.88 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 22.17 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 365.5 us = 0.38% latency, 688.54 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.59 ms = 3.71% latency, 173.05 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.6% latency, 199.48 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.21 ms = 1.25% latency, 254.92 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.46 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (10): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.68 ms = 7.95% latency, 147.95 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 362.63 us = 0.38% latency, 693.97 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.5 ms = 2.58% latency, 206.19 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.28% latency, 187.04 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 391.48 us = 0.4% latency, 197.48 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.7 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 363.35 us = 0.38% latency, 692.61 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.6 ms = 3.72% latency, 172.66 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.55 ms = 1.6% latency, 199.42 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.22 ms = 1.26% latency, 253.28 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.46 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
      (11): Block(
        7.08 M = 8.25% Params, 566.94 GMACs = 8.33% MACs, 7.69 ms = 7.95% latency, 147.92 TFLOPS
        (ln_1): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 363.59 us = 0.38% latency, 692.15 GFLOPS)
        (attn): CausalSelfAttention(
          2.36 M = 2.75% Params, 257.7 GMACs = 3.79% MACs, 2.5 ms = 2.59% latency, 206.08 TFLOPS
          (c_attn): Linear(1.77 M = 2.06% Params, 115.96 GMACs = 1.7% MACs, 1.24 ms = 1.28% latency, 186.79 TFLOPS, in_features=768, out_features=2304, bias=False)
          (c_proj): Linear(589.82 K = 0.69% Params, 38.65 GMACs = 0.57% MACs, 394.82 us = 0.41% latency, 195.81 TFLOPS, in_features=768, out_features=768, bias=False)
          (attn_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 0 s = 0% latency, 0 FLOPS, p=0.0, inplace=False)
          (resid_dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 21.93 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
        (ln_2): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 364.07 us = 0.38% latency, 691.25 GFLOPS)
        (mlp): MLP(
          4.72 M = 5.5% Params, 309.24 GMACs = 4.54% MACs, 3.59 ms = 3.71% latency, 173.04 TFLOPS
          (c_fc): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.54 ms = 1.6% latency, 200.22 TFLOPS, in_features=768, out_features=3072, bias=False)
          (act_fn): GELU(0 = 0% Params, 0 MACs = 0% MACs, 7.64 ms = 7.9% latency, 316.27 GFLOPS, approximate='none')
          (c_proj): Linear(2.36 M = 2.75% Params, 154.62 GMACs = 2.27% MACs, 1.21 ms = 1.25% latency, 254.87 TFLOPS, in_features=3072, out_features=768, bias=False)
          (dropout): Dropout(0 = 0% Params, 0 MACs = 0% MACs, 23.37 us = 0.02% latency, 0 FLOPS, p=0.0, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm(768 = 0% Params, 0 MACs = 0% MACs, 361.2 us = 0.37% latency, 696.72 GFLOPS)
  )
  (lm_head): Linear(49.92 K = 0.06% Params, 3.27 GMACs = 0.05% MACs, 566.01 us = 0.59% latency, 11.56 TFLOPS, in_features=768, out_features=65, bias=False)
)
------------------------------------------------------------------------------
[2024-07-17 07:47:15,201] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2024-07-17 07:47:15,201] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.80 | bwd_microstep: 180.78 | bwd_inner_microstep: 178.00 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:15,201] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 0.00 | bwd: 0.00 | bwd_inner: 178.00 | bwd_allreduce: 2.74 | step: 0.00
[2024-07-17 07:47:15,489] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:15,490] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.17 | bwd_microstep: 180.90 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.29
[2024-07-17 07:47:15,490] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.16 | bwd: 180.89 | bwd_inner: 178.11 | bwd_allreduce: 2.74 | step: 3.30
[2024-07-17 07:47:15,778] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:15,779] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.82 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.53 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.32
[2024-07-17 07:47:15,779] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.82 | bwd: 181.30 | bwd_inner: 178.52 | bwd_allreduce: 2.74 | step: 3.33
[2024-07-17 07:47:16,067] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.84 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:16,067] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.90 | bwd_microstep: 180.98 | bwd_inner_microstep: 178.21 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.45
[2024-07-17 07:47:16,068] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.89 | bwd: 180.97 | bwd_inner: 178.21 | bwd_allreduce: 2.73 | step: 3.46
[2024-07-17 07:47:16,356] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:16,356] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.77 | bwd_microstep: 181.17 | bwd_inner_microstep: 178.41 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.48
[2024-07-17 07:47:16,357] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.77 | bwd: 181.15 | bwd_inner: 178.40 | bwd_allreduce: 2.72 | step: 3.49
[2024-07-17 07:47:16,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:16,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.97 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.55 | bwd_allreduce_microstep: 2.71 | step_microstep: 3.38
[2024-07-17 07:47:16,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.97 | bwd: 181.29 | bwd_inner: 178.54 | bwd_allreduce: 2.71 | step: 3.39
[2024-07-17 07:47:16,935] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:16,935] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.89 | bwd_microstep: 181.13 | bwd_inner_microstep: 178.35 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.32
[2024-07-17 07:47:16,935] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.88 | bwd: 181.12 | bwd_inner: 178.35 | bwd_allreduce: 2.74 | step: 3.33
[2024-07-17 07:47:17,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:17,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.74 | bwd_microstep: 180.88 | bwd_inner_microstep: 178.11 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.30
[2024-07-17 07:47:17,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.73 | bwd: 180.87 | bwd_inner: 178.10 | bwd_allreduce: 2.74 | step: 3.31
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:17.224916␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m10␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.350655␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.288187␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084324␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.184725␛[0m ␛[3;94msps␛[0m=␛[95m13␛[0m␛[95m.879891␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.469973␛[0m ␛[3;94mtps␛[0m=␛[95m909632␛[0m␛[95m.507695␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m227408␛[0m␛[95m.126924␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.428335␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:17,514] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:17,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[5.9999999999999995e-05, 5.9999999999999995e-05], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:17,515] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=889.4296529820815, CurrSamplesPerSec=889.5144800391016, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:17,515] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.81 | bwd_microstep: 181.27 | bwd_inner_microstep: 178.51 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.88
[2024-07-17 07:47:17,515] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.80 | bwd: 181.26 | bwd_inner: 178.51 | bwd_allreduce: 2.72 | step: 3.89
[2024-07-17 07:47:17,803] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:17,804] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.86 | bwd_microstep: 181.12 | bwd_inner_microstep: 178.36 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.25
[2024-07-17 07:47:17,804] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.85 | bwd: 181.11 | bwd_inner: 178.35 | bwd_allreduce: 2.73 | step: 3.26
[2024-07-17 07:47:18,097] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:18,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.73 | bwd_microstep: 180.80 | bwd_inner_microstep: 178.03 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.26
[2024-07-17 07:47:18,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.72 | bwd: 180.79 | bwd_inner: 178.03 | bwd_allreduce: 2.74 | step: 3.27
[2024-07-17 07:47:18,386] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:18,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.73 | bwd_microstep: 181.15 | bwd_inner_microstep: 178.39 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:47:18,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.73 | bwd: 181.14 | bwd_inner: 178.38 | bwd_allreduce: 2.73 | step: 3.33
[2024-07-17 07:47:18,676] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:18,676] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.40 | bwd_microstep: 182.22 | bwd_inner_microstep: 179.45 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.43
[2024-07-17 07:47:18,677] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.39 | bwd: 182.21 | bwd_inner: 179.44 | bwd_allreduce: 2.74 | step: 3.44
[2024-07-17 07:47:18,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:18,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.07 | bwd_microstep: 180.84 | bwd_inner_microstep: 178.07 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:47:18,966] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.06 | bwd: 180.83 | bwd_inner: 178.07 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:47:19,254] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:19,254] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.87 | bwd_microstep: 181.29 | bwd_inner_microstep: 178.52 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.30
[2024-07-17 07:47:19,254] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.86 | bwd: 181.28 | bwd_inner: 178.51 | bwd_allreduce: 2.74 | step: 3.31
[2024-07-17 07:47:19,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:19,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.98 | bwd_microstep: 181.08 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:47:19,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.97 | bwd: 181.07 | bwd_inner: 178.31 | bwd_allreduce: 2.73 | step: 3.33
[2024-07-17 07:47:19,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.67
[2024-07-17 07:47:19,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.93 | bwd_microstep: 181.10 | bwd_inner_microstep: 178.35 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.29
[2024-07-17 07:47:19,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.92 | bwd: 181.09 | bwd_inner: 178.34 | bwd_allreduce: 2.72 | step: 3.30
[2024-07-17 07:47:20,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:20,121] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.08 | bwd_microstep: 180.91 | bwd_inner_microstep: 178.13 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.36
[2024-07-17 07:47:20,121] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.07 | bwd: 180.90 | bwd_inner: 178.13 | bwd_allreduce: 2.74 | step: 3.37
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:20.122322␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m20␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.068224␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.288676␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084670␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.184845␛[0m ␛[3;94msps␛[0m=␛[95m13␛[0m␛[95m.856364␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.464091␛[0m ␛[3;94mtps␛[0m=␛[95m908090␛[0m␛[95m.678114␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m227022␛[0m␛[95m.669528␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.420635␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:20,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:20,412] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.00011999999999999999, 0.00011999999999999999], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:20,412] [INFO] [timer.py:260:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=888.4815701936816, CurrSamplesPerSec=889.3789118474871, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:20,413] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.95 | bwd_microstep: 181.20 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.82
[2024-07-17 07:47:20,413] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.94 | bwd: 181.19 | bwd_inner: 178.42 | bwd_allreduce: 2.74 | step: 3.83
[2024-07-17 07:47:20,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:20,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.97 | bwd_microstep: 181.34 | bwd_inner_microstep: 178.60 | bwd_allreduce_microstep: 2.71 | step_microstep: 3.31
[2024-07-17 07:47:20,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.96 | bwd: 181.34 | bwd_inner: 178.59 | bwd_allreduce: 2.71 | step: 3.32
[2024-07-17 07:47:20,962] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.83 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:20,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.25 | bwd_microstep: 181.98 | bwd_inner_microstep: 179.22 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.31
[2024-07-17 07:47:20,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.24 | bwd: 181.98 | bwd_inner: 179.22 | bwd_allreduce: 2.74 | step: 3.32
[2024-07-17 07:47:21,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:21,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.07 | bwd_microstep: 181.89 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 3.45 | step_microstep: 3.25
[2024-07-17 07:47:21,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.06 | bwd: 181.89 | bwd_inner: 178.42 | bwd_allreduce: 3.45 | step: 3.26
[2024-07-17 07:47:21,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:21,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.96 | bwd_microstep: 182.03 | bwd_inner_microstep: 179.12 | bwd_allreduce_microstep: 2.89 | step_microstep: 3.28
[2024-07-17 07:47:21,514] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.95 | bwd: 182.03 | bwd_inner: 179.12 | bwd_allreduce: 2.89 | step: 3.30
[2024-07-17 07:47:21,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:21,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.12 | bwd_microstep: 181.33 | bwd_inner_microstep: 178.18 | bwd_allreduce_microstep: 3.13 | step_microstep: 3.27
[2024-07-17 07:47:21,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.11 | bwd: 181.33 | bwd_inner: 178.18 | bwd_allreduce: 3.13 | step: 3.28
[2024-07-17 07:47:22,063] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:22,063] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.13 | bwd_microstep: 181.85 | bwd_inner_microstep: 178.45 | bwd_allreduce_microstep: 3.39 | step_microstep: 3.31
[2024-07-17 07:47:22,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.12 | bwd: 181.85 | bwd_inner: 178.45 | bwd_allreduce: 3.39 | step: 3.32
[2024-07-17 07:47:22,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.83 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:22,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.26 | bwd_microstep: 182.08 | bwd_inner_microstep: 179.33 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.31
[2024-07-17 07:47:22,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.25 | bwd: 182.08 | bwd_inner: 179.33 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:22,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:22,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.98 | bwd_microstep: 181.71 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 3.47 | step_microstep: 3.29
[2024-07-17 07:47:22,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.98 | bwd: 181.71 | bwd_inner: 178.23 | bwd_allreduce: 3.47 | step: 3.30
[2024-07-17 07:47:22,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:22,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.29 | bwd_microstep: 181.75 | bwd_inner_microstep: 179.00 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:47:22,890] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.28 | bwd: 181.75 | bwd_inner: 179.00 | bwd_allreduce: 2.74 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:22.890860␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m30␛[0m ␛[3;94mloss␛[0m=␛[95m2␛[0m␛[95m.795047␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.275275␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084835␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.188299␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.530946␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.632736␛[0m ␛[3;94mtps␛[0m=␛[95m952300␛[0m␛[95m.065479␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m238075␛[0m␛[95m.016370␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.634493␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:23,166] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:23,167] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.00017999999999999998, 0.00017999999999999998], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:23,167] [INFO] [timer.py:260:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=904.0902561092338, CurrSamplesPerSec=933.5846305802485, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:23,167] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.35 | bwd_microstep: 181.44 | bwd_inner_microstep: 178.69 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.74
[2024-07-17 07:47:23,168] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.34 | bwd: 181.44 | bwd_inner: 178.69 | bwd_allreduce: 2.73 | step: 3.76
[2024-07-17 07:47:23,442] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:23,442] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.11 | bwd_microstep: 181.67 | bwd_inner_microstep: 178.93 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:47:23,442] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.10 | bwd: 181.67 | bwd_inner: 178.93 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:47:23,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:23,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.27 | bwd_microstep: 181.36 | bwd_inner_microstep: 178.59 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.28
[2024-07-17 07:47:23,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.26 | bwd: 181.36 | bwd_inner: 178.59 | bwd_allreduce: 2.75 | step: 3.29
[2024-07-17 07:47:23,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:23,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.11 | bwd_microstep: 181.36 | bwd_inner_microstep: 178.14 | bwd_allreduce_microstep: 3.20 | step_microstep: 3.29
[2024-07-17 07:47:23,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.10 | bwd: 181.36 | bwd_inner: 178.14 | bwd_allreduce: 3.20 | step: 3.31
[2024-07-17 07:47:24,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:24,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.34 | bwd_microstep: 181.32 | bwd_inner_microstep: 178.57 | bwd_allreduce_microstep: 2.71 | step_microstep: 3.50
[2024-07-17 07:47:24,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.33 | bwd: 181.31 | bwd_inner: 178.57 | bwd_allreduce: 2.71 | step: 3.51
[2024-07-17 07:47:24,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:24,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.09 | bwd_microstep: 181.06 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:47:24,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.08 | bwd: 181.06 | bwd_inner: 178.31 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:24,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:24,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.04 | bwd_microstep: 181.98 | bwd_inner_microstep: 179.23 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:47:24,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.03 | bwd: 181.98 | bwd_inner: 179.23 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:47:25,106] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:25,106] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.10 | bwd_microstep: 181.62 | bwd_inner_microstep: 178.26 | bwd_allreduce_microstep: 3.34 | step_microstep: 3.29
[2024-07-17 07:47:25,107] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.10 | bwd: 181.62 | bwd_inner: 178.26 | bwd_allreduce: 3.34 | step: 3.31
[2024-07-17 07:47:25,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:25,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.33 | bwd_microstep: 181.84 | bwd_inner_microstep: 179.09 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:25,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.32 | bwd: 181.84 | bwd_inner: 179.09 | bwd_allreduce: 2.74 | step: 3.28
[2024-07-17 07:47:25,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:25,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.11 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.55 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.33
[2024-07-17 07:47:25,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.10 | bwd: 181.30 | bwd_inner: 178.55 | bwd_allreduce: 2.73 | step: 3.34
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:25.657876␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m40␛[0m ␛[3;94mloss␛[0m=␛[95m2␛[0m␛[95m.678048␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.274633␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084700␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187714␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.564918␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.641229␛[0m ␛[3;94mtps␛[0m=␛[95m954526␛[0m␛[95m.446888␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m238631␛[0m␛[95m.611722␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.838084␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:25,933] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:25,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.00023999999999999998, 0.00023999999999999998], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:25,934] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=910.5991244880666, CurrSamplesPerSec=933.8842522650399, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:25,934] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.15 | bwd_microstep: 181.49 | bwd_inner_microstep: 178.74 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.80
[2024-07-17 07:47:25,935] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.14 | bwd: 181.49 | bwd_inner: 178.74 | bwd_allreduce: 2.73 | step: 3.81
[2024-07-17 07:47:26,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:26,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.24 | bwd_microstep: 181.07 | bwd_inner_microstep: 178.30 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:47:26,223] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.23 | bwd: 181.06 | bwd_inner: 178.29 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:47:26,511] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:26,511] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.16 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:47:26,512] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.15 | bwd: 180.99 | bwd_inner: 178.23 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:47:26,805] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:26,805] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.99 | bwd_microstep: 180.71 | bwd_inner_microstep: 177.96 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.24
[2024-07-17 07:47:26,805] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.98 | bwd: 180.70 | bwd_inner: 177.95 | bwd_allreduce: 2.72 | step: 3.25
[2024-07-17 07:47:27,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:27,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.07 | bwd_microstep: 181.52 | bwd_inner_microstep: 178.75 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:47:27,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.07 | bwd: 181.51 | bwd_inner: 178.75 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:47:27,383] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:27,383] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.07 | bwd_microstep: 181.38 | bwd_inner_microstep: 178.62 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.27
[2024-07-17 07:47:27,383] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.06 | bwd: 181.37 | bwd_inner: 178.62 | bwd_allreduce: 2.72 | step: 3.28
[2024-07-17 07:47:27,666] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:27,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.12 | bwd_microstep: 181.32 | bwd_inner_microstep: 178.56 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:47:27,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.11 | bwd: 181.31 | bwd_inner: 178.56 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:27,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:27,951] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.38 | bwd_microstep: 181.32 | bwd_inner_microstep: 178.55 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.51
[2024-07-17 07:47:27,951] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.37 | bwd: 181.31 | bwd_inner: 178.55 | bwd_allreduce: 2.73 | step: 3.52
[2024-07-17 07:47:28,240] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:28,240] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.29 | bwd_microstep: 181.21 | bwd_inner_microstep: 178.43 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.34
[2024-07-17 07:47:28,241] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.28 | bwd: 181.20 | bwd_inner: 178.43 | bwd_allreduce: 2.74 | step: 3.35
[2024-07-17 07:47:28,531] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:28,532] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.26 | bwd_microstep: 186.63 | bwd_inner_microstep: 183.86 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.33
[2024-07-17 07:47:28,532] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.25 | bwd: 186.62 | bwd_inner: 183.85 | bwd_allreduce: 2.73 | step: 3.33
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:28.533659␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m50␛[0m ␛[3;94mloss␛[0m=␛[95m2␛[0m␛[95m.798814␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.291380␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084897␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.190538␛[0m ␛[3;94msps␛[0m=␛[95m13␛[0m␛[95m.727779␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.431945␛[0m ␛[3;94mtps␛[0m=␛[95m899663␛[0m␛[95m.740395␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m224915␛[0m␛[95m.935099␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.747323␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:28,812] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:28,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0003, 0.0003], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:28,813] [INFO] [timer.py:260:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=906.9290904683086, CurrSamplesPerSec=923.8523270500858, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:28,813] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.92 | bwd_microstep: 184.65 | bwd_inner_microstep: 181.90 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.89
[2024-07-17 07:47:28,814] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.91 | bwd: 184.65 | bwd_inner: 181.90 | bwd_allreduce: 2.74 | step: 3.90
[2024-07-17 07:47:29,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:29,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.17 | bwd_microstep: 181.37 | bwd_inner_microstep: 178.63 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:47:29,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.16 | bwd: 181.37 | bwd_inner: 178.63 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:29,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:29,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.08 | bwd_microstep: 181.31 | bwd_inner_microstep: 178.49 | bwd_allreduce_microstep: 2.80 | step_microstep: 3.29
[2024-07-17 07:47:29,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.08 | bwd: 181.31 | bwd_inner: 178.49 | bwd_allreduce: 2.80 | step: 3.30
[2024-07-17 07:47:29,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:29,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.34 | bwd_microstep: 181.22 | bwd_inner_microstep: 178.45 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.31
[2024-07-17 07:47:29,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.32 | bwd: 181.21 | bwd_inner: 178.44 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:29,923] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:29,923] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.28 | bwd_microstep: 181.93 | bwd_inner_microstep: 179.18 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:47:29,923] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.27 | bwd: 181.93 | bwd_inner: 179.18 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:47:30,197] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:30,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.04 | bwd_microstep: 181.18 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.92 | step_microstep: 3.35
[2024-07-17 07:47:30,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.03 | bwd: 181.18 | bwd_inner: 178.24 | bwd_allreduce: 2.92 | step: 3.36
[2024-07-17 07:47:30,472] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:30,473] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.97 | bwd_microstep: 181.86 | bwd_inner_microstep: 178.98 | bwd_allreduce_microstep: 2.86 | step_microstep: 3.31
[2024-07-17 07:47:30,473] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.96 | bwd: 181.86 | bwd_inner: 178.98 | bwd_allreduce: 2.86 | step: 3.32
[2024-07-17 07:47:30,747] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:30,748] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.33 | bwd_microstep: 181.18 | bwd_inner_microstep: 178.43 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:47:30,748] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.30 | bwd: 181.18 | bwd_inner: 178.43 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:47:31,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:31,023] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.20 | bwd_microstep: 181.52 | bwd_inner_microstep: 178.77 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:47:31,023] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.19 | bwd: 181.52 | bwd_inner: 178.77 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:47:31,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:31,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.29 | bwd_microstep: 181.91 | bwd_inner_microstep: 179.15 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:47:31,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.26 | bwd: 181.91 | bwd_inner: 179.15 | bwd_allreduce: 2.74 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:31.299744␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m60␛[0m ␛[3;94mloss␛[0m=␛[95m2␛[0m␛[95m.803483␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.275445␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084852␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.188247␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.521937␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.630484␛[0m ␛[3;94mtps␛[0m=␛[95m951709␛[0m␛[95m.666672␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m237927␛[0m␛[95m.416668␛[0m ␛[3;94mmfu␛[0m=␛[95m45␛[0m␛[95m.925564␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:31,574] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:31,575] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[0.00035999999999999997, 0.00035999999999999997], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:31,575] [INFO] [timer.py:260:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=911.0284113711489, CurrSamplesPerSec=936.8927156963773, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:31,575] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.83 | bwd_microstep: 180.93 | bwd_inner_microstep: 178.17 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.81
[2024-07-17 07:47:31,576] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.82 | bwd: 180.93 | bwd_inner: 178.17 | bwd_allreduce: 2.73 | step: 3.82
[2024-07-17 07:47:31,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:31,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.08 | bwd_microstep: 181.55 | bwd_inner_microstep: 178.80 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:47:31,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.07 | bwd: 181.55 | bwd_inner: 178.80 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:47:32,137] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:32,138] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.17 | bwd_microstep: 181.19 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.57
[2024-07-17 07:47:32,138] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.16 | bwd: 181.18 | bwd_inner: 178.41 | bwd_allreduce: 2.73 | step: 3.58
[2024-07-17 07:47:32,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:32,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.94 | bwd_microstep: 181.21 | bwd_inner_microstep: 178.46 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:47:32,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.94 | bwd: 181.21 | bwd_inner: 178.46 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:47:32,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:32,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.05 | bwd_microstep: 181.32 | bwd_inner_microstep: 178.57 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:47:32,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.05 | bwd: 181.32 | bwd_inner: 178.57 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:47:32,962] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:32,962] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.04 | bwd_microstep: 181.85 | bwd_inner_microstep: 178.27 | bwd_allreduce_microstep: 3.56 | step_microstep: 3.28
[2024-07-17 07:47:32,962] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.03 | bwd: 181.85 | bwd_inner: 178.27 | bwd_allreduce: 3.56 | step: 3.29
[2024-07-17 07:47:33,236] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:33,237] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.03 | bwd_microstep: 181.53 | bwd_inner_microstep: 178.58 | bwd_allreduce_microstep: 2.93 | step_microstep: 3.27
[2024-07-17 07:47:33,237] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.02 | bwd: 181.53 | bwd_inner: 178.58 | bwd_allreduce: 2.93 | step: 3.28
[2024-07-17 07:47:33,510] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:33,511] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.04 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.26
[2024-07-17 07:47:33,511] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.03 | bwd: 181.00 | bwd_inner: 178.23 | bwd_allreduce: 2.75 | step: 3.27
[2024-07-17 07:47:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.03 | bwd_microstep: 181.87 | bwd_inner_microstep: 178.58 | bwd_allreduce_microstep: 3.26 | step_microstep: 3.29
[2024-07-17 07:47:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.02 | bwd: 181.87 | bwd_inner: 178.58 | bwd_allreduce: 3.26 | step: 3.30
[2024-07-17 07:47:34,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:34,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.11 | bwd_microstep: 181.31 | bwd_inner_microstep: 178.57 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.30
[2024-07-17 07:47:34,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.10 | bwd: 181.31 | bwd_inner: 178.57 | bwd_allreduce: 2.72 | step: 3.31
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:34.062175␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m70␛[0m ␛[3;94mloss␛[0m=␛[95m2␛[0m␛[95m.958974␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.274689␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084710␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187573␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.561917␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.640479␛[0m ␛[3;94mtps␛[0m=␛[95m954329␛[0m␛[95m.787606␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m238582␛[0m␛[95m.446901␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.099065␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:34,337] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:34,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[0.00041999999999999996, 0.00041999999999999996], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:34,338] [INFO] [timer.py:260:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=913.8762775449933, CurrSamplesPerSec=935.8523961054299, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:34,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.98 | bwd_microstep: 181.06 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.86
[2024-07-17 07:47:34,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.97 | bwd: 181.06 | bwd_inner: 178.31 | bwd_allreduce: 2.74 | step: 3.87
[2024-07-17 07:47:34,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:34,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.93 | bwd_microstep: 181.19 | bwd_inner_microstep: 178.40 | bwd_allreduce_microstep: 2.77 | step_microstep: 3.32
[2024-07-17 07:47:34,613] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.91 | bwd: 181.19 | bwd_inner: 178.40 | bwd_allreduce: 2.77 | step: 3.32
[2024-07-17 07:47:34,887] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:34,887] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.02 | bwd_microstep: 181.48 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 3.34 | step_microstep: 3.26
[2024-07-17 07:47:34,887] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.01 | bwd: 181.48 | bwd_inner: 178.12 | bwd_allreduce: 3.34 | step: 3.27
[2024-07-17 07:47:35,161] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:35,162] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.01 | bwd_microstep: 181.09 | bwd_inner_microstep: 178.25 | bwd_allreduce_microstep: 2.83 | step_microstep: 3.31
[2024-07-17 07:47:35,162] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.99 | bwd: 181.09 | bwd_inner: 178.25 | bwd_allreduce: 2.83 | step: 3.32
[2024-07-17 07:47:35,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:35,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.97 | bwd_microstep: 181.41 | bwd_inner_microstep: 178.65 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.29
[2024-07-17 07:47:35,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.96 | bwd: 181.41 | bwd_inner: 178.65 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:47:35,710] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:35,710] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.95 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:35,711] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.94 | bwd: 180.99 | bwd_inner: 178.24 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:47:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.79 | bwd_microstep: 181.78 | bwd_inner_microstep: 178.51 | bwd_allreduce_microstep: 3.26 | step_microstep: 3.31
[2024-07-17 07:47:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.78 | bwd: 181.78 | bwd_inner: 178.51 | bwd_allreduce: 3.26 | step: 3.31
[2024-07-17 07:47:36,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:36,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.98 | bwd_microstep: 180.81 | bwd_inner_microstep: 178.05 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:47:36,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.97 | bwd: 180.80 | bwd_inner: 178.04 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:47:36,547] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:36,548] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.67 | bwd_microstep: 181.33 | bwd_inner_microstep: 178.57 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.26
[2024-07-17 07:47:36,548] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.66 | bwd: 181.33 | bwd_inner: 178.57 | bwd_allreduce: 2.74 | step: 3.27
[2024-07-17 07:47:36,821] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:36,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.66 | bwd_microstep: 181.08 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.26
[2024-07-17 07:47:36,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.66 | bwd: 181.08 | bwd_inner: 178.31 | bwd_allreduce: 2.75 | step: 3.27
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:36.823166␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m80␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.155790␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273945␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084245␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187372␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.601493␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.650373␛[0m ␛[3;94mtps␛[0m=␛[95m956923␛[0m␛[95m.428219␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239230␛[0m␛[95m.857055␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.268170␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:37,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:37,098] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[0.00047999999999999996, 0.00047999999999999996], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:37,098] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=916.0932308187823, CurrSamplesPerSec=936.585442102224, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:37,099] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.75 | bwd_microstep: 181.13 | bwd_inner_microstep: 178.38 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.77
[2024-07-17 07:47:37,099] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.74 | bwd: 181.13 | bwd_inner: 178.38 | bwd_allreduce: 2.73 | step: 3.79
[2024-07-17 07:47:37,373] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:37,373] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.65 | bwd_microstep: 181.33 | bwd_inner_microstep: 178.58 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:37,373] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.64 | bwd: 181.33 | bwd_inner: 178.58 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:47:37,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:37,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 181.37 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 3.04 | step_microstep: 3.29
[2024-07-17 07:47:37,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.37 | bwd_inner: 178.31 | bwd_allreduce: 3.04 | step: 3.30
[2024-07-17 07:47:37,921] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:37,921] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.80 | bwd_microstep: 181.27 | bwd_inner_microstep: 178.52 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.31
[2024-07-17 07:47:37,922] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.79 | bwd: 181.27 | bwd_inner: 178.52 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:47:38,195] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.81 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:38,195] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 181.04 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.78 | step_microstep: 3.33
[2024-07-17 07:47:38,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.04 | bwd_inner: 178.24 | bwd_allreduce: 2.78 | step: 3.34
[2024-07-17 07:47:38,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:38,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 180.89 | bwd_inner_microstep: 178.14 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.27
[2024-07-17 07:47:38,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.52 | bwd: 180.88 | bwd_inner: 178.13 | bwd_allreduce: 2.72 | step: 3.29
[2024-07-17 07:47:38,771] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.40 | optimizer_step: 0.68
[2024-07-17 07:47:38,771] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.54 | bwd_microstep: 186.29 | bwd_inner_microstep: 183.53 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.41
[2024-07-17 07:47:38,771] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.53 | bwd: 186.28 | bwd_inner: 183.52 | bwd_allreduce: 2.73 | step: 3.42
[2024-07-17 07:47:39,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:39,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.57 | bwd_microstep: 180.79 | bwd_inner_microstep: 178.02 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.35
[2024-07-17 07:47:39,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.56 | bwd: 180.78 | bwd_inner: 178.01 | bwd_allreduce: 2.73 | step: 3.36
[2024-07-17 07:47:39,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:39,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.42 | bwd_microstep: 180.89 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:39,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.41 | bwd: 180.88 | bwd_inner: 178.11 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:47:39,651] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:39,652] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.22 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:47:39,652] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.52 | bwd: 180.98 | bwd_inner: 178.21 | bwd_allreduce: 2.74 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:39.653095␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m90␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.250755␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.293544␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084111␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.184792␛[0m ␛[3;94msps␛[0m=␛[95m13␛[0m␛[95m.626575␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.406644␛[0m ␛[3;94mtps␛[0m=␛[95m893031␛[0m␛[95m.204005␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m223257␛[0m␛[95m.801001␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.101277␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
[2024-07-17 07:47:39,942] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:39,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[0.0005399999999999999, 0.0005399999999999999], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:47:39,942] [INFO] [timer.py:260:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=914.7108592543074, CurrSamplesPerSec=891.7314163418761, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:47:39,942] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.54 | bwd_microstep: 180.88 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.81
[2024-07-17 07:47:39,943] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.53 | bwd: 180.87 | bwd_inner: 178.12 | bwd_allreduce: 2.72 | step: 3.82
[2024-07-17 07:47:40,228] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:40,228] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.68 | bwd_microstep: 180.81 | bwd_inner_microstep: 178.06 | bwd_allreduce_microstep: 2.71 | step_microstep: 3.32
[2024-07-17 07:47:40,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.65 | bwd: 180.80 | bwd_inner: 178.06 | bwd_allreduce: 2.71 | step: 3.33
[2024-07-17 07:47:40,503] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:40,503] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.35 | bwd_microstep: 181.38 | bwd_inner_microstep: 178.61 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.33
[2024-07-17 07:47:40,503] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.34 | bwd: 181.37 | bwd_inner: 178.61 | bwd_allreduce: 2.74 | step: 3.34
[2024-07-17 07:47:40,777] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:40,777] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.66 | bwd_microstep: 180.98 | bwd_inner_microstep: 178.16 | bwd_allreduce_microstep: 2.80 | step_microstep: 3.32
[2024-07-17 07:47:40,777] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.65 | bwd: 180.98 | bwd_inner: 178.16 | bwd_allreduce: 2.80 | step: 3.33
[2024-07-17 07:47:41,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:41,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.49 | bwd_microstep: 181.17 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.31
[2024-07-17 07:47:41,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.48 | bwd: 181.17 | bwd_inner: 178.42 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:47:41,325] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:47:41,325] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 181.04 | bwd_inner_microstep: 178.09 | bwd_allreduce_microstep: 2.93 | step_microstep: 3.30
[2024-07-17 07:47:41,325] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.04 | bwd_inner: 178.09 | bwd_allreduce: 2.93 | step: 3.31
[2024-07-17 07:47:41,598] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:41,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.33 | bwd_microstep: 181.12 | bwd_inner_microstep: 178.37 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:47:41,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.32 | bwd: 181.12 | bwd_inner: 178.37 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:47:41,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:47:41,873] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.39 | bwd_microstep: 181.31 | bwd_inner_microstep: 178.10 | bwd_allreduce_microstep: 3.19 | step_microstep: 3.32
[2024-07-17 07:47:41,873] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.38 | bwd: 181.31 | bwd_inner: 178.10 | bwd_allreduce: 3.19 | step: 3.33
[2024-07-17 07:47:42,154] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:47:42,154] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.30 | bwd_microstep: 186.57 | bwd_inner_microstep: 183.80 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.38
[2024-07-17 07:47:42,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.29 | bwd: 186.56 | bwd_inner: 183.79 | bwd_allreduce: 2.74 | step: 3.38
[2024-07-17 07:47:42,428] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:47:42,428] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.34 | bwd_microstep: 180.96 | bwd_inner_microstep: 178.21 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:47:42,428] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.33 | bwd: 180.96 | bwd_inner: 178.21 | bwd_allreduce: 2.73 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:42.429672␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m100␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.267256␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273626␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.083996␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187215␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.618489␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.654622␛[0m ␛[3;94mtps␛[0m=␛[95m958037␛[0m␛[95m.314479␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239509␛[0m␛[95m.328620␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.275723␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m ␛[3;94mval_loss␛[0m=␛[95m0␛[0m␛[95m.000000␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:43.890742␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m820␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;92m'prompt'␛[0m␛[1;97m]␛[0m: ␛[3;92m'What is an LLM?'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:47:43.891469␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m824␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;92m'response'␛[0m␛[1;97m]␛[0m:

What is an LLM?rluua ho dey iyarit tr
osed
h dlostedosdmsrdetnu
t h
sh  shldrt d
rtnd m iarrthrnil 
e aeh oshhiooonl oo mtnay dlo dohnaa tiuattle

nhyesettr ttraso on oaseluaalosteidaeresaohoa sdn
soinru  e a
astil e ee  r  hatu ne ls e s
eer d esio  a ts ol  artoensn he
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:20.888956␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m760␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSaving checkpoint to: ␛[32m/home/foremans/tmp/polaris-talk/outputs/runs/pytorch/deepspeed/2024-07-17/␛[0m␛[35m07-47-05␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:20.889718␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m761␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mSaving model to: ␛[32m/home/foremans/tmp/polaris-talk/outputs/runs/pytorch/deepspeed/2024-07-17/07-47-05/␛[0m␛[35mmodel.pth␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:21.662588␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mconfigs␛[0m␛[94m:␛[0m␛[30m141␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0mAppending ␛[32m/home/foremans/tmp/polaris-talk/outputs/runs/pytorch/deepspeed/2024-07-17/␛[0m␛[35m07-47-05␛[0m to ␛[32m/home/foremans/tmp/polaris-talk/2024-07-17-073327/wordplay/src/ckpts/␛[0m␛[35mcheckpoints.log␛[0m
[2024-07-17 07:48:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.98 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0006, 0.0006], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:21,938] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=916.3309097944017, CurrSamplesPerSec=936.8722790142501, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:21,942] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 35769.54 | bwd_microstep: 181.11 | bwd_inner_microstep: 178.37 | bwd_allreduce_microstep: 2.72 | step_microstep: 4.29
[2024-07-17 07:48:21,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 35765.82 | bwd: 181.11 | bwd_inner: 178.37 | bwd_allreduce: 2.72 | step: 4.30
[2024-07-17 07:48:22,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:22,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.20 | bwd_microstep: 181.07 | bwd_inner_microstep: 178.30 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.31
[2024-07-17 07:48:22,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.18 | bwd: 181.06 | bwd_inner: 178.30 | bwd_allreduce: 2.74 | step: 3.32
[2024-07-17 07:48:22,512] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:22,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.14 | bwd_microstep: 185.01 | bwd_inner_microstep: 182.26 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.36
[2024-07-17 07:48:22,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.13 | bwd: 185.01 | bwd_inner: 182.26 | bwd_allreduce: 2.73 | step: 3.36
[2024-07-17 07:48:22,789] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:22,790] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.47 | bwd_microstep: 184.34 | bwd_inner_microstep: 181.59 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:48:22,790] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.46 | bwd: 184.34 | bwd_inner: 181.59 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:48:23,063] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:23,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.70 | bwd_microstep: 180.82 | bwd_inner_microstep: 178.07 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:48:23,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.69 | bwd: 180.82 | bwd_inner: 178.07 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:48:23,337] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:23,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 181.21 | bwd_inner_microstep: 178.27 | bwd_allreduce_microstep: 2.93 | step_microstep: 3.29
[2024-07-17 07:48:23,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.51 | bwd: 181.21 | bwd_inner: 178.27 | bwd_allreduce: 2.93 | step: 3.30
[2024-07-17 07:48:23,611] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.67
[2024-07-17 07:48:23,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.55 | bwd_microstep: 181.25 | bwd_inner_microstep: 178.50 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:23,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 181.25 | bwd_inner: 178.50 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:23,885] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:23,886] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.55 | bwd_microstep: 181.17 | bwd_inner_microstep: 178.41 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.29
[2024-07-17 07:48:23,886] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.53 | bwd: 181.17 | bwd_inner: 178.41 | bwd_allreduce: 2.74 | step: 3.30
[2024-07-17 07:48:24,173] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:24,174] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.62 | bwd_microstep: 181.29 | bwd_inner_microstep: 178.53 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:48:24,174] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.61 | bwd: 181.28 | bwd_inner: 178.52 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:48:24,447] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:24,448] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.39 | bwd_microstep: 181.13 | bwd_inner_microstep: 178.38 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:24,448] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.38 | bwd: 181.13 | bwd_inner: 178.38 | bwd_allreduce: 2.74 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:24.449187␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m110␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.268529␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273788␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084018␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187498␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.609868␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.652467␛[0m ␛[3;94mtps␛[0m=␛[95m957472␛[0m␛[95m.321813␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239368␛[0m␛[95m.080453␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.429903␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:24,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:24,724] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[0.0005999999996297664, 0.0005999999996297664], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:24,724] [INFO] [timer.py:260:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=917.2045962530959, CurrSamplesPerSec=937.1944648589767, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:24,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.42 | bwd_microstep: 181.25 | bwd_inner_microstep: 178.50 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.83
[2024-07-17 07:48:24,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.41 | bwd: 181.25 | bwd_inner: 178.49 | bwd_allreduce: 2.73 | step: 3.84
[2024-07-17 07:48:24,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:24,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.47 | bwd_microstep: 181.05 | bwd_inner_microstep: 178.29 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.27
[2024-07-17 07:48:24,999] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.46 | bwd: 181.05 | bwd_inner: 178.29 | bwd_allreduce: 2.75 | step: 3.28
[2024-07-17 07:48:25,272] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:25,272] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.44 | bwd_microstep: 181.18 | bwd_inner_microstep: 178.44 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:25,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.43 | bwd: 181.18 | bwd_inner: 178.44 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:25,546] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:25,546] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.41 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.26 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.29
[2024-07-17 07:48:25,546] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.40 | bwd: 181.00 | bwd_inner: 178.26 | bwd_allreduce: 2.72 | step: 3.30
[2024-07-17 07:48:25,820] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:25,820] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.58 | bwd_microstep: 181.18 | bwd_inner_microstep: 178.44 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:25,821] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.57 | bwd: 181.18 | bwd_inner: 178.44 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:48:26,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:26,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.61 | bwd_microstep: 180.89 | bwd_inner_microstep: 178.15 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.37
[2024-07-17 07:48:26,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.60 | bwd: 180.89 | bwd_inner: 178.15 | bwd_allreduce: 2.72 | step: 3.38
[2024-07-17 07:48:26,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:26,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.47 | bwd_microstep: 181.20 | bwd_inner_microstep: 178.45 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:26,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.47 | bwd: 181.20 | bwd_inner: 178.45 | bwd_allreduce: 2.74 | step: 3.28
[2024-07-17 07:48:26,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:26,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.41 | bwd_microstep: 180.81 | bwd_inner_microstep: 178.05 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:26,642] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.41 | bwd: 180.81 | bwd_inner: 178.05 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:48:26,915] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2466] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.48 | bwd_microstep: 181.02 | bwd_inner_microstep: 178.26 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.79
[2024-07-17 07:48:27,466] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.47 | bwd: 181.01 | bwd_inner: 178.26 | bwd_allreduce: 2.74 | step: 3.80
[2024-07-17 07:48:27,739] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:27,739] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.41 | bwd_microstep: 181.15 | bwd_inner_microstep: 178.40 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:27,740] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.39 | bwd: 181.15 | bwd_inner: 178.40 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:28,013] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.88 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:28,013] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.71 | bwd_microstep: 181.03 | bwd_inner_microstep: 178.29 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.41
[2024-07-17 07:48:28,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.70 | bwd: 181.03 | bwd_inner: 178.29 | bwd_allreduce: 2.73 | step: 3.42
[2024-07-17 07:48:28,294] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.83 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:28,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.61 | bwd_microstep: 181.27 | bwd_inner_microstep: 178.51 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:48:28,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.60 | bwd: 181.26 | bwd_inner: 178.50 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:48:28,588] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:28,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.40 | bwd_microstep: 186.52 | bwd_inner_microstep: 183.76 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.29
[2024-07-17 07:48:28,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.39 | bwd: 186.51 | bwd_inner: 183.76 | bwd_allreduce: 2.72 | step: 3.30
[2024-07-17 07:48:28,863] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:28,864] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.43 | bwd_microstep: 181.43 | bwd_inner_microstep: 178.64 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.47
[2024-07-17 07:48:28,864] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.42 | bwd: 181.41 | bwd_inner: 178.63 | bwd_allreduce: 2.74 | step: 3.47
[2024-07-17 07:48:29,137] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:29,138] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.39 | bwd_microstep: 181.16 | bwd_inner_microstep: 178.41 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.30
[2024-07-17 07:48:29,138] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.38 | bwd: 181.16 | bwd_inner: 178.41 | bwd_allreduce: 2.74 | step: 3.31
[2024-07-17 07:48:29,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:29,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.65 | bwd_microstep: 181.19 | bwd_inner_microstep: 178.43 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:29,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.64 | bwd: 181.19 | bwd_inner: 178.43 | bwd_allreduce: 2.74 | step: 3.30
[2024-07-17 07:48:29,685] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:29,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.35 | bwd_microstep: 181.13 | bwd_inner_microstep: 178.38 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:48:29,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.34 | bwd: 181.13 | bwd_inner: 178.38 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:29,959] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:29,959] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.52 | bwd_microstep: 180.89 | bwd_inner_microstep: 178.14 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:29,960] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.51 | bwd: 180.89 | bwd_inner: 178.14 | bwd_allreduce: 2.74 | step: 3.28
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:29.961068␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m130␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.291870␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273645␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084134␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187607␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.617496␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.654374␛[0m ␛[3;94mtps␛[0m=␛[95m957972␛[0m␛[95m.213636␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239493␛[0m␛[95m.053409␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.697313␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:30,242] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:30,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[0.0005999999966678979, 0.0005999999966678979], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:30,243] [INFO] [timer.py:260:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=919.4978055453124, CurrSamplesPerSec=915.386386790032, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:30,243] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.48 | bwd_microstep: 181.02 | bwd_inner_microstep: 178.26 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.86
[2024-07-17 07:48:30,244] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.47 | bwd: 181.01 | bwd_inner: 178.25 | bwd_allreduce: 2.73 | step: 3.87
[2024-07-17 07:48:30,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:30,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.65 | bwd_microstep: 181.29 | bwd_inner_microstep: 178.55 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.31
[2024-07-17 07:48:30,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.64 | bwd: 181.29 | bwd_inner: 178.55 | bwd_allreduce: 2.72 | step: 3.33
[2024-07-17 07:48:30,791] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:30,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.32 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.15 | bwd_allreduce_microstep: 3.14 | step_microstep: 3.45
[2024-07-17 07:48:30,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.31 | bwd: 181.30 | bwd_inner: 178.15 | bwd_allreduce: 3.14 | step: 3.46
[2024-07-17 07:48:31,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:31,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.37 | bwd_microstep: 181.21 | bwd_inner_microstep: 178.37 | bwd_allreduce_microstep: 2.83 | step_microstep: 3.27
[2024-07-17 07:48:31,066] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.36 | bwd: 181.21 | bwd_inner: 178.37 | bwd_allreduce: 2.83 | step: 3.28
[2024-07-17 07:48:31,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:31,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.56 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.56 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.28
[2024-07-17 07:48:31,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.56 | bwd: 181.30 | bwd_inner: 178.56 | bwd_allreduce: 2.72 | step: 3.29
[2024-07-17 07:48:31,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:31,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.47 | bwd_microstep: 182.26 | bwd_inner_microstep: 178.25 | bwd_allreduce_microstep: 3.99 | step_microstep: 3.28
[2024-07-17 07:48:31,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.46 | bwd: 182.26 | bwd_inner: 178.25 | bwd_allreduce: 3.99 | step: 3.29
[2024-07-17 07:48:31,888] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:31,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.52 | bwd_microstep: 181.37 | bwd_inner_microstep: 178.62 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.29
[2024-07-17 07:48:31,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.51 | bwd: 181.37 | bwd_inner: 178.62 | bwd_allreduce: 2.74 | step: 3.30
[2024-07-17 07:48:32,176] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:32,177] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.52 | bwd_microstep: 180.81 | bwd_inner_microstep: 178.04 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:48:32,177] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.51 | bwd: 180.80 | bwd_inner: 178.03 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:48:32,450] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:32,451] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.46 | bwd_microstep: 181.09 | bwd_inner_microstep: 178.32 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:32,451] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.45 | bwd: 181.08 | bwd_inner: 178.32 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:32,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:32,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.38 | bwd_microstep: 181.04 | bwd_inner_microstep: 178.29 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:32,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.37 | bwd: 181.04 | bwd_inner: 178.29 | bwd_allreduce: 2.73 | step: 3.30
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:32.726383␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m140␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.242165␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273809␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084003␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187512␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.608741␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.652185␛[0m ␛[3;94mtps␛[0m=␛[95m957398␛[0m␛[95m.466131␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239349␛[0m␛[95m.616533␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.808965␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:33,001] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:33,001] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[0.0005999999940762629, 0.0005999999940762629], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:33,002] [INFO] [timer.py:260:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=920.425678365925, CurrSamplesPerSec=937.5733574331906, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:33,002] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.37 | bwd_microstep: 181.20 | bwd_inner_microstep: 178.46 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.78
[2024-07-17 07:48:33,002] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.36 | bwd: 181.20 | bwd_inner: 178.46 | bwd_allreduce: 2.73 | step: 3.78
[2024-07-17 07:48:33,275] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:33,276] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.57 | bwd_microstep: 180.96 | bwd_inner_microstep: 178.21 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:48:33,276] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.56 | bwd: 180.96 | bwd_inner: 178.21 | bwd_allreduce: 2.73 | step: 3.27
[2024-07-17 07:48:33,549] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:33,550] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.36 | bwd_microstep: 181.42 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.99 | step_microstep: 3.28
[2024-07-17 07:48:33,550] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.34 | bwd: 181.42 | bwd_inner: 178.41 | bwd_allreduce: 2.99 | step: 3.28
[2024-07-17 07:48:33,823] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:33,823] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.44 | bwd_microstep: 180.81 | bwd_inner_microstep: 178.05 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:33,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.43 | bwd: 180.81 | bwd_inner: 178.05 | bwd_allreduce: 2.74 | step: 3.28
[2024-07-17 07:48:34,097] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:34,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.52 | bwd_microstep: 181.24 | bwd_inner_microstep: 178.50 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.38
[2024-07-17 07:48:34,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.50 | bwd: 181.24 | bwd_inner: 178.50 | bwd_allreduce: 2.73 | step: 3.39
[2024-07-17 07:48:34,371] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:34,371] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 180.96 | bwd_inner_microstep: 178.20 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:34,372] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.53 | bwd: 180.96 | bwd_inner: 178.20 | bwd_allreduce: 2.74 | step: 3.28
[2024-07-17 07:48:34,645] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:34,646] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.65 | bwd_microstep: 181.11 | bwd_inner_microstep: 178.36 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:34,646] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.64 | bwd: 181.11 | bwd_inner: 178.36 | bwd_allreduce: 2.74 | step: 3.27
[2024-07-17 07:48:34,919] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:34,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.43 | bwd_microstep: 181.20 | bwd_inner_microstep: 178.45 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:48:34,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.41 | bwd: 181.20 | bwd_inner: 178.45 | bwd_allreduce: 2.73 | step: 3.33
[2024-07-17 07:48:35,193] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:35,193] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.49 | bwd_microstep: 180.88 | bwd_inner_microstep: 178.13 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:35,194] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.48 | bwd: 180.88 | bwd_inner: 178.13 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:35,467] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:35,467] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 181.11 | bwd_inner_microstep: 178.36 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:35,468] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.11 | bwd_inner: 178.36 | bwd_allreduce: 2.73 | step: 3.29
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:35.468975␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m150␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.252073␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.274022␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084222␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187362␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.597348␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.649337␛[0m ␛[3;94mtps␛[0m=␛[95m956651␛[0m␛[95m.795693␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239162␛[0m␛[95m.948923␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.905723␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:35,743] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.67
[2024-07-17 07:48:35,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[0.0005999999907441608, 0.0005999999907441608], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:35,744] [INFO] [timer.py:260:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=921.5994910660538, CurrSamplesPerSec=938.489528605903, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:35,744] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.51 | bwd_microstep: 180.83 | bwd_inner_microstep: 178.09 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.76
[2024-07-17 07:48:35,744] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.50 | bwd: 180.83 | bwd_inner: 178.09 | bwd_allreduce: 2.73 | step: 3.78
[2024-07-17 07:48:36,017] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:36,018] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.33 | bwd_microstep: 180.94 | bwd_inner_microstep: 178.20 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.33
[2024-07-17 07:48:36,018] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.32 | bwd: 180.94 | bwd_inner: 178.20 | bwd_allreduce: 2.73 | step: 3.34
[2024-07-17 07:48:36,310] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:36,310] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.69 | bwd_microstep: 185.29 | bwd_inner_microstep: 182.52 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:36,311] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.68 | bwd: 185.28 | bwd_inner: 182.52 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:48:36,598] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:36,598] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.54 | bwd_microstep: 180.94 | bwd_inner_microstep: 178.16 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.50
[2024-07-17 07:48:36,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 180.93 | bwd_inner: 178.15 | bwd_allreduce: 2.75 | step: 3.51
[2024-07-17 07:48:36,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:36,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.61 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.34
[2024-07-17 07:48:36,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.60 | bwd: 180.98 | bwd_inner: 178.22 | bwd_allreduce: 2.73 | step: 3.34
[2024-07-17 07:48:37,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.67
[2024-07-17 07:48:37,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.74 | bwd_microstep: 180.90 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.31
[2024-07-17 07:48:37,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.73 | bwd: 180.89 | bwd_inner: 178.11 | bwd_allreduce: 2.75 | step: 3.32
[2024-07-17 07:48:37,459] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:37,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.65 | bwd_microstep: 181.25 | bwd_inner_microstep: 178.48 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:48:37,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.64 | bwd: 181.24 | bwd_inner: 178.48 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:48:37,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:37,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.46 | bwd_microstep: 181.17 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:37,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.46 | bwd: 181.17 | bwd_inner: 178.42 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:38,007] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:38,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.61 | bwd_microstep: 181.21 | bwd_inner_microstep: 178.47 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:38,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.60 | bwd: 181.21 | bwd_inner: 178.47 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:38,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:38,296] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.43 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.28
[2024-07-17 07:48:38,296] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.42 | bwd: 180.99 | bwd_inner: 178.24 | bwd_allreduce: 2.72 | step: 3.29
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:38.297089␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m160␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.262697␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.287927␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084057␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.184830␛[0m ␛[3;94msps␛[0m=␛[95m13␛[0m␛[95m.892415␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.473104␛[0m ␛[3;94mtps␛[0m=␛[95m910453␛[0m␛[95m.330012␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m227613␛[0m␛[95m.332503␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.762083␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:38,571] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:38,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[0.0005999999866715917, 0.0005999999866715917], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:38,572] [INFO] [timer.py:260:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=920.8195296892249, CurrSamplesPerSec=938.8431999692223, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:38,572] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.39 | bwd_microstep: 180.78 | bwd_inner_microstep: 178.03 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.80
[2024-07-17 07:48:38,573] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.38 | bwd: 180.78 | bwd_inner: 178.03 | bwd_allreduce: 2.73 | step: 3.81
[2024-07-17 07:48:38,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:38,846] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.58 | bwd_microstep: 180.93 | bwd_inner_microstep: 178.17 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.27
[2024-07-17 07:48:38,846] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.58 | bwd: 180.93 | bwd_inner: 178.17 | bwd_allreduce: 2.74 | step: 3.28
[2024-07-17 07:48:39,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:39,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.67 | bwd_microstep: 181.36 | bwd_inner_microstep: 178.61 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.30
[2024-07-17 07:48:39,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.66 | bwd: 181.36 | bwd_inner: 178.61 | bwd_allreduce: 2.72 | step: 3.31
[2024-07-17 07:48:39,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:39,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.55 | bwd_microstep: 181.09 | bwd_inner_microstep: 178.34 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:48:39,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 181.09 | bwd_inner: 178.34 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:48:39,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:39,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.49 | bwd_microstep: 181.16 | bwd_inner_microstep: 178.41 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:48:39,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.49 | bwd: 181.16 | bwd_inner: 178.41 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:48:39,941] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:39,941] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 180.86 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:39,942] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.52 | bwd: 180.86 | bwd_inner: 178.12 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:40,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:40,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.84 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.32
[2024-07-17 07:48:40,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.83 | bwd: 180.98 | bwd_inner: 178.23 | bwd_allreduce: 2.73 | step: 3.33
[2024-07-17 07:48:40,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:40,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.40 | bwd_microstep: 180.85 | bwd_inner_microstep: 178.07 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.32
[2024-07-17 07:48:40,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.39 | bwd: 180.84 | bwd_inner: 178.07 | bwd_allreduce: 2.74 | step: 3.33
[2024-07-17 07:48:40,791] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:40,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.52 | bwd_microstep: 180.83 | bwd_inner_microstep: 178.05 | bwd_allreduce_microstep: 2.76 | step_microstep: 3.42
[2024-07-17 07:48:40,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.51 | bwd: 180.83 | bwd_inner: 178.05 | bwd_allreduce: 2.76 | step: 3.44
[2024-07-17 07:48:41,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:41,066] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.50 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 2.76 | step_microstep: 3.30
[2024-07-17 07:48:41,066] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.49 | bwd: 181.00 | bwd_inner: 178.23 | bwd_allreduce: 2.76 | step: 3.33
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:41.067527␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m170␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.250784␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.274002␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084158␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187247␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.598438␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.649610␛[0m ␛[3;94mtps␛[0m=␛[95m956723␛[0m␛[95m.259904␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239180␛[0m␛[95m.814976␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.863886␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:41,342] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:41,342] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[0.0005999999818585554, 0.0005999999818585554], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:41,343] [INFO] [timer.py:260:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=921.2519794415686, CurrSamplesPerSec=937.425200975017, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:41,343] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.48 | bwd_microstep: 181.08 | bwd_inner_microstep: 178.33 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.88
[2024-07-17 07:48:41,343] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.47 | bwd: 181.08 | bwd_inner: 178.33 | bwd_allreduce: 2.73 | step: 3.89
[2024-07-17 07:48:41,617] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:41,617] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.69 | bwd_microstep: 181.03 | bwd_inner_microstep: 178.28 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:41,617] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.68 | bwd: 181.03 | bwd_inner: 178.28 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:48:41,891] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:41,891] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.42 | bwd_microstep: 181.19 | bwd_inner_microstep: 178.44 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:41,891] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.41 | bwd: 181.18 | bwd_inner: 178.44 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:42,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:42,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.64 | bwd_microstep: 186.25 | bwd_inner_microstep: 183.47 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.38
[2024-07-17 07:48:42,185] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.63 | bwd: 186.24 | bwd_inner: 183.47 | bwd_allreduce: 2.74 | step: 3.39
[2024-07-17 07:48:42,459] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:42,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.61 | bwd_microstep: 181.50 | bwd_inner_microstep: 178.74 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.44
[2024-07-17 07:48:42,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.60 | bwd: 181.49 | bwd_inner: 178.73 | bwd_allreduce: 2.72 | step: 3.44
[2024-07-17 07:48:42,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:42,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.72 | bwd_microstep: 181.35 | bwd_inner_microstep: 178.61 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.31
[2024-07-17 07:48:42,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.71 | bwd: 181.35 | bwd_inner: 178.61 | bwd_allreduce: 2.73 | step: 3.32
[2024-07-17 07:48:43,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:43,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.55 | bwd_microstep: 181.01 | bwd_inner_microstep: 178.26 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.27
[2024-07-17 07:48:43,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 181.01 | bwd_inner: 178.26 | bwd_allreduce: 2.73 | step: 3.28
[2024-07-17 07:48:43,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:43,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.74 | bwd_microstep: 181.30 | bwd_inner_microstep: 178.55 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.30
[2024-07-17 07:48:43,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.73 | bwd: 181.30 | bwd_inner: 178.55 | bwd_allreduce: 2.72 | step: 3.32
[2024-07-17 07:48:43,559] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:43,559] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.54 | bwd_microstep: 184.15 | bwd_inner_microstep: 181.40 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.33
[2024-07-17 07:48:43,559] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.53 | bwd: 184.15 | bwd_inner: 181.40 | bwd_allreduce: 2.73 | step: 3.34
[2024-07-17 07:48:43,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:43,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.32 | bwd_microstep: 180.97 | bwd_inner_microstep: 178.21 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.31
[2024-07-17 07:48:43,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.31 | bwd: 180.97 | bwd_inner: 178.21 | bwd_allreduce: 2.75 | step: 3.32
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:43.834167␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m180␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.233929␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273513␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.083949␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187379␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.624516␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.656129␛[0m ␛[3;94mtps␛[0m=␛[95m958432␛[0m␛[95m.253308␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239608␛[0m␛[95m.063327␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.964044␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:44,123] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:44,123] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[0.000599999976305052, 0.000599999976305052], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:44,124] [INFO] [timer.py:260:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=921.4542411482878, CurrSamplesPerSec=890.8546993513615, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:44,124] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 181.07 | bwd_inner_microstep: 178.31 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.85
[2024-07-17 07:48:44,124] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.06 | bwd_inner: 178.31 | bwd_allreduce: 2.72 | step: 3.86
[2024-07-17 07:48:44,399] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:44,399] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.66 | bwd_microstep: 181.29 | bwd_inner_microstep: 178.53 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.30
[2024-07-17 07:48:44,399] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.65 | bwd: 181.28 | bwd_inner: 178.53 | bwd_allreduce: 2.73 | step: 3.31
[2024-07-17 07:48:44,673] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:44,673] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.43 | bwd_microstep: 181.42 | bwd_inner_microstep: 178.67 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.32
[2024-07-17 07:48:44,673] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.42 | bwd: 181.42 | bwd_inner: 178.67 | bwd_allreduce: 2.73 | step: 3.33
[2024-07-17 07:48:44,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:44,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.75 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.75 | step_microstep: 3.30
[2024-07-17 07:48:44,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.74 | bwd: 181.01 | bwd_inner: 178.24 | bwd_allreduce: 2.75 | step: 3.30
[2024-07-17 07:48:45,221] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:45,221] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.53 | bwd_microstep: 181.17 | bwd_inner_microstep: 178.41 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:45,221] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.52 | bwd: 181.17 | bwd_inner: 178.41 | bwd_allreduce: 2.74 | step: 3.30
[2024-07-17 07:48:45,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:45,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.58 | bwd_microstep: 180.96 | bwd_inner_microstep: 178.19 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.31
[2024-07-17 07:48:45,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.57 | bwd: 180.96 | bwd_inner: 178.20 | bwd_allreduce: 2.74 | step: 3.32
[2024-07-17 07:48:45,769] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:45,769] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.48 | bwd_microstep: 181.79 | bwd_inner_microstep: 178.43 | bwd_allreduce_microstep: 3.34 | step_microstep: 3.30
[2024-07-17 07:48:45,770] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.47 | bwd: 181.79 | bwd_inner: 178.43 | bwd_allreduce: 3.34 | step: 3.31
[2024-07-17 07:48:46,043] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:46,044] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.63 | bwd_microstep: 181.31 | bwd_inner_microstep: 178.50 | bwd_allreduce_microstep: 2.79 | step_microstep: 3.36
[2024-07-17 07:48:46,044] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.62 | bwd: 181.31 | bwd_inner: 178.50 | bwd_allreduce: 2.79 | step: 3.36
[2024-07-17 07:48:46,317] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:46,317] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.47 | bwd_microstep: 181.00 | bwd_inner_microstep: 178.24 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.28
[2024-07-17 07:48:46,318] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.46 | bwd: 181.00 | bwd_inner: 178.24 | bwd_allreduce: 2.73 | step: 3.29
[2024-07-17 07:48:46,591] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.84 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:46,591] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.56 | bwd_microstep: 181.24 | bwd_inner_microstep: 178.49 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.39
[2024-07-17 07:48:46,592] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 181.24 | bwd_inner: 178.49 | bwd_allreduce: 2.73 | step: 3.40
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:46.592996␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m190␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.225155␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.274166␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084157␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187567␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.589724␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.647431␛[0m ␛[3;94mtps␛[0m=␛[95m956152␛[0m␛[95m.166549␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239038␛[0m␛[95m.041637␛[0m ␛[3;94mmfu␛[0m=␛[95m47␛[0m␛[95m.042799␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:46,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[0.0005999999700110816, 0.0005999999700110816], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:46,868] [INFO] [timer.py:260:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=922.2692748995811, CurrSamplesPerSec=937.5987369935837, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.60 | bwd_microstep: 180.96 | bwd_inner_microstep: 178.22 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.81
[2024-07-17 07:48:46,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 180.96 | bwd_inner: 178.22 | bwd_allreduce: 2.72 | step: 3.82
[2024-07-17 07:48:47,141] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:47,142] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.38 | bwd_microstep: 181.12 | bwd_inner_microstep: 178.37 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:47,142] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.37 | bwd: 181.12 | bwd_inner: 178.37 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:47,415] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:47,416] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.64 | bwd_microstep: 181.05 | bwd_inner_microstep: 178.12 | bwd_allreduce_microstep: 2.91 | step_microstep: 3.32
[2024-07-17 07:48:47,416] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.63 | bwd: 181.05 | bwd_inner: 178.12 | bwd_allreduce: 2.91 | step: 3.33
[2024-07-17 07:48:47,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.38 | optimizer_step: 0.69
[2024-07-17 07:48:47,690] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.62 | bwd_microstep: 181.19 | bwd_inner_microstep: 178.44 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.31
[2024-07-17 07:48:47,690] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.61 | bwd: 181.19 | bwd_inner: 178.44 | bwd_allreduce: 2.74 | step: 3.32
[2024-07-17 07:48:47,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:47,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.59 | bwd_microstep: 181.49 | bwd_inner_microstep: 178.61 | bwd_allreduce_microstep: 2.86 | step_microstep: 3.28
[2024-07-17 07:48:47,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.59 | bwd: 181.49 | bwd_inner: 178.61 | bwd_allreduce: 2.86 | step: 3.30
[2024-07-17 07:48:48,251] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:48,251] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.45 | bwd_microstep: 180.94 | bwd_inner_microstep: 178.18 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.34
[2024-07-17 07:48:48,251] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.44 | bwd: 180.93 | bwd_inner: 178.18 | bwd_allreduce: 2.73 | step: 3.35
[2024-07-17 07:48:48,524] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:48,525] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.43 | bwd_microstep: 180.99 | bwd_inner_microstep: 178.23 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.32
[2024-07-17 07:48:48,525] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.42 | bwd: 180.99 | bwd_inner: 178.23 | bwd_allreduce: 2.74 | step: 3.34
[2024-07-17 07:48:48,798] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:48,799] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.56 | bwd_microstep: 181.27 | bwd_inner_microstep: 178.52 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.29
[2024-07-17 07:48:48,799] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.55 | bwd: 181.27 | bwd_inner: 178.52 | bwd_allreduce: 2.73 | step: 3.30
[2024-07-17 07:48:49,072] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.69
[2024-07-17 07:48:49,073] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.49 | bwd_microstep: 181.10 | bwd_inner_microstep: 178.04 | bwd_allreduce_microstep: 3.04 | step_microstep: 3.31
[2024-07-17 07:48:49,073] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.49 | bwd: 181.10 | bwd_inner: 178.04 | bwd_allreduce: 3.04 | step: 3.32
[2024-07-17 07:48:49,346] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:49,346] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.40 | bwd_microstep: 181.15 | bwd_inner_microstep: 178.42 | bwd_allreduce_microstep: 2.72 | step_microstep: 3.28
[2024-07-17 07:48:49,347] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.39 | bwd: 181.15 | bwd_inner: 178.42 | bwd_allreduce: 2.72 | step: 3.29
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:49.347919␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m200␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.237496␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273764␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.083984␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187309␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.611123␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.652781␛[0m ␛[3;94mtps␛[0m=␛[95m957554␛[0m␛[95m.528072␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239388␛[0m␛[95m.632018␛[0m ␛[3;94mmfu␛[0m=␛[95m47␛[0m␛[95m.120682␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:50.658590␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m820␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;92m'prompt'␛[0m␛[1;97m]␛[0m: ␛[3;92m'What is an LLM?'␛[0m
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:50.659230␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m824␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[1;97m[␛[0m␛[3;92m'response'␛[0m␛[1;97m]␛[0m:

What is an LLM?e  l
diosa
h 

tasi
aesyeraa as oeiry  nhe o md ts enntn,dr rooetr
oettoeo iiishneon,e  oe eeir
 lhion a   w  hon  led  rrhso wtinht sltttouelteyoht hrenio daoreoa,
i oi
ihara  d tade re doh l
o,
eeo hs hra  het noirin ha iooseo aeo
ult niliti lr  nt ihd d024-07-17 07:48:26,915] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.30 | bwd_microstep: 181.10 | bwd_inner_microstep: 178.35 | bwd_allreduce_microstep: 2.74 | step_microstep: 3.28
[2024-07-17 07:48:26,915] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.30 | bwd: 181.10 | bwd_inner: 178.35 | bwd_allreduce: 2.74 | step: 3.29
[2024-07-17 07:48:27,189] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 0.38 | optimizer_step: 0.68
[2024-07-17 07:48:27,189] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 88.55 | bwd_microstep: 180.93 | bwd_inner_microstep: 178.19 | bwd_allreduce_microstep: 2.73 | step_microstep: 3.26
[2024-07-17 07:48:27,189] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 88.54 | bwd: 180.93 | bwd_inner: 178.19 | bwd_allreduce: 2.73 | step: 3.27
␛[30m[␛[0m␛[30m2024-07-17 ␛[0m␛[90m07:48:27.190389␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[1;32mINFO␛[0m␛[30m]␛[0m␛[30m[␛[0m␛[3;34mtrainer␛[0m␛[94m:␛[0m␛[30m885␛[0m␛[30m]␛[0m␛[1;38;2;131;131;131m - ␛[0m␛[3;94mstep␛[0m=␛[95m120␛[0m ␛[3;94mloss␛[0m=␛[95m3␛[0m␛[95m.260242␛[0m ␛[3;94mdt␛[0m=␛[95m0␛[0m␛[95m.273707␛[0m ␛[3;94mdtf␛[0m=␛[95m0␛[0m␛[95m.084185␛[0m ␛[3;94mdtb␛[0m=␛[95m0␛[0m␛[95m.187241␛[0m ␛[3;94msps␛[0m=␛[95m14␛[0m␛[95m.614162␛[0m ␛[3;94msps_per_gpu␛[0m=␛[95m3␛[0m␛[95m.653541␛[0m ␛[3;94mtps␛[0m=␛[95m957753␛[0m␛[95m.750640␛[0m ␛[3;94mtps_per_gpu␛[0m=␛[95m239438␛[0m␛[95m.437660␛[0m ␛[3;94mmfu␛[0m=␛[95m46␛[0m␛[95m.570071␛[0m ␛[3;94mtrain_loss␛[0m=␛[95m3␛[0m␛[95m.263901␛[0m ␛[3;94mval_loss␛[0m=␛[95m3␛[0m␛[95m.294297␛[0m
[2024-07-17 07:48:27,465] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 0.39 | optimizer_step: 0.68
[2024-07-17 07:48:27,465] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[0.0005999999985190656, 0.0005999999985190656], mom=[(0.9, 0.95), (0.9, 0.95)]
[2024-07-17 07:48:27,465] [INFO] [timer.py:260:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=918.9535257542127, CurrSamplesPerSec=937.9173263802448, MemAllocated=0.43GB, MaxMemAllocated=22.48GB
[2024-07-17 07:48:27,
```
