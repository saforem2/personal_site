<!--
```{pyodide}
import micropip as mp
await mp.install("seaborn")
await mp.install("pandas")
await mp.install("https://github.com/saforem2/ambivalent")
```
-->

::: {.callout-tip icon=false title='üî• What I Work on' collapse="true" style="text-align: left!important; background-color:rgba(131,131,131,0.05)!important; border: 1px solid rgba(131,131,131,0.0); width: calc(100% - 2pt)!important; opacity:100%;"}

As a member of the [AI / ML Group](https://www.alcf.anl.gov/about/people/group/506) at
[ALCF](https://alcf.anl.gov), I work on:

::: {.flex-container}

::: {.flex-container}

- ü§ñ üß™ [AI + Science](https://github.com/saforem2/)

- üé≤ [Building better sampling methods for Lattice QCD](https://github.com/saforem2/l2hmc-qcd)

- üß¨ [Genome-Scale Language Models](https://www.biorxiv.org/content/10.1101/2022.10.10.511571v2)

    - [{{< iconify logos github-octocat >}} GenSLM](https://github.com/ramanathanlab/genslm)

    - ü•á [ACM Gordon Bell Special Prize](https://www.acm.org/media-center/2022/november/gordon-bell-special-prize-covid-research-2022)

:::

::: {.flex-container}

- üåç [Foundation models for long term climate forecasting](https://saforem2.github.io/climate-analysis)

- üèÉ‚Äç‚ôÇÔ∏è [Scaling Large Language Models](https://github.com/argonne-lcf/Megatron-DeepSpeed)

- üèéÔ∏è [Distributed training across thousands of GPUs](https://github.com/argonne-lcf/mlprof)

:::

:::

:::

::: {.callout-tip icon=false title='üìç How I got here' collapse="true" style="text-align: left!important; background-color:rgba(131,131,131,0.05)!important; border: 1px solid rgba(131,131,131,0.0); width: calc(100% - 2pt)!important; opacity:100%;"}

  [NOTE: Update the **NEW** text below !!]: #

  My [current research](https://saforem2.github.io/l2hmc-qcd) focuses on
  using deep generative modeling to help build better sampling algorithms
  in lattice gauge theory. In particular, I'm interested in building gauge
  equivariant neural network architectures and using inductive priors to
  incorporate physical symmetries into machine learning models.

  <br>

  I received my PhD in Physics from the University of Iowa in 2019 and my
  thesis was on
  [Learning Better Physics: A Machine Learning Approach to Lattice Gauge Theory](https://iro.uiowa.edu/esploro/outputs/doctoral/Learning-better-physics-a-machine-learning/9983776792002771).

  <br>

  Prior to this, I completed two bachelors degrees (Engineering Physics and
  Applied Mathematics, 2015) at The University of Illinois at
  Urbana-Champaign. My undergraduate dissertation was titled 
  [Energy Storage in Quantum Resonators](https://aip.scitation.org/doi/10.1063/1.5009698)
  and was
  supervised by Professor 
  [Alfred H√ºbler](https://en.wikipedia.org/wiki/Alfred_H%C3%BCbler)
  within the Center for Complex Systems Research at UIUC.

  This work ultimately resulted in a [patent](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vV_1zDwAAAAJ&pagesize=80&citation_for_view=vV_1zDwAAAAJ:SeFeTyx0c_EC) !!

  <!-- </details> -->
:::

